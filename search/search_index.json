{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":""},{"location":"#getting-started-with-pyiceberg","title":"Getting started with PyIceberg","text":"<p>PyIceberg is a Python implementation for accessing Iceberg tables, without the need of a JVM.</p>"},{"location":"#installation","title":"Installation","text":"<p>Before installing PyIceberg, make sure that you're on an up-to-date version of <code>pip</code>:</p> <pre><code>pip install --upgrade pip\n</code></pre> <p>You can install the latest release version from pypi:</p> <pre><code>pip install \"pyiceberg[s3fs,hive]\"\n</code></pre> <p>You can mix and match optional dependencies depending on your needs:</p> Key Description: hive Support for the Hive metastore glue Support for AWS Glue dynamodb Support for AWS DynamoDB sql-postgres Support for SQL Catalog backed by Postgresql sql-sqlite Support for SQL Catalog backed by SQLite pyarrow PyArrow as a FileIO implementation to interact with the object store pandas Installs both PyArrow and Pandas duckdb Installs both PyArrow and DuckDB ray Installs PyArrow, Pandas, and Ray daft Installs Daft s3fs S3FS as a FileIO implementation to interact with the object store adlfs ADLFS as a FileIO implementation to interact with the object store snappy Support for snappy Avro compression gcsfs GCSFS as a FileIO implementation to interact with the object store <p>You either need to install <code>s3fs</code>, <code>adlfs</code>, <code>gcsfs</code>, or <code>pyarrow</code> to be able to fetch files from an object store.</p>"},{"location":"#connecting-to-a-catalog","title":"Connecting to a catalog","text":"<p>Iceberg leverages the catalog to have one centralized place to organize the tables. This can be a traditional Hive catalog to store your Iceberg tables next to the rest, a vendor solution like the AWS Glue catalog, or an implementation of Icebergs' own REST protocol. Checkout the configuration page to find all the configuration details.</p> <p>For the sake of demonstration, we'll configure the catalog to use the <code>SqlCatalog</code> implementation, which will store information in a local <code>sqlite</code> database. We'll also configure the catalog to store data files in the local filesystem instead of an object store. This should not be used in production due to the limited scalability.</p> <p>Create a temporary location for Iceberg:</p> <pre><code>mkdir /tmp/warehouse\n</code></pre> <p>Open a Python 3 REPL to set up the catalog:</p> <pre><code>from pyiceberg.catalog.sql import SqlCatalog\n\nwarehouse_path = \"/tmp/warehouse\"\ncatalog = SqlCatalog(\n    \"default\",\n    **{\n        \"uri\": f\"sqlite:///{warehouse_path}/pyiceberg_catalog.db\",\n        \"warehouse\": f\"file://{warehouse_path}\",\n    },\n)\n</code></pre>"},{"location":"#write-a-pyarrow-dataframe","title":"Write a PyArrow dataframe","text":"<p>Let's take the Taxi dataset, and write this to an Iceberg table.</p> <p>First download one month of data:</p> <pre><code>curl https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet -o /tmp/yellow_tripdata_2023-01.parquet\n</code></pre> <p>Load it into your PyArrow dataframe:</p> <pre><code>import pyarrow.parquet as pq\n\ndf = pq.read_table(\"/tmp/yellow_tripdata_2023-01.parquet\")\n</code></pre> <p>Create a new Iceberg table:</p> <pre><code>catalog.create_namespace(\"default\")\n\ntable = catalog.create_table(\n    \"default.taxi_dataset\",\n    schema=df.schema,\n)\n</code></pre> <p>Append the dataframe to the table:</p> <pre><code>table.append(df)\nlen(table.scan().to_arrow())\n</code></pre> <p>3066766 rows have been written to the table.</p> <p>Now generate a tip-per-mile feature to train the model on:</p> <pre><code>import pyarrow.compute as pc\n\ndf = df.append_column(\"tip_per_mile\", pc.divide(df[\"tip_amount\"], df[\"trip_distance\"]))\n</code></pre> <p>Evolve the schema of the table with the new column:</p> <pre><code>with table.update_schema() as update_schema:\n    update_schema.union_by_name(df.schema)\n</code></pre> <p>And now we can write the new dataframe to the Iceberg table:</p> <pre><code>table.overwrite(df)\nprint(table.scan().to_arrow())\n</code></pre> <p>And the new column is there:</p> <pre><code>taxi_dataset(\n  1: VendorID: optional long,\n  2: tpep_pickup_datetime: optional timestamp,\n  3: tpep_dropoff_datetime: optional timestamp,\n  4: passenger_count: optional double,\n  5: trip_distance: optional double,\n  6: RatecodeID: optional double,\n  7: store_and_fwd_flag: optional string,\n  8: PULocationID: optional long,\n  9: DOLocationID: optional long,\n  10: payment_type: optional long,\n  11: fare_amount: optional double,\n  12: extra: optional double,\n  13: mta_tax: optional double,\n  14: tip_amount: optional double,\n  15: tolls_amount: optional double,\n  16: improvement_surcharge: optional double,\n  17: total_amount: optional double,\n  18: congestion_surcharge: optional double,\n  19: airport_fee: optional double,\n  20: tip_per_mile: optional double\n),\n</code></pre> <p>And we can see that 2371784 rows have a tip-per-mile:</p> <pre><code>df = table.scan(row_filter=\"tip_per_mile &gt; 0\").to_arrow()\nlen(df)\n</code></pre>"},{"location":"#explore-iceberg-data-and-metadata-files","title":"Explore Iceberg data and metadata files","text":"<p>Since the catalog was configured to use the local filesystem, we can explore how Iceberg saved data and metadata files from the above operations.</p> <pre><code>find /tmp/warehouse/\n</code></pre>"},{"location":"#more-details","title":"More details","text":"<p>For the details, please check the CLI or Python API page.</p>"},{"location":"SUMMARY/","title":"SUMMARY","text":"<ul> <li>Getting started</li> <li>Configuration</li> <li>CLI</li> <li>API</li> <li>Contributing</li> <li>Community</li> <li>Releases<ul> <li>Verify a release</li> <li>How to release</li> </ul> </li> <li>Code Reference</li> </ul>"},{"location":"api/","title":"API","text":""},{"location":"api/#python-api","title":"Python API","text":"<p>PyIceberg is based around catalogs to load tables. First step is to instantiate a catalog that loads tables. Let's use the following configuration to define a catalog called <code>prod</code>:</p> <pre><code>catalog:\n  prod:\n    uri: http://rest-catalog/ws/\n    credential: t-1234:secret\n</code></pre> <p>Note that multiple catalogs can be defined in the same <code>.pyiceberg.yaml</code>:</p> <pre><code>catalog:\n  hive:\n    uri: thrift://127.0.0.1:9083\n    s3.endpoint: http://127.0.0.1:9000\n    s3.access-key-id: admin\n    s3.secret-access-key: password\n  rest:\n    uri: https://rest-server:8181/\n    warehouse: my-warehouse\n</code></pre> <p>and loaded in python by calling <code>load_catalog(name=\"hive\")</code> and <code>load_catalog(name=\"rest\")</code>.</p> <p>This information must be placed inside a file called <code>.pyiceberg.yaml</code> located either in the <code>$HOME</code> or <code>%USERPROFILE%</code> directory (depending on whether the operating system is Unix-based or Windows-based, respectively) or in the <code>$PYICEBERG_HOME</code> directory (if the corresponding environment variable is set).</p> <p>For more details on possible configurations refer to the specific page.</p> <p>Then load the <code>prod</code> catalog:</p> <pre><code>from pyiceberg.catalog import load_catalog\n\ncatalog = load_catalog(\n    \"docs\",\n    **{\n        \"uri\": \"http://127.0.0.1:8181\",\n        \"s3.endpoint\": \"http://127.0.0.1:9000\",\n        \"py-io-impl\": \"pyiceberg.io.pyarrow.PyArrowFileIO\",\n        \"s3.access-key-id\": \"admin\",\n        \"s3.secret-access-key\": \"password\",\n    }\n)\n</code></pre> <p>Let's create a namespace:</p> <pre><code>catalog.create_namespace(\"docs_example\")\n</code></pre> <p>And then list them:</p> <pre><code>ns = catalog.list_namespaces()\n\nassert ns == [(\"docs_example\",)]\n</code></pre> <p>And then list tables in the namespace:</p> <pre><code>catalog.list_tables(\"docs_example\")\n</code></pre>"},{"location":"api/#create-a-table","title":"Create a table","text":"<p>To create a table from a catalog:</p> <pre><code>from pyiceberg.schema import Schema\nfrom pyiceberg.types import (\n    TimestampType,\n    FloatType,\n    DoubleType,\n    StringType,\n    NestedField,\n    StructType,\n)\n\nschema = Schema(\n    NestedField(field_id=1, name=\"datetime\", field_type=TimestampType(), required=True),\n    NestedField(field_id=2, name=\"symbol\", field_type=StringType(), required=True),\n    NestedField(field_id=3, name=\"bid\", field_type=FloatType(), required=False),\n    NestedField(field_id=4, name=\"ask\", field_type=DoubleType(), required=False),\n    NestedField(\n        field_id=5,\n        name=\"details\",\n        field_type=StructType(\n            NestedField(\n                field_id=4, name=\"created_by\", field_type=StringType(), required=False\n            ),\n        ),\n        required=False,\n    ),\n)\n\nfrom pyiceberg.partitioning import PartitionSpec, PartitionField\nfrom pyiceberg.transforms import DayTransform\n\npartition_spec = PartitionSpec(\n    PartitionField(\n        source_id=1, field_id=1000, transform=DayTransform(), name=\"datetime_day\"\n    )\n)\n\nfrom pyiceberg.table.sorting import SortOrder, SortField\nfrom pyiceberg.transforms import IdentityTransform\n\n# Sort on the symbol\nsort_order = SortOrder(SortField(source_id=2, transform=IdentityTransform()))\n\ncatalog.create_table(\n    identifier=\"docs_example.bids\",\n    schema=schema,\n    location=\"s3://pyiceberg\",\n    partition_spec=partition_spec,\n    sort_order=sort_order,\n)\n</code></pre> <p>To create a table using a pyarrow schema:</p> <pre><code>import pyarrow as pa\n\nschema = pa.schema(\n    [\n        pa.field(\"foo\", pa.string(), nullable=True),\n        pa.field(\"bar\", pa.int32(), nullable=False),\n        pa.field(\"baz\", pa.bool_(), nullable=True),\n    ]\n)\n\ncatalog.create_table(\n    identifier=\"docs_example.bids\",\n    schema=schema,\n)\n</code></pre>"},{"location":"api/#load-a-table","title":"Load a table","text":""},{"location":"api/#catalog-table","title":"Catalog table","text":"<p>Loading the <code>bids</code> table:</p> <pre><code>table = catalog.load_table(\"docs_example.bids\")\n# Equivalent to:\ntable = catalog.load_table((\"docs_example\", \"bids\"))\n# The tuple syntax can be used if the namespace or table contains a dot.\n</code></pre> <p>This returns a <code>Table</code> that represents an Iceberg table that can be queried and altered.</p>"},{"location":"api/#static-table","title":"Static table","text":"<p>To load a table directly from a metadata file (i.e., without using a catalog), you can use a <code>StaticTable</code> as follows:</p> <pre><code>from pyiceberg.table import StaticTable\n\nstatic_table = StaticTable.from_metadata(\n    \"s3://warehouse/wh/nyc.db/taxis/metadata/00002-6ea51ce3-62aa-4197-9cf8-43d07c3440ca.metadata.json\"\n)\n</code></pre> <p>The static-table is considered read-only.</p>"},{"location":"api/#write-support","title":"Write support","text":"<p>With PyIceberg 0.6.0 write support is added through Arrow. Let's consider an Arrow Table:</p> <pre><code>import pyarrow as pa\n\ndf = pa.Table.from_pylist(\n    [\n        {\"city\": \"Amsterdam\", \"lat\": 52.371807, \"long\": 4.896029},\n        {\"city\": \"San Francisco\", \"lat\": 37.773972, \"long\": -122.431297},\n        {\"city\": \"Drachten\", \"lat\": 53.11254, \"long\": 6.0989},\n        {\"city\": \"Paris\", \"lat\": 48.864716, \"long\": 2.349014},\n    ],\n)\n</code></pre> <p>Next, create a table based on the schema:</p> <pre><code>from pyiceberg.catalog import load_catalog\n\ncatalog = load_catalog(\"default\")\n\nfrom pyiceberg.schema import Schema\nfrom pyiceberg.types import NestedField, StringType, DoubleType\n\nschema = Schema(\n    NestedField(1, \"city\", StringType(), required=False),\n    NestedField(2, \"lat\", DoubleType(), required=False),\n    NestedField(3, \"long\", DoubleType(), required=False),\n)\n\ntbl = catalog.create_table(\"default.cities\", schema=schema)\n</code></pre> <p>Now write the data to the table:</p> <p>Fast append</p> <p>PyIceberg default to the fast append to minimize the amount of data written. This enables quick writes, reducing the possibility of conflicts. The downside of the fast append is that it creates more metadata than a normal commit. Compaction is planned and will automatically rewrite all the metadata when a threshold is hit, to maintain performant reads.</p> <pre><code>tbl.append(df)\n\n# or\n\ntbl.overwrite(df)\n</code></pre> <p>The data is written to the table, and when the table is read using <code>tbl.scan().to_arrow()</code>:</p> <pre><code>pyarrow.Table\ncity: string\nlat: double\nlong: double\n----\ncity: [[\"Amsterdam\",\"San Francisco\",\"Drachten\",\"Paris\"]]\nlat: [[52.371807,37.773972,53.11254,48.864716]]\nlong: [[4.896029,-122.431297,6.0989,2.349014]]\n</code></pre> <p>You both can use <code>append(df)</code> or <code>overwrite(df)</code> since there is no data yet. If we want to add more data, we can use <code>.append()</code> again:</p> <pre><code>df = pa.Table.from_pylist(\n    [{\"city\": \"Groningen\", \"lat\": 53.21917, \"long\": 6.56667}],\n)\n\ntbl.append(df)\n</code></pre> <p>When reading the table <code>tbl.scan().to_arrow()</code> you can see that <code>Groningen</code> is now also part of the table:</p> <pre><code>pyarrow.Table\ncity: string\nlat: double\nlong: double\n----\ncity: [[\"Amsterdam\",\"San Francisco\",\"Drachten\",\"Paris\"],[\"Groningen\"]]\nlat: [[52.371807,37.773972,53.11254,48.864716],[53.21917]]\nlong: [[4.896029,-122.431297,6.0989,2.349014],[6.56667]]\n</code></pre> <p>The nested lists indicate the different Arrow buffers, where the first write results into a buffer, and the second append in a separate buffer. This is expected since it will read two parquet files.</p> <p>Under development</p> <p>Writing using PyIceberg is still under development. Support for partial overwrites and writing to partitioned tables is planned and being worked on.</p>"},{"location":"api/#schema-evolution","title":"Schema evolution","text":"<p>PyIceberg supports full schema evolution through the Python API. It takes care of setting the field-IDs and makes sure that only non-breaking changes are done (can be overriden).</p> <p>In the examples below, the <code>.update_schema()</code> is called from the table itself.</p> <pre><code>with table.update_schema() as update:\n    update.add_column(\"some_field\", IntegerType(), \"doc\")\n</code></pre> <p>You can also initiate a transaction if you want to make more changes than just evolving the schema:</p> <pre><code>with table.transaction() as transaction:\n    with transaction.update_schema() as update_schema:\n        update.add_column(\"some_other_field\", IntegerType(), \"doc\")\n    # ... Update properties etc\n</code></pre>"},{"location":"api/#union-by-name","title":"Union by Name","text":"<p>Using <code>.union_by_name()</code> you can merge another schema into an existing schema without having to worry about field-IDs:</p> <pre><code>from pyiceberg.catalog import load_catalog\nfrom pyiceberg.schema import Schema\nfrom pyiceberg.types import NestedField, StringType, DoubleType, LongType\n\ncatalog = load_catalog()\n\nschema = Schema(\n    NestedField(1, \"city\", StringType(), required=False),\n    NestedField(2, \"lat\", DoubleType(), required=False),\n    NestedField(3, \"long\", DoubleType(), required=False),\n)\n\ntable = catalog.create_table(\"default.locations\", schema)\n\nnew_schema = Schema(\n    NestedField(1, \"city\", StringType(), required=False),\n    NestedField(2, \"lat\", DoubleType(), required=False),\n    NestedField(3, \"long\", DoubleType(), required=False),\n    NestedField(10, \"population\", LongType(), required=False),\n)\n\nwith table.update_schema() as update:\n    update.union_by_name(new_schema)\n</code></pre> <p>Now the table has the union of the two schemas <code>print(table.schema())</code>:</p> <pre><code>table {\n  1: city: optional string\n  2: lat: optional double\n  3: long: optional double\n  4: population: optional long\n}\n</code></pre>"},{"location":"api/#add-column","title":"Add column","text":"<p>Using <code>add_column</code> you can add a column, without having to worry about the field-id:</p> <pre><code>with table.update_schema() as update:\n    update.add_column(\"retries\", IntegerType(), \"Number of retries to place the bid\")\n    # In a struct\n    update.add_column(\"details.confirmed_by\", StringType(), \"Name of the exchange\")\n</code></pre>"},{"location":"api/#rename-column","title":"Rename column","text":"<p>Renaming a field in an Iceberg table is simple:</p> <pre><code>with table.update_schema() as update:\n    update.rename_column(\"retries\", \"num_retries\")\n    # This will rename `confirmed_by` to `exchange`\n    update.rename_column(\"properties.confirmed_by\", \"exchange\")\n</code></pre>"},{"location":"api/#move-column","title":"Move column","text":"<p>Move a field inside of struct:</p> <pre><code>with table.update_schema() as update:\n    update.move_first(\"symbol\")\n    update.move_after(\"bid\", \"ask\")\n    # This will move `confirmed_by` before `exchange`\n    update.move_before(\"details.created_by\", \"details.exchange\")\n</code></pre>"},{"location":"api/#update-column","title":"Update column","text":"<p>Update a fields' type, description or required.</p> <pre><code>with table.update_schema() as update:\n    # Promote a float to a double\n    update.update_column(\"bid\", field_type=DoubleType())\n    # Make a field optional\n    update.update_column(\"symbol\", required=False)\n    # Update the documentation\n    update.update_column(\"symbol\", doc=\"Name of the share on the exchange\")\n</code></pre> <p>Be careful, some operations are not compatible, but can still be done at your own risk by setting <code>allow_incompatible_changes</code>:</p> <pre><code>with table.update_schema(allow_incompatible_changes=True) as update:\n    # Incompatible change, cannot require an optional field\n    update.update_column(\"symbol\", required=True)\n</code></pre>"},{"location":"api/#delete-column","title":"Delete column","text":"<p>Delete a field, careful this is a incompatible change (readers/writers might expect this field):</p> <pre><code>with table.update_schema(allow_incompatible_changes=True) as update:\n    update.delete_column(\"some_field\")\n</code></pre>"},{"location":"api/#table-properties","title":"Table properties","text":"<p>Set and remove properties through the <code>Transaction</code> API:</p> <pre><code>with table.transaction() as transaction:\n    transaction.set_properties(abc=\"def\")\n\nassert table.properties == {\"abc\": \"def\"}\n\nwith table.transaction() as transaction:\n    transaction.remove_properties(\"abc\")\n\nassert table.properties == {}\n</code></pre> <p>Or, without context manager:</p> <pre><code>table = table.transaction().set_properties(abc=\"def\").commit_transaction()\n\nassert table.properties == {\"abc\": \"def\"}\n\ntable = table.transaction().remove_properties(\"abc\").commit_transaction()\n\nassert table.properties == {}\n</code></pre>"},{"location":"api/#query-the-data","title":"Query the data","text":"<p>To query a table, a table scan is needed. A table scan accepts a filter, columns, optionally a limit and a snapshot ID:</p> <pre><code>from pyiceberg.catalog import load_catalog\nfrom pyiceberg.expressions import GreaterThanOrEqual\n\ncatalog = load_catalog(\"default\")\ntable = catalog.load_table(\"nyc.taxis\")\n\nscan = table.scan(\n    row_filter=GreaterThanOrEqual(\"trip_distance\", 10.0),\n    selected_fields=(\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"),\n    limit=100,\n)\n\n# Or filter using a string predicate\nscan = table.scan(\n    row_filter=\"trip_distance &gt; 10.0\",\n)\n\n[task.file.file_path for task in scan.plan_files()]\n</code></pre> <p>The low level API <code>plan_files</code> methods returns a set of tasks that provide the files that might contain matching rows:</p> <pre><code>[\n  \"s3://warehouse/wh/nyc/taxis/data/00003-4-42464649-92dd-41ad-b83b-dea1a2fe4b58-00001.parquet\"\n]\n</code></pre> <p>In this case it is up to the engine itself to filter the file itself. Below, <code>to_arrow()</code> and <code>to_duckdb()</code> that already do this for you.</p>"},{"location":"api/#apache-arrow","title":"Apache Arrow","text":"<p>Requirements</p> <p>This requires <code>pyarrow</code> to be installed.</p> <p>Using PyIceberg it is filter out data from a huge table and pull it into a PyArrow table:</p> <pre><code>table.scan(\n    row_filter=GreaterThanOrEqual(\"trip_distance\", 10.0),\n    selected_fields=(\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"),\n).to_arrow()\n</code></pre> <p>This will return a PyArrow table:</p> <pre><code>pyarrow.Table\nVendorID: int64\ntpep_pickup_datetime: timestamp[us, tz=+00:00]\ntpep_dropoff_datetime: timestamp[us, tz=+00:00]\n----\nVendorID: [[2,1,2,1,1,...,2,2,2,2,2],[2,1,1,1,2,...,1,1,2,1,2],...,[2,2,2,2,2,...,2,6,6,2,2],[2,2,2,2,2,...,2,2,2,2,2]]\ntpep_pickup_datetime: [[2021-04-01 00:28:05.000000,...,2021-04-30 23:44:25.000000]]\ntpep_dropoff_datetime: [[2021-04-01 00:47:59.000000,...,2021-05-01 00:14:47.000000]]\n</code></pre> <p>This will only pull in the files that that might contain matching rows.</p>"},{"location":"api/#pandas","title":"Pandas","text":"<p>Requirements</p> <p>This requires <code>pandas</code> to be installed.</p> <p>PyIceberg makes it easy to filter out data from a huge table and pull it into a Pandas dataframe locally. This will only fetch the relevant Parquet files for the query and apply the filter. This will reduce IO and therefore improve performance and reduce cost.</p> <pre><code>table.scan(\n    row_filter=\"trip_distance &gt;= 10.0\",\n    selected_fields=(\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"),\n).to_pandas()\n</code></pre> <p>This will return a Pandas dataframe:</p> <pre><code>        VendorID      tpep_pickup_datetime     tpep_dropoff_datetime\n0              2 2021-04-01 00:28:05+00:00 2021-04-01 00:47:59+00:00\n1              1 2021-04-01 00:39:01+00:00 2021-04-01 00:57:39+00:00\n2              2 2021-04-01 00:14:42+00:00 2021-04-01 00:42:59+00:00\n3              1 2021-04-01 00:17:17+00:00 2021-04-01 00:43:38+00:00\n4              1 2021-04-01 00:24:04+00:00 2021-04-01 00:56:20+00:00\n...          ...                       ...                       ...\n116976         2 2021-04-30 23:56:18+00:00 2021-05-01 00:29:13+00:00\n116977         2 2021-04-30 23:07:41+00:00 2021-04-30 23:37:18+00:00\n116978         2 2021-04-30 23:38:28+00:00 2021-05-01 00:12:04+00:00\n116979         2 2021-04-30 23:33:00+00:00 2021-04-30 23:59:00+00:00\n116980         2 2021-04-30 23:44:25+00:00 2021-05-01 00:14:47+00:00\n\n[116981 rows x 3 columns]\n</code></pre> <p>It is recommended to use Pandas 2 or later, because it stores the data in an Apache Arrow backend which avoids copies of data.</p>"},{"location":"api/#duckdb","title":"DuckDB","text":"<p>Requirements</p> <p>This requires DuckDB to be installed.</p> <p>A table scan can also be converted into a in-memory DuckDB table:</p> <pre><code>con = table.scan(\n    row_filter=GreaterThanOrEqual(\"trip_distance\", 10.0),\n    selected_fields=(\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"),\n).to_duckdb(table_name=\"distant_taxi_trips\")\n</code></pre> <p>Using the cursor that we can run queries on the DuckDB table:</p> <pre><code>print(\n    con.execute(\n        \"SELECT tpep_dropoff_datetime - tpep_pickup_datetime AS duration FROM distant_taxi_trips LIMIT 4\"\n    ).fetchall()\n)\n[\n    (datetime.timedelta(seconds=1194),),\n    (datetime.timedelta(seconds=1118),),\n    (datetime.timedelta(seconds=1697),),\n    (datetime.timedelta(seconds=1581),),\n]\n</code></pre>"},{"location":"api/#ray","title":"Ray","text":"<p>Requirements</p> <p>This requires Ray to be installed.</p> <p>A table scan can also be converted into a Ray dataset:</p> <pre><code>ray_dataset = table.scan(\n    row_filter=GreaterThanOrEqual(\"trip_distance\", 10.0),\n    selected_fields=(\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"),\n).to_ray()\n</code></pre> <p>This will return a Ray dataset:</p> <pre><code>Dataset(\n    num_blocks=1,\n    num_rows=1168798,\n    schema={\n        VendorID: int64,\n        tpep_pickup_datetime: timestamp[us, tz=UTC],\n        tpep_dropoff_datetime: timestamp[us, tz=UTC]\n    }\n)\n</code></pre> <p>Using Ray Dataset API to interact with the dataset:</p> <pre><code>print(ray_dataset.take(2))\n[\n    {\n        \"VendorID\": 2,\n        \"tpep_pickup_datetime\": datetime.datetime(2008, 12, 31, 23, 23, 50),\n        \"tpep_dropoff_datetime\": datetime.datetime(2009, 1, 1, 0, 34, 31),\n    },\n    {\n        \"VendorID\": 2,\n        \"tpep_pickup_datetime\": datetime.datetime(2008, 12, 31, 23, 5, 3),\n        \"tpep_dropoff_datetime\": datetime.datetime(2009, 1, 1, 16, 10, 18),\n    },\n]\n</code></pre>"},{"location":"api/#daft","title":"Daft","text":"<p>PyIceberg interfaces closely with Daft Dataframes (see also: Daft integration with Iceberg) which provides a full lazily optimized query engine interface on top of PyIceberg tables.</p> <p>Requirements</p> <p>This requires Daft to be installed.</p> <p>A table can be read easily into a Daft Dataframe:</p> <pre><code>df = table.to_daft()  # equivalent to `daft.read_iceberg(table)`\ndf = df.where(df[\"trip_distance\"] &gt;= 10.0)\ndf = df.select(\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\")\n</code></pre> <p>This returns a Daft Dataframe which is lazily materialized. Printing <code>df</code> will display the schema:</p> <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 VendorID \u2506 tpep_pickup_datetime          \u2506 tpep_dropoff_datetime         \u2502\n\u2502 ---      \u2506 ---                           \u2506 ---                           \u2502\n\u2502 Int64    \u2506 Timestamp(Microseconds, None) \u2506 Timestamp(Microseconds, None) \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n(No data to display: Dataframe not materialized)\n</code></pre> <p>We can execute the Dataframe to preview the first few rows of the query with <code>df.show()</code>.</p> <p>This is correctly optimized to take advantage of Iceberg features such as hidden partitioning and file-level statistics for efficient reads.</p> <pre><code>df.show(2)\n</code></pre> <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 VendorID \u2506 tpep_pickup_datetime          \u2506 tpep_dropoff_datetime         \u2502\n\u2502 ---      \u2506 ---                           \u2506 ---                           \u2502\n\u2502 Int64    \u2506 Timestamp(Microseconds, None) \u2506 Timestamp(Microseconds, None) \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2        \u2506 2008-12-31T23:23:50.000000    \u2506 2009-01-01T00:34:31.000000    \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 2        \u2506 2008-12-31T23:05:03.000000    \u2506 2009-01-01T16:10:18.000000    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n(Showing first 2 rows)\n</code></pre>"},{"location":"cli/","title":"CLI","text":""},{"location":"cli/#python-cli","title":"Python CLI","text":"<p>Pyiceberg comes with a CLI that's available after installing the <code>pyiceberg</code> package.</p> <p>You can pass the path to the Catalog using the <code>--uri</code> and <code>--credential</code> argument, but it is recommended to setup a <code>~/.pyiceberg.yaml</code> config as described in the Catalog section.</p> <pre><code>\u279c  pyiceberg --help\nUsage: pyiceberg [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n--catalog TEXT\n--verbose BOOLEAN\n--output [text|json]\n--uri TEXT\n--credential TEXT\n--help                Show this message and exit.\n\nCommands:\ndescribe    Describes a namespace xor table\ndrop        Operations to drop a namespace or table\nlist        Lists tables or namespaces\nlocation    Returns the location of the table\nproperties  Properties on tables/namespaces\nrename      Renames a table\nschema      Gets the schema of the table\nspec        Returns the partition spec of the table\nuuid        Returns the UUID of the table\n</code></pre> <p>This example assumes that you have a default catalog set. If you want to load another catalog, for example, the rest example above. Then you need to set <code>--catalog rest</code>.</p> <pre><code>\u279c  pyiceberg list\ndefault\nnyc\n</code></pre> <pre><code>\u279c  pyiceberg list nyc\nnyc.taxis\n</code></pre> <pre><code>\u279c  pyiceberg describe nyc.taxis\nTable format version  1\nMetadata location     file:/.../nyc.db/taxis/metadata/00000-aa3a3eac-ea08-4255-b890-383a64a94e42.metadata.json\nTable UUID            6cdfda33-bfa3-48a7-a09e-7abb462e3460\nLast Updated          1661783158061\nPartition spec        []\nSort order            []\nCurrent schema        Schema, id=0\n\u251c\u2500\u2500 1: VendorID: optional long\n\u251c\u2500\u2500 2: tpep_pickup_datetime: optional timestamptz\n\u251c\u2500\u2500 3: tpep_dropoff_datetime: optional timestamptz\n\u251c\u2500\u2500 4: passenger_count: optional double\n\u251c\u2500\u2500 5: trip_distance: optional double\n\u251c\u2500\u2500 6: RatecodeID: optional double\n\u251c\u2500\u2500 7: store_and_fwd_flag: optional string\n\u251c\u2500\u2500 8: PULocationID: optional long\n\u251c\u2500\u2500 9: DOLocationID: optional long\n\u251c\u2500\u2500 10: payment_type: optional long\n\u251c\u2500\u2500 11: fare_amount: optional double\n\u251c\u2500\u2500 12: extra: optional double\n\u251c\u2500\u2500 13: mta_tax: optional double\n\u251c\u2500\u2500 14: tip_amount: optional double\n\u251c\u2500\u2500 15: tolls_amount: optional double\n\u251c\u2500\u2500 16: improvement_surcharge: optional double\n\u251c\u2500\u2500 17: total_amount: optional double\n\u251c\u2500\u2500 18: congestion_surcharge: optional double\n\u2514\u2500\u2500 19: airport_fee: optional double\nCurrent snapshot      Operation.APPEND: id=5937117119577207079, schema_id=0\nSnapshots             Snapshots\n\u2514\u2500\u2500 Snapshot 5937117119577207079, schema 0: file:/.../nyc.db/taxis/metadata/snap-5937117119577207079-1-94656c4f-4c66-4600-a4ca-f30377300527.avro\nProperties            owner                 root\nwrite.format.default  parquet\n</code></pre> <p>Or output in JSON for automation:</p> <pre><code>\u279c  pyiceberg --output json describe nyc.taxis | jq\n{\n  \"identifier\": [\n    \"nyc\",\n    \"taxis\"\n  ],\n  \"metadata_location\": \"file:/.../nyc.db/taxis/metadata/00000-aa3a3eac-ea08-4255-b890-383a64a94e42.metadata.json\",\n  \"metadata\": {\n    \"location\": \"file:/.../nyc.db/taxis\",\n    \"table-uuid\": \"6cdfda33-bfa3-48a7-a09e-7abb462e3460\",\n    \"last-updated-ms\": 1661783158061,\n    \"last-column-id\": 19,\n    \"schemas\": [\n      {\n        \"type\": \"struct\",\n        \"fields\": [\n          {\n            \"id\": 1,\n            \"name\": \"VendorID\",\n            \"type\": \"long\",\n            \"required\": false\n          },\n...\n          {\n            \"id\": 19,\n            \"name\": \"airport_fee\",\n            \"type\": \"double\",\n            \"required\": false\n          }\n        ],\n        \"schema-id\": 0,\n        \"identifier-field-ids\": []\n      }\n    ],\n    \"current-schema-id\": 0,\n    \"partition-specs\": [\n      {\n        \"spec-id\": 0,\n        \"fields\": []\n      }\n    ],\n    \"default-spec-id\": 0,\n    \"last-partition-id\": 999,\n    \"properties\": {\n      \"owner\": \"root\",\n      \"write.format.default\": \"parquet\"\n    },\n    \"current-snapshot-id\": 5937117119577207000,\n    \"snapshots\": [\n      {\n        \"snapshot-id\": 5937117119577207000,\n        \"timestamp-ms\": 1661783158061,\n        \"manifest-list\": \"file:/.../nyc.db/taxis/metadata/snap-5937117119577207079-1-94656c4f-4c66-4600-a4ca-f30377300527.avro\",\n        \"summary\": {\n          \"operation\": \"append\",\n          \"spark.app.id\": \"local-1661783139151\",\n          \"added-data-files\": \"1\",\n          \"added-records\": \"2979431\",\n          \"added-files-size\": \"46600777\",\n          \"changed-partition-count\": \"1\",\n          \"total-records\": \"2979431\",\n          \"total-files-size\": \"46600777\",\n          \"total-data-files\": \"1\",\n          \"total-delete-files\": \"0\",\n          \"total-position-deletes\": \"0\",\n          \"total-equality-deletes\": \"0\"\n        },\n        \"schema-id\": 0\n      }\n    ],\n    \"snapshot-log\": [\n      {\n        \"snapshot-id\": \"5937117119577207079\",\n        \"timestamp-ms\": 1661783158061\n      }\n    ],\n    \"metadata-log\": [],\n    \"sort-orders\": [\n      {\n        \"order-id\": 0,\n        \"fields\": []\n      }\n    ],\n    \"default-sort-order-id\": 0,\n    \"refs\": {\n      \"main\": {\n        \"snapshot-id\": 5937117119577207000,\n        \"type\": \"branch\"\n      }\n    },\n    \"format-version\": 1,\n    \"schema\": {\n      \"type\": \"struct\",\n      \"fields\": [\n        {\n          \"id\": 1,\n          \"name\": \"VendorID\",\n          \"type\": \"long\",\n          \"required\": false\n        },\n...\n        {\n          \"id\": 19,\n          \"name\": \"airport_fee\",\n          \"type\": \"double\",\n          \"required\": false\n        }\n      ],\n      \"schema-id\": 0,\n      \"identifier-field-ids\": []\n    },\n    \"partition-spec\": []\n  }\n}\n</code></pre>"},{"location":"community/","title":"Community","text":""},{"location":"community/#join-the-community","title":"Join the community","text":"<p>Apache Iceberg tracks issues in GitHub and prefers to receive contributions as pull requests.</p> <p>Community discussions happen primarily on the dev mailing list, on Apache Iceberg Slack workspace in the #python channel, and on specific GitHub issues.</p>"},{"location":"community/#iceberg-community-events","title":"Iceberg Community Events","text":"<p>The PyIceberg community sync is on the last Tuesday of every month. To join, make sure to subscribe to the iceberg-python-sync Google group.</p>"},{"location":"community/#community-guidelines","title":"Community Guidelines","text":""},{"location":"community/#apache-iceberg-community-guidelines","title":"Apache Iceberg Community Guidelines","text":"<p>The Apache Iceberg community is built on the principles described in the Apache Way and all who engage with the community are expected to be respectful, open, come with the best interests of the community in mind, and abide by the Apache Foundation Code of Conduct.</p>"},{"location":"community/#participants-with-corporate-interests","title":"Participants with Corporate Interests","text":"<p>A wide range of corporate entities have interests that overlap in both features and frameworks related to Iceberg and while we encourage engagement and contributions, the community is not a venue for marketing, solicitation, or recruitment.</p> <p>Any vendor who wants to participate in the Apache Iceberg community Slack workspace should create a dedicated vendor channel for their organization prefixed by <code>vendor-</code>.</p> <p>This space can be used to discuss features and integration with Iceberg related to the vendor offering.  This space should not be used to promote competing vendor products/services or disparage other vendor offerings.  Discussion should be focused on questions asked by the community and not to expand/introduce/redirect users to alternate offerings.</p>"},{"location":"community/#marketing-solicitation-recruiting","title":"Marketing / Solicitation / Recruiting","text":"<p>The Apache Iceberg community is a space for everyone to operate free of influence. The development lists, Slack workspace, and GitHub should not be used to market products or services.  Solicitation or overt promotion should not be performed in common channels or through direct messages.</p> <p>Recruitment of community members should not be conducted through direct messages or community channels, but opportunities related to contributing to or using Iceberg can be posted to the <code>#jobs</code> channel.</p> <p>For questions regarding any of the guidelines above, please contact a PMC member</p>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#catalogs","title":"Catalogs","text":"<p>PyIceberg currently has native support for REST, SQL, Hive, Glue and DynamoDB.</p> <p>There are three ways to pass in configuration:</p> <ul> <li>Using the <code>~/.pyiceberg.yaml</code> configuration file</li> <li>Through environment variables</li> <li>By passing in credentials through the CLI or the Python API</li> </ul> <p>The configuration file is recommended since that's the easiest way to manage the credentials.</p> <p>Another option is through environment variables:</p> <pre><code>export PYICEBERG_CATALOG__DEFAULT__URI=thrift://localhost:9083\nexport PYICEBERG_CATALOG__DEFAULT__S3__ACCESS_KEY_ID=username\nexport PYICEBERG_CATALOG__DEFAULT__S3__SECRET_ACCESS_KEY=password\n</code></pre> <p>The environment variable picked up by Iceberg starts with <code>PYICEBERG_</code> and then follows the yaml structure below, where a double underscore <code>__</code> represents a nested field, and the underscore <code>_</code> is converted into a dash <code>-</code>.</p> <p>For example, <code>PYICEBERG_CATALOG__DEFAULT__S3__ACCESS_KEY_ID</code>, sets <code>s3.access-key-id</code> on the <code>default</code> catalog.</p>"},{"location":"configuration/#tables","title":"Tables","text":"<p>Iceberg tables support table properties to configure table behavior.</p>"},{"location":"configuration/#write-options","title":"Write options","text":"Key Options Default Description <code>write.parquet.compression-codec</code> <code>{uncompressed,zstd,gzip,snappy}</code> zstd Sets the Parquet compression coddec. <code>write.parquet.compression-level</code> Integer null Parquet compression level for the codec. If not set, it is up to PyIceberg <code>write.parquet.page-size-bytes</code> Size in bytes 1MB Set a target threshold for the approximate encoded size of data pages within a column chunk <code>write.parquet.page-row-limit</code> Number of rows 20000 Set a target threshold for the approximate encoded size of data pages within a column chunk <code>write.parquet.dict-size-bytes</code> Size in bytes 2MB Set the dictionary page size limit per row group <code>write.parquet.row-group-limit</code> Number of rows 122880 The Parquet row group limit"},{"location":"configuration/#fileio","title":"FileIO","text":"<p>Iceberg works with the concept of a FileIO which is a pluggable module for reading, writing, and deleting files. By default, PyIceberg will try to initialize the FileIO that's suitable for the scheme (<code>s3://</code>, <code>gs://</code>, etc.) and will use the first one that's installed.</p> <ul> <li>s3, s3a, s3n: <code>PyArrowFileIO</code>, <code>FsspecFileIO</code></li> <li>gs: <code>PyArrowFileIO</code></li> <li>file: <code>PyArrowFileIO</code></li> <li>hdfs: <code>PyArrowFileIO</code></li> <li>abfs, abfss: <code>FsspecFileIO</code></li> </ul> <p>You can also set the FileIO explicitly:</p> Key Example Description py-io-impl pyiceberg.io.fsspec.FsspecFileIO Sets the FileIO explicitly to an implementation, and will fail explicitly if it can't be loaded <p>For the FileIO there are several configuration options available:</p>"},{"location":"configuration/#s3","title":"S3","text":"Key Example Description s3.endpoint https://10.0.19.25/ Configure an alternative endpoint of the S3 service for the FileIO to access. This could be used to use S3FileIO with any s3-compatible object storage service that has a different endpoint, or access a private S3 endpoint in a virtual private cloud. s3.access-key-id admin Configure the static secret access key used to access the FileIO. s3.secret-access-key password Configure the static session token used to access the FileIO. s3.signer bearer Configure the signature version of the FileIO. s3.region us-west-2 Sets the region of the bucket s3.proxy-uri http://my.proxy.com:8080 Configure the proxy server to be used by the FileIO. s3.connect-timeout 60.0 Configure socket connection timeout, in seconds."},{"location":"configuration/#hdfs","title":"HDFS","text":"Key Example Description hdfs.host https://10.0.19.25/ Configure the HDFS host to connect to hdfs.port 9000 Configure the HDFS port to connect to. hdfs.user user Configure the HDFS username used for connection. hdfs.kerberos_ticket kerberos_ticket Configure the path to the Kerberos ticket cache."},{"location":"configuration/#azure-data-lake","title":"Azure Data lake","text":"Key Example Description adlfs.connection-string AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqF...;BlobEndpoint=http://localhost/ A connection string. This could be used to use FileIO with any adlfs-compatible object storage service that has a different endpoint (like azurite). adlfs.account-name devstoreaccount1 The account that you want to connect to adlfs.account-key Eby8vdM02xNOcqF... The key to authentication against the account. adlfs.sas-token NuHOuuzdQN7VRM%2FOpOeqBlawRCA845IY05h9eu1Yte4%3D The shared access signature adlfs.tenant-id ad667be4-b811-11ed-afa1-0242ac120002 The tenant-id adlfs.client-id ad667be4-b811-11ed-afa1-0242ac120002 The client-id adlfs.client-secret oCA3R6P*ka#oa1Sms2J74z... The client-secret"},{"location":"configuration/#google-cloud-storage","title":"Google Cloud Storage","text":"Key Example Description gcs.project-id my-gcp-project Configure Google Cloud Project for GCS FileIO. gcs.oauth.token ya29.dr.AfM... Configure method authentication to GCS for FileIO. Can be the following, 'google_default', 'cache', 'anon', 'browser', 'cloud'. If not specified your credentials will be resolved in the following order: gcloud CLI default, gcsfs cached token, google compute metadata service, anonymous. gcs.oauth.token-expires-at 1690971805918 Configure expiration for credential generated with an access token. Milliseconds since epoch gcs.access read_only Configure client to have specific access. Must be one of 'read_only', 'read_write', or 'full_control' gcs.consistency md5 Configure the check method when writing files. Must be one of 'none', 'size', or 'md5' gcs.cache-timeout 60 Configure the cache expiration time in seconds for object metadata cache gcs.requester-pays False Configure whether to use requester-pays requests gcs.session-kwargs {} Configure a dict of parameters to pass on to aiohttp.ClientSession; can contain, for example, proxy settings. gcs.endpoint http://0.0.0.0:4443 Configure an alternative endpoint for the GCS FileIO to access (format protocol://host:port) If not given, defaults to the value of environment variable \"STORAGE_EMULATOR_HOST\"; if that is not set either, will use the standard Google endpoint. gcs.default-location US Configure the default location where buckets are created, like 'US' or 'EUROPE-WEST3'. gcs.version-aware False Configure whether to support object versioning on the GCS bucket."},{"location":"configuration/#rest-catalog","title":"REST Catalog","text":"<pre><code>catalog:\n  default:\n    uri: http://rest-catalog/ws/\n    credential: t-1234:secret\n\n  default-mtls-secured-catalog:\n    uri: https://rest-catalog/ws/\n    ssl:\n      client:\n        cert: /absolute/path/to/client.crt\n        key: /absolute/path/to/client.key\n      cabundle: /absolute/path/to/cabundle.pem\n</code></pre> Key Example Description uri https://rest-catalog/ws URI identifying the REST Server credential t-1234:secret Credential to use for OAuth2 credential flow when initializing the catalog token FEW23.DFSDF.FSDF Bearer token value to use for <code>Authorization</code> header rest.sigv4-enabled true Sign requests to the REST Server using AWS SigV4 protocol rest.signing-region us-east-1 The region to use when SigV4 signing a request rest.signing-name execute-api The service signing name to use when SigV4 signing a request rest.authorization-url https://auth-service/cc Authentication URL to use for client credentials authentication (default: uri + 'v1/oauth/tokens')"},{"location":"configuration/#sql-catalog","title":"SQL Catalog","text":"<p>The SQL catalog requires a database for its backend. PyIceberg supports PostgreSQL and SQLite through psycopg2. The database connection has to be configured using the <code>uri</code> property. See SQLAlchemy's documentation for URL format:</p> <p>For PostgreSQL:</p> <pre><code>catalog:\n  default:\n    type: sql\n    uri: postgresql+psycopg2://username:password@localhost/mydatabase\n</code></pre> <p>In the case of SQLite:</p> <p>Development only</p> <p>SQLite is not built for concurrency, you should use this catalog for exploratory or development purposes.</p> <pre><code>catalog:\n  default:\n    type: sql\n    uri: sqlite:////tmp/pyiceberg.db\n</code></pre>"},{"location":"configuration/#hive-catalog","title":"Hive Catalog","text":"<pre><code>catalog:\n  default:\n    uri: thrift://localhost:9083\n    s3.endpoint: http://localhost:9000\n    s3.access-key-id: admin\n    s3.secret-access-key: password\n</code></pre>"},{"location":"configuration/#glue-catalog","title":"Glue Catalog","text":"<p>Your AWS credentials can be passed directly through the Python API. Otherwise, please refer to How to configure AWS credentials to set your AWS account credentials locally. If you did not set up a default AWS profile, you can configure the <code>profile_name</code>.</p> <pre><code>catalog:\n  default:\n    type: glue\n    aws_access_key_id: &lt;ACCESS_KEY_ID&gt;\n    aws_secret_access_key: &lt;SECRET_ACCESS_KEY&gt;\n    aws_session_token: &lt;SESSION_TOKEN&gt;\n    region_name: &lt;REGION_NAME&gt;\n</code></pre> <pre><code>catalog:\n  default:\n    type: glue\n    profile_name: &lt;PROFILE_NAME&gt;\n    region_name: &lt;REGION_NAME&gt;\n</code></pre>"},{"location":"configuration/#dynamodb-catalog","title":"DynamoDB Catalog","text":"<p>If you want to use AWS DynamoDB as the catalog, you can use the last two ways to configure the pyiceberg and refer How to configure AWS credentials to set your AWS account credentials locally.</p> <pre><code>catalog:\n  default:\n    type: dynamodb\n    table-name: iceberg\n</code></pre> <p>If you prefer to pass the credentials explicitly to the client instead of relying on environment variables,</p> <pre><code>catalog:\n  default:\n    type: dynamodb\n    table-name: iceberg\n    aws_access_key_id: &lt;ACCESS_KEY_ID&gt;\n    aws_secret_access_key: &lt;SECRET_ACCESS_KEY&gt;\n    aws_session_token: &lt;SESSION_TOKEN&gt;\n    region_name: &lt;REGION_NAME&gt;\n</code></pre>"},{"location":"configuration/#concurrency","title":"Concurrency","text":"<p>PyIceberg uses multiple threads to parallelize operations. The number of workers can be configured by supplying a <code>max-workers</code> entry in the configuration file, or by setting the <code>PYICEBERG_MAX_WORKERS</code> environment variable. The default value depends on the system hardware and Python version. See the Python documentation for more details.</p>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing-to-the-iceberg-python-library","title":"Contributing to the Iceberg Python library","text":"<p>For the development, Poetry is used for packing and dependency management. You can install this using:</p> <pre><code>pip install poetry\n</code></pre> <p>Make sure you're using an up-to-date environment from venv</p> <pre><code>pip install --upgrade virtualenv pip\npython -m venv ./venv\nsource ./venv/bin/activate\n</code></pre> <p>To get started, you can run <code>make install</code>, which installs Poetry and all the dependencies of the Iceberg library. This also installs the development dependencies. If you don't want to install the development dependencies, you need to install using <code>poetry install --no-dev</code>.</p> <p>If you want to install the library on the host, you can simply run <code>pip3 install -e .</code>. If you wish to use a virtual environment, you can run <code>poetry shell</code>. Poetry will open up a virtual environment with all the dependencies set.</p> <p>To set up IDEA with Poetry (also on Loom):</p> <ul> <li>Open up the Python project in IntelliJ</li> <li>Make sure that you're on latest main (that includes Poetry)</li> <li>Go to File -&gt; Project Structure (\u2318;)</li> <li>Go to Platform Settings -&gt; SDKs</li> <li>Click the + sign -&gt; Add Python SDK</li> <li>Select Poetry Environment from the left hand side bar and hit OK</li> <li>It can take some time to download all the dependencies based on your internet</li> <li>Go to Project Settings -&gt; Project</li> <li>Select the Poetry SDK from the SDK dropdown, and click OK</li> </ul> <p>For IDEA \u22642021 you need to install the Poetry integration as a plugin.</p> <p>Now you're set using Poetry, and all the tests will run in Poetry, and you'll have syntax highlighting in the pyproject.toml to indicate stale dependencies.</p>"},{"location":"contributing/#installation-from-source","title":"Installation from source","text":"<p>Clone the repository for local development:</p> <pre><code>git clone https://github.com/apache/iceberg-python.git\ncd iceberg-python\npip3 install -e \".[s3fs,hive]\"\n</code></pre> <p>Install it directly for GitHub (not recommended), but sometimes handy:</p> <pre><code>pip install \"git+https://github.com/apache/iceberg-python.git#egg=pyiceberg[s3fs]\"\n</code></pre>"},{"location":"contributing/#linting","title":"Linting","text":"<p><code>pre-commit</code> is used for autoformatting and linting:</p> <pre><code>make lint\n</code></pre> <p>Pre-commit will automatically fix the violations such as import orders, formatting etc. Pylint errors you need to fix yourself.</p> <p>In contrast to the name suggest, it doesn't run the checks on the commit. If this is something that you like, you can set this up by running <code>pre-commit install</code>.</p> <p>You can bump the integrations to the latest version using <code>pre-commit autoupdate</code>. This will check if there is a newer version of <code>{black,mypy,isort,...}</code> and update the yaml.</p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>For Python, <code>pytest</code> is used a testing framework in combination with <code>coverage</code> to enforce 90%+ code coverage.</p> <pre><code>make test\n</code></pre> <p>By default, S3 and ADLFS tests are ignored because that require minio and azurite to be running. To run the S3 suite:</p> <pre><code>make test-s3\n</code></pre> <p>To run the ADLFS suite:</p> <pre><code>make test-adlfs\n</code></pre> <p>To pass additional arguments to pytest, you can use <code>PYTEST_ARGS</code>.</p> <p>Run pytest in verbose mode</p> <pre><code>make test PYTEST_ARGS=\"-v\"\n</code></pre> <p>Run pytest with pdb enabled</p> <pre><code>make test PYTEST_ARGS=\"--pdb\"\n</code></pre> <p>To see all available pytest arguments, run <code>make test PYTEST_ARGS=\"--help\"</code>.</p>"},{"location":"contributing/#integration-tests","title":"Integration tests","text":"<p>PyIceberg has integration tests with Apache Spark. Spark will create a new database and provision some tables that PyIceberg can query against.</p> <pre><code>make test-integration\n</code></pre> <p>This will restart the containers, to get to a clean state, and then run the PyTest suite. In case something changed in the Dockerfile or the provision script, you can run:</p> <pre><code>make test-integration-rebuild\n</code></pre> <p>To rebuild the containers from scratch.</p>"},{"location":"contributing/#code-standards","title":"Code standards","text":"<p>Below are the formalized conventions that we adhere to in the PyIceberg project. The goal of this is to have a common agreement on how to evolve the codebase, but also using it as guidelines for newcomers to the project.</p>"},{"location":"contributing/#api-compatibility","title":"API Compatibility","text":"<p>It is important to keep the Python public API compatible across versions. The Python official PEP-8 defines public methods as: Public attributes should have no leading underscores. This means not removing any methods without any notice, or removing or renaming any existing parameters. Adding new optional parameters is okay.</p> <p>If you want to remove a method, please add a deprecation notice by annotating the function using <code>@deprecated</code>:</p> <pre><code>from pyiceberg.utils.deprecated import deprecated\n\n\n@deprecated(\n    deprecated_in=\"0.1.0\",\n    removed_in=\"0.2.0\",\n    help_message=\"Please use load_something_else() instead\",\n)\ndef load_something():\n    pass\n</code></pre> <p>Which will warn:</p> <pre><code>Call to load_something, deprecated in 0.1.0, will be removed in 0.2.0. Please use load_something_else() instead.\n</code></pre>"},{"location":"contributing/#type-annotations","title":"Type annotations","text":"<p>For the type annotation the types from the <code>Typing</code> package are used.</p> <p>PyIceberg offers support from Python 3.8 onwards, we can't use the type hints from the standard collections.</p>"},{"location":"contributing/#third-party-libraries","title":"Third party libraries","text":"<p>PyIceberg naturally integrates into the rich Python ecosystem, however it is important to be hesitant adding third party packages. Adding a lot of packages makes the library heavyweight, and causes incompatibilities with other projects if they use a different version of the library. Also, big libraries such as <code>s3fs</code>, <code>adlfs</code>, <code>pyarrow</code>, <code>thrift</code> should be optional to avoid downloading everything, while not being sure if is actually being used.</p>"},{"location":"how-to-release/","title":"How to release","text":""},{"location":"how-to-release/#how-to-release","title":"How to release","text":"<p>The guide to release PyIceberg.</p> <p>The first step is to publish a release candidate (RC) and publish it to the public for testing and validation. Once the vote has passed on the RC, the RC turns into the new release.</p>"},{"location":"how-to-release/#running-a-release-candidate","title":"Running a release candidate","text":"<p>Make sure that the version is correct in <code>pyproject.toml</code> and <code>pyiceberg/__init__.py</code>. Correct means that it reflects the version that you want to release.</p>"},{"location":"how-to-release/#setting-the-tag","title":"Setting the tag","text":"<p>Make sure that you're on the right branch, and the latest branch:</p> <p>For a Major/Minor release, make sure that you're on <code>main</code>, for patch versions the branch corresponding to the version that you want to patch, i.e. <code>pyiceberg-0.6.x</code>.</p> <pre><code>git checkout &lt;branch&gt;\ngit fetch --all\ngit reset --hard apache/&lt;branch&gt;\n</code></pre> <p>Set the tag on the last commit:</p> <pre><code>export RC=rc1\nexport VERSION=0.1.0${RC}\nexport VERSION_WITHOUT_RC=${VERSION/rc?/}\nexport VERSION_BRANCH=${VERSION_WITHOUT_RC//./-}\nexport GIT_TAG=pyiceberg-${VERSION}\n\ngit tag -s ${GIT_TAG} -m \"PyIceberg ${VERSION}\"\ngit push apache ${GIT_TAG}\n\nexport GIT_TAG_REF=$(git show-ref ${GIT_TAG})\nexport GIT_TAG_HASH=${GIT_TAG_REF:0:40}\nexport LAST_COMMIT_ID=$(git rev-list ${GIT_TAG} 2&gt; /dev/null | head -n 1)\n</code></pre> <p>The <code>-s</code> option will sign the commit. If you don't have a key yet, you can find the instructions here. To install gpg on a M1 based Mac, a couple of additional steps are required: https://gist.github.com/phortuin/cf24b1cca3258720c71ad42977e1ba57</p>"},{"location":"how-to-release/#upload-to-apache-svn","title":"Upload to Apache SVN","text":"<p>Both the source distribution (<code>sdist</code>) and the binary distributions (<code>wheels</code>) need to be published for the RC. The wheels are convenient to avoid having people to install compilers locally. The downside is that each architecture requires its own wheel. use <code>cibuildwheel</code> runs in Github actions to create a wheel for each of the architectures.</p> <p>Before committing the files to the Apache SVN artifact distribution SVN hashes need to be generated, and those need to be signed with gpg to make sure that they are authentic.</p> <p>Go to Github Actions and run the <code>Python release</code> action. Set the version to main, since we cannot modify the source. Download the zip, and sign the files:</p> <pre><code>cd release-main/\n\nfor name in $(ls pyiceberg-*.whl pyiceberg-*.tar.gz)\ndo\n    gpg --yes --armor --local-user fokko@apache.org --output \"${name}.asc\" --detach-sig \"${name}\"\n    shasum -a 512 \"${name}\" &gt; \"${name}.sha512\"\ndone\n</code></pre> <p>Now we can upload the files from the same directory:</p> <pre><code>export SVN_TMP_DIR=/tmp/iceberg-${VERSION_BRANCH}/\nsvn checkout https://dist.apache.org/repos/dist/dev/iceberg $SVN_TMP_DIR\n\nexport SVN_TMP_DIR_VERSIONED=${SVN_TMP_DIR}pyiceberg-$VERSION/\nmkdir -p $SVN_TMP_DIR_VERSIONED\ncp * $SVN_TMP_DIR_VERSIONED\nsvn add $SVN_TMP_DIR_VERSIONED\nsvn ci -m \"PyIceberg ${VERSION}\" ${SVN_TMP_DIR_VERSIONED}\n</code></pre>"},{"location":"how-to-release/#upload-to-pypi","title":"Upload to PyPi","text":"<p>Go to Github Actions and run the <code>Python release</code> action. Set the version of the release candidate as the input: <code>0.1.0rc1</code>. Download the zip and unzip it locally.</p> <p>Next step is to upload them to pypi. Please keep in mind that this won't bump the version for everyone that hasn't pinned their version, since it is set to an RC pre-release and those are ignored.</p> <pre><code>twine upload -s release-0.1.0rc1/*\n</code></pre> <p>Final step is to generate the email to the dev mail list:</p> <pre><code>cat &lt;&lt; EOF &gt; release-announcement-email.txt\nTo: dev@iceberg.apache.org\nSubject: [VOTE] Release Apache PyIceberg $VERSION\nHi Everyone,\n\nI propose that we release the following RC as the official PyIceberg $VERSION_WITHOUT_RC release.\n\nA summary of the high level features:\n\n* &lt;Add summary by hand&gt;\n\nThe commit ID is $LAST_COMMIT_ID\n\n* This corresponds to the tag: $GIT_TAG ($GIT_TAG_HASH)\n* https://github.com/apache/iceberg-python/releases/tag/$GIT_TAG\n* https://github.com/apache/iceberg-python/tree/$LAST_COMMIT_ID\n\nThe release tarball, signature, and checksums are here:\n\n* https://dist.apache.org/repos/dist/dev/iceberg/pyiceberg-$VERSION/\n\nYou can find the KEYS file here:\n\n* https://dist.apache.org/repos/dist/dev/iceberg/KEYS\n\nConvenience binary artifacts are staged on pypi:\n\nhttps://pypi.org/project/pyiceberg/$VERSION/\n\nAnd can be installed using: pip3 install pyiceberg==$VERSION\n\nPlease download, verify, and test.\n\nPlease vote in the next 72 hours.\n[ ] +1 Release this as PyIceberg $VERSION_WITHOUT_RC\n[ ] +0\n[ ] -1 Do not release this because...\nEOF\n\ncat release-announcement-email.txt\n</code></pre>"},{"location":"how-to-release/#vote-has-passed","title":"Vote has passed","text":"<p>Once the vote has been passed, you can close the vote thread by concluding it:</p> <pre><code>Thanks everyone for voting! The 72 hours have passed, and a minimum of 3 binding votes have been cast:\n\n+1 Foo Bar (non-binding)\n...\n+1 Fokko Driesprong (binding)\n\nThe release candidate has been accepted as PyIceberg &lt;VERSION&gt;. Thanks everyone, when all artifacts are published the announcement will be sent out.\n\nKind regards,\n</code></pre>"},{"location":"how-to-release/#copy-the-artifacts-to-the-release-dist","title":"Copy the artifacts to the release dist","text":"<pre><code>svn checkout https://dist.apache.org/repos/dist/dev/iceberg /tmp/iceberg-dist-dev\nsvn checkout https://dist.apache.org/repos/dist/release/iceberg/ /tmp/iceberg-dist-release\n\nmkdir -p /tmp/iceberg-dist-release/pyiceberg-&lt;VERSION&gt;\ncp -r /tmp/iceberg-dist-dev/pyiceberg-&lt;VERSION&gt;rcN/* /tmp/iceberg-dist-release/pyiceberg-&lt;VERSION&gt;\n\nsvn add /tmp/iceberg-dist-release/\nsvn ci -m \"PyIceberg &lt;VERSION&gt;\" /tmp/iceberg-dist-release/\n</code></pre> <p>The latest version can be pushed to PyPi. Check out the Apache SVN and make sure to publish the right version with <code>twine</code>:</p> <pre><code>twine upload -s /tmp/iceberg-dist-release/pyiceberg-&lt;VERSION&gt;/*\n</code></pre> <p>Send out an announcement on the dev mail list:</p> <pre><code>To: dev@iceberg.apache.org\nSubject: [ANNOUNCE] Apache PyIceberg release &lt;VERSION&gt;\n\nI'm pleased to announce the release of Apache PyIceberg &lt;VERSION&gt;!\n\nApache Iceberg is an open table format for huge analytic datasets. Iceberg\ndelivers high query performance for tables with tens of petabytes of data,\nalong with atomic commits, concurrent writes, and SQL-compatible table\nevolution.\n\nThis Python release can be downloaded from: https://pypi.org/project/pyiceberg/&lt;VERSION&gt;/\n\nThanks to everyone for contributing!\n</code></pre>"},{"location":"how-to-release/#release-the-docs","title":"Release the docs","text":"<p>A committer triggers the <code>Python Docs</code> Github Actions through the UI by selecting the branch that just has been released. This will publish the new docs.</p>"},{"location":"verify-release/","title":"Verify a release","text":""},{"location":"verify-release/#verifying-a-release","title":"Verifying a release","text":"<p>Each Apache PyIceberg release is validated by the community by holding a vote. A community release manager will prepare a release candidate and call a vote on the Iceberg dev list. To validate the release candidate, community members will test it out in their downstream projects and environments.</p> <p>In addition to testing in downstream projects, community members also check the release\u2019s signatures, checksums, and license documentation.</p>"},{"location":"verify-release/#validating-a-release-candidate","title":"Validating a release candidate","text":"<p>Release announcements include links to the following:</p> <ul> <li>A source tarball</li> <li>A signature (.asc)</li> <li>A checksum (.sha512)</li> <li>KEYS file</li> <li>GitHub change comparison</li> </ul> <p>After downloading the source tarball, signature, checksum, and KEYS file, here are instructions on how to verify signatures, checksums, and documentation.</p>"},{"location":"verify-release/#verifying-signatures","title":"Verifying signatures","text":"<p>First, import the keys.</p> <pre><code>curl https://dist.apache.org/repos/dist/dev/iceberg/KEYS -o KEYS\ngpg --import KEYS\n</code></pre> <p>Next, verify the <code>.asc</code> file.</p> <pre><code>svn checkout https://dist.apache.org/repos/dist/dev/iceberg/pyiceberg-0.5.0rc1/ /tmp/pyiceberg/\n\nfor name in $(ls /tmp/pyiceberg/pyiceberg-*.whl /tmp/pyiceberg/pyiceberg-*.tar.gz)\ndo\n    gpg --verify ${name}.asc ${name}\ndone\n</code></pre>"},{"location":"verify-release/#verifying-checksums","title":"Verifying checksums","text":"<pre><code>cd  /tmp/pyiceberg/\nfor name in $(ls /tmp/pyiceberg/pyiceberg-*.whl.sha512 /tmp/pyiceberg/pyiceberg-*.tar.gz.sha512)\ndo\n    shasum -a 512 --check ${name}\ndone\n</code></pre>"},{"location":"verify-release/#verifying-license-documentation","title":"Verifying License Documentation","text":"<pre><code>tar xzf pyiceberg-0.5.0.tar.gz\ncd pyiceberg-0.5.0\n</code></pre> <p>Run RAT checks to validate license header:</p> <pre><code>./dev/check-license\n</code></pre>"},{"location":"verify-release/#testing","title":"Testing","text":"<p>This section explains how to run the tests of the source distribution.</p> <p>Clean environment</p> <p>To make sure that your environment is fresh is to run the tests in a new Docker container: <code>docker run -t -i -v $(pwd):/pyiceberg/ python:3.9 bash</code>. And change directory: <code>cd /pyiceberg/</code>.</p> <p>First step is to install the package:</p> <pre><code>make install\n</code></pre> <p>And then run the tests:</p> <pre><code>make test\n</code></pre> <p>To run the full integration tests:</p> <pre><code>make test-s3\n</code></pre> <p>This will include a Minio S3 container being spun up.</p>"},{"location":"verify-release/#cast-the-vote","title":"Cast the vote","text":"<p>Votes are cast by replying to the release candidate announcement email on the dev mailing list with either <code>+1</code>, <code>0</code>, or <code>-1</code>. For example :</p> <p>[ ] +1 Release this as PyIceberg 0.3.0 [ ] +0 [ ] -1 Do not release this because\u2026</p> <p>In addition to your vote, it\u2019s customary to specify if your vote is binding or non-binding. Only members of the Project Management Committee have formally binding votes. If you\u2019re unsure, you can specify that your vote is non-binding. To read more about voting in the Apache framework, checkout the Voting information page on the Apache foundation\u2019s website.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>pyiceberg<ul> <li>avro<ul> <li>codecs<ul> <li>bzip2</li> <li>codec</li> <li>deflate</li> <li>snappy_codec</li> <li>zstandard_codec</li> </ul> </li> <li>decoder</li> <li>encoder</li> <li>file</li> <li>reader</li> <li>resolver</li> <li>writer</li> </ul> </li> <li>catalog<ul> <li>dynamodb</li> <li>glue</li> <li>hive</li> <li>noop</li> <li>rest</li> <li>sql</li> </ul> </li> <li>cli<ul> <li>console</li> <li>output</li> </ul> </li> <li>conversions</li> <li>exceptions</li> <li>expressions<ul> <li>literals</li> <li>parser</li> <li>visitors</li> </ul> </li> <li>io<ul> <li>fsspec</li> <li>pyarrow</li> </ul> </li> <li>manifest</li> <li>partitioning</li> <li>schema</li> <li>serializers</li> <li>table<ul> <li>metadata</li> <li>name_mapping</li> <li>refs</li> <li>snapshots</li> <li>sorting</li> </ul> </li> <li>transforms</li> <li>typedef</li> <li>types</li> <li>utils<ul> <li>bin_packing</li> <li>concurrent</li> <li>config</li> <li>datetime</li> <li>decimal</li> <li>deprecated</li> <li>lazydict</li> <li>parsing</li> <li>schema_conversion</li> <li>singleton</li> <li>truncate</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/pyiceberg/","title":"pyiceberg","text":""},{"location":"reference/pyiceberg/conversions/","title":"conversions","text":"<p>Utility module for various conversions around PrimitiveType implementations.</p> This module enables <ul> <li>Converting partition strings to built-in python objects.</li> <li>Converting a value to a byte buffer.</li> <li>Converting a byte buffer to a value.</li> </ul> Note <p>Conversion logic varies based on the PrimitiveType implementation. Therefore conversion functions are defined here as generic functions using the @singledispatch decorator. For each PrimitiveType implementation, a concrete function is registered for each generic conversion function. For PrimitiveType implementations that share the same conversion logic, registrations can be stacked.</p>"},{"location":"reference/pyiceberg/conversions/#pyiceberg.conversions.from_bytes","title":"<code>from_bytes(primitive_type, b)</code>","text":"<p>Convert bytes to a built-in python value.</p> <p>Parameters:</p> Name Type Description Default <code>primitive_type</code> <code>PrimitiveType</code> <p>An implementation of the PrimitiveType base class.</p> required <code>b</code> <code>bytes</code> <p>The bytes to convert.</p> required Source code in <code>pyiceberg/conversions.py</code> <pre><code>@singledispatch\ndef from_bytes(primitive_type: PrimitiveType, b: bytes) -&gt; L:  # type: ignore\n    \"\"\"Convert bytes to a built-in python value.\n\n    Args:\n        primitive_type (PrimitiveType): An implementation of the PrimitiveType base class.\n        b (bytes): The bytes to convert.\n    \"\"\"\n    raise TypeError(f\"Cannot deserialize bytes, type {primitive_type} not supported: {str(b)}\")\n</code></pre>"},{"location":"reference/pyiceberg/conversions/#pyiceberg.conversions.handle_none","title":"<code>handle_none(func)</code>","text":"<p>Handle cases where partition values are <code>None</code> or \"HIVE_DEFAULT_PARTITION\".</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>A function registered to the singledispatch function <code>partition_to_py</code>.</p> required Source code in <code>pyiceberg/conversions.py</code> <pre><code>def handle_none(func: Callable) -&gt; Callable:  # type: ignore\n    \"\"\"Handle cases where partition values are `None` or \"__HIVE_DEFAULT_PARTITION__\".\n\n    Args:\n        func (Callable): A function registered to the singledispatch function `partition_to_py`.\n    \"\"\"\n\n    def wrapper(primitive_type: PrimitiveType, value_str: Optional[str]) -&gt; Any:\n        if value_str is None:\n            return None\n        elif value_str == \"__HIVE_DEFAULT_PARTITION__\":\n            return None\n        return func(primitive_type, value_str)\n\n    return wrapper\n</code></pre>"},{"location":"reference/pyiceberg/conversions/#pyiceberg.conversions.partition_to_py","title":"<code>partition_to_py(primitive_type, value_str)</code>","text":"<p>Convert a partition string to a python built-in.</p> <p>Parameters:</p> Name Type Description Default <code>primitive_type</code> <code>PrimitiveType</code> <p>An implementation of the PrimitiveType base class.</p> required <code>value_str</code> <code>str</code> <p>A string representation of a partition value.</p> required Source code in <code>pyiceberg/conversions.py</code> <pre><code>@singledispatch\ndef partition_to_py(primitive_type: PrimitiveType, value_str: str) -&gt; Union[int, float, str, uuid.UUID, bytes, Decimal]:\n    \"\"\"Convert a partition string to a python built-in.\n\n    Args:\n        primitive_type (PrimitiveType): An implementation of the PrimitiveType base class.\n        value_str (str): A string representation of a partition value.\n    \"\"\"\n    raise TypeError(f\"Cannot convert '{value_str}' to unsupported type: {primitive_type}\")\n</code></pre>"},{"location":"reference/pyiceberg/conversions/#pyiceberg.conversions.to_bytes","title":"<code>to_bytes(primitive_type, _)</code>","text":"<p>Convert a built-in python value to bytes.</p> <p>This conversion follows the serialization scheme for storing single values as individual binary values defined in the Iceberg specification that can be found at https://iceberg.apache.org/spec/#appendix-d-single-value-serialization</p> <p>Parameters:</p> Name Type Description Default <code>primitive_type</code> <code>PrimitiveType</code> <p>An implementation of the PrimitiveType base class.</p> required <code>_</code> <code>Union[bool, bytes, Decimal, date, datetime, float, int, str, time, UUID]</code> <p>The value to convert to bytes (The type of this value depends on which dispatched function is used--check dispatchable functions for type hints).</p> required Source code in <code>pyiceberg/conversions.py</code> <pre><code>@singledispatch\ndef to_bytes(\n    primitive_type: PrimitiveType, _: Union[bool, bytes, Decimal, date, datetime, float, int, str, time, uuid.UUID]\n) -&gt; bytes:\n    \"\"\"Convert a built-in python value to bytes.\n\n    This conversion follows the serialization scheme for storing single values as individual binary values defined in the Iceberg specification that\n    can be found at https://iceberg.apache.org/spec/#appendix-d-single-value-serialization\n\n    Args:\n        primitive_type (PrimitiveType): An implementation of the PrimitiveType base class.\n        _: The value to convert to bytes (The type of this value depends on which dispatched function is\n            used--check dispatchable functions for type hints).\n    \"\"\"\n    raise TypeError(f\"scale does not match {primitive_type}\")\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/","title":"exceptions","text":""},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.AuthorizationExpiredError","title":"<code>AuthorizationExpiredError</code>","text":"<p>             Bases: <code>RESTError</code></p> <p>When the credentials are expired when performing an action on the REST catalog.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class AuthorizationExpiredError(RESTError):\n    \"\"\"When the credentials are expired when performing an action on the REST catalog.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.BadRequestError","title":"<code>BadRequestError</code>","text":"<p>             Bases: <code>RESTError</code></p> <p>Raises when an invalid request is being made.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class BadRequestError(RESTError):\n    \"\"\"Raises when an invalid request is being made.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.CommitFailedException","title":"<code>CommitFailedException</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Commit failed, refresh and try again.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class CommitFailedException(Exception):\n    \"\"\"Commit failed, refresh and try again.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.CommitStateUnknownException","title":"<code>CommitStateUnknownException</code>","text":"<p>             Bases: <code>RESTError</code></p> <p>Commit failed due to unknown reason.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class CommitStateUnknownException(RESTError):\n    \"\"\"Commit failed due to unknown reason.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.ForbiddenError","title":"<code>ForbiddenError</code>","text":"<p>             Bases: <code>RESTError</code></p> <p>Raises when you don't have the credentials to perform the action on the REST catalog.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class ForbiddenError(RESTError):\n    \"\"\"Raises when you don't have the credentials to perform the action on the REST catalog.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.NamespaceAlreadyExistsError","title":"<code>NamespaceAlreadyExistsError</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Raised when a name-space being created already exists in the catalog.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class NamespaceAlreadyExistsError(Exception):\n    \"\"\"Raised when a name-space being created already exists in the catalog.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.NamespaceNotEmptyError","title":"<code>NamespaceNotEmptyError</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Raised when a name-space being dropped is not empty.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class NamespaceNotEmptyError(Exception):\n    \"\"\"Raised when a name-space being dropped is not empty.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.NoSuchIcebergTableError","title":"<code>NoSuchIcebergTableError</code>","text":"<p>             Bases: <code>NoSuchTableError</code></p> <p>Raises when the table found in the REST catalog is not an iceberg table.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class NoSuchIcebergTableError(NoSuchTableError):\n    \"\"\"Raises when the table found in the REST catalog is not an iceberg table.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.NoSuchNamespaceError","title":"<code>NoSuchNamespaceError</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Raised when a referenced name-space is not found.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class NoSuchNamespaceError(Exception):\n    \"\"\"Raised when a referenced name-space is not found.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.NoSuchPropertyException","title":"<code>NoSuchPropertyException</code>","text":"<p>             Bases: <code>Exception</code></p> <p>When a property is missing.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class NoSuchPropertyException(Exception):\n    \"\"\"When a property is missing.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.NoSuchTableError","title":"<code>NoSuchTableError</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Raises when the table can't be found in the REST catalog.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class NoSuchTableError(Exception):\n    \"\"\"Raises when the table can't be found in the REST catalog.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.NotInstalledError","title":"<code>NotInstalledError</code>","text":"<p>             Bases: <code>Exception</code></p> <p>When an optional dependency is not installed.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class NotInstalledError(Exception):\n    \"\"\"When an optional dependency is not installed.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.OAuthError","title":"<code>OAuthError</code>","text":"<p>             Bases: <code>RESTError</code></p> <p>Raises when there is an error with the OAuth call.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class OAuthError(RESTError):\n    \"\"\"Raises when there is an error with the OAuth call.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.RESTError","title":"<code>RESTError</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Raises when there is an unknown response from the REST Catalog.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class RESTError(Exception):\n    \"\"\"Raises when there is an unknown response from the REST Catalog.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.ServerError","title":"<code>ServerError</code>","text":"<p>             Bases: <code>RESTError</code></p> <p>Raises when there is an unhandled exception on the server side.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class ServerError(RESTError):\n    \"\"\"Raises when there is an unhandled exception on the server side.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.ServiceUnavailableError","title":"<code>ServiceUnavailableError</code>","text":"<p>             Bases: <code>RESTError</code></p> <p>Raises when the service doesn't respond.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class ServiceUnavailableError(RESTError):\n    \"\"\"Raises when the service doesn't respond.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.SignError","title":"<code>SignError</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Raises when unable to sign a S3 request.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class SignError(Exception):\n    \"\"\"Raises when unable to sign a S3 request.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.TableAlreadyExistsError","title":"<code>TableAlreadyExistsError</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Raised when creating a table with a name that already exists.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class TableAlreadyExistsError(Exception):\n    \"\"\"Raised when creating a table with a name that already exists.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.UnauthorizedError","title":"<code>UnauthorizedError</code>","text":"<p>             Bases: <code>RESTError</code></p> <p>Raises when you don't have the proper authorization.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class UnauthorizedError(RESTError):\n    \"\"\"Raises when you don't have the proper authorization.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/exceptions/#pyiceberg.exceptions.ValidationError","title":"<code>ValidationError</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Raises when there is an issue with the schema.</p> Source code in <code>pyiceberg/exceptions.py</code> <pre><code>class ValidationError(Exception):\n    \"\"\"Raises when there is an issue with the schema.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/manifest/","title":"manifest","text":""},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.DataFile","title":"<code>DataFile</code>","text":"<p>             Bases: <code>Record</code></p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>class DataFile(Record):\n    __slots__ = (\n        \"content\",\n        \"file_path\",\n        \"file_format\",\n        \"partition\",\n        \"record_count\",\n        \"file_size_in_bytes\",\n        \"column_sizes\",\n        \"value_counts\",\n        \"null_value_counts\",\n        \"nan_value_counts\",\n        \"lower_bounds\",\n        \"upper_bounds\",\n        \"key_metadata\",\n        \"split_offsets\",\n        \"equality_ids\",\n        \"sort_order_id\",\n        \"spec_id\",\n    )\n    content: DataFileContent\n    file_path: str\n    file_format: FileFormat\n    partition: Record\n    record_count: int\n    file_size_in_bytes: int\n    column_sizes: Dict[int, int]\n    value_counts: Dict[int, int]\n    null_value_counts: Dict[int, int]\n    nan_value_counts: Dict[int, int]\n    lower_bounds: Dict[int, bytes]\n    upper_bounds: Dict[int, bytes]\n    key_metadata: Optional[bytes]\n    split_offsets: Optional[List[int]]\n    equality_ids: Optional[List[int]]\n    sort_order_id: Optional[int]\n    spec_id: Optional[int]\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        \"\"\"Assign a key/value to a DataFile.\"\"\"\n        # The file_format is written as a string, so we need to cast it to the Enum\n        if name == \"file_format\":\n            value = FileFormat[value]\n        super().__setattr__(name, value)\n\n    def __init__(self, format_version: Literal[1, 2] = DEFAULT_READ_VERSION, *data: Any, **named_data: Any) -&gt; None:\n        super().__init__(\n            *data,\n            **{\"struct\": DATA_FILE_TYPE[format_version], **named_data},\n        )\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Return the hash of the file path.\"\"\"\n        return hash(self.file_path)\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Compare the datafile with another object.\n\n        If it is a datafile, it will compare based on the file_path.\n        \"\"\"\n        return self.file_path == other.file_path if isinstance(other, DataFile) else False\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.DataFile.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Compare the datafile with another object.</p> <p>If it is a datafile, it will compare based on the file_path.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Compare the datafile with another object.\n\n    If it is a datafile, it will compare based on the file_path.\n    \"\"\"\n    return self.file_path == other.file_path if isinstance(other, DataFile) else False\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.DataFile.__hash__","title":"<code>__hash__()</code>","text":"<p>Return the hash of the file path.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Return the hash of the file path.\"\"\"\n    return hash(self.file_path)\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.DataFile.__setattr__","title":"<code>__setattr__(name, value)</code>","text":"<p>Assign a key/value to a DataFile.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def __setattr__(self, name: str, value: Any) -&gt; None:\n    \"\"\"Assign a key/value to a DataFile.\"\"\"\n    # The file_format is written as a string, so we need to cast it to the Enum\n    if name == \"file_format\":\n        value = FileFormat[value]\n    super().__setattr__(name, value)\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.DataFileContent","title":"<code>DataFileContent</code>","text":"<p>             Bases: <code>int</code>, <code>Enum</code></p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>class DataFileContent(int, Enum):\n    DATA = 0\n    POSITION_DELETES = 1\n    EQUALITY_DELETES = 2\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the DataFileContent class.\"\"\"\n        return f\"DataFileContent.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.DataFileContent.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the DataFileContent class.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the DataFileContent class.\"\"\"\n    return f\"DataFileContent.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.FileFormat","title":"<code>FileFormat</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>class FileFormat(str, Enum):\n    AVRO = \"AVRO\"\n    PARQUET = \"PARQUET\"\n    ORC = \"ORC\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the FileFormat class.\"\"\"\n        return f\"FileFormat.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.FileFormat.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the FileFormat class.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the FileFormat class.\"\"\"\n    return f\"FileFormat.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.ManifestContent","title":"<code>ManifestContent</code>","text":"<p>             Bases: <code>int</code>, <code>Enum</code></p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>class ManifestContent(int, Enum):\n    DATA = 0\n    DELETES = 1\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the ManifestContent class.\"\"\"\n        return f\"ManifestContent.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.ManifestContent.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the ManifestContent class.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the ManifestContent class.\"\"\"\n    return f\"ManifestContent.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.ManifestEntryStatus","title":"<code>ManifestEntryStatus</code>","text":"<p>             Bases: <code>int</code>, <code>Enum</code></p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>class ManifestEntryStatus(int, Enum):\n    EXISTING = 0\n    ADDED = 1\n    DELETED = 2\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the ManifestEntryStatus class.\"\"\"\n        return f\"ManifestEntryStatus.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.ManifestEntryStatus.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the ManifestEntryStatus class.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the ManifestEntryStatus class.\"\"\"\n    return f\"ManifestEntryStatus.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.ManifestFile","title":"<code>ManifestFile</code>","text":"<p>             Bases: <code>Record</code></p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>class ManifestFile(Record):\n    __slots__ = (\n        \"manifest_path\",\n        \"manifest_length\",\n        \"partition_spec_id\",\n        \"content\",\n        \"sequence_number\",\n        \"min_sequence_number\",\n        \"added_snapshot_id\",\n        \"added_files_count\",\n        \"existing_files_count\",\n        \"deleted_files_count\",\n        \"added_rows_count\",\n        \"existing_rows_count\",\n        \"deleted_rows_count\",\n        \"partitions\",\n        \"key_metadata\",\n    )\n    manifest_path: str\n    manifest_length: int\n    partition_spec_id: int\n    content: ManifestContent\n    sequence_number: int\n    min_sequence_number: int\n    added_snapshot_id: int\n    added_files_count: Optional[int]\n    existing_files_count: Optional[int]\n    deleted_files_count: Optional[int]\n    added_rows_count: Optional[int]\n    existing_rows_count: Optional[int]\n    deleted_rows_count: Optional[int]\n    partitions: Optional[List[PartitionFieldSummary]]\n    key_metadata: Optional[bytes]\n\n    def __init__(self, *data: Any, **named_data: Any) -&gt; None:\n        super().__init__(*data, **{\"struct\": MANIFEST_LIST_FILE_STRUCTS[DEFAULT_READ_VERSION], **named_data})\n\n    def has_added_files(self) -&gt; bool:\n        return self.added_files_count is None or self.added_files_count &gt; 0\n\n    def has_existing_files(self) -&gt; bool:\n        return self.existing_files_count is None or self.existing_files_count &gt; 0\n\n    def fetch_manifest_entry(self, io: FileIO, discard_deleted: bool = True) -&gt; List[ManifestEntry]:\n        \"\"\"\n        Read the manifest entries from the manifest file.\n\n        Args:\n            io: The FileIO to fetch the file.\n            discard_deleted: Filter on live entries.\n\n        Returns:\n            An Iterator of manifest entries.\n        \"\"\"\n        input_file = io.new_input(self.manifest_path)\n        with AvroFile[ManifestEntry](\n            input_file,\n            MANIFEST_ENTRY_SCHEMAS[DEFAULT_READ_VERSION],\n            read_types={-1: ManifestEntry, 2: DataFile},\n            read_enums={0: ManifestEntryStatus, 101: FileFormat, 134: DataFileContent},\n        ) as reader:\n            return [\n                _inherit_from_manifest(entry, self)\n                for entry in reader\n                if not discard_deleted or entry.status != ManifestEntryStatus.DELETED\n            ]\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.ManifestFile.fetch_manifest_entry","title":"<code>fetch_manifest_entry(io, discard_deleted=True)</code>","text":"<p>Read the manifest entries from the manifest file.</p> <p>Parameters:</p> Name Type Description Default <code>io</code> <code>FileIO</code> <p>The FileIO to fetch the file.</p> required <code>discard_deleted</code> <code>bool</code> <p>Filter on live entries.</p> <code>True</code> <p>Returns:</p> Type Description <code>List[ManifestEntry]</code> <p>An Iterator of manifest entries.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def fetch_manifest_entry(self, io: FileIO, discard_deleted: bool = True) -&gt; List[ManifestEntry]:\n    \"\"\"\n    Read the manifest entries from the manifest file.\n\n    Args:\n        io: The FileIO to fetch the file.\n        discard_deleted: Filter on live entries.\n\n    Returns:\n        An Iterator of manifest entries.\n    \"\"\"\n    input_file = io.new_input(self.manifest_path)\n    with AvroFile[ManifestEntry](\n        input_file,\n        MANIFEST_ENTRY_SCHEMAS[DEFAULT_READ_VERSION],\n        read_types={-1: ManifestEntry, 2: DataFile},\n        read_enums={0: ManifestEntryStatus, 101: FileFormat, 134: DataFileContent},\n    ) as reader:\n        return [\n            _inherit_from_manifest(entry, self)\n            for entry in reader\n            if not discard_deleted or entry.status != ManifestEntryStatus.DELETED\n        ]\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.ManifestListWriter","title":"<code>ManifestListWriter</code>","text":"<p>             Bases: <code>ABC</code></p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>class ManifestListWriter(ABC):\n    _format_version: Literal[1, 2]\n    _output_file: OutputFile\n    _meta: Dict[str, str]\n    _manifest_files: List[ManifestFile]\n    _commit_snapshot_id: int\n    _writer: AvroOutputFile[ManifestFile]\n\n    def __init__(self, format_version: Literal[1, 2], output_file: OutputFile, meta: Dict[str, Any]):\n        self._format_version = format_version\n        self._output_file = output_file\n        self._meta = meta\n        self._manifest_files = []\n\n    def __enter__(self) -&gt; ManifestListWriter:\n        \"\"\"Open the writer for writing.\"\"\"\n        self._writer = AvroOutputFile[ManifestFile](\n            output_file=self._output_file,\n            record_schema=MANIFEST_LIST_FILE_SCHEMAS[DEFAULT_READ_VERSION],\n            file_schema=MANIFEST_LIST_FILE_SCHEMAS[self._format_version],\n            schema_name=\"manifest_file\",\n            metadata=self._meta,\n        )\n        self._writer.__enter__()\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_value: Optional[BaseException],\n        traceback: Optional[TracebackType],\n    ) -&gt; None:\n        \"\"\"Close the writer.\"\"\"\n        self._writer.__exit__(exc_type, exc_value, traceback)\n        return\n\n    @abstractmethod\n    def prepare_manifest(self, manifest_file: ManifestFile) -&gt; ManifestFile: ...\n\n    def add_manifests(self, manifest_files: List[ManifestFile]) -&gt; ManifestListWriter:\n        self._writer.write_block([self.prepare_manifest(manifest_file) for manifest_file in manifest_files])\n        return self\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.ManifestListWriter.__enter__","title":"<code>__enter__()</code>","text":"<p>Open the writer for writing.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def __enter__(self) -&gt; ManifestListWriter:\n    \"\"\"Open the writer for writing.\"\"\"\n    self._writer = AvroOutputFile[ManifestFile](\n        output_file=self._output_file,\n        record_schema=MANIFEST_LIST_FILE_SCHEMAS[DEFAULT_READ_VERSION],\n        file_schema=MANIFEST_LIST_FILE_SCHEMAS[self._format_version],\n        schema_name=\"manifest_file\",\n        metadata=self._meta,\n    )\n    self._writer.__enter__()\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.ManifestListWriter.__exit__","title":"<code>__exit__(exc_type, exc_value, traceback)</code>","text":"<p>Close the writer.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def __exit__(\n    self,\n    exc_type: Optional[Type[BaseException]],\n    exc_value: Optional[BaseException],\n    traceback: Optional[TracebackType],\n) -&gt; None:\n    \"\"\"Close the writer.\"\"\"\n    self._writer.__exit__(exc_type, exc_value, traceback)\n    return\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.ManifestWriter","title":"<code>ManifestWriter</code>","text":"<p>             Bases: <code>ABC</code></p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>class ManifestWriter(ABC):\n    closed: bool\n    _spec: PartitionSpec\n    _schema: Schema\n    _output_file: OutputFile\n    _writer: AvroOutputFile[ManifestEntry]\n    _snapshot_id: int\n    _meta: Dict[str, str]\n    _added_files: int\n    _added_rows: int\n    _existing_files: int\n    _existing_rows: int\n    _deleted_files: int\n    _deleted_rows: int\n    _min_data_sequence_number: Optional[int]\n    _partitions: List[Record]\n\n    def __init__(\n        self, spec: PartitionSpec, schema: Schema, output_file: OutputFile, snapshot_id: int, meta: Dict[str, str] = EMPTY_DICT\n    ) -&gt; None:\n        self.closed = False\n        self._spec = spec\n        self._schema = schema\n        self._output_file = output_file\n        self._snapshot_id = snapshot_id\n        self._meta = meta\n\n        self._added_files = 0\n        self._added_rows = 0\n        self._existing_files = 0\n        self._existing_rows = 0\n        self._deleted_files = 0\n        self._deleted_rows = 0\n        self._min_data_sequence_number = None\n        self._partitions = []\n\n    def __enter__(self) -&gt; ManifestWriter:\n        \"\"\"Open the writer.\"\"\"\n        self._writer = self.new_writer()\n        self._writer.__enter__()\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_value: Optional[BaseException],\n        traceback: Optional[TracebackType],\n    ) -&gt; None:\n        \"\"\"Close the writer.\"\"\"\n        self.closed = True\n        self._writer.__exit__(exc_type, exc_value, traceback)\n\n    @abstractmethod\n    def content(self) -&gt; ManifestContent: ...\n\n    @property\n    @abstractmethod\n    def version(self) -&gt; Literal[1, 2]: ...\n\n    def _with_partition(self, format_version: Literal[1, 2]) -&gt; Schema:\n        data_file_type = data_file_with_partition(\n            format_version=format_version, partition_type=self._spec.partition_type(self._schema)\n        )\n        return manifest_entry_schema_with_data_file(format_version=format_version, data_file=data_file_type)\n\n    def new_writer(self) -&gt; AvroOutputFile[ManifestEntry]:\n        return AvroOutputFile[ManifestEntry](\n            output_file=self._output_file,\n            file_schema=self._with_partition(self.version),\n            record_schema=self._with_partition(DEFAULT_READ_VERSION),\n            schema_name=\"manifest_entry\",\n            metadata=self._meta,\n        )\n\n    @abstractmethod\n    def prepare_entry(self, entry: ManifestEntry) -&gt; ManifestEntry: ...\n\n    def to_manifest_file(self) -&gt; ManifestFile:\n        \"\"\"Return the manifest file.\"\"\"\n        # once the manifest file is generated, no more entries can be added\n        self.closed = True\n        min_sequence_number = self._min_data_sequence_number or UNASSIGNED_SEQ\n        return ManifestFile(\n            manifest_path=self._output_file.location,\n            manifest_length=len(self._writer.output_file),\n            partition_spec_id=self._spec.spec_id,\n            content=self.content(),\n            sequence_number=UNASSIGNED_SEQ,\n            min_sequence_number=min_sequence_number,\n            added_snapshot_id=self._snapshot_id,\n            added_files_count=self._added_files,\n            existing_files_count=self._existing_files,\n            deleted_files_count=self._deleted_files,\n            added_rows_count=self._added_rows,\n            existing_rows_count=self._existing_rows,\n            deleted_rows_count=self._deleted_rows,\n            partitions=construct_partition_summaries(self._spec, self._schema, self._partitions),\n            key_metadata=None,\n        )\n\n    def add_entry(self, entry: ManifestEntry) -&gt; ManifestWriter:\n        if self.closed:\n            raise RuntimeError(\"Cannot add entry to closed manifest writer\")\n        if entry.status == ManifestEntryStatus.ADDED:\n            self._added_files += 1\n            self._added_rows += entry.data_file.record_count\n        elif entry.status == ManifestEntryStatus.EXISTING:\n            self._existing_files += 1\n            self._existing_rows += entry.data_file.record_count\n        elif entry.status == ManifestEntryStatus.DELETED:\n            self._deleted_files += 1\n            self._deleted_rows += entry.data_file.record_count\n\n        self._partitions.append(entry.data_file.partition)\n\n        if (\n            (entry.status == ManifestEntryStatus.ADDED or entry.status == ManifestEntryStatus.EXISTING)\n            and entry.data_sequence_number is not None\n            and (self._min_data_sequence_number is None or entry.data_sequence_number &lt; self._min_data_sequence_number)\n        ):\n            self._min_data_sequence_number = entry.data_sequence_number\n\n        self._writer.write_block([self.prepare_entry(entry)])\n        return self\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.ManifestWriter.__enter__","title":"<code>__enter__()</code>","text":"<p>Open the writer.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def __enter__(self) -&gt; ManifestWriter:\n    \"\"\"Open the writer.\"\"\"\n    self._writer = self.new_writer()\n    self._writer.__enter__()\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.ManifestWriter.__exit__","title":"<code>__exit__(exc_type, exc_value, traceback)</code>","text":"<p>Close the writer.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def __exit__(\n    self,\n    exc_type: Optional[Type[BaseException]],\n    exc_value: Optional[BaseException],\n    traceback: Optional[TracebackType],\n) -&gt; None:\n    \"\"\"Close the writer.\"\"\"\n    self.closed = True\n    self._writer.__exit__(exc_type, exc_value, traceback)\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.ManifestWriter.to_manifest_file","title":"<code>to_manifest_file()</code>","text":"<p>Return the manifest file.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def to_manifest_file(self) -&gt; ManifestFile:\n    \"\"\"Return the manifest file.\"\"\"\n    # once the manifest file is generated, no more entries can be added\n    self.closed = True\n    min_sequence_number = self._min_data_sequence_number or UNASSIGNED_SEQ\n    return ManifestFile(\n        manifest_path=self._output_file.location,\n        manifest_length=len(self._writer.output_file),\n        partition_spec_id=self._spec.spec_id,\n        content=self.content(),\n        sequence_number=UNASSIGNED_SEQ,\n        min_sequence_number=min_sequence_number,\n        added_snapshot_id=self._snapshot_id,\n        added_files_count=self._added_files,\n        existing_files_count=self._existing_files,\n        deleted_files_count=self._deleted_files,\n        added_rows_count=self._added_rows,\n        existing_rows_count=self._existing_rows,\n        deleted_rows_count=self._deleted_rows,\n        partitions=construct_partition_summaries(self._spec, self._schema, self._partitions),\n        key_metadata=None,\n    )\n</code></pre>"},{"location":"reference/pyiceberg/manifest/#pyiceberg.manifest.read_manifest_list","title":"<code>read_manifest_list(input_file)</code>","text":"<p>Read the manifests from the manifest list.</p> <p>Parameters:</p> Name Type Description Default <code>input_file</code> <code>InputFile</code> <p>The input file where the stream can be read from.</p> required <p>Returns:</p> Type Description <code>Iterator[ManifestFile]</code> <p>An iterator of ManifestFiles that are part of the list.</p> Source code in <code>pyiceberg/manifest.py</code> <pre><code>def read_manifest_list(input_file: InputFile) -&gt; Iterator[ManifestFile]:\n    \"\"\"\n    Read the manifests from the manifest list.\n\n    Args:\n        input_file: The input file where the stream can be read from.\n\n    Returns:\n        An iterator of ManifestFiles that are part of the list.\n    \"\"\"\n    with AvroFile[ManifestFile](\n        input_file,\n        MANIFEST_LIST_FILE_SCHEMAS[DEFAULT_READ_VERSION],\n        read_types={-1: ManifestFile, 508: PartitionFieldSummary},\n        read_enums={517: ManifestContent},\n    ) as reader:\n        yield from reader\n</code></pre>"},{"location":"reference/pyiceberg/partitioning/","title":"partitioning","text":""},{"location":"reference/pyiceberg/partitioning/#pyiceberg.partitioning.PartitionField","title":"<code>PartitionField</code>","text":"<p>             Bases: <code>IcebergBaseModel</code></p> <p>PartitionField represents how one partition value is derived from the source column via transformation.</p> <p>Attributes:</p> Name Type Description <code>source_id(int)</code> <p>The source column id of table's schema.</p> <code>field_id(int)</code> <p>The partition field id across all the table partition specs.</p> <code>transform(Transform)</code> <p>The transform used to produce partition values from source column.</p> <code>name(str)</code> <p>The name of this partition field.</p> Source code in <code>pyiceberg/partitioning.py</code> <pre><code>class PartitionField(IcebergBaseModel):\n    \"\"\"PartitionField represents how one partition value is derived from the source column via transformation.\n\n    Attributes:\n        source_id(int): The source column id of table's schema.\n        field_id(int): The partition field id across all the table partition specs.\n        transform(Transform): The transform used to produce partition values from source column.\n        name(str): The name of this partition field.\n    \"\"\"\n\n    source_id: int = Field(alias=\"source-id\")\n    field_id: int = Field(alias=\"field-id\")\n    transform: Annotated[  # type: ignore\n        Transform,\n        BeforeValidator(parse_transform),\n        PlainSerializer(lambda c: str(c), return_type=str),  # pylint: disable=W0108\n        WithJsonSchema({\"type\": \"string\"}, mode=\"serialization\"),\n    ] = Field()\n    name: str = Field()\n\n    def __init__(\n        self,\n        source_id: Optional[int] = None,\n        field_id: Optional[int] = None,\n        transform: Optional[Transform[Any, Any]] = None,\n        name: Optional[str] = None,\n        **data: Any,\n    ):\n        if source_id is not None:\n            data[\"source-id\"] = source_id\n        if field_id is not None:\n            data[\"field-id\"] = field_id\n        if transform is not None:\n            data[\"transform\"] = transform\n        if name is not None:\n            data[\"name\"] = name\n\n        super().__init__(**data)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the PartitionField class.\"\"\"\n        return f\"{self.field_id}: {self.name}: {self.transform}({self.source_id})\"\n</code></pre>"},{"location":"reference/pyiceberg/partitioning/#pyiceberg.partitioning.PartitionField.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the PartitionField class.</p> Source code in <code>pyiceberg/partitioning.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the PartitionField class.\"\"\"\n    return f\"{self.field_id}: {self.name}: {self.transform}({self.source_id})\"\n</code></pre>"},{"location":"reference/pyiceberg/partitioning/#pyiceberg.partitioning.PartitionSpec","title":"<code>PartitionSpec</code>","text":"<p>             Bases: <code>IcebergBaseModel</code></p> <p>PartitionSpec captures the transformation from table data to partition values.</p> <p>Attributes:</p> Name Type Description <code>spec_id(int)</code> <p>any change to PartitionSpec will produce a new specId.</p> <code>fields(Tuple[PartitionField)</code> <p>list of partition fields to produce partition values.</p> Source code in <code>pyiceberg/partitioning.py</code> <pre><code>class PartitionSpec(IcebergBaseModel):\n    \"\"\"\n    PartitionSpec captures the transformation from table data to partition values.\n\n    Attributes:\n        spec_id(int): any change to PartitionSpec will produce a new specId.\n        fields(Tuple[PartitionField): list of partition fields to produce partition values.\n    \"\"\"\n\n    spec_id: int = Field(alias=\"spec-id\", default=INITIAL_PARTITION_SPEC_ID)\n    fields: Tuple[PartitionField, ...] = Field(default_factory=tuple)\n\n    def __init__(\n        self,\n        *fields: PartitionField,\n        **data: Any,\n    ):\n        if fields:\n            data[\"fields\"] = tuple(fields)\n        super().__init__(**data)\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"\n        Produce a boolean to return True if two objects are considered equal.\n\n        Note:\n            Equality of PartitionSpec is determined by spec_id and partition fields only.\n        \"\"\"\n        if not isinstance(other, PartitionSpec):\n            return False\n        return self.spec_id == other.spec_id and self.fields == other.fields\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Produce a human-readable string representation of PartitionSpec.\n\n        Note:\n            Only include list of partition fields in the PartitionSpec's string representation.\n        \"\"\"\n        result_str = \"[\"\n        if self.fields:\n            result_str += \"\\n  \" + \"\\n  \".join([str(field) for field in self.fields]) + \"\\n\"\n        result_str += \"]\"\n        return result_str\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the PartitionSpec class.\"\"\"\n        fields = f\"{', '.join(repr(column) for column in self.fields)}, \" if self.fields else \"\"\n        return f\"PartitionSpec({fields}spec_id={self.spec_id})\"\n\n    def is_unpartitioned(self) -&gt; bool:\n        return not self.fields\n\n    @property\n    def last_assigned_field_id(self) -&gt; int:\n        if self.fields:\n            return max(pf.field_id for pf in self.fields)\n        return PARTITION_FIELD_ID_START\n\n    @cached_property\n    def source_id_to_fields_map(self) -&gt; Dict[int, List[PartitionField]]:\n        source_id_to_fields_map: Dict[int, List[PartitionField]] = {}\n        for partition_field in self.fields:\n            existing = source_id_to_fields_map.get(partition_field.source_id, [])\n            existing.append(partition_field)\n            source_id_to_fields_map[partition_field.source_id] = existing\n        return source_id_to_fields_map\n\n    def fields_by_source_id(self, field_id: int) -&gt; List[PartitionField]:\n        return self.source_id_to_fields_map.get(field_id, [])\n\n    def compatible_with(self, other: PartitionSpec) -&gt; bool:\n        \"\"\"Produce a boolean to return True if two PartitionSpec are considered compatible.\"\"\"\n        if self == other:\n            return True\n        if len(self.fields) != len(other.fields):\n            return False\n        return all(\n            this_field.source_id == that_field.source_id\n            and this_field.transform == that_field.transform\n            and this_field.name == that_field.name\n            for this_field, that_field in zip(self.fields, other.fields)\n        )\n\n    def partition_type(self, schema: Schema) -&gt; StructType:\n        \"\"\"Produce a struct of the PartitionSpec.\n\n        The partition fields should be optional:\n\n        - All partition transforms are required to produce null if the input value is null, so it can\n          happen when the source column is optional.\n        - Partition fields may be added later, in which case not all files would have the result field,\n          and it may be null.\n\n        There is a case where we can guarantee that a partition field in the first and only partition spec\n        that uses a required source column will never be null, but it doesn't seem worth tracking this case.\n\n        :param schema: The schema to bind to.\n        :return: A StructType that represents the PartitionSpec, with a NestedField for each PartitionField.\n        \"\"\"\n        nested_fields = []\n        for field in self.fields:\n            source_type = schema.find_type(field.source_id)\n            result_type = field.transform.result_type(source_type)\n            nested_fields.append(NestedField(field.field_id, field.name, result_type, required=False))\n        return StructType(*nested_fields)\n</code></pre>"},{"location":"reference/pyiceberg/partitioning/#pyiceberg.partitioning.PartitionSpec.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Produce a boolean to return True if two objects are considered equal.</p> Note <p>Equality of PartitionSpec is determined by spec_id and partition fields only.</p> Source code in <code>pyiceberg/partitioning.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"\n    Produce a boolean to return True if two objects are considered equal.\n\n    Note:\n        Equality of PartitionSpec is determined by spec_id and partition fields only.\n    \"\"\"\n    if not isinstance(other, PartitionSpec):\n        return False\n    return self.spec_id == other.spec_id and self.fields == other.fields\n</code></pre>"},{"location":"reference/pyiceberg/partitioning/#pyiceberg.partitioning.PartitionSpec.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the PartitionSpec class.</p> Source code in <code>pyiceberg/partitioning.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the PartitionSpec class.\"\"\"\n    fields = f\"{', '.join(repr(column) for column in self.fields)}, \" if self.fields else \"\"\n    return f\"PartitionSpec({fields}spec_id={self.spec_id})\"\n</code></pre>"},{"location":"reference/pyiceberg/partitioning/#pyiceberg.partitioning.PartitionSpec.__str__","title":"<code>__str__()</code>","text":"<p>Produce a human-readable string representation of PartitionSpec.</p> Note <p>Only include list of partition fields in the PartitionSpec's string representation.</p> Source code in <code>pyiceberg/partitioning.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Produce a human-readable string representation of PartitionSpec.\n\n    Note:\n        Only include list of partition fields in the PartitionSpec's string representation.\n    \"\"\"\n    result_str = \"[\"\n    if self.fields:\n        result_str += \"\\n  \" + \"\\n  \".join([str(field) for field in self.fields]) + \"\\n\"\n    result_str += \"]\"\n    return result_str\n</code></pre>"},{"location":"reference/pyiceberg/partitioning/#pyiceberg.partitioning.PartitionSpec.compatible_with","title":"<code>compatible_with(other)</code>","text":"<p>Produce a boolean to return True if two PartitionSpec are considered compatible.</p> Source code in <code>pyiceberg/partitioning.py</code> <pre><code>def compatible_with(self, other: PartitionSpec) -&gt; bool:\n    \"\"\"Produce a boolean to return True if two PartitionSpec are considered compatible.\"\"\"\n    if self == other:\n        return True\n    if len(self.fields) != len(other.fields):\n        return False\n    return all(\n        this_field.source_id == that_field.source_id\n        and this_field.transform == that_field.transform\n        and this_field.name == that_field.name\n        for this_field, that_field in zip(self.fields, other.fields)\n    )\n</code></pre>"},{"location":"reference/pyiceberg/partitioning/#pyiceberg.partitioning.PartitionSpec.partition_type","title":"<code>partition_type(schema)</code>","text":"<p>Produce a struct of the PartitionSpec.</p> <p>The partition fields should be optional:</p> <ul> <li>All partition transforms are required to produce null if the input value is null, so it can   happen when the source column is optional.</li> <li>Partition fields may be added later, in which case not all files would have the result field,   and it may be null.</li> </ul> <p>There is a case where we can guarantee that a partition field in the first and only partition spec that uses a required source column will never be null, but it doesn't seem worth tracking this case.</p> <p>:param schema: The schema to bind to. :return: A StructType that represents the PartitionSpec, with a NestedField for each PartitionField.</p> Source code in <code>pyiceberg/partitioning.py</code> <pre><code>def partition_type(self, schema: Schema) -&gt; StructType:\n    \"\"\"Produce a struct of the PartitionSpec.\n\n    The partition fields should be optional:\n\n    - All partition transforms are required to produce null if the input value is null, so it can\n      happen when the source column is optional.\n    - Partition fields may be added later, in which case not all files would have the result field,\n      and it may be null.\n\n    There is a case where we can guarantee that a partition field in the first and only partition spec\n    that uses a required source column will never be null, but it doesn't seem worth tracking this case.\n\n    :param schema: The schema to bind to.\n    :return: A StructType that represents the PartitionSpec, with a NestedField for each PartitionField.\n    \"\"\"\n    nested_fields = []\n    for field in self.fields:\n        source_type = schema.find_type(field.source_id)\n        result_type = field.transform.result_type(source_type)\n        nested_fields.append(NestedField(field.field_id, field.name, result_type, required=False))\n    return StructType(*nested_fields)\n</code></pre>"},{"location":"reference/pyiceberg/schema/","title":"schema","text":""},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Accessor","title":"<code>Accessor</code>  <code>dataclass</code>","text":"<p>An accessor for a specific position in a container that implements the StructProtocol.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@dataclass(init=True, eq=True, frozen=True)\nclass Accessor:\n    \"\"\"An accessor for a specific position in a container that implements the StructProtocol.\"\"\"\n\n    position: int\n    inner: Optional[Accessor] = None\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the Accessor class.\"\"\"\n        return f\"Accessor(position={self.position},inner={self.inner})\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the Accessor class.\"\"\"\n        return self.__str__()\n\n    def get(self, container: StructProtocol) -&gt; Any:\n        \"\"\"Return the value at self.position in `container`.\n\n        Args:\n            container (StructProtocol): A container to access at position `self.position`.\n\n        Returns:\n            Any: The value at position `self.position` in the container.\n        \"\"\"\n        pos = self.position\n        val = container[pos]\n        inner = self\n        while inner.inner:\n            inner = inner.inner\n            val = val[inner.position]\n\n        return val\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Accessor.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the Accessor class.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the Accessor class.\"\"\"\n    return self.__str__()\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Accessor.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the Accessor class.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the Accessor class.\"\"\"\n    return f\"Accessor(position={self.position},inner={self.inner})\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Accessor.get","title":"<code>get(container)</code>","text":"<p>Return the value at self.position in <code>container</code>.</p> <p>Parameters:</p> Name Type Description Default <code>container</code> <code>StructProtocol</code> <p>A container to access at position <code>self.position</code>.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The value at position <code>self.position</code> in the container.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def get(self, container: StructProtocol) -&gt; Any:\n    \"\"\"Return the value at self.position in `container`.\n\n    Args:\n        container (StructProtocol): A container to access at position `self.position`.\n\n    Returns:\n        Any: The value at position `self.position` in the container.\n    \"\"\"\n    pos = self.position\n    val = container[pos]\n    inner = self\n    while inner.inner:\n        inner = inner.inner\n        val = val[inner.position]\n\n    return val\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PartnerAccessor","title":"<code>PartnerAccessor</code>","text":"<p>             Bases: <code>Generic[P]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/schema.py</code> <pre><code>class PartnerAccessor(Generic[P], ABC):\n    @abstractmethod\n    def schema_partner(self, partner: Optional[P]) -&gt; Optional[P]:\n        \"\"\"Return the equivalent of the schema as a struct.\"\"\"\n\n    @abstractmethod\n    def field_partner(self, partner_struct: Optional[P], field_id: int, field_name: str) -&gt; Optional[P]:\n        \"\"\"Return the equivalent struct field by name or id in the partner struct.\"\"\"\n\n    @abstractmethod\n    def list_element_partner(self, partner_list: Optional[P]) -&gt; Optional[P]:\n        \"\"\"Return the equivalent list element in the partner list.\"\"\"\n\n    @abstractmethod\n    def map_key_partner(self, partner_map: Optional[P]) -&gt; Optional[P]:\n        \"\"\"Return the equivalent map key in the partner map.\"\"\"\n\n    @abstractmethod\n    def map_value_partner(self, partner_map: Optional[P]) -&gt; Optional[P]:\n        \"\"\"Return the equivalent map value in the partner map.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PartnerAccessor.field_partner","title":"<code>field_partner(partner_struct, field_id, field_name)</code>  <code>abstractmethod</code>","text":"<p>Return the equivalent struct field by name or id in the partner struct.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef field_partner(self, partner_struct: Optional[P], field_id: int, field_name: str) -&gt; Optional[P]:\n    \"\"\"Return the equivalent struct field by name or id in the partner struct.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PartnerAccessor.list_element_partner","title":"<code>list_element_partner(partner_list)</code>  <code>abstractmethod</code>","text":"<p>Return the equivalent list element in the partner list.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef list_element_partner(self, partner_list: Optional[P]) -&gt; Optional[P]:\n    \"\"\"Return the equivalent list element in the partner list.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PartnerAccessor.map_key_partner","title":"<code>map_key_partner(partner_map)</code>  <code>abstractmethod</code>","text":"<p>Return the equivalent map key in the partner map.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef map_key_partner(self, partner_map: Optional[P]) -&gt; Optional[P]:\n    \"\"\"Return the equivalent map key in the partner map.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PartnerAccessor.map_value_partner","title":"<code>map_value_partner(partner_map)</code>  <code>abstractmethod</code>","text":"<p>Return the equivalent map value in the partner map.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef map_value_partner(self, partner_map: Optional[P]) -&gt; Optional[P]:\n    \"\"\"Return the equivalent map value in the partner map.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PartnerAccessor.schema_partner","title":"<code>schema_partner(partner)</code>  <code>abstractmethod</code>","text":"<p>Return the equivalent of the schema as a struct.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef schema_partner(self, partner: Optional[P]) -&gt; Optional[P]:\n    \"\"\"Return the equivalent of the schema as a struct.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PreOrderSchemaVisitor","title":"<code>PreOrderSchemaVisitor</code>","text":"<p>             Bases: <code>Generic[T]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/schema.py</code> <pre><code>class PreOrderSchemaVisitor(Generic[T], ABC):\n    @abstractmethod\n    def schema(self, schema: Schema, struct_result: Callable[[], T]) -&gt; T:\n        \"\"\"Visit a Schema.\"\"\"\n\n    @abstractmethod\n    def struct(self, struct: StructType, field_results: List[Callable[[], T]]) -&gt; T:\n        \"\"\"Visit a StructType.\"\"\"\n\n    @abstractmethod\n    def field(self, field: NestedField, field_result: Callable[[], T]) -&gt; T:\n        \"\"\"Visit a NestedField.\"\"\"\n\n    @abstractmethod\n    def list(self, list_type: ListType, element_result: Callable[[], T]) -&gt; T:\n        \"\"\"Visit a ListType.\"\"\"\n\n    @abstractmethod\n    def map(self, map_type: MapType, key_result: Callable[[], T], value_result: Callable[[], T]) -&gt; T:\n        \"\"\"Visit a MapType.\"\"\"\n\n    @abstractmethod\n    def primitive(self, primitive: PrimitiveType) -&gt; T:\n        \"\"\"Visit a PrimitiveType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PreOrderSchemaVisitor.field","title":"<code>field(field, field_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a NestedField.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef field(self, field: NestedField, field_result: Callable[[], T]) -&gt; T:\n    \"\"\"Visit a NestedField.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PreOrderSchemaVisitor.list","title":"<code>list(list_type, element_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a ListType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef list(self, list_type: ListType, element_result: Callable[[], T]) -&gt; T:\n    \"\"\"Visit a ListType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PreOrderSchemaVisitor.map","title":"<code>map(map_type, key_result, value_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a MapType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef map(self, map_type: MapType, key_result: Callable[[], T], value_result: Callable[[], T]) -&gt; T:\n    \"\"\"Visit a MapType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PreOrderSchemaVisitor.primitive","title":"<code>primitive(primitive)</code>  <code>abstractmethod</code>","text":"<p>Visit a PrimitiveType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef primitive(self, primitive: PrimitiveType) -&gt; T:\n    \"\"\"Visit a PrimitiveType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PreOrderSchemaVisitor.schema","title":"<code>schema(schema, struct_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a Schema.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef schema(self, schema: Schema, struct_result: Callable[[], T]) -&gt; T:\n    \"\"\"Visit a Schema.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PreOrderSchemaVisitor.struct","title":"<code>struct(struct, field_results)</code>  <code>abstractmethod</code>","text":"<p>Visit a StructType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef struct(self, struct: StructType, field_results: List[Callable[[], T]]) -&gt; T:\n    \"\"\"Visit a StructType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor","title":"<code>PrimitiveWithPartnerVisitor</code>","text":"<p>             Bases: <code>SchemaWithPartnerVisitor[P, T]</code></p> Source code in <code>pyiceberg/schema.py</code> <pre><code>class PrimitiveWithPartnerVisitor(SchemaWithPartnerVisitor[P, T]):\n    def primitive(self, primitive: PrimitiveType, primitive_partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a PrimitiveType.\"\"\"\n        if isinstance(primitive, BooleanType):\n            return self.visit_boolean(primitive, primitive_partner)\n        elif isinstance(primitive, IntegerType):\n            return self.visit_integer(primitive, primitive_partner)\n        elif isinstance(primitive, LongType):\n            return self.visit_long(primitive, primitive_partner)\n        elif isinstance(primitive, FloatType):\n            return self.visit_float(primitive, primitive_partner)\n        elif isinstance(primitive, DoubleType):\n            return self.visit_double(primitive, primitive_partner)\n        elif isinstance(primitive, DecimalType):\n            return self.visit_decimal(primitive, primitive_partner)\n        elif isinstance(primitive, DateType):\n            return self.visit_date(primitive, primitive_partner)\n        elif isinstance(primitive, TimeType):\n            return self.visit_time(primitive, primitive_partner)\n        elif isinstance(primitive, TimestampType):\n            return self.visit_timestamp(primitive, primitive_partner)\n        elif isinstance(primitive, TimestamptzType):\n            return self.visit_timestamptz(primitive, primitive_partner)\n        elif isinstance(primitive, StringType):\n            return self.visit_string(primitive, primitive_partner)\n        elif isinstance(primitive, UUIDType):\n            return self.visit_uuid(primitive, primitive_partner)\n        elif isinstance(primitive, FixedType):\n            return self.visit_fixed(primitive, primitive_partner)\n        elif isinstance(primitive, BinaryType):\n            return self.visit_binary(primitive, primitive_partner)\n        else:\n            raise ValueError(f\"Unknown type: {primitive}\")\n\n    @abstractmethod\n    def visit_boolean(self, boolean_type: BooleanType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a BooleanType.\"\"\"\n\n    @abstractmethod\n    def visit_integer(self, integer_type: IntegerType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a IntegerType.\"\"\"\n\n    @abstractmethod\n    def visit_long(self, long_type: LongType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a LongType.\"\"\"\n\n    @abstractmethod\n    def visit_float(self, float_type: FloatType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a FloatType.\"\"\"\n\n    @abstractmethod\n    def visit_double(self, double_type: DoubleType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a DoubleType.\"\"\"\n\n    @abstractmethod\n    def visit_decimal(self, decimal_type: DecimalType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a DecimalType.\"\"\"\n\n    @abstractmethod\n    def visit_date(self, date_type: DateType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a DecimalType.\"\"\"\n\n    @abstractmethod\n    def visit_time(self, time_type: TimeType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a DecimalType.\"\"\"\n\n    @abstractmethod\n    def visit_timestamp(self, timestamp_type: TimestampType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a TimestampType.\"\"\"\n\n    @abstractmethod\n    def visit_timestamptz(self, timestamptz_type: TimestamptzType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a TimestamptzType.\"\"\"\n\n    @abstractmethod\n    def visit_string(self, string_type: StringType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a StringType.\"\"\"\n\n    @abstractmethod\n    def visit_uuid(self, uuid_type: UUIDType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a UUIDType.\"\"\"\n\n    @abstractmethod\n    def visit_fixed(self, fixed_type: FixedType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a FixedType.\"\"\"\n\n    @abstractmethod\n    def visit_binary(self, binary_type: BinaryType, partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a BinaryType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.primitive","title":"<code>primitive(primitive, primitive_partner)</code>","text":"<p>Visit a PrimitiveType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def primitive(self, primitive: PrimitiveType, primitive_partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a PrimitiveType.\"\"\"\n    if isinstance(primitive, BooleanType):\n        return self.visit_boolean(primitive, primitive_partner)\n    elif isinstance(primitive, IntegerType):\n        return self.visit_integer(primitive, primitive_partner)\n    elif isinstance(primitive, LongType):\n        return self.visit_long(primitive, primitive_partner)\n    elif isinstance(primitive, FloatType):\n        return self.visit_float(primitive, primitive_partner)\n    elif isinstance(primitive, DoubleType):\n        return self.visit_double(primitive, primitive_partner)\n    elif isinstance(primitive, DecimalType):\n        return self.visit_decimal(primitive, primitive_partner)\n    elif isinstance(primitive, DateType):\n        return self.visit_date(primitive, primitive_partner)\n    elif isinstance(primitive, TimeType):\n        return self.visit_time(primitive, primitive_partner)\n    elif isinstance(primitive, TimestampType):\n        return self.visit_timestamp(primitive, primitive_partner)\n    elif isinstance(primitive, TimestamptzType):\n        return self.visit_timestamptz(primitive, primitive_partner)\n    elif isinstance(primitive, StringType):\n        return self.visit_string(primitive, primitive_partner)\n    elif isinstance(primitive, UUIDType):\n        return self.visit_uuid(primitive, primitive_partner)\n    elif isinstance(primitive, FixedType):\n        return self.visit_fixed(primitive, primitive_partner)\n    elif isinstance(primitive, BinaryType):\n        return self.visit_binary(primitive, primitive_partner)\n    else:\n        raise ValueError(f\"Unknown type: {primitive}\")\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_binary","title":"<code>visit_binary(binary_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a BinaryType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_binary(self, binary_type: BinaryType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a BinaryType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_boolean","title":"<code>visit_boolean(boolean_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a BooleanType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_boolean(self, boolean_type: BooleanType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a BooleanType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_date","title":"<code>visit_date(date_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a DecimalType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_date(self, date_type: DateType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a DecimalType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_decimal","title":"<code>visit_decimal(decimal_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a DecimalType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_decimal(self, decimal_type: DecimalType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a DecimalType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_double","title":"<code>visit_double(double_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a DoubleType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_double(self, double_type: DoubleType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a DoubleType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_fixed","title":"<code>visit_fixed(fixed_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a FixedType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_fixed(self, fixed_type: FixedType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a FixedType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_float","title":"<code>visit_float(float_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a FloatType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_float(self, float_type: FloatType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a FloatType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_integer","title":"<code>visit_integer(integer_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a IntegerType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_integer(self, integer_type: IntegerType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a IntegerType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_long","title":"<code>visit_long(long_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a LongType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_long(self, long_type: LongType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a LongType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_string","title":"<code>visit_string(string_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a StringType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_string(self, string_type: StringType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a StringType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_time","title":"<code>visit_time(time_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a DecimalType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_time(self, time_type: TimeType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a DecimalType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_timestamp","title":"<code>visit_timestamp(timestamp_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a TimestampType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_timestamp(self, timestamp_type: TimestampType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a TimestampType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_timestamptz","title":"<code>visit_timestamptz(timestamptz_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a TimestamptzType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_timestamptz(self, timestamptz_type: TimestamptzType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a TimestamptzType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.PrimitiveWithPartnerVisitor.visit_uuid","title":"<code>visit_uuid(uuid_type, partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a UUIDType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_uuid(self, uuid_type: UUIDType, partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a UUIDType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema","title":"<code>Schema</code>","text":"<p>             Bases: <code>IcebergBaseModel</code></p> <p>A table Schema.</p> Example <p>from pyiceberg import schema from pyiceberg import types</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>class Schema(IcebergBaseModel):\n    \"\"\"A table Schema.\n\n    Example:\n        &gt;&gt;&gt; from pyiceberg import schema\n        &gt;&gt;&gt; from pyiceberg import types\n    \"\"\"\n\n    type: Literal[\"struct\"] = \"struct\"\n    fields: Tuple[NestedField, ...] = Field(default_factory=tuple)\n    schema_id: int = Field(alias=\"schema-id\", default=INITIAL_SCHEMA_ID)\n    identifier_field_ids: List[int] = Field(alias=\"identifier-field-ids\", default_factory=list)\n\n    _name_to_id: Dict[str, int] = PrivateAttr()\n\n    def __init__(self, *fields: NestedField, **data: Any):\n        if fields:\n            data[\"fields\"] = fields\n        super().__init__(**data)\n        self._name_to_id = index_by_name(self)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the Schema class.\"\"\"\n        return \"table {\\n\" + \"\\n\".join([\"  \" + str(field) for field in self.columns]) + \"\\n}\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the Schema class.\"\"\"\n        return f\"Schema({', '.join(repr(column) for column in self.columns)}, schema_id={self.schema_id}, identifier_field_ids={self.identifier_field_ids})\"\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the length of an instance of the Literal class.\"\"\"\n        return len(self.fields)\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the Schema class.\"\"\"\n        if not other:\n            return False\n\n        if not isinstance(other, Schema):\n            return False\n\n        if len(self.columns) != len(other.columns):\n            return False\n\n        identifier_field_ids_is_equal = self.identifier_field_ids == other.identifier_field_ids\n        schema_is_equal = all(lhs == rhs for lhs, rhs in zip(self.columns, other.columns))\n\n        return identifier_field_ids_is_equal and schema_is_equal\n\n    @model_validator(mode=\"after\")\n    def check_schema(self) -&gt; Schema:\n        if self.identifier_field_ids:\n            for field_id in self.identifier_field_ids:\n                self._validate_identifier_field(field_id)\n\n        return self\n\n    @property\n    def columns(self) -&gt; Tuple[NestedField, ...]:\n        \"\"\"A tuple of the top-level fields.\"\"\"\n        return self.fields\n\n    @cached_property\n    def _lazy_id_to_field(self) -&gt; Dict[int, NestedField]:\n        \"\"\"Return an index of field ID to NestedField instance.\n\n        This is calculated once when called for the first time. Subsequent calls to this method will use a cached index.\n        \"\"\"\n        return index_by_id(self)\n\n    @cached_property\n    def _lazy_id_to_parent(self) -&gt; Dict[int, int]:\n        \"\"\"Returns an index of field ID to parent field IDs.\n\n        This is calculated once when called for the first time. Subsequent calls to this method will use a cached index.\n        \"\"\"\n        return _index_parents(self)\n\n    @cached_property\n    def _lazy_name_to_id_lower(self) -&gt; Dict[str, int]:\n        \"\"\"Return an index of lower-case field names to field IDs.\n\n        This is calculated once when called for the first time. Subsequent calls to this method will use a cached index.\n        \"\"\"\n        return {name.lower(): field_id for name, field_id in self._name_to_id.items()}\n\n    @cached_property\n    def _lazy_id_to_name(self) -&gt; Dict[int, str]:\n        \"\"\"Return an index of field ID to full name.\n\n        This is calculated once when called for the first time. Subsequent calls to this method will use a cached index.\n        \"\"\"\n        return index_name_by_id(self)\n\n    @cached_property\n    def _lazy_id_to_accessor(self) -&gt; Dict[int, Accessor]:\n        \"\"\"Return an index of field ID to accessor.\n\n        This is calculated once when called for the first time. Subsequent calls to this method will use a cached index.\n        \"\"\"\n        return build_position_accessors(self)\n\n    def as_struct(self) -&gt; StructType:\n        \"\"\"Return the schema as a struct.\"\"\"\n        return StructType(*self.fields)\n\n    def find_field(self, name_or_id: Union[str, int], case_sensitive: bool = True) -&gt; NestedField:\n        \"\"\"Find a field using a field name or field ID.\n\n        Args:\n            name_or_id (Union[str, int]): Either a field name or a field ID.\n            case_sensitive (bool, optional): Whether to perform a case-sensitive lookup using a field name. Defaults to True.\n\n        Raises:\n            ValueError: When the value cannot be found.\n\n        Returns:\n            NestedField: The matched NestedField.\n        \"\"\"\n        if isinstance(name_or_id, int):\n            if name_or_id not in self._lazy_id_to_field:\n                raise ValueError(f\"Could not find field with id: {name_or_id}\")\n            return self._lazy_id_to_field[name_or_id]\n\n        if case_sensitive:\n            field_id = self._name_to_id.get(name_or_id)\n        else:\n            field_id = self._lazy_name_to_id_lower.get(name_or_id.lower())\n\n        if field_id is None:\n            raise ValueError(f\"Could not find field with name {name_or_id}, case_sensitive={case_sensitive}\")\n\n        return self._lazy_id_to_field[field_id]\n\n    def find_type(self, name_or_id: Union[str, int], case_sensitive: bool = True) -&gt; IcebergType:\n        \"\"\"Find a field type using a field name or field ID.\n\n        Args:\n            name_or_id (Union[str, int]): Either a field name or a field ID.\n            case_sensitive (bool, optional): Whether to perform a case-sensitive lookup using a field name. Defaults to True.\n\n        Returns:\n            NestedField: The type of the matched NestedField.\n        \"\"\"\n        field = self.find_field(name_or_id=name_or_id, case_sensitive=case_sensitive)\n        if not field:\n            raise ValueError(f\"Could not find field with name or id {name_or_id}, case_sensitive={case_sensitive}\")\n        return field.field_type\n\n    @property\n    def highest_field_id(self) -&gt; int:\n        return max(self._lazy_id_to_name.keys(), default=0)\n\n    def find_column_name(self, column_id: int) -&gt; Optional[str]:\n        \"\"\"Find a column name given a column ID.\n\n        Args:\n            column_id (int): The ID of the column.\n\n        Returns:\n            str: The column name (or None if the column ID cannot be found).\n        \"\"\"\n        return self._lazy_id_to_name.get(column_id)\n\n    @property\n    def column_names(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of all the column names, including nested fields.\n\n        Excludes short names.\n\n        Returns:\n            List[str]: The column names.\n        \"\"\"\n        return list(self._lazy_id_to_name.values())\n\n    def accessor_for_field(self, field_id: int) -&gt; Accessor:\n        \"\"\"Find a schema position accessor given a field ID.\n\n        Args:\n            field_id (int): The ID of the field.\n\n        Raises:\n            ValueError: When the value cannot be found.\n\n        Returns:\n            Accessor: An accessor for the given field ID.\n        \"\"\"\n        if field_id not in self._lazy_id_to_accessor:\n            raise ValueError(f\"Could not find accessor for field with id: {field_id}\")\n\n        return self._lazy_id_to_accessor[field_id]\n\n    def identifier_field_names(self) -&gt; Set[str]:\n        \"\"\"Return the names of the identifier fields.\n\n        Returns:\n            Set of names of the identifier fields\n        \"\"\"\n        ids = set()\n        for field_id in self.identifier_field_ids:\n            column_name = self.find_column_name(field_id)\n            if column_name is None:\n                raise ValueError(f\"Could not find identifier column id: {field_id}\")\n            ids.add(column_name)\n\n        return ids\n\n    def select(self, *names: str, case_sensitive: bool = True) -&gt; Schema:\n        \"\"\"Return a new schema instance pruned to a subset of columns.\n\n        Args:\n            names (List[str]): A list of column names.\n            case_sensitive (bool, optional): Whether to perform a case-sensitive lookup for each column name. Defaults to True.\n\n        Returns:\n            Schema: A new schema with pruned columns.\n\n        Raises:\n            ValueError: If a column is selected that doesn't exist.\n        \"\"\"\n        try:\n            if case_sensitive:\n                ids = {self._name_to_id[name] for name in names}\n            else:\n                ids = {self._lazy_name_to_id_lower[name.lower()] for name in names}\n        except KeyError as e:\n            raise ValueError(f\"Could not find column: {e}\") from e\n\n        return prune_columns(self, ids)\n\n    @property\n    def field_ids(self) -&gt; Set[int]:\n        \"\"\"Return the IDs of the current schema.\"\"\"\n        return set(self._name_to_id.values())\n\n    def _validate_identifier_field(self, field_id: int) -&gt; None:\n        \"\"\"Validate that the field with the given ID is a valid identifier field.\n\n        Args:\n          field_id: The ID of the field to validate.\n\n        Raises:\n          ValueError: If the field is not valid.\n        \"\"\"\n        field = self.find_field(field_id)\n        if not field.field_type.is_primitive:\n            raise ValueError(f\"Identifier field {field_id} invalid: not a primitive type field\")\n\n        if not field.required:\n            raise ValueError(f\"Identifier field {field_id} invalid: not a required field\")\n\n        if isinstance(field.field_type, (DoubleType, FloatType)):\n            raise ValueError(f\"Identifier field {field_id} invalid: must not be float or double field\")\n\n        # Check whether the nested field is in a chain of required struct fields\n        # Exploring from root for better error message for list and map types\n        parent_id = self._lazy_id_to_parent.get(field.field_id)\n        fields: List[int] = []\n        while parent_id is not None:\n            fields.append(parent_id)\n            parent_id = self._lazy_id_to_parent.get(parent_id)\n\n        while fields:\n            parent = self.find_field(fields.pop())\n            if not parent.field_type.is_struct:\n                raise ValueError(f\"Cannot add field {field.name} as an identifier field: must not be nested in {parent}\")\n\n            if not parent.required:\n                raise ValueError(\n                    f\"Cannot add field {field.name} as an identifier field: must not be nested in an optional field {parent}\"\n                )\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.column_names","title":"<code>column_names: List[str]</code>  <code>property</code>","text":"<p>Return a list of all the column names, including nested fields.</p> <p>Excludes short names.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: The column names.</p>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.columns","title":"<code>columns: Tuple[NestedField, ...]</code>  <code>property</code>","text":"<p>A tuple of the top-level fields.</p>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.field_ids","title":"<code>field_ids: Set[int]</code>  <code>property</code>","text":"<p>Return the IDs of the current schema.</p>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the Schema class.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the Schema class.\"\"\"\n    if not other:\n        return False\n\n    if not isinstance(other, Schema):\n        return False\n\n    if len(self.columns) != len(other.columns):\n        return False\n\n    identifier_field_ids_is_equal = self.identifier_field_ids == other.identifier_field_ids\n    schema_is_equal = all(lhs == rhs for lhs, rhs in zip(self.columns, other.columns))\n\n    return identifier_field_ids_is_equal and schema_is_equal\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of an instance of the Literal class.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the length of an instance of the Literal class.\"\"\"\n    return len(self.fields)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the Schema class.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the Schema class.\"\"\"\n    return f\"Schema({', '.join(repr(column) for column in self.columns)}, schema_id={self.schema_id}, identifier_field_ids={self.identifier_field_ids})\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the Schema class.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the Schema class.\"\"\"\n    return \"table {\\n\" + \"\\n\".join([\"  \" + str(field) for field in self.columns]) + \"\\n}\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.accessor_for_field","title":"<code>accessor_for_field(field_id)</code>","text":"<p>Find a schema position accessor given a field ID.</p> <p>Parameters:</p> Name Type Description Default <code>field_id</code> <code>int</code> <p>The ID of the field.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>When the value cannot be found.</p> <p>Returns:</p> Name Type Description <code>Accessor</code> <code>Accessor</code> <p>An accessor for the given field ID.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def accessor_for_field(self, field_id: int) -&gt; Accessor:\n    \"\"\"Find a schema position accessor given a field ID.\n\n    Args:\n        field_id (int): The ID of the field.\n\n    Raises:\n        ValueError: When the value cannot be found.\n\n    Returns:\n        Accessor: An accessor for the given field ID.\n    \"\"\"\n    if field_id not in self._lazy_id_to_accessor:\n        raise ValueError(f\"Could not find accessor for field with id: {field_id}\")\n\n    return self._lazy_id_to_accessor[field_id]\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.as_struct","title":"<code>as_struct()</code>","text":"<p>Return the schema as a struct.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def as_struct(self) -&gt; StructType:\n    \"\"\"Return the schema as a struct.\"\"\"\n    return StructType(*self.fields)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.find_column_name","title":"<code>find_column_name(column_id)</code>","text":"<p>Find a column name given a column ID.</p> <p>Parameters:</p> Name Type Description Default <code>column_id</code> <code>int</code> <p>The ID of the column.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>Optional[str]</code> <p>The column name (or None if the column ID cannot be found).</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def find_column_name(self, column_id: int) -&gt; Optional[str]:\n    \"\"\"Find a column name given a column ID.\n\n    Args:\n        column_id (int): The ID of the column.\n\n    Returns:\n        str: The column name (or None if the column ID cannot be found).\n    \"\"\"\n    return self._lazy_id_to_name.get(column_id)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.find_field","title":"<code>find_field(name_or_id, case_sensitive=True)</code>","text":"<p>Find a field using a field name or field ID.</p> <p>Parameters:</p> Name Type Description Default <code>name_or_id</code> <code>Union[str, int]</code> <p>Either a field name or a field ID.</p> required <code>case_sensitive</code> <code>bool</code> <p>Whether to perform a case-sensitive lookup using a field name. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>When the value cannot be found.</p> <p>Returns:</p> Name Type Description <code>NestedField</code> <code>NestedField</code> <p>The matched NestedField.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def find_field(self, name_or_id: Union[str, int], case_sensitive: bool = True) -&gt; NestedField:\n    \"\"\"Find a field using a field name or field ID.\n\n    Args:\n        name_or_id (Union[str, int]): Either a field name or a field ID.\n        case_sensitive (bool, optional): Whether to perform a case-sensitive lookup using a field name. Defaults to True.\n\n    Raises:\n        ValueError: When the value cannot be found.\n\n    Returns:\n        NestedField: The matched NestedField.\n    \"\"\"\n    if isinstance(name_or_id, int):\n        if name_or_id not in self._lazy_id_to_field:\n            raise ValueError(f\"Could not find field with id: {name_or_id}\")\n        return self._lazy_id_to_field[name_or_id]\n\n    if case_sensitive:\n        field_id = self._name_to_id.get(name_or_id)\n    else:\n        field_id = self._lazy_name_to_id_lower.get(name_or_id.lower())\n\n    if field_id is None:\n        raise ValueError(f\"Could not find field with name {name_or_id}, case_sensitive={case_sensitive}\")\n\n    return self._lazy_id_to_field[field_id]\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.find_type","title":"<code>find_type(name_or_id, case_sensitive=True)</code>","text":"<p>Find a field type using a field name or field ID.</p> <p>Parameters:</p> Name Type Description Default <code>name_or_id</code> <code>Union[str, int]</code> <p>Either a field name or a field ID.</p> required <code>case_sensitive</code> <code>bool</code> <p>Whether to perform a case-sensitive lookup using a field name. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>NestedField</code> <code>IcebergType</code> <p>The type of the matched NestedField.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def find_type(self, name_or_id: Union[str, int], case_sensitive: bool = True) -&gt; IcebergType:\n    \"\"\"Find a field type using a field name or field ID.\n\n    Args:\n        name_or_id (Union[str, int]): Either a field name or a field ID.\n        case_sensitive (bool, optional): Whether to perform a case-sensitive lookup using a field name. Defaults to True.\n\n    Returns:\n        NestedField: The type of the matched NestedField.\n    \"\"\"\n    field = self.find_field(name_or_id=name_or_id, case_sensitive=case_sensitive)\n    if not field:\n        raise ValueError(f\"Could not find field with name or id {name_or_id}, case_sensitive={case_sensitive}\")\n    return field.field_type\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.identifier_field_names","title":"<code>identifier_field_names()</code>","text":"<p>Return the names of the identifier fields.</p> <p>Returns:</p> Type Description <code>Set[str]</code> <p>Set of names of the identifier fields</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def identifier_field_names(self) -&gt; Set[str]:\n    \"\"\"Return the names of the identifier fields.\n\n    Returns:\n        Set of names of the identifier fields\n    \"\"\"\n    ids = set()\n    for field_id in self.identifier_field_ids:\n        column_name = self.find_column_name(field_id)\n        if column_name is None:\n            raise ValueError(f\"Could not find identifier column id: {field_id}\")\n        ids.add(column_name)\n\n    return ids\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.Schema.select","title":"<code>select(*names, case_sensitive=True)</code>","text":"<p>Return a new schema instance pruned to a subset of columns.</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>List[str]</code> <p>A list of column names.</p> <code>()</code> <code>case_sensitive</code> <code>bool</code> <p>Whether to perform a case-sensitive lookup for each column name. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>Schema</code> <code>Schema</code> <p>A new schema with pruned columns.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a column is selected that doesn't exist.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def select(self, *names: str, case_sensitive: bool = True) -&gt; Schema:\n    \"\"\"Return a new schema instance pruned to a subset of columns.\n\n    Args:\n        names (List[str]): A list of column names.\n        case_sensitive (bool, optional): Whether to perform a case-sensitive lookup for each column name. Defaults to True.\n\n    Returns:\n        Schema: A new schema with pruned columns.\n\n    Raises:\n        ValueError: If a column is selected that doesn't exist.\n    \"\"\"\n    try:\n        if case_sensitive:\n            ids = {self._name_to_id[name] for name in names}\n        else:\n            ids = {self._lazy_name_to_id_lower[name.lower()] for name in names}\n    except KeyError as e:\n        raise ValueError(f\"Could not find column: {e}\") from e\n\n    return prune_columns(self, ids)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor","title":"<code>SchemaVisitor</code>","text":"<p>             Bases: <code>Generic[T]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/schema.py</code> <pre><code>class SchemaVisitor(Generic[T], ABC):\n    def before_field(self, field: NestedField) -&gt; None:\n        \"\"\"Override this method to perform an action immediately before visiting a field.\"\"\"\n\n    def after_field(self, field: NestedField) -&gt; None:\n        \"\"\"Override this method to perform an action immediately after visiting a field.\"\"\"\n\n    def before_list_element(self, element: NestedField) -&gt; None:\n        \"\"\"Override this method to perform an action immediately before visiting an element within a ListType.\"\"\"\n        self.before_field(element)\n\n    def after_list_element(self, element: NestedField) -&gt; None:\n        \"\"\"Override this method to perform an action immediately after visiting an element within a ListType.\"\"\"\n        self.after_field(element)\n\n    def before_map_key(self, key: NestedField) -&gt; None:\n        \"\"\"Override this method to perform an action immediately before visiting a key within a MapType.\"\"\"\n        self.before_field(key)\n\n    def after_map_key(self, key: NestedField) -&gt; None:\n        \"\"\"Override this method to perform an action immediately after visiting a key within a MapType.\"\"\"\n        self.after_field(key)\n\n    def before_map_value(self, value: NestedField) -&gt; None:\n        \"\"\"Override this method to perform an action immediately before visiting a value within a MapType.\"\"\"\n        self.before_field(value)\n\n    def after_map_value(self, value: NestedField) -&gt; None:\n        \"\"\"Override this method to perform an action immediately after visiting a value within a MapType.\"\"\"\n        self.after_field(value)\n\n    @abstractmethod\n    def schema(self, schema: Schema, struct_result: T) -&gt; T:\n        \"\"\"Visit a Schema.\"\"\"\n\n    @abstractmethod\n    def struct(self, struct: StructType, field_results: List[T]) -&gt; T:\n        \"\"\"Visit a StructType.\"\"\"\n\n    @abstractmethod\n    def field(self, field: NestedField, field_result: T) -&gt; T:\n        \"\"\"Visit a NestedField.\"\"\"\n\n    @abstractmethod\n    def list(self, list_type: ListType, element_result: T) -&gt; T:\n        \"\"\"Visit a ListType.\"\"\"\n\n    @abstractmethod\n    def map(self, map_type: MapType, key_result: T, value_result: T) -&gt; T:\n        \"\"\"Visit a MapType.\"\"\"\n\n    @abstractmethod\n    def primitive(self, primitive: PrimitiveType) -&gt; T:\n        \"\"\"Visit a PrimitiveType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.after_field","title":"<code>after_field(field)</code>","text":"<p>Override this method to perform an action immediately after visiting a field.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def after_field(self, field: NestedField) -&gt; None:\n    \"\"\"Override this method to perform an action immediately after visiting a field.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.after_list_element","title":"<code>after_list_element(element)</code>","text":"<p>Override this method to perform an action immediately after visiting an element within a ListType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def after_list_element(self, element: NestedField) -&gt; None:\n    \"\"\"Override this method to perform an action immediately after visiting an element within a ListType.\"\"\"\n    self.after_field(element)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.after_map_key","title":"<code>after_map_key(key)</code>","text":"<p>Override this method to perform an action immediately after visiting a key within a MapType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def after_map_key(self, key: NestedField) -&gt; None:\n    \"\"\"Override this method to perform an action immediately after visiting a key within a MapType.\"\"\"\n    self.after_field(key)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.after_map_value","title":"<code>after_map_value(value)</code>","text":"<p>Override this method to perform an action immediately after visiting a value within a MapType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def after_map_value(self, value: NestedField) -&gt; None:\n    \"\"\"Override this method to perform an action immediately after visiting a value within a MapType.\"\"\"\n    self.after_field(value)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.before_field","title":"<code>before_field(field)</code>","text":"<p>Override this method to perform an action immediately before visiting a field.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def before_field(self, field: NestedField) -&gt; None:\n    \"\"\"Override this method to perform an action immediately before visiting a field.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.before_list_element","title":"<code>before_list_element(element)</code>","text":"<p>Override this method to perform an action immediately before visiting an element within a ListType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def before_list_element(self, element: NestedField) -&gt; None:\n    \"\"\"Override this method to perform an action immediately before visiting an element within a ListType.\"\"\"\n    self.before_field(element)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.before_map_key","title":"<code>before_map_key(key)</code>","text":"<p>Override this method to perform an action immediately before visiting a key within a MapType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def before_map_key(self, key: NestedField) -&gt; None:\n    \"\"\"Override this method to perform an action immediately before visiting a key within a MapType.\"\"\"\n    self.before_field(key)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.before_map_value","title":"<code>before_map_value(value)</code>","text":"<p>Override this method to perform an action immediately before visiting a value within a MapType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def before_map_value(self, value: NestedField) -&gt; None:\n    \"\"\"Override this method to perform an action immediately before visiting a value within a MapType.\"\"\"\n    self.before_field(value)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.field","title":"<code>field(field, field_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a NestedField.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef field(self, field: NestedField, field_result: T) -&gt; T:\n    \"\"\"Visit a NestedField.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.list","title":"<code>list(list_type, element_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a ListType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef list(self, list_type: ListType, element_result: T) -&gt; T:\n    \"\"\"Visit a ListType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.map","title":"<code>map(map_type, key_result, value_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a MapType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef map(self, map_type: MapType, key_result: T, value_result: T) -&gt; T:\n    \"\"\"Visit a MapType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.primitive","title":"<code>primitive(primitive)</code>  <code>abstractmethod</code>","text":"<p>Visit a PrimitiveType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef primitive(self, primitive: PrimitiveType) -&gt; T:\n    \"\"\"Visit a PrimitiveType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.schema","title":"<code>schema(schema, struct_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a Schema.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef schema(self, schema: Schema, struct_result: T) -&gt; T:\n    \"\"\"Visit a Schema.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitor.struct","title":"<code>struct(struct, field_results)</code>  <code>abstractmethod</code>","text":"<p>Visit a StructType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef struct(self, struct: StructType, field_results: List[T]) -&gt; T:\n    \"\"\"Visit a StructType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType","title":"<code>SchemaVisitorPerPrimitiveType</code>","text":"<p>             Bases: <code>SchemaVisitor[T]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/schema.py</code> <pre><code>class SchemaVisitorPerPrimitiveType(SchemaVisitor[T], ABC):\n    def primitive(self, primitive: PrimitiveType) -&gt; T:\n        \"\"\"Visit a PrimitiveType.\"\"\"\n        if isinstance(primitive, FixedType):\n            return self.visit_fixed(primitive)\n        elif isinstance(primitive, DecimalType):\n            return self.visit_decimal(primitive)\n        elif isinstance(primitive, BooleanType):\n            return self.visit_boolean(primitive)\n        elif isinstance(primitive, IntegerType):\n            return self.visit_integer(primitive)\n        elif isinstance(primitive, LongType):\n            return self.visit_long(primitive)\n        elif isinstance(primitive, FloatType):\n            return self.visit_float(primitive)\n        elif isinstance(primitive, DoubleType):\n            return self.visit_double(primitive)\n        elif isinstance(primitive, DateType):\n            return self.visit_date(primitive)\n        elif isinstance(primitive, TimeType):\n            return self.visit_time(primitive)\n        elif isinstance(primitive, TimestampType):\n            return self.visit_timestamp(primitive)\n        elif isinstance(primitive, TimestamptzType):\n            return self.visit_timestamptz(primitive)\n        elif isinstance(primitive, StringType):\n            return self.visit_string(primitive)\n        elif isinstance(primitive, UUIDType):\n            return self.visit_uuid(primitive)\n        elif isinstance(primitive, BinaryType):\n            return self.visit_binary(primitive)\n        else:\n            raise ValueError(f\"Unknown type: {primitive}\")\n\n    @abstractmethod\n    def visit_fixed(self, fixed_type: FixedType) -&gt; T:\n        \"\"\"Visit a FixedType.\"\"\"\n\n    @abstractmethod\n    def visit_decimal(self, decimal_type: DecimalType) -&gt; T:\n        \"\"\"Visit a DecimalType.\"\"\"\n\n    @abstractmethod\n    def visit_boolean(self, boolean_type: BooleanType) -&gt; T:\n        \"\"\"Visit a BooleanType.\"\"\"\n\n    @abstractmethod\n    def visit_integer(self, integer_type: IntegerType) -&gt; T:\n        \"\"\"Visit a IntegerType.\"\"\"\n\n    @abstractmethod\n    def visit_long(self, long_type: LongType) -&gt; T:\n        \"\"\"Visit a LongType.\"\"\"\n\n    @abstractmethod\n    def visit_float(self, float_type: FloatType) -&gt; T:\n        \"\"\"Visit a FloatType.\"\"\"\n\n    @abstractmethod\n    def visit_double(self, double_type: DoubleType) -&gt; T:\n        \"\"\"Visit a DoubleType.\"\"\"\n\n    @abstractmethod\n    def visit_date(self, date_type: DateType) -&gt; T:\n        \"\"\"Visit a DecimalType.\"\"\"\n\n    @abstractmethod\n    def visit_time(self, time_type: TimeType) -&gt; T:\n        \"\"\"Visit a DecimalType.\"\"\"\n\n    @abstractmethod\n    def visit_timestamp(self, timestamp_type: TimestampType) -&gt; T:\n        \"\"\"Visit a TimestampType.\"\"\"\n\n    @abstractmethod\n    def visit_timestamptz(self, timestamptz_type: TimestamptzType) -&gt; T:\n        \"\"\"Visit a TimestamptzType.\"\"\"\n\n    @abstractmethod\n    def visit_string(self, string_type: StringType) -&gt; T:\n        \"\"\"Visit a StringType.\"\"\"\n\n    @abstractmethod\n    def visit_uuid(self, uuid_type: UUIDType) -&gt; T:\n        \"\"\"Visit a UUIDType.\"\"\"\n\n    @abstractmethod\n    def visit_binary(self, binary_type: BinaryType) -&gt; T:\n        \"\"\"Visit a BinaryType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.primitive","title":"<code>primitive(primitive)</code>","text":"<p>Visit a PrimitiveType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def primitive(self, primitive: PrimitiveType) -&gt; T:\n    \"\"\"Visit a PrimitiveType.\"\"\"\n    if isinstance(primitive, FixedType):\n        return self.visit_fixed(primitive)\n    elif isinstance(primitive, DecimalType):\n        return self.visit_decimal(primitive)\n    elif isinstance(primitive, BooleanType):\n        return self.visit_boolean(primitive)\n    elif isinstance(primitive, IntegerType):\n        return self.visit_integer(primitive)\n    elif isinstance(primitive, LongType):\n        return self.visit_long(primitive)\n    elif isinstance(primitive, FloatType):\n        return self.visit_float(primitive)\n    elif isinstance(primitive, DoubleType):\n        return self.visit_double(primitive)\n    elif isinstance(primitive, DateType):\n        return self.visit_date(primitive)\n    elif isinstance(primitive, TimeType):\n        return self.visit_time(primitive)\n    elif isinstance(primitive, TimestampType):\n        return self.visit_timestamp(primitive)\n    elif isinstance(primitive, TimestamptzType):\n        return self.visit_timestamptz(primitive)\n    elif isinstance(primitive, StringType):\n        return self.visit_string(primitive)\n    elif isinstance(primitive, UUIDType):\n        return self.visit_uuid(primitive)\n    elif isinstance(primitive, BinaryType):\n        return self.visit_binary(primitive)\n    else:\n        raise ValueError(f\"Unknown type: {primitive}\")\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_binary","title":"<code>visit_binary(binary_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a BinaryType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_binary(self, binary_type: BinaryType) -&gt; T:\n    \"\"\"Visit a BinaryType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_boolean","title":"<code>visit_boolean(boolean_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a BooleanType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_boolean(self, boolean_type: BooleanType) -&gt; T:\n    \"\"\"Visit a BooleanType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_date","title":"<code>visit_date(date_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a DecimalType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_date(self, date_type: DateType) -&gt; T:\n    \"\"\"Visit a DecimalType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_decimal","title":"<code>visit_decimal(decimal_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a DecimalType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_decimal(self, decimal_type: DecimalType) -&gt; T:\n    \"\"\"Visit a DecimalType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_double","title":"<code>visit_double(double_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a DoubleType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_double(self, double_type: DoubleType) -&gt; T:\n    \"\"\"Visit a DoubleType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_fixed","title":"<code>visit_fixed(fixed_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a FixedType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_fixed(self, fixed_type: FixedType) -&gt; T:\n    \"\"\"Visit a FixedType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_float","title":"<code>visit_float(float_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a FloatType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_float(self, float_type: FloatType) -&gt; T:\n    \"\"\"Visit a FloatType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_integer","title":"<code>visit_integer(integer_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a IntegerType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_integer(self, integer_type: IntegerType) -&gt; T:\n    \"\"\"Visit a IntegerType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_long","title":"<code>visit_long(long_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a LongType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_long(self, long_type: LongType) -&gt; T:\n    \"\"\"Visit a LongType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_string","title":"<code>visit_string(string_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a StringType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_string(self, string_type: StringType) -&gt; T:\n    \"\"\"Visit a StringType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_time","title":"<code>visit_time(time_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a DecimalType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_time(self, time_type: TimeType) -&gt; T:\n    \"\"\"Visit a DecimalType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_timestamp","title":"<code>visit_timestamp(timestamp_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a TimestampType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_timestamp(self, timestamp_type: TimestampType) -&gt; T:\n    \"\"\"Visit a TimestampType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_timestamptz","title":"<code>visit_timestamptz(timestamptz_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a TimestamptzType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_timestamptz(self, timestamptz_type: TimestamptzType) -&gt; T:\n    \"\"\"Visit a TimestamptzType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaVisitorPerPrimitiveType.visit_uuid","title":"<code>visit_uuid(uuid_type)</code>  <code>abstractmethod</code>","text":"<p>Visit a UUIDType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef visit_uuid(self, uuid_type: UUIDType) -&gt; T:\n    \"\"\"Visit a UUIDType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor","title":"<code>SchemaWithPartnerVisitor</code>","text":"<p>             Bases: <code>Generic[P, T]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/schema.py</code> <pre><code>class SchemaWithPartnerVisitor(Generic[P, T], ABC):\n    def before_field(self, field: NestedField, field_partner: Optional[P]) -&gt; None:\n        \"\"\"Override this method to perform an action immediately before visiting a field.\"\"\"\n\n    def after_field(self, field: NestedField, field_partner: Optional[P]) -&gt; None:\n        \"\"\"Override this method to perform an action immediately after visiting a field.\"\"\"\n\n    def before_list_element(self, element: NestedField, element_partner: Optional[P]) -&gt; None:\n        \"\"\"Override this method to perform an action immediately before visiting an element within a ListType.\"\"\"\n        self.before_field(element, element_partner)\n\n    def after_list_element(self, element: NestedField, element_partner: Optional[P]) -&gt; None:\n        \"\"\"Override this method to perform an action immediately after visiting an element within a ListType.\"\"\"\n        self.after_field(element, element_partner)\n\n    def before_map_key(self, key: NestedField, key_partner: Optional[P]) -&gt; None:\n        \"\"\"Override this method to perform an action immediately before visiting a key within a MapType.\"\"\"\n        self.before_field(key, key_partner)\n\n    def after_map_key(self, key: NestedField, key_partner: Optional[P]) -&gt; None:\n        \"\"\"Override this method to perform an action immediately after visiting a key within a MapType.\"\"\"\n        self.after_field(key, key_partner)\n\n    def before_map_value(self, value: NestedField, value_partner: Optional[P]) -&gt; None:\n        \"\"\"Override this method to perform an action immediately before visiting a value within a MapType.\"\"\"\n        self.before_field(value, value_partner)\n\n    def after_map_value(self, value: NestedField, value_partner: Optional[P]) -&gt; None:\n        \"\"\"Override this method to perform an action immediately after visiting a value within a MapType.\"\"\"\n        self.after_field(value, value_partner)\n\n    @abstractmethod\n    def schema(self, schema: Schema, schema_partner: Optional[P], struct_result: T) -&gt; T:\n        \"\"\"Visit a schema with a partner.\"\"\"\n\n    @abstractmethod\n    def struct(self, struct: StructType, struct_partner: Optional[P], field_results: List[T]) -&gt; T:\n        \"\"\"Visit a struct type with a partner.\"\"\"\n\n    @abstractmethod\n    def field(self, field: NestedField, field_partner: Optional[P], field_result: T) -&gt; T:\n        \"\"\"Visit a nested field with a partner.\"\"\"\n\n    @abstractmethod\n    def list(self, list_type: ListType, list_partner: Optional[P], element_result: T) -&gt; T:\n        \"\"\"Visit a list type with a partner.\"\"\"\n\n    @abstractmethod\n    def map(self, map_type: MapType, map_partner: Optional[P], key_result: T, value_result: T) -&gt; T:\n        \"\"\"Visit a map type with a partner.\"\"\"\n\n    @abstractmethod\n    def primitive(self, primitive: PrimitiveType, primitive_partner: Optional[P]) -&gt; T:\n        \"\"\"Visit a primitive type with a partner.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.after_field","title":"<code>after_field(field, field_partner)</code>","text":"<p>Override this method to perform an action immediately after visiting a field.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def after_field(self, field: NestedField, field_partner: Optional[P]) -&gt; None:\n    \"\"\"Override this method to perform an action immediately after visiting a field.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.after_list_element","title":"<code>after_list_element(element, element_partner)</code>","text":"<p>Override this method to perform an action immediately after visiting an element within a ListType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def after_list_element(self, element: NestedField, element_partner: Optional[P]) -&gt; None:\n    \"\"\"Override this method to perform an action immediately after visiting an element within a ListType.\"\"\"\n    self.after_field(element, element_partner)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.after_map_key","title":"<code>after_map_key(key, key_partner)</code>","text":"<p>Override this method to perform an action immediately after visiting a key within a MapType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def after_map_key(self, key: NestedField, key_partner: Optional[P]) -&gt; None:\n    \"\"\"Override this method to perform an action immediately after visiting a key within a MapType.\"\"\"\n    self.after_field(key, key_partner)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.after_map_value","title":"<code>after_map_value(value, value_partner)</code>","text":"<p>Override this method to perform an action immediately after visiting a value within a MapType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def after_map_value(self, value: NestedField, value_partner: Optional[P]) -&gt; None:\n    \"\"\"Override this method to perform an action immediately after visiting a value within a MapType.\"\"\"\n    self.after_field(value, value_partner)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.before_field","title":"<code>before_field(field, field_partner)</code>","text":"<p>Override this method to perform an action immediately before visiting a field.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def before_field(self, field: NestedField, field_partner: Optional[P]) -&gt; None:\n    \"\"\"Override this method to perform an action immediately before visiting a field.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.before_list_element","title":"<code>before_list_element(element, element_partner)</code>","text":"<p>Override this method to perform an action immediately before visiting an element within a ListType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def before_list_element(self, element: NestedField, element_partner: Optional[P]) -&gt; None:\n    \"\"\"Override this method to perform an action immediately before visiting an element within a ListType.\"\"\"\n    self.before_field(element, element_partner)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.before_map_key","title":"<code>before_map_key(key, key_partner)</code>","text":"<p>Override this method to perform an action immediately before visiting a key within a MapType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def before_map_key(self, key: NestedField, key_partner: Optional[P]) -&gt; None:\n    \"\"\"Override this method to perform an action immediately before visiting a key within a MapType.\"\"\"\n    self.before_field(key, key_partner)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.before_map_value","title":"<code>before_map_value(value, value_partner)</code>","text":"<p>Override this method to perform an action immediately before visiting a value within a MapType.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def before_map_value(self, value: NestedField, value_partner: Optional[P]) -&gt; None:\n    \"\"\"Override this method to perform an action immediately before visiting a value within a MapType.\"\"\"\n    self.before_field(value, value_partner)\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.field","title":"<code>field(field, field_partner, field_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a nested field with a partner.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef field(self, field: NestedField, field_partner: Optional[P], field_result: T) -&gt; T:\n    \"\"\"Visit a nested field with a partner.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.list","title":"<code>list(list_type, list_partner, element_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a list type with a partner.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef list(self, list_type: ListType, list_partner: Optional[P], element_result: T) -&gt; T:\n    \"\"\"Visit a list type with a partner.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.map","title":"<code>map(map_type, map_partner, key_result, value_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a map type with a partner.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef map(self, map_type: MapType, map_partner: Optional[P], key_result: T, value_result: T) -&gt; T:\n    \"\"\"Visit a map type with a partner.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.primitive","title":"<code>primitive(primitive, primitive_partner)</code>  <code>abstractmethod</code>","text":"<p>Visit a primitive type with a partner.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef primitive(self, primitive: PrimitiveType, primitive_partner: Optional[P]) -&gt; T:\n    \"\"\"Visit a primitive type with a partner.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.schema","title":"<code>schema(schema, schema_partner, struct_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a schema with a partner.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef schema(self, schema: Schema, schema_partner: Optional[P], struct_result: T) -&gt; T:\n    \"\"\"Visit a schema with a partner.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.SchemaWithPartnerVisitor.struct","title":"<code>struct(struct, struct_partner, field_results)</code>  <code>abstractmethod</code>","text":"<p>Visit a struct type with a partner.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@abstractmethod\ndef struct(self, struct: StructType, struct_partner: Optional[P], field_results: List[T]) -&gt; T:\n    \"\"\"Visit a struct type with a partner.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.assign_fresh_schema_ids","title":"<code>assign_fresh_schema_ids(schema_or_type, next_id=None)</code>","text":"<p>Traverses the schema, and sets new IDs.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def assign_fresh_schema_ids(schema_or_type: Union[Schema, IcebergType], next_id: Optional[Callable[[], int]] = None) -&gt; Schema:\n    \"\"\"Traverses the schema, and sets new IDs.\"\"\"\n    return pre_order_visit(schema_or_type, _SetFreshIDs(next_id_func=next_id))\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.build_position_accessors","title":"<code>build_position_accessors(schema_or_type)</code>","text":"<p>Generate an index of field IDs to schema position accessors.</p> <p>Parameters:</p> Name Type Description Default <code>schema_or_type</code> <code>Union[Schema, IcebergType]</code> <p>A schema or type to index.</p> required <p>Returns:</p> Type Description <code>Dict[int, Accessor]</code> <p>Dict[int, Accessor]: An index of field IDs to accessors.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def build_position_accessors(schema_or_type: Union[Schema, IcebergType]) -&gt; Dict[int, Accessor]:\n    \"\"\"Generate an index of field IDs to schema position accessors.\n\n    Args:\n        schema_or_type (Union[Schema, IcebergType]): A schema or type to index.\n\n    Returns:\n        Dict[int, Accessor]: An index of field IDs to accessors.\n    \"\"\"\n    return visit(schema_or_type, _BuildPositionAccessors())\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.index_by_id","title":"<code>index_by_id(schema_or_type)</code>","text":"<p>Generate an index of field IDs to NestedField instances.</p> <p>Parameters:</p> Name Type Description Default <code>schema_or_type</code> <code>Union[Schema, IcebergType]</code> <p>A schema or type to index.</p> required <p>Returns:</p> Type Description <code>Dict[int, NestedField]</code> <p>Dict[int, NestedField]: An index of field IDs to NestedField instances.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def index_by_id(schema_or_type: Union[Schema, IcebergType]) -&gt; Dict[int, NestedField]:\n    \"\"\"Generate an index of field IDs to NestedField instances.\n\n    Args:\n        schema_or_type (Union[Schema, IcebergType]): A schema or type to index.\n\n    Returns:\n        Dict[int, NestedField]: An index of field IDs to NestedField instances.\n    \"\"\"\n    return visit(schema_or_type, _IndexById())\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.index_by_name","title":"<code>index_by_name(schema_or_type)</code>","text":"<p>Generate an index of field names to field IDs.</p> <p>Parameters:</p> Name Type Description Default <code>schema_or_type</code> <code>Union[Schema, IcebergType]</code> <p>A schema or type to index.</p> required <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>Dict[str, int]: An index of field names to field IDs.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def index_by_name(schema_or_type: Union[Schema, IcebergType]) -&gt; Dict[str, int]:\n    \"\"\"Generate an index of field names to field IDs.\n\n    Args:\n        schema_or_type (Union[Schema, IcebergType]): A schema or type to index.\n\n    Returns:\n        Dict[str, int]: An index of field names to field IDs.\n    \"\"\"\n    if len(schema_or_type.fields) &gt; 0:\n        indexer = _IndexByName()\n        visit(schema_or_type, indexer)\n        return indexer.by_name()\n    else:\n        return EMPTY_DICT\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.index_name_by_id","title":"<code>index_name_by_id(schema_or_type)</code>","text":"<p>Generate an index of field IDs full field names.</p> <p>Parameters:</p> Name Type Description Default <code>schema_or_type</code> <code>Union[Schema, IcebergType]</code> <p>A schema or type to index.</p> required <p>Returns:</p> Type Description <code>Dict[int, str]</code> <p>Dict[str, int]: An index of field IDs to full names.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def index_name_by_id(schema_or_type: Union[Schema, IcebergType]) -&gt; Dict[int, str]:\n    \"\"\"Generate an index of field IDs full field names.\n\n    Args:\n        schema_or_type (Union[Schema, IcebergType]): A schema or type to index.\n\n    Returns:\n        Dict[str, int]: An index of field IDs to full names.\n    \"\"\"\n    indexer = _IndexByName()\n    visit(schema_or_type, indexer)\n    return indexer.by_id()\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.pre_order_visit","title":"<code>pre_order_visit(obj, visitor)</code>","text":"<p>Apply a schema visitor to any point within a schema.</p> <p>The function traverses the schema in pre-order fashion. This is a slimmed down version compared to the post-order traversal (missing before and after methods), mostly because we don't use the pre-order traversal much.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Union[Schema, IcebergType]</code> <p>An instance of a Schema or an IcebergType.</p> required <code>visitor</code> <code>PreOrderSchemaVisitor[T]</code> <p>An instance of an implementation of the generic PreOrderSchemaVisitor base class.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If attempting to visit an unrecognized object type.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@singledispatch\ndef pre_order_visit(obj: Union[Schema, IcebergType], visitor: PreOrderSchemaVisitor[T]) -&gt; T:\n    \"\"\"Apply a schema visitor to any point within a schema.\n\n    The function traverses the schema in pre-order fashion. This is a slimmed down version\n    compared to the post-order traversal (missing before and after methods), mostly\n    because we don't use the pre-order traversal much.\n\n    Args:\n        obj (Union[Schema, IcebergType]): An instance of a Schema or an IcebergType.\n        visitor (PreOrderSchemaVisitor[T]): An instance of an implementation of the generic PreOrderSchemaVisitor base class.\n\n    Raises:\n        NotImplementedError: If attempting to visit an unrecognized object type.\n    \"\"\"\n    raise NotImplementedError(f\"Cannot visit non-type: {obj}\")\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.promote","title":"<code>promote(file_type, read_type)</code>","text":"<p>Promotes reading a file type to a read type.</p> <p>Parameters:</p> Name Type Description Default <code>file_type</code> <code>IcebergType</code> <p>The type of the Avro file.</p> required <code>read_type</code> <code>IcebergType</code> <p>The requested read type.</p> required <p>Raises:</p> Type Description <code>ResolveError</code> <p>If attempting to resolve an unrecognized object type.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@singledispatch\ndef promote(file_type: IcebergType, read_type: IcebergType) -&gt; IcebergType:\n    \"\"\"Promotes reading a file type to a read type.\n\n    Args:\n        file_type (IcebergType): The type of the Avro file.\n        read_type (IcebergType): The requested read type.\n\n    Raises:\n        ResolveError: If attempting to resolve an unrecognized object type.\n    \"\"\"\n    if file_type == read_type:\n        return file_type\n    else:\n        raise ResolveError(f\"Cannot promote {file_type} to {read_type}\")\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.prune_columns","title":"<code>prune_columns(schema, selected, select_full_types=True)</code>","text":"<p>Prunes a column by only selecting a set of field-ids.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>Schema</code> <p>The schema to be pruned.</p> required <code>selected</code> <code>Set[int]</code> <p>The field-ids to be included.</p> required <code>select_full_types</code> <code>bool</code> <p>Return the full struct when a subset is recorded</p> <code>True</code> <p>Returns:</p> Type Description <code>Schema</code> <p>The pruned schema.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def prune_columns(schema: Schema, selected: Set[int], select_full_types: bool = True) -&gt; Schema:\n    \"\"\"Prunes a column by only selecting a set of field-ids.\n\n    Args:\n        schema: The schema to be pruned.\n        selected: The field-ids to be included.\n        select_full_types: Return the full struct when a subset is recorded\n\n    Returns:\n        The pruned schema.\n    \"\"\"\n    result = visit(schema.as_struct(), _PruneColumnsVisitor(selected, select_full_types))\n    return Schema(\n        *(result or StructType()).fields,\n        schema_id=schema.schema_id,\n        identifier_field_ids=list(selected.intersection(schema.identifier_field_ids)),\n    )\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.sanitize_column_names","title":"<code>sanitize_column_names(schema)</code>","text":"<p>Sanitize column names to make them compatible with Avro.</p> <p>The column name should be starting with '' or digit followed by a string only contains '', digit or alphabet, otherwise it will be sanitized to conform the avro naming convention.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>Schema</code> <p>The schema to be sanitized.</p> required <p>Returns:</p> Type Description <code>Schema</code> <p>The sanitized schema.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>def sanitize_column_names(schema: Schema) -&gt; Schema:\n    \"\"\"Sanitize column names to make them compatible with Avro.\n\n    The column name should be starting with '_' or digit followed by a string only contains '_', digit or alphabet,\n    otherwise it will be sanitized to conform the avro naming convention.\n\n    Args:\n        schema: The schema to be sanitized.\n\n    Returns:\n        The sanitized schema.\n    \"\"\"\n    result = visit(schema.as_struct(), _SanitizeColumnsVisitor())\n    return Schema(\n        *(result or StructType()).fields,\n        schema_id=schema.schema_id,\n        identifier_field_ids=schema.identifier_field_ids,\n    )\n</code></pre>"},{"location":"reference/pyiceberg/schema/#pyiceberg.schema.visit","title":"<code>visit(obj, visitor)</code>","text":"<p>Apply a schema visitor to any point within a schema.</p> <p>The function traverses the schema in post-order fashion.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Union[Schema, IcebergType]</code> <p>An instance of a Schema or an IcebergType.</p> required <code>visitor</code> <code>SchemaVisitor[T]</code> <p>An instance of an implementation of the generic SchemaVisitor base class.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If attempting to visit an unrecognized object type.</p> Source code in <code>pyiceberg/schema.py</code> <pre><code>@singledispatch\ndef visit(obj: Union[Schema, IcebergType], visitor: SchemaVisitor[T]) -&gt; T:\n    \"\"\"Apply a schema visitor to any point within a schema.\n\n    The function traverses the schema in post-order fashion.\n\n    Args:\n        obj (Union[Schema, IcebergType]): An instance of a Schema or an IcebergType.\n        visitor (SchemaVisitor[T]): An instance of an implementation of the generic SchemaVisitor base class.\n\n    Raises:\n        NotImplementedError: If attempting to visit an unrecognized object type.\n    \"\"\"\n    raise NotImplementedError(f\"Cannot visit non-type: {obj}\")\n</code></pre>"},{"location":"reference/pyiceberg/serializers/","title":"serializers","text":""},{"location":"reference/pyiceberg/serializers/#pyiceberg.serializers.Compressor","title":"<code>Compressor</code>","text":"<p>             Bases: <code>ABC</code></p> Source code in <code>pyiceberg/serializers.py</code> <pre><code>class Compressor(ABC):\n    @staticmethod\n    def get_compressor(location: str) -&gt; Compressor:\n        return GzipCompressor() if location.endswith(\".gz.metadata.json\") else NOOP_COMPRESSOR\n\n    @abstractmethod\n    def stream_decompressor(self, inp: InputStream) -&gt; InputStream:\n        \"\"\"Return a stream decompressor.\n\n        Args:\n            inp: The input stream that needs decompressing.\n\n        Returns:\n            The wrapped stream\n        \"\"\"\n\n    @abstractmethod\n    def bytes_compressor(self) -&gt; Callable[[bytes], bytes]:\n        \"\"\"Return a function to compress bytes.\n\n        Returns:\n            A function that can be used to compress bytes.\n        \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/serializers/#pyiceberg.serializers.Compressor.bytes_compressor","title":"<code>bytes_compressor()</code>  <code>abstractmethod</code>","text":"<p>Return a function to compress bytes.</p> <p>Returns:</p> Type Description <code>Callable[[bytes], bytes]</code> <p>A function that can be used to compress bytes.</p> Source code in <code>pyiceberg/serializers.py</code> <pre><code>@abstractmethod\ndef bytes_compressor(self) -&gt; Callable[[bytes], bytes]:\n    \"\"\"Return a function to compress bytes.\n\n    Returns:\n        A function that can be used to compress bytes.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/serializers/#pyiceberg.serializers.Compressor.stream_decompressor","title":"<code>stream_decompressor(inp)</code>  <code>abstractmethod</code>","text":"<p>Return a stream decompressor.</p> <p>Parameters:</p> Name Type Description Default <code>inp</code> <code>InputStream</code> <p>The input stream that needs decompressing.</p> required <p>Returns:</p> Type Description <code>InputStream</code> <p>The wrapped stream</p> Source code in <code>pyiceberg/serializers.py</code> <pre><code>@abstractmethod\ndef stream_decompressor(self, inp: InputStream) -&gt; InputStream:\n    \"\"\"Return a stream decompressor.\n\n    Args:\n        inp: The input stream that needs decompressing.\n\n    Returns:\n        The wrapped stream\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/serializers/#pyiceberg.serializers.FromByteStream","title":"<code>FromByteStream</code>","text":"<p>A collection of methods that deserialize dictionaries into Iceberg objects.</p> Source code in <code>pyiceberg/serializers.py</code> <pre><code>class FromByteStream:\n    \"\"\"A collection of methods that deserialize dictionaries into Iceberg objects.\"\"\"\n\n    @staticmethod\n    def table_metadata(\n        byte_stream: InputStream, encoding: str = UTF8, compression: Compressor = NOOP_COMPRESSOR\n    ) -&gt; TableMetadata:\n        \"\"\"Instantiate a TableMetadata object from a byte stream.\n\n        Args:\n            byte_stream: A file-like byte stream object.\n            encoding (default \"utf-8\"): The byte encoder to use for the reader.\n            compression: Optional compression method\n        \"\"\"\n        with compression.stream_decompressor(byte_stream) as byte_stream:\n            reader = codecs.getreader(encoding)\n            json_bytes = reader(byte_stream)\n            metadata = json_bytes.read()\n\n        return TableMetadataUtil.parse_raw(metadata)\n</code></pre>"},{"location":"reference/pyiceberg/serializers/#pyiceberg.serializers.FromByteStream.table_metadata","title":"<code>table_metadata(byte_stream, encoding=UTF8, compression=NOOP_COMPRESSOR)</code>  <code>staticmethod</code>","text":"<p>Instantiate a TableMetadata object from a byte stream.</p> <p>Parameters:</p> Name Type Description Default <code>byte_stream</code> <code>InputStream</code> <p>A file-like byte stream object.</p> required <code>encoding</code> <code>default \"utf-8\"</code> <p>The byte encoder to use for the reader.</p> <code>UTF8</code> <code>compression</code> <code>Compressor</code> <p>Optional compression method</p> <code>NOOP_COMPRESSOR</code> Source code in <code>pyiceberg/serializers.py</code> <pre><code>@staticmethod\ndef table_metadata(\n    byte_stream: InputStream, encoding: str = UTF8, compression: Compressor = NOOP_COMPRESSOR\n) -&gt; TableMetadata:\n    \"\"\"Instantiate a TableMetadata object from a byte stream.\n\n    Args:\n        byte_stream: A file-like byte stream object.\n        encoding (default \"utf-8\"): The byte encoder to use for the reader.\n        compression: Optional compression method\n    \"\"\"\n    with compression.stream_decompressor(byte_stream) as byte_stream:\n        reader = codecs.getreader(encoding)\n        json_bytes = reader(byte_stream)\n        metadata = json_bytes.read()\n\n    return TableMetadataUtil.parse_raw(metadata)\n</code></pre>"},{"location":"reference/pyiceberg/serializers/#pyiceberg.serializers.FromInputFile","title":"<code>FromInputFile</code>","text":"<p>A collection of methods that deserialize InputFiles into Iceberg objects.</p> Source code in <code>pyiceberg/serializers.py</code> <pre><code>class FromInputFile:\n    \"\"\"A collection of methods that deserialize InputFiles into Iceberg objects.\"\"\"\n\n    @staticmethod\n    def table_metadata(input_file: InputFile, encoding: str = UTF8) -&gt; TableMetadata:\n        \"\"\"Create a TableMetadata instance from an input file.\n\n        Args:\n            input_file (InputFile): A custom implementation of the iceberg.io.file.InputFile abstract base class.\n            encoding (str): Encoding to use when loading bytestream.\n\n        Returns:\n            TableMetadata: A table metadata instance.\n\n        \"\"\"\n        with input_file.open() as input_stream:\n            return FromByteStream.table_metadata(\n                byte_stream=input_stream, encoding=encoding, compression=Compressor.get_compressor(location=input_file.location)\n            )\n</code></pre>"},{"location":"reference/pyiceberg/serializers/#pyiceberg.serializers.FromInputFile.table_metadata","title":"<code>table_metadata(input_file, encoding=UTF8)</code>  <code>staticmethod</code>","text":"<p>Create a TableMetadata instance from an input file.</p> <p>Parameters:</p> Name Type Description Default <code>input_file</code> <code>InputFile</code> <p>A custom implementation of the iceberg.io.file.InputFile abstract base class.</p> required <code>encoding</code> <code>str</code> <p>Encoding to use when loading bytestream.</p> <code>UTF8</code> <p>Returns:</p> Name Type Description <code>TableMetadata</code> <code>TableMetadata</code> <p>A table metadata instance.</p> Source code in <code>pyiceberg/serializers.py</code> <pre><code>@staticmethod\ndef table_metadata(input_file: InputFile, encoding: str = UTF8) -&gt; TableMetadata:\n    \"\"\"Create a TableMetadata instance from an input file.\n\n    Args:\n        input_file (InputFile): A custom implementation of the iceberg.io.file.InputFile abstract base class.\n        encoding (str): Encoding to use when loading bytestream.\n\n    Returns:\n        TableMetadata: A table metadata instance.\n\n    \"\"\"\n    with input_file.open() as input_stream:\n        return FromByteStream.table_metadata(\n            byte_stream=input_stream, encoding=encoding, compression=Compressor.get_compressor(location=input_file.location)\n        )\n</code></pre>"},{"location":"reference/pyiceberg/serializers/#pyiceberg.serializers.ToOutputFile","title":"<code>ToOutputFile</code>","text":"<p>A collection of methods that serialize Iceberg objects into files given an OutputFile instance.</p> Source code in <code>pyiceberg/serializers.py</code> <pre><code>class ToOutputFile:\n    \"\"\"A collection of methods that serialize Iceberg objects into files given an OutputFile instance.\"\"\"\n\n    @staticmethod\n    def table_metadata(metadata: TableMetadata, output_file: OutputFile, overwrite: bool = False) -&gt; None:\n        \"\"\"Write a TableMetadata instance to an output file.\n\n        Args:\n            output_file (OutputFile): A custom implementation of the iceberg.io.file.OutputFile abstract base class.\n            overwrite (bool): Where to overwrite the file if it already exists. Defaults to `False`.\n        \"\"\"\n        with output_file.create(overwrite=overwrite) as output_stream:\n            json_bytes = metadata.model_dump_json().encode(UTF8)\n            json_bytes = Compressor.get_compressor(output_file.location).bytes_compressor()(json_bytes)\n            output_stream.write(json_bytes)\n</code></pre>"},{"location":"reference/pyiceberg/serializers/#pyiceberg.serializers.ToOutputFile.table_metadata","title":"<code>table_metadata(metadata, output_file, overwrite=False)</code>  <code>staticmethod</code>","text":"<p>Write a TableMetadata instance to an output file.</p> <p>Parameters:</p> Name Type Description Default <code>output_file</code> <code>OutputFile</code> <p>A custom implementation of the iceberg.io.file.OutputFile abstract base class.</p> required <code>overwrite</code> <code>bool</code> <p>Where to overwrite the file if it already exists. Defaults to <code>False</code>.</p> <code>False</code> Source code in <code>pyiceberg/serializers.py</code> <pre><code>@staticmethod\ndef table_metadata(metadata: TableMetadata, output_file: OutputFile, overwrite: bool = False) -&gt; None:\n    \"\"\"Write a TableMetadata instance to an output file.\n\n    Args:\n        output_file (OutputFile): A custom implementation of the iceberg.io.file.OutputFile abstract base class.\n        overwrite (bool): Where to overwrite the file if it already exists. Defaults to `False`.\n    \"\"\"\n    with output_file.create(overwrite=overwrite) as output_stream:\n        json_bytes = metadata.model_dump_json().encode(UTF8)\n        json_bytes = Compressor.get_compressor(output_file.location).bytes_compressor()(json_bytes)\n        output_stream.write(json_bytes)\n</code></pre>"},{"location":"reference/pyiceberg/transforms/","title":"transforms","text":""},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.BoundTransform","title":"<code>BoundTransform</code>","text":"<p>             Bases: <code>BoundTerm[L]</code></p> <p>A transform expression.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>class BoundTransform(BoundTerm[L]):\n    \"\"\"A transform expression.\"\"\"\n\n    transform: Transform[L, Any]\n\n    def __init__(self, term: BoundTerm[L], transform: Transform[L, Any]):\n        self.term: BoundTerm[L] = term\n        self.transform = transform\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.BucketTransform","title":"<code>BucketTransform</code>","text":"<p>             Bases: <code>Transform[S, int]</code></p> <p>Base Transform class to transform a value into a bucket partition value.</p> <p>Transforms are parameterized by a number of buckets. Bucket partition transforms use a 32-bit hash of the source value to produce a positive value by mod the bucket number.</p> <p>Parameters:</p> Name Type Description Default <code>num_buckets</code> <code>int</code> <p>The number of buckets.</p> required Source code in <code>pyiceberg/transforms.py</code> <pre><code>class BucketTransform(Transform[S, int]):\n    \"\"\"Base Transform class to transform a value into a bucket partition value.\n\n    Transforms are parameterized by a number of buckets. Bucket partition transforms use a 32-bit\n    hash of the source value to produce a positive value by mod the bucket number.\n\n    Args:\n      num_buckets (int): The number of buckets.\n    \"\"\"\n\n    root: str = Field()\n    _num_buckets: PositiveInt = PrivateAttr()\n\n    def __init__(self, num_buckets: int, **data: Any) -&gt; None:\n        self._num_buckets = num_buckets\n        super().__init__(f\"bucket[{num_buckets}]\", **data)\n\n    @property\n    def num_buckets(self) -&gt; int:\n        return self._num_buckets\n\n    def hash(self, value: S) -&gt; int:\n        raise NotImplementedError()\n\n    def apply(self, value: Optional[S]) -&gt; Optional[int]:\n        return (self.hash(value) &amp; IntegerType.max) % self._num_buckets if value else None\n\n    def result_type(self, source: IcebergType) -&gt; IcebergType:\n        return IntegerType()\n\n    def project(self, name: str, pred: BoundPredicate[L]) -&gt; Optional[UnboundPredicate[Any]]:\n        transformer = self.transform(pred.term.ref().field.field_type)\n\n        if isinstance(pred.term, BoundTransform):\n            return _project_transform_predicate(self, name, pred)\n        elif isinstance(pred, BoundUnaryPredicate):\n            return pred.as_unbound(Reference(name))\n        elif isinstance(pred, BoundEqualTo):\n            return pred.as_unbound(Reference(name), _transform_literal(transformer, pred.literal))\n        elif isinstance(pred, BoundIn):  # NotIn can't be projected\n            return pred.as_unbound(Reference(name), {_transform_literal(transformer, literal) for literal in pred.literals})\n        else:\n            # - Comparison predicates can't be projected, notEq can't be projected\n            # - Small ranges can be projected:\n            #   For example, (x &gt; 0) and (x &lt; 3) can be turned into in({1, 2}) and projected.\n            return None\n\n    def can_transform(self, source: IcebergType) -&gt; bool:\n        return isinstance(\n            source,\n            (\n                IntegerType,\n                DateType,\n                LongType,\n                TimeType,\n                TimestampType,\n                TimestamptzType,\n                DecimalType,\n                StringType,\n                FixedType,\n                BinaryType,\n                UUIDType,\n            ),\n        )\n\n    def transform(self, source: IcebergType, bucket: bool = True) -&gt; Callable[[Optional[Any]], Optional[int]]:\n        if isinstance(source, (IntegerType, LongType, DateType, TimeType, TimestampType, TimestamptzType)):\n\n            def hash_func(v: Any) -&gt; int:\n                return mmh3.hash(struct.pack(\"&lt;q\", v))\n\n        elif isinstance(source, DecimalType):\n\n            def hash_func(v: Any) -&gt; int:\n                return mmh3.hash(decimal_to_bytes(v))\n\n        elif isinstance(source, (StringType, FixedType, BinaryType)):\n\n            def hash_func(v: Any) -&gt; int:\n                return mmh3.hash(v)\n\n        elif isinstance(source, UUIDType):\n\n            def hash_func(v: Any) -&gt; int:\n                if isinstance(v, UUID):\n                    return mmh3.hash(v.bytes)\n                return mmh3.hash(v)\n\n        else:\n            raise ValueError(f\"Unknown type {source}\")\n\n        if bucket:\n            return lambda v: (hash_func(v) &amp; IntegerType.max) % self._num_buckets if v is not None else None\n        return hash_func\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the BucketTransform class.\"\"\"\n        return f\"BucketTransform(num_buckets={self._num_buckets})\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.BucketTransform.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the BucketTransform class.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the BucketTransform class.\"\"\"\n    return f\"BucketTransform(num_buckets={self._num_buckets})\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.DayTransform","title":"<code>DayTransform</code>","text":"<p>             Bases: <code>TimeTransform[S]</code></p> <p>Transforms a datetime value into a day value.</p> Example <p>transform = MonthTransform() transform.transform(DateType())(17501) 17501</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>class DayTransform(TimeTransform[S]):\n    \"\"\"Transforms a datetime value into a day value.\n\n    Example:\n        &gt;&gt;&gt; transform = MonthTransform()\n        &gt;&gt;&gt; transform.transform(DateType())(17501)\n        17501\n    \"\"\"\n\n    root: LiteralType[\"day\"] = Field(default=\"day\")  # noqa: F821\n\n    def transform(self, source: IcebergType) -&gt; Callable[[Optional[S]], Optional[int]]:\n        if isinstance(source, DateType):\n\n            def day_func(v: Any) -&gt; int:\n                return v\n\n        elif isinstance(source, (TimestampType, TimestamptzType)):\n\n            def day_func(v: Any) -&gt; int:\n                return datetime.micros_to_days(v)\n\n        else:\n            raise ValueError(f\"Cannot apply day transform for type: {source}\")\n\n        return lambda v: day_func(v) if v is not None else None\n\n    def can_transform(self, source: IcebergType) -&gt; bool:\n        return isinstance(source, (DateType, TimestampType, TimestamptzType))\n\n    def result_type(self, source: IcebergType) -&gt; IcebergType:\n        return DateType()\n\n    @property\n    def granularity(self) -&gt; TimeResolution:\n        return TimeResolution.DAY\n\n    def to_human_string(self, _: IcebergType, value: Optional[S]) -&gt; str:\n        return datetime.to_human_day(value) if isinstance(value, int) else \"null\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the DayTransform class.\"\"\"\n        return \"DayTransform()\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.DayTransform.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the DayTransform class.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the DayTransform class.\"\"\"\n    return \"DayTransform()\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.HourTransform","title":"<code>HourTransform</code>","text":"<p>             Bases: <code>TimeTransform[S]</code></p> <p>Transforms a datetime value into a hour value.</p> Example <p>transform = HourTransform() transform.transform(TimestampType())(1512151975038194) 420042</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>class HourTransform(TimeTransform[S]):\n    \"\"\"Transforms a datetime value into a hour value.\n\n    Example:\n        &gt;&gt;&gt; transform = HourTransform()\n        &gt;&gt;&gt; transform.transform(TimestampType())(1512151975038194)\n        420042\n    \"\"\"\n\n    root: LiteralType[\"hour\"] = Field(default=\"hour\")  # noqa: F821\n\n    def transform(self, source: IcebergType) -&gt; Callable[[Optional[S]], Optional[int]]:\n        if isinstance(source, (TimestampType, TimestamptzType)):\n\n            def hour_func(v: Any) -&gt; int:\n                return datetime.micros_to_hours(v)\n\n        else:\n            raise ValueError(f\"Cannot apply hour transform for type: {source}\")\n\n        return lambda v: hour_func(v) if v is not None else None\n\n    def can_transform(self, source: IcebergType) -&gt; bool:\n        return isinstance(source, (TimestampType, TimestamptzType))\n\n    @property\n    def granularity(self) -&gt; TimeResolution:\n        return TimeResolution.HOUR\n\n    def to_human_string(self, _: IcebergType, value: Optional[S]) -&gt; str:\n        return datetime.to_human_hour(value) if isinstance(value, int) else \"null\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the HourTransform class.\"\"\"\n        return \"HourTransform()\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.HourTransform.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the HourTransform class.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the HourTransform class.\"\"\"\n    return \"HourTransform()\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.IdentityTransform","title":"<code>IdentityTransform</code>","text":"<p>             Bases: <code>Transform[S, S]</code></p> <p>Transforms a value into itself.</p> Example <p>transform = IdentityTransform() transform.transform(StringType())('hello-world') 'hello-world'</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>class IdentityTransform(Transform[S, S]):\n    \"\"\"Transforms a value into itself.\n\n    Example:\n        &gt;&gt;&gt; transform = IdentityTransform()\n        &gt;&gt;&gt; transform.transform(StringType())('hello-world')\n        'hello-world'\n    \"\"\"\n\n    root: LiteralType[\"identity\"] = Field(default=\"identity\")  # noqa: F821\n\n    def __init__(self) -&gt; None:\n        super().__init__(\"identity\")\n\n    def transform(self, source: IcebergType) -&gt; Callable[[Optional[S]], Optional[S]]:\n        return lambda v: v\n\n    def can_transform(self, source: IcebergType) -&gt; bool:\n        return source.is_primitive\n\n    def result_type(self, source: IcebergType) -&gt; IcebergType:\n        return source\n\n    def project(self, name: str, pred: BoundPredicate[L]) -&gt; Optional[UnboundPredicate[Any]]:\n        if isinstance(pred.term, BoundTransform):\n            return _project_transform_predicate(self, name, pred)\n        elif isinstance(pred, BoundUnaryPredicate):\n            return pred.as_unbound(Reference(name))\n        elif isinstance(pred, BoundLiteralPredicate):\n            return pred.as_unbound(Reference(name), pred.literal)\n        elif isinstance(pred, (BoundIn, BoundNotIn)):\n            return pred.as_unbound(Reference(name), pred.literals)\n        else:\n            raise ValueError(f\"Could not project: {pred}\")\n\n    @property\n    def preserves_order(self) -&gt; bool:\n        return True\n\n    def satisfies_order_of(self, other: Transform[S, T]) -&gt; bool:\n        \"\"\"Ordering by value is the same as long as the other preserves order.\"\"\"\n        return other.preserves_order\n\n    def to_human_string(self, source_type: IcebergType, value: Optional[S]) -&gt; str:\n        return _human_string(value, source_type) if value is not None else \"null\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the IdentityTransform class.\"\"\"\n        return \"identity\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the IdentityTransform class.\"\"\"\n        return \"IdentityTransform()\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.IdentityTransform.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the IdentityTransform class.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the IdentityTransform class.\"\"\"\n    return \"IdentityTransform()\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.IdentityTransform.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the IdentityTransform class.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the IdentityTransform class.\"\"\"\n    return \"identity\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.IdentityTransform.satisfies_order_of","title":"<code>satisfies_order_of(other)</code>","text":"<p>Ordering by value is the same as long as the other preserves order.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>def satisfies_order_of(self, other: Transform[S, T]) -&gt; bool:\n    \"\"\"Ordering by value is the same as long as the other preserves order.\"\"\"\n    return other.preserves_order\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.MonthTransform","title":"<code>MonthTransform</code>","text":"<p>             Bases: <code>TimeTransform[S]</code></p> <p>Transforms a datetime value into a month value.</p> Example <p>transform = MonthTransform() transform.transform(DateType())(17501) 575</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>class MonthTransform(TimeTransform[S]):\n    \"\"\"Transforms a datetime value into a month value.\n\n    Example:\n        &gt;&gt;&gt; transform = MonthTransform()\n        &gt;&gt;&gt; transform.transform(DateType())(17501)\n        575\n    \"\"\"\n\n    root: LiteralType[\"month\"] = Field(default=\"month\")  # noqa: F821\n\n    def transform(self, source: IcebergType) -&gt; Callable[[Optional[S]], Optional[int]]:\n        if isinstance(source, DateType):\n\n            def month_func(v: Any) -&gt; int:\n                return datetime.days_to_months(v)\n\n        elif isinstance(source, (TimestampType, TimestamptzType)):\n\n            def month_func(v: Any) -&gt; int:\n                return datetime.micros_to_months(v)\n\n        else:\n            raise ValueError(f\"Cannot apply month transform for type: {source}\")\n\n        return lambda v: month_func(v) if v is not None else None\n\n    def can_transform(self, source: IcebergType) -&gt; bool:\n        return isinstance(source, (DateType, TimestampType, TimestamptzType))\n\n    @property\n    def granularity(self) -&gt; TimeResolution:\n        return TimeResolution.MONTH\n\n    def to_human_string(self, _: IcebergType, value: Optional[S]) -&gt; str:\n        return datetime.to_human_month(value) if isinstance(value, int) else \"null\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the MonthTransform class.\"\"\"\n        return \"MonthTransform()\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.MonthTransform.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the MonthTransform class.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the MonthTransform class.\"\"\"\n    return \"MonthTransform()\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.Transform","title":"<code>Transform</code>","text":"<p>             Bases: <code>IcebergRootModel[str]</code>, <code>ABC</code>, <code>Generic[S, T]</code></p> <p>Transform base class for concrete transforms.</p> <p>A base class to transform values and project predicates on partition values. This class is not used directly. Instead, use one of module method to create the child classes.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>class Transform(IcebergRootModel[str], ABC, Generic[S, T]):\n    \"\"\"Transform base class for concrete transforms.\n\n    A base class to transform values and project predicates on partition values.\n    This class is not used directly. Instead, use one of module method to create the child classes.\n    \"\"\"\n\n    root: str = Field()\n\n    @abstractmethod\n    def transform(self, source: IcebergType) -&gt; Callable[[Optional[S]], Optional[T]]: ...\n\n    @abstractmethod\n    def can_transform(self, source: IcebergType) -&gt; bool:\n        return False\n\n    @abstractmethod\n    def result_type(self, source: IcebergType) -&gt; IcebergType: ...\n\n    @abstractmethod\n    def project(self, name: str, pred: BoundPredicate[L]) -&gt; Optional[UnboundPredicate[Any]]: ...\n\n    @property\n    def preserves_order(self) -&gt; bool:\n        return False\n\n    def satisfies_order_of(self, other: Any) -&gt; bool:\n        return self == other\n\n    def to_human_string(self, _: IcebergType, value: Optional[S]) -&gt; str:\n        return str(value) if value is not None else \"null\"\n\n    @property\n    def dedup_name(self) -&gt; str:\n        return self.__str__()\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the Transform class.\"\"\"\n        return self.root\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the Transform class.\"\"\"\n        if isinstance(other, Transform):\n            return self.root == other.root\n        return False\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.Transform.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the Transform class.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the Transform class.\"\"\"\n    if isinstance(other, Transform):\n        return self.root == other.root\n    return False\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.Transform.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the Transform class.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the Transform class.\"\"\"\n    return self.root\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.TruncateTransform","title":"<code>TruncateTransform</code>","text":"<p>             Bases: <code>Transform[S, S]</code></p> <p>A transform for truncating a value to a specified width.</p> <p>Parameters:</p> Name Type Description Default <code>width</code> <code>int</code> <p>The truncate width, should be positive.</p> required <p>Raises:   ValueError: If a type is provided that is incompatible with a Truncate transform.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>class TruncateTransform(Transform[S, S]):\n    \"\"\"A transform for truncating a value to a specified width.\n\n    Args:\n      width (int): The truncate width, should be positive.\n    Raises:\n      ValueError: If a type is provided that is incompatible with a Truncate transform.\n    \"\"\"\n\n    root: str = Field()\n    _source_type: IcebergType = PrivateAttr()\n    _width: PositiveInt = PrivateAttr()\n\n    def __init__(self, width: int, **data: Any):\n        super().__init__(root=f\"truncate[{width}]\", **data)\n        self._width = width\n\n    def can_transform(self, source: IcebergType) -&gt; bool:\n        return isinstance(source, (IntegerType, LongType, StringType, BinaryType, DecimalType))\n\n    def result_type(self, source: IcebergType) -&gt; IcebergType:\n        return source\n\n    @property\n    def preserves_order(self) -&gt; bool:\n        return True\n\n    @property\n    def source_type(self) -&gt; IcebergType:\n        return self._source_type\n\n    def project(self, name: str, pred: BoundPredicate[L]) -&gt; Optional[UnboundPredicate[Any]]:\n        field_type = pred.term.ref().field.field_type\n\n        if isinstance(pred.term, BoundTransform):\n            return _project_transform_predicate(self, name, pred)\n\n        if isinstance(pred, BoundUnaryPredicate):\n            return pred.as_unbound(Reference(name))\n        elif isinstance(pred, BoundIn):\n            return _set_apply_transform(name, pred, self.transform(field_type))\n        elif isinstance(field_type, (IntegerType, LongType, DecimalType)):\n            if isinstance(pred, BoundLiteralPredicate):\n                return _truncate_number(name, pred, self.transform(field_type))\n        elif isinstance(field_type, (BinaryType, StringType)):\n            if isinstance(pred, BoundLiteralPredicate):\n                return _truncate_array(name, pred, self.transform(field_type))\n        return None\n\n    @property\n    def width(self) -&gt; int:\n        return self._width\n\n    def transform(self, source: IcebergType) -&gt; Callable[[Optional[S]], Optional[S]]:\n        if isinstance(source, (IntegerType, LongType)):\n\n            def truncate_func(v: Any) -&gt; Any:\n                return v - v % self._width\n\n        elif isinstance(source, (StringType, BinaryType)):\n\n            def truncate_func(v: Any) -&gt; Any:\n                return v[0 : min(self._width, len(v))]\n\n        elif isinstance(source, DecimalType):\n\n            def truncate_func(v: Any) -&gt; Any:\n                return truncate_decimal(v, self._width)\n\n        else:\n            raise ValueError(f\"Cannot truncate for type: {source}\")\n\n        return lambda v: truncate_func(v) if v is not None else None\n\n    def satisfies_order_of(self, other: Transform[S, T]) -&gt; bool:\n        if self == other:\n            return True\n        elif (\n            isinstance(self.source_type, StringType)\n            and isinstance(other, TruncateTransform)\n            and isinstance(other.source_type, StringType)\n        ):\n            return self.width &gt;= other.width\n\n        return False\n\n    def to_human_string(self, _: IcebergType, value: Optional[S]) -&gt; str:\n        if value is None:\n            return \"null\"\n        elif isinstance(value, bytes):\n            return _base64encode(value)\n        else:\n            return str(value)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the TruncateTransform class.\"\"\"\n        return f\"TruncateTransform(width={self._width})\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.TruncateTransform.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the TruncateTransform class.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the TruncateTransform class.\"\"\"\n    return f\"TruncateTransform(width={self._width})\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.UnknownTransform","title":"<code>UnknownTransform</code>","text":"<p>             Bases: <code>Transform[S, T]</code></p> <p>A transform that represents when an unknown transform is provided.</p> <p>Parameters:</p> Name Type Description Default <code>transform</code> <code>str</code> <p>A string name of a transform.</p> required <p>Other Parameters:</p> Name Type Description <code>source_type</code> <code>IcebergType</code> <p>An Iceberg <code>Type</code>.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>class UnknownTransform(Transform[S, T]):\n    \"\"\"A transform that represents when an unknown transform is provided.\n\n    Args:\n      transform (str): A string name of a transform.\n\n    Keyword Args:\n      source_type (IcebergType): An Iceberg `Type`.\n    \"\"\"\n\n    root: LiteralType[\"unknown\"] = Field(default=\"unknown\")  # noqa: F821\n    _transform: str = PrivateAttr()\n\n    def __init__(self, transform: str, **data: Any):\n        super().__init__(**data)\n        self._transform = transform\n\n    def transform(self, source: IcebergType) -&gt; Callable[[Optional[S]], Optional[T]]:\n        raise AttributeError(f\"Cannot apply unsupported transform: {self}\")\n\n    def can_transform(self, source: IcebergType) -&gt; bool:\n        return False\n\n    def result_type(self, source: IcebergType) -&gt; StringType:\n        return StringType()\n\n    def project(self, name: str, pred: BoundPredicate[L]) -&gt; Optional[UnboundPredicate[Any]]:\n        return None\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the UnknownTransform class.\"\"\"\n        return f\"UnknownTransform(transform={repr(self._transform)})\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.UnknownTransform.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the UnknownTransform class.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the UnknownTransform class.\"\"\"\n    return f\"UnknownTransform(transform={repr(self._transform)})\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.VoidTransform","title":"<code>VoidTransform</code>","text":"<p>             Bases: <code>Transform[S, None]</code>, <code>Singleton</code></p> <p>A transform that always returns None.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>class VoidTransform(Transform[S, None], Singleton):\n    \"\"\"A transform that always returns None.\"\"\"\n\n    root: str = \"void\"\n\n    def transform(self, source: IcebergType) -&gt; Callable[[Optional[S]], Optional[T]]:\n        return lambda v: None\n\n    def can_transform(self, _: IcebergType) -&gt; bool:\n        return True\n\n    def result_type(self, source: IcebergType) -&gt; IcebergType:\n        return source\n\n    def project(self, name: str, pred: BoundPredicate[L]) -&gt; Optional[UnboundPredicate[Any]]:\n        return None\n\n    def to_human_string(self, _: IcebergType, value: Optional[S]) -&gt; str:\n        return \"null\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the VoidTransform class.\"\"\"\n        return \"VoidTransform()\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.VoidTransform.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the VoidTransform class.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the VoidTransform class.\"\"\"\n    return \"VoidTransform()\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.YearTransform","title":"<code>YearTransform</code>","text":"<p>             Bases: <code>TimeTransform[S]</code></p> <p>Transforms a datetime value into a year value.</p> Example <p>transform = YearTransform() transform.transform(TimestampType())(1512151975038194) 47</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>class YearTransform(TimeTransform[S]):\n    \"\"\"Transforms a datetime value into a year value.\n\n    Example:\n        &gt;&gt;&gt; transform = YearTransform()\n        &gt;&gt;&gt; transform.transform(TimestampType())(1512151975038194)\n        47\n    \"\"\"\n\n    root: LiteralType[\"year\"] = Field(default=\"year\")  # noqa: F821\n\n    def transform(self, source: IcebergType) -&gt; Callable[[Optional[S]], Optional[int]]:\n        if isinstance(source, DateType):\n\n            def year_func(v: Any) -&gt; int:\n                return datetime.days_to_years(v)\n\n        elif isinstance(source, (TimestampType, TimestamptzType)):\n\n            def year_func(v: Any) -&gt; int:\n                return datetime.micros_to_years(v)\n\n        else:\n            raise ValueError(f\"Cannot apply year transform for type: {source}\")\n\n        return lambda v: year_func(v) if v is not None else None\n\n    def can_transform(self, source: IcebergType) -&gt; bool:\n        return isinstance(source, (DateType, TimestampType, TimestamptzType))\n\n    @property\n    def granularity(self) -&gt; TimeResolution:\n        return TimeResolution.YEAR\n\n    def to_human_string(self, _: IcebergType, value: Optional[S]) -&gt; str:\n        return datetime.to_human_year(value) if isinstance(value, int) else \"null\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the YearTransform class.\"\"\"\n        return \"YearTransform()\"\n</code></pre>"},{"location":"reference/pyiceberg/transforms/#pyiceberg.transforms.YearTransform.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the YearTransform class.</p> Source code in <code>pyiceberg/transforms.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the YearTransform class.\"\"\"\n    return \"YearTransform()\"\n</code></pre>"},{"location":"reference/pyiceberg/typedef/","title":"typedef","text":""},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.FrozenDict","title":"<code>FrozenDict</code>","text":"<p>             Bases: <code>Dict[Any, Any]</code></p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>class FrozenDict(Dict[Any, Any]):\n    def __setitem__(self, instance: Any, value: Any) -&gt; None:\n        \"\"\"Assign a value to a FrozenDict.\"\"\"\n        raise AttributeError(\"FrozenDict does not support assignment\")\n\n    def update(self, *args: Any, **kwargs: Any) -&gt; None:\n        raise AttributeError(\"FrozenDict does not support .update()\")\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.FrozenDict.__setitem__","title":"<code>__setitem__(instance, value)</code>","text":"<p>Assign a value to a FrozenDict.</p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>def __setitem__(self, instance: Any, value: Any) -&gt; None:\n    \"\"\"Assign a value to a FrozenDict.\"\"\"\n    raise AttributeError(\"FrozenDict does not support assignment\")\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.IcebergBaseModel","title":"<code>IcebergBaseModel</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class extends the Pydantic BaseModel to set default values by overriding them.</p> <p>This is because we always want to set by_alias to True. In Python, the dash can't be used in variable names, and this is used throughout the Iceberg spec.</p> <p>The same goes for exclude_none, if a field is None we want to omit it from serialization, for example, the doc attribute on the NestedField object. Default non-null values will be serialized.</p> <p>This is recommended by Pydantic: https://pydantic-docs.helpmanual.io/usage/model_config/#change-behaviour-globally</p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>class IcebergBaseModel(BaseModel):\n    \"\"\"\n    This class extends the Pydantic BaseModel to set default values by overriding them.\n\n    This is because we always want to set by_alias to True. In Python, the dash can't\n    be used in variable names, and this is used throughout the Iceberg spec.\n\n    The same goes for exclude_none, if a field is None we want to omit it from\n    serialization, for example, the doc attribute on the NestedField object.\n    Default non-null values will be serialized.\n\n    This is recommended by Pydantic:\n    https://pydantic-docs.helpmanual.io/usage/model_config/#change-behaviour-globally\n    \"\"\"\n\n    model_config = ConfigDict(populate_by_name=True, frozen=True)\n\n    def _exclude_private_properties(self, exclude: Optional[Set[str]] = None) -&gt; Set[str]:\n        # A small trick to exclude private properties. Properties are serialized by pydantic,\n        # regardless if they start with an underscore.\n        # This will look at the dict, and find the fields and exclude them\n        return set.union(\n            {field for field in self.__dict__ if field.startswith(\"_\") and not field == \"__root__\"}, exclude or set()\n        )\n\n    def model_dump(\n        self, exclude_none: bool = True, exclude: Optional[Set[str]] = None, by_alias: bool = True, **kwargs: Any\n    ) -&gt; Dict[str, Any]:\n        return super().model_dump(\n            exclude_none=exclude_none, exclude=self._exclude_private_properties(exclude), by_alias=by_alias, **kwargs\n        )\n\n    def model_dump_json(\n        self, exclude_none: bool = True, exclude: Optional[Set[str]] = None, by_alias: bool = True, **kwargs: Any\n    ) -&gt; str:\n        return super().model_dump_json(\n            exclude_none=exclude_none, exclude=self._exclude_private_properties(exclude), by_alias=by_alias, **kwargs\n        )\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.IcebergRootModel","title":"<code>IcebergRootModel</code>","text":"<p>             Bases: <code>RootModel[T]</code>, <code>Generic[T]</code></p> <p>This class extends the Pydantic BaseModel to set default values by overriding them.</p> <p>This is because we always want to set by_alias to True. In Python, the dash can't be used in variable names, and this is used throughout the Iceberg spec.</p> <p>The same goes for exclude_none, if a field is None we want to omit it from serialization, for example, the doc attribute on the NestedField object. Default non-null values will be serialized.</p> <p>This is recommended by Pydantic: https://pydantic-docs.helpmanual.io/usage/model_config/#change-behaviour-globally</p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>class IcebergRootModel(RootModel[T], Generic[T]):\n    \"\"\"\n    This class extends the Pydantic BaseModel to set default values by overriding them.\n\n    This is because we always want to set by_alias to True. In Python, the dash can't\n    be used in variable names, and this is used throughout the Iceberg spec.\n\n    The same goes for exclude_none, if a field is None we want to omit it from\n    serialization, for example, the doc attribute on the NestedField object.\n    Default non-null values will be serialized.\n\n    This is recommended by Pydantic:\n    https://pydantic-docs.helpmanual.io/usage/model_config/#change-behaviour-globally\n    \"\"\"\n\n    model_config = ConfigDict(frozen=True)\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.KeyDefaultDict","title":"<code>KeyDefaultDict</code>","text":"<p>             Bases: <code>Dict[K, V]</code></p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>class KeyDefaultDict(Dict[K, V]):\n    def __init__(self, default_factory: Callable[[K], V]):\n        super().__init__()\n        self.default_factory = default_factory\n\n    def __missing__(self, key: K) -&gt; V:\n        \"\"\"Define behavior if you access a non-existent key in a KeyDefaultDict.\"\"\"\n        val = self.default_factory(key)\n        self[key] = val\n        return val\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.KeyDefaultDict.__missing__","title":"<code>__missing__(key)</code>","text":"<p>Define behavior if you access a non-existent key in a KeyDefaultDict.</p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>def __missing__(self, key: K) -&gt; V:\n    \"\"\"Define behavior if you access a non-existent key in a KeyDefaultDict.\"\"\"\n    val = self.default_factory(key)\n    self[key] = val\n    return val\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.Record","title":"<code>Record</code>","text":"<p>             Bases: <code>StructProtocol</code></p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>class Record(StructProtocol):\n    __slots__ = (\"_position_to_field_name\",)\n    _position_to_field_name: Tuple[str, ...]\n\n    def __init__(self, *data: Any, struct: Optional[StructType] = None, **named_data: Any) -&gt; None:\n        if struct is not None:\n            self._position_to_field_name = _get_struct_fields(struct)\n        elif named_data:\n            # Order of named_data is preserved (PEP 468) so this can be used to generate the position dict\n            self._position_to_field_name = tuple(named_data.keys())\n        else:\n            self._position_to_field_name = tuple(f\"field{idx + 1}\" for idx in range(len(data)))\n\n        for idx, d in enumerate(data):\n            self[idx] = d\n\n        for field_name, d in named_data.items():\n            self.__setattr__(field_name, d)\n\n    def __setitem__(self, pos: int, value: Any) -&gt; None:\n        \"\"\"Assign a value to a Record.\"\"\"\n        self.__setattr__(self._position_to_field_name[pos], value)\n\n    def __getitem__(self, pos: int) -&gt; Any:\n        \"\"\"Fetch a value from a Record.\"\"\"\n        return self.__getattribute__(self._position_to_field_name[pos])\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the Record class.\"\"\"\n        if not isinstance(other, Record):\n            return False\n        return self.__dict__ == other.__dict__\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the Record class.\"\"\"\n        return f\"{self.__class__.__name__}[{', '.join(f'{key}={repr(value)}' for key, value in self.__dict__.items() if not key.startswith('_'))}]\"\n\n    def record_fields(self) -&gt; List[str]:\n        \"\"\"Return values of all the fields of the Record class except those specified in skip_fields.\"\"\"\n        return [self.__getattribute__(v) if hasattr(self, v) else None for v in self._position_to_field_name]\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.Record.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the Record class.</p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the Record class.\"\"\"\n    if not isinstance(other, Record):\n        return False\n    return self.__dict__ == other.__dict__\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.Record.__getitem__","title":"<code>__getitem__(pos)</code>","text":"<p>Fetch a value from a Record.</p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>def __getitem__(self, pos: int) -&gt; Any:\n    \"\"\"Fetch a value from a Record.\"\"\"\n    return self.__getattribute__(self._position_to_field_name[pos])\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.Record.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the Record class.</p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the Record class.\"\"\"\n    return f\"{self.__class__.__name__}[{', '.join(f'{key}={repr(value)}' for key, value in self.__dict__.items() if not key.startswith('_'))}]\"\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.Record.__setitem__","title":"<code>__setitem__(pos, value)</code>","text":"<p>Assign a value to a Record.</p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>def __setitem__(self, pos: int, value: Any) -&gt; None:\n    \"\"\"Assign a value to a Record.\"\"\"\n    self.__setattr__(self._position_to_field_name[pos], value)\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.Record.record_fields","title":"<code>record_fields()</code>","text":"<p>Return values of all the fields of the Record class except those specified in skip_fields.</p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>def record_fields(self) -&gt; List[str]:\n    \"\"\"Return values of all the fields of the Record class except those specified in skip_fields.\"\"\"\n    return [self.__getattribute__(v) if hasattr(self, v) else None for v in self._position_to_field_name]\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.StructProtocol","title":"<code>StructProtocol</code>","text":"<p>             Bases: <code>Protocol</code></p> <p>A generic protocol used by accessors to get and set at positions of an object.</p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>@runtime_checkable\nclass StructProtocol(Protocol):  # pragma: no cover\n    \"\"\"A generic protocol used by accessors to get and set at positions of an object.\"\"\"\n\n    @abstractmethod\n    def __getitem__(self, pos: int) -&gt; Any:\n        \"\"\"Fetch a value from a StructProtocol.\"\"\"\n\n    @abstractmethod\n    def __setitem__(self, pos: int, value: Any) -&gt; None:\n        \"\"\"Assign a value to a StructProtocol.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.StructProtocol.__getitem__","title":"<code>__getitem__(pos)</code>  <code>abstractmethod</code>","text":"<p>Fetch a value from a StructProtocol.</p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>@abstractmethod\ndef __getitem__(self, pos: int) -&gt; Any:\n    \"\"\"Fetch a value from a StructProtocol.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/typedef/#pyiceberg.typedef.StructProtocol.__setitem__","title":"<code>__setitem__(pos, value)</code>  <code>abstractmethod</code>","text":"<p>Assign a value to a StructProtocol.</p> Source code in <code>pyiceberg/typedef.py</code> <pre><code>@abstractmethod\ndef __setitem__(self, pos: int, value: Any) -&gt; None:\n    \"\"\"Assign a value to a StructProtocol.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/types/","title":"types","text":"<p>Data types used in describing Iceberg schemas.</p> <p>This module implements the data types described in the Iceberg specification for Iceberg schemas. To describe an Iceberg table schema, these classes can be used in the construction of a StructType instance.</p> Example <p>str(StructType( ...     NestedField(1, \"required_field\", StringType(), True), ...     NestedField(2, \"optional_field\", IntegerType()) ... )) 'struct&lt;1: required_field: optional string, 2: optional_field: optional int&gt;'</p> Notes <ul> <li>https://iceberg.apache.org/#spec/#primitive-types</li> </ul>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.BinaryType","title":"<code>BinaryType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>A Binary data type in Iceberg can be represented using an instance of this class.</p> <p>Binaries in Iceberg are arbitrary-length byte arrays.</p> Example <p>column_foo = BinaryType() isinstance(column_foo, BinaryType) True column_foo BinaryType()</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class BinaryType(PrimitiveType):\n    \"\"\"A Binary data type in Iceberg can be represented using an instance of this class.\n\n    Binaries in Iceberg are arbitrary-length byte arrays.\n\n    Example:\n        &gt;&gt;&gt; column_foo = BinaryType()\n        &gt;&gt;&gt; isinstance(column_foo, BinaryType)\n        True\n        &gt;&gt;&gt; column_foo\n        BinaryType()\n    \"\"\"\n\n    root: Literal[\"binary\"] = Field(default=\"binary\")\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.BooleanType","title":"<code>BooleanType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>A boolean data type in Iceberg can be represented using an instance of this class.</p> Example <p>column_foo = BooleanType() isinstance(column_foo, BooleanType) True column_foo BooleanType()</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class BooleanType(PrimitiveType):\n    \"\"\"A boolean data type in Iceberg can be represented using an instance of this class.\n\n    Example:\n        &gt;&gt;&gt; column_foo = BooleanType()\n        &gt;&gt;&gt; isinstance(column_foo, BooleanType)\n        True\n        &gt;&gt;&gt; column_foo\n        BooleanType()\n    \"\"\"\n\n    root: Literal[\"boolean\"] = Field(default=\"boolean\")\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.DateType","title":"<code>DateType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>A Date data type in Iceberg can be represented using an instance of this class.</p> <p>Dates in Iceberg are calendar dates without a timezone or time.</p> Example <p>column_foo = DateType() isinstance(column_foo, DateType) True column_foo DateType()</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class DateType(PrimitiveType):\n    \"\"\"A Date data type in Iceberg can be represented using an instance of this class.\n\n    Dates in Iceberg are calendar dates without a timezone or time.\n\n    Example:\n        &gt;&gt;&gt; column_foo = DateType()\n        &gt;&gt;&gt; isinstance(column_foo, DateType)\n        True\n        &gt;&gt;&gt; column_foo\n        DateType()\n    \"\"\"\n\n    root: Literal[\"date\"] = Field(default=\"date\")\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.DecimalType","title":"<code>DecimalType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>A decimal data type in Iceberg.</p> Example <p>DecimalType(32, 3) DecimalType(precision=32, scale=3) DecimalType(8, 3) == DecimalType(8, 3) True</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class DecimalType(PrimitiveType):\n    \"\"\"A decimal data type in Iceberg.\n\n    Example:\n        &gt;&gt;&gt; DecimalType(32, 3)\n        DecimalType(precision=32, scale=3)\n        &gt;&gt;&gt; DecimalType(8, 3) == DecimalType(8, 3)\n        True\n    \"\"\"\n\n    root: Tuple[int, int]\n\n    def __init__(self, precision: int, scale: int) -&gt; None:\n        super().__init__(root=(precision, scale))\n\n    @model_serializer\n    def ser_model(self) -&gt; str:\n        \"\"\"Serialize the model to a string.\"\"\"\n        return f\"decimal({self.precision}, {self.scale})\"\n\n    @property\n    def precision(self) -&gt; int:\n        \"\"\"Return the precision of the decimal.\"\"\"\n        return self.root[0]\n\n    @property\n    def scale(self) -&gt; int:\n        \"\"\"Return the scale of the decimal.\"\"\"\n        return self.root[1]\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the DecimalType class.\"\"\"\n        return f\"DecimalType(precision={self.precision}, scale={self.scale})\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation.\"\"\"\n        return f\"decimal({self.precision}, {self.scale})\"\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Return the hash of the tuple.\"\"\"\n        return hash(self.root)\n\n    def __getnewargs__(self) -&gt; Tuple[int, int]:\n        \"\"\"Pickle the DecimalType class.\"\"\"\n        return self.precision, self.scale\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Compare to root to another object.\"\"\"\n        return self.root == other.root if isinstance(other, DecimalType) else False\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.DecimalType.precision","title":"<code>precision: int</code>  <code>property</code>","text":"<p>Return the precision of the decimal.</p>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.DecimalType.scale","title":"<code>scale: int</code>  <code>property</code>","text":"<p>Return the scale of the decimal.</p>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.DecimalType.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Compare to root to another object.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Compare to root to another object.\"\"\"\n    return self.root == other.root if isinstance(other, DecimalType) else False\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.DecimalType.__getnewargs__","title":"<code>__getnewargs__()</code>","text":"<p>Pickle the DecimalType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __getnewargs__(self) -&gt; Tuple[int, int]:\n    \"\"\"Pickle the DecimalType class.\"\"\"\n    return self.precision, self.scale\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.DecimalType.__hash__","title":"<code>__hash__()</code>","text":"<p>Return the hash of the tuple.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Return the hash of the tuple.\"\"\"\n    return hash(self.root)\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.DecimalType.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the DecimalType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the DecimalType class.\"\"\"\n    return f\"DecimalType(precision={self.precision}, scale={self.scale})\"\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.DecimalType.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation.\"\"\"\n    return f\"decimal({self.precision}, {self.scale})\"\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.DecimalType.ser_model","title":"<code>ser_model()</code>","text":"<p>Serialize the model to a string.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>@model_serializer\ndef ser_model(self) -&gt; str:\n    \"\"\"Serialize the model to a string.\"\"\"\n    return f\"decimal({self.precision}, {self.scale})\"\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.DoubleType","title":"<code>DoubleType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>A Double data type in Iceberg can be represented using an instance of this class.</p> <p>Doubles in Iceberg are 64-bit IEEE 754 floating points.</p> Example <p>column_foo = DoubleType() isinstance(column_foo, DoubleType) True column_foo DoubleType()</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class DoubleType(PrimitiveType):\n    \"\"\"A Double data type in Iceberg can be represented using an instance of this class.\n\n    Doubles in Iceberg are 64-bit IEEE 754 floating points.\n\n    Example:\n        &gt;&gt;&gt; column_foo = DoubleType()\n        &gt;&gt;&gt; isinstance(column_foo, DoubleType)\n        True\n        &gt;&gt;&gt; column_foo\n        DoubleType()\n    \"\"\"\n\n    root: Literal[\"double\"] = Field(default=\"double\")\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.FixedType","title":"<code>FixedType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>A fixed data type in Iceberg.</p> Example <p>FixedType(8) FixedType(length=8) FixedType(8) == FixedType(8) True FixedType(19) == FixedType(25) False</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class FixedType(PrimitiveType):\n    \"\"\"A fixed data type in Iceberg.\n\n    Example:\n        &gt;&gt;&gt; FixedType(8)\n        FixedType(length=8)\n        &gt;&gt;&gt; FixedType(8) == FixedType(8)\n        True\n        &gt;&gt;&gt; FixedType(19) == FixedType(25)\n        False\n    \"\"\"\n\n    root: int = Field()\n\n    def __init__(self, length: int) -&gt; None:\n        super().__init__(root=length)\n\n    @model_serializer\n    def ser_model(self) -&gt; str:\n        return f\"fixed[{self.root}]\"\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the length of an instance of the FixedType class.\"\"\"\n        return self.root\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation.\"\"\"\n        return f\"fixed[{self.root}]\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the FixedType class.\"\"\"\n        return f\"FixedType(length={self.root})\"\n\n    def __getnewargs__(self) -&gt; tuple[int]:\n        \"\"\"Pickle the FixedType class.\"\"\"\n        return (self.root,)\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.FixedType.__getnewargs__","title":"<code>__getnewargs__()</code>","text":"<p>Pickle the FixedType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __getnewargs__(self) -&gt; tuple[int]:\n    \"\"\"Pickle the FixedType class.\"\"\"\n    return (self.root,)\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.FixedType.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of an instance of the FixedType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the length of an instance of the FixedType class.\"\"\"\n    return self.root\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.FixedType.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the FixedType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the FixedType class.\"\"\"\n    return f\"FixedType(length={self.root})\"\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.FixedType.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation.\"\"\"\n    return f\"fixed[{self.root}]\"\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.FloatType","title":"<code>FloatType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>A Float data type in Iceberg can be represented using an instance of this class.</p> <p>Floats in Iceberg are 32-bit IEEE 754 floating points and can be promoted to Doubles.</p> Example <p>column_foo = FloatType() isinstance(column_foo, FloatType) True column_foo FloatType()</p> <p>Attributes:</p> Name Type Description <code>max</code> <code>float</code> <p>The maximum allowed value for Floats, inherited from the canonical Iceberg implementation in Java. (returns <code>3.4028235e38</code>)</p> <code>min</code> <code>float</code> <p>The minimum allowed value for Floats, inherited from the canonical Iceberg implementation in Java (returns <code>-3.4028235e38</code>)</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class FloatType(PrimitiveType):\n    \"\"\"A Float data type in Iceberg can be represented using an instance of this class.\n\n    Floats in Iceberg are 32-bit IEEE 754 floating points and can be promoted to Doubles.\n\n    Example:\n        &gt;&gt;&gt; column_foo = FloatType()\n        &gt;&gt;&gt; isinstance(column_foo, FloatType)\n        True\n        &gt;&gt;&gt; column_foo\n        FloatType()\n\n    Attributes:\n        max (float): The maximum allowed value for Floats, inherited from the canonical Iceberg implementation\n            in Java. (returns `3.4028235e38`)\n        min (float): The minimum allowed value for Floats, inherited from the canonical Iceberg implementation\n            in Java (returns `-3.4028235e38`)\n    \"\"\"\n\n    max: ClassVar[float] = 3.4028235e38\n    min: ClassVar[float] = -3.4028235e38\n\n    root: Literal[\"float\"] = Field(default=\"float\")\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.IcebergType","title":"<code>IcebergType</code>","text":"<p>             Bases: <code>IcebergBaseModel</code></p> <p>Base type for all Iceberg Types.</p> Example <p>str(IcebergType()) 'IcebergType()' repr(IcebergType()) 'IcebergType()'</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class IcebergType(IcebergBaseModel):\n    \"\"\"Base type for all Iceberg Types.\n\n    Example:\n        &gt;&gt;&gt; str(IcebergType())\n        'IcebergType()'\n        &gt;&gt;&gt; repr(IcebergType())\n        'IcebergType()'\n    \"\"\"\n\n    @model_validator(mode=\"wrap\")\n    @classmethod\n    def handle_primitive_type(cls, v: Any, handler: ValidatorFunctionWrapHandler) -&gt; IcebergType:\n        # Pydantic works mostly around dicts, and there seems to be something\n        # by not serializing into a RootModel, might revisit this.\n        if isinstance(v, str):\n            if v == \"boolean\":\n                return BooleanType()\n            elif v == \"string\":\n                return StringType()\n            elif v == \"int\":\n                return IntegerType()\n            elif v == \"long\":\n                return LongType()\n            if v == \"float\":\n                return FloatType()\n            if v == \"double\":\n                return DoubleType()\n            if v == \"timestamp\":\n                return TimestampType()\n            if v == \"timestamptz\":\n                return TimestamptzType()\n            if v == \"date\":\n                return DateType()\n            if v == \"time\":\n                return TimeType()\n            if v == \"uuid\":\n                return UUIDType()\n            if v == \"binary\":\n                return BinaryType()\n            if v.startswith(\"fixed\"):\n                return FixedType(_parse_fixed_type(v))\n            if v.startswith(\"decimal\"):\n                precision, scale = _parse_decimal_type(v)\n                return DecimalType(precision, scale)\n            else:\n                raise ValueError(f\"Unknown type: {v}\")\n        if isinstance(v, dict) and cls == IcebergType:\n            complex_type = v.get(\"type\")\n            if complex_type == \"list\":\n                return ListType(**v)\n            elif complex_type == \"map\":\n                return MapType(**v)\n            elif complex_type == \"struct\":\n                return StructType(**v)\n            else:\n                return NestedField(**v)\n        return handler(v)\n\n    @property\n    def is_primitive(self) -&gt; bool:\n        return isinstance(self, PrimitiveType)\n\n    @property\n    def is_struct(self) -&gt; bool:\n        return isinstance(self, StructType)\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.IntegerType","title":"<code>IntegerType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>An Integer data type in Iceberg can be represented using an instance of this class.</p> <p>Integers in Iceberg are 32-bit signed and can be promoted to Longs.</p> Example <p>column_foo = IntegerType() isinstance(column_foo, IntegerType) True</p> <p>Attributes:</p> Name Type Description <code>max</code> <code>int</code> <p>The maximum allowed value for Integers, inherited from the canonical Iceberg implementation in Java (returns <code>2147483647</code>)</p> <code>min</code> <code>int</code> <p>The minimum allowed value for Integers, inherited from the canonical Iceberg implementation in Java (returns <code>-2147483648</code>)</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class IntegerType(PrimitiveType):\n    \"\"\"An Integer data type in Iceberg can be represented using an instance of this class.\n\n    Integers in Iceberg are 32-bit signed and can be promoted to Longs.\n\n    Example:\n        &gt;&gt;&gt; column_foo = IntegerType()\n        &gt;&gt;&gt; isinstance(column_foo, IntegerType)\n        True\n\n    Attributes:\n        max (int): The maximum allowed value for Integers, inherited from the canonical Iceberg implementation\n            in Java (returns `2147483647`)\n        min (int): The minimum allowed value for Integers, inherited from the canonical Iceberg implementation\n            in Java (returns `-2147483648`)\n    \"\"\"\n\n    root: Literal[\"int\"] = Field(default=\"int\")\n\n    max: ClassVar[int] = 2147483647\n    min: ClassVar[int] = -2147483648\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.ListType","title":"<code>ListType</code>","text":"<p>             Bases: <code>IcebergType</code></p> <p>A list type in Iceberg.</p> Example <p>ListType(element_id=3, element_type=StringType(), element_required=True) ListType(element_id=3, element_type=StringType(), element_required=True)</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class ListType(IcebergType):\n    \"\"\"A list type in Iceberg.\n\n    Example:\n        &gt;&gt;&gt; ListType(element_id=3, element_type=StringType(), element_required=True)\n        ListType(element_id=3, element_type=StringType(), element_required=True)\n    \"\"\"\n\n    type: Literal[\"list\"] = Field(default=\"list\")\n    element_id: int = Field(alias=\"element-id\")\n    element_type: SerializeAsAny[IcebergType] = Field(alias=\"element\")\n    element_required: bool = Field(alias=\"element-required\", default=True)\n    _element_field: NestedField = PrivateAttr()\n    _hash: int = PrivateAttr()\n\n    def __init__(\n        self, element_id: Optional[int] = None, element: Optional[IcebergType] = None, element_required: bool = True, **data: Any\n    ):\n        data[\"element-id\"] = data[\"element-id\"] if \"element-id\" in data else element_id\n        data[\"element\"] = element or data[\"element_type\"]\n        data[\"element-required\"] = data[\"element-required\"] if \"element-required\" in data else element_required\n        super().__init__(**data)\n        self._hash = hash(data.values())\n\n    @cached_property\n    def element_field(self) -&gt; NestedField:\n        return NestedField(\n            name=\"element\",\n            field_id=self.element_id,\n            field_type=self.element_type,\n            required=self.element_required,\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the ListType class.\"\"\"\n        return f\"list&lt;{self.element_type}&gt;\"\n\n    def __getnewargs__(self) -&gt; Tuple[int, IcebergType, bool]:\n        \"\"\"Pickle the ListType class.\"\"\"\n        return (self.element_id, self.element_type, self.element_required)\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Use the cache hash value of the StructType class.\"\"\"\n        return self._hash\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Compare the list type to another list type.\"\"\"\n        return self.element_field == other.element_field if isinstance(other, ListType) else False\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.ListType.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Compare the list type to another list type.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Compare the list type to another list type.\"\"\"\n    return self.element_field == other.element_field if isinstance(other, ListType) else False\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.ListType.__getnewargs__","title":"<code>__getnewargs__()</code>","text":"<p>Pickle the ListType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __getnewargs__(self) -&gt; Tuple[int, IcebergType, bool]:\n    \"\"\"Pickle the ListType class.\"\"\"\n    return (self.element_id, self.element_type, self.element_required)\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.ListType.__hash__","title":"<code>__hash__()</code>","text":"<p>Use the cache hash value of the StructType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Use the cache hash value of the StructType class.\"\"\"\n    return self._hash\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.ListType.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the ListType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the ListType class.\"\"\"\n    return f\"list&lt;{self.element_type}&gt;\"\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.LongType","title":"<code>LongType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>A Long data type in Iceberg can be represented using an instance of this class.</p> <p>Longs in Iceberg are 64-bit signed integers.</p> Example <p>column_foo = LongType() isinstance(column_foo, LongType) True column_foo LongType() str(column_foo) 'long'</p> <p>Attributes:</p> Name Type Description <code>max</code> <code>int</code> <p>The maximum allowed value for Longs, inherited from the canonical Iceberg implementation in Java. (returns <code>9223372036854775807</code>)</p> <code>min</code> <code>int</code> <p>The minimum allowed value for Longs, inherited from the canonical Iceberg implementation in Java (returns <code>-9223372036854775808</code>)</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class LongType(PrimitiveType):\n    \"\"\"A Long data type in Iceberg can be represented using an instance of this class.\n\n    Longs in Iceberg are 64-bit signed integers.\n\n    Example:\n        &gt;&gt;&gt; column_foo = LongType()\n        &gt;&gt;&gt; isinstance(column_foo, LongType)\n        True\n        &gt;&gt;&gt; column_foo\n        LongType()\n        &gt;&gt;&gt; str(column_foo)\n        'long'\n\n    Attributes:\n        max (int): The maximum allowed value for Longs, inherited from the canonical Iceberg implementation\n            in Java. (returns `9223372036854775807`)\n        min (int): The minimum allowed value for Longs, inherited from the canonical Iceberg implementation\n            in Java (returns `-9223372036854775808`)\n    \"\"\"\n\n    root: Literal[\"long\"] = Field(default=\"long\")\n\n    max: ClassVar[int] = 9223372036854775807\n    min: ClassVar[int] = -9223372036854775808\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.MapType","title":"<code>MapType</code>","text":"<p>             Bases: <code>IcebergType</code></p> <p>A map type in Iceberg.</p> Example <p>MapType(key_id=1, key_type=StringType(), value_id=2, value_type=IntegerType(), value_required=True) MapType(key_id=1, key_type=StringType(), value_id=2, value_type=IntegerType(), value_required=True)</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class MapType(IcebergType):\n    \"\"\"A map type in Iceberg.\n\n    Example:\n        &gt;&gt;&gt; MapType(key_id=1, key_type=StringType(), value_id=2, value_type=IntegerType(), value_required=True)\n        MapType(key_id=1, key_type=StringType(), value_id=2, value_type=IntegerType(), value_required=True)\n    \"\"\"\n\n    type: Literal[\"map\"] = Field(default=\"map\")\n    key_id: int = Field(alias=\"key-id\")\n    key_type: SerializeAsAny[IcebergType] = Field(alias=\"key\")\n    value_id: int = Field(alias=\"value-id\")\n    value_type: SerializeAsAny[IcebergType] = Field(alias=\"value\")\n    value_required: bool = Field(alias=\"value-required\", default=True)\n    _hash: int = PrivateAttr()\n\n    def __init__(\n        self,\n        key_id: Optional[int] = None,\n        key_type: Optional[IcebergType] = None,\n        value_id: Optional[int] = None,\n        value_type: Optional[IcebergType] = None,\n        value_required: bool = True,\n        **data: Any,\n    ):\n        data[\"key-id\"] = data[\"key-id\"] if \"key-id\" in data else key_id\n        data[\"key\"] = data[\"key\"] if \"key\" in data else key_type\n        data[\"value-id\"] = data[\"value-id\"] if \"value-id\" in data else value_id\n        data[\"value\"] = data[\"value\"] if \"value\" in data else value_type\n        data[\"value-required\"] = data[\"value-required\"] if \"value-required\" in data else value_required\n        super().__init__(**data)\n        self._hash = hash(self.__getnewargs__())\n\n    @cached_property\n    def key_field(self) -&gt; NestedField:\n        return NestedField(\n            name=\"key\",\n            field_id=self.key_id,\n            field_type=self.key_type,\n            required=True,\n        )\n\n    @cached_property\n    def value_field(self) -&gt; NestedField:\n        return NestedField(\n            name=\"value\",\n            field_id=self.value_id,\n            field_type=self.value_type,\n            required=self.value_required,\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the MapType class.\"\"\"\n        return f\"map&lt;{self.key_type}, {self.value_type}&gt;\"\n\n    def __getnewargs__(self) -&gt; Tuple[int, IcebergType, int, IcebergType, bool]:\n        \"\"\"Pickle the MapType class.\"\"\"\n        return (self.key_id, self.key_type, self.value_id, self.value_type, self.value_required)\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Return the hash of the MapType.\"\"\"\n        return self._hash\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Compare the MapType to another object.\"\"\"\n        return (\n            self.key_field == other.key_field and self.value_field == other.value_field if isinstance(other, MapType) else False\n        )\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.MapType.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Compare the MapType to another object.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Compare the MapType to another object.\"\"\"\n    return (\n        self.key_field == other.key_field and self.value_field == other.value_field if isinstance(other, MapType) else False\n    )\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.MapType.__getnewargs__","title":"<code>__getnewargs__()</code>","text":"<p>Pickle the MapType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __getnewargs__(self) -&gt; Tuple[int, IcebergType, int, IcebergType, bool]:\n    \"\"\"Pickle the MapType class.\"\"\"\n    return (self.key_id, self.key_type, self.value_id, self.value_type, self.value_required)\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.MapType.__hash__","title":"<code>__hash__()</code>","text":"<p>Return the hash of the MapType.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Return the hash of the MapType.\"\"\"\n    return self._hash\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.MapType.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the MapType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the MapType class.\"\"\"\n    return f\"map&lt;{self.key_type}, {self.value_type}&gt;\"\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.NestedField","title":"<code>NestedField</code>","text":"<p>             Bases: <code>IcebergType</code></p> <p>Represents a field of a struct, a map key, a map value, or a list element.</p> <p>This is where field IDs, names, docs, and nullability are tracked.</p> Example <p>str(NestedField( ...     field_id=1, ...     name='foo', ...     field_type=FixedType(22), ...     required=False, ... )) '1: foo: optional fixed[22]' str(NestedField( ...     field_id=2, ...     name='bar', ...     field_type=LongType(), ...     is_optional=False, ...     doc=\"Just a long\" ... )) '2: bar: required long (Just a long)'</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class NestedField(IcebergType):\n    \"\"\"Represents a field of a struct, a map key, a map value, or a list element.\n\n    This is where field IDs, names, docs, and nullability are tracked.\n\n    Example:\n        &gt;&gt;&gt; str(NestedField(\n        ...     field_id=1,\n        ...     name='foo',\n        ...     field_type=FixedType(22),\n        ...     required=False,\n        ... ))\n        '1: foo: optional fixed[22]'\n        &gt;&gt;&gt; str(NestedField(\n        ...     field_id=2,\n        ...     name='bar',\n        ...     field_type=LongType(),\n        ...     is_optional=False,\n        ...     doc=\"Just a long\"\n        ... ))\n        '2: bar: required long (Just a long)'\n    \"\"\"\n\n    field_id: int = Field(alias=\"id\")\n    name: str = Field()\n    field_type: SerializeAsAny[IcebergType] = Field(alias=\"type\")\n    required: bool = Field(default=True)\n    doc: Optional[str] = Field(default=None, repr=False)\n    initial_default: Optional[Any] = Field(alias=\"initial-default\", default=None, repr=False)\n    write_default: Optional[L] = Field(alias=\"write-default\", default=None, repr=False)  # type: ignore\n\n    def __init__(\n        self,\n        field_id: Optional[int] = None,\n        name: Optional[str] = None,\n        field_type: Optional[IcebergType] = None,\n        required: bool = True,\n        doc: Optional[str] = None,\n        initial_default: Optional[Any] = None,\n        write_default: Optional[L] = None,\n        **data: Any,\n    ):\n        # We need an init when we want to use positional arguments, but\n        # need also to support the aliases.\n        data[\"id\"] = data[\"id\"] if \"id\" in data else field_id\n        data[\"name\"] = name\n        data[\"type\"] = data[\"type\"] if \"type\" in data else field_type\n        data[\"required\"] = required\n        data[\"doc\"] = doc\n        data[\"initial-default\"] = initial_default\n        data[\"write-default\"] = write_default\n        super().__init__(**data)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the NestedField class.\"\"\"\n        doc = \"\" if not self.doc else f\" ({self.doc})\"\n        req = \"required\" if self.required else \"optional\"\n        return f\"{self.field_id}: {self.name}: {req} {self.field_type}{doc}\"\n\n    def __getnewargs__(self) -&gt; Tuple[int, str, IcebergType, bool, Optional[str]]:\n        \"\"\"Pickle the NestedField class.\"\"\"\n        return (self.field_id, self.name, self.field_type, self.required, self.doc)\n\n    @property\n    def optional(self) -&gt; bool:\n        return not self.required\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.NestedField.__getnewargs__","title":"<code>__getnewargs__()</code>","text":"<p>Pickle the NestedField class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __getnewargs__(self) -&gt; Tuple[int, str, IcebergType, bool, Optional[str]]:\n    \"\"\"Pickle the NestedField class.\"\"\"\n    return (self.field_id, self.name, self.field_type, self.required, self.doc)\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.NestedField.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the NestedField class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the NestedField class.\"\"\"\n    doc = \"\" if not self.doc else f\" ({self.doc})\"\n    req = \"required\" if self.required else \"optional\"\n    return f\"{self.field_id}: {self.name}: {req} {self.field_type}{doc}\"\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.PrimitiveType","title":"<code>PrimitiveType</code>","text":"<p>             Bases: <code>IcebergRootModel[str]</code>, <code>IcebergType</code>, <code>Singleton</code></p> <p>Base class for all Iceberg Primitive Types.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class PrimitiveType(IcebergRootModel[str], IcebergType, Singleton):\n    \"\"\"Base class for all Iceberg Primitive Types.\"\"\"\n\n    root: Any = Field()\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the PrimitiveType class.\"\"\"\n        return f\"{type(self).__name__}()\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the PrimitiveType class.\"\"\"\n        return self.root\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.PrimitiveType.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the PrimitiveType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the PrimitiveType class.\"\"\"\n    return f\"{type(self).__name__}()\"\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.PrimitiveType.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the PrimitiveType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the PrimitiveType class.\"\"\"\n    return self.root\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.StringType","title":"<code>StringType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>A String data type in Iceberg can be represented using an instance of this class.</p> <p>Strings in Iceberg are arbitrary-length character sequences and are encoded with UTF-8.</p> Example <p>column_foo = StringType() isinstance(column_foo, StringType) True column_foo StringType()</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class StringType(PrimitiveType):\n    \"\"\"A String data type in Iceberg can be represented using an instance of this class.\n\n    Strings in Iceberg are arbitrary-length character sequences and are encoded with UTF-8.\n\n    Example:\n        &gt;&gt;&gt; column_foo = StringType()\n        &gt;&gt;&gt; isinstance(column_foo, StringType)\n        True\n        &gt;&gt;&gt; column_foo\n        StringType()\n    \"\"\"\n\n    root: Literal[\"string\"] = Field(default=\"string\")\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.StructType","title":"<code>StructType</code>","text":"<p>             Bases: <code>IcebergType</code></p> <p>A struct type in Iceberg.</p> Example <p>str(StructType( ...     NestedField(1, \"required_field\", StringType(), True), ...     NestedField(2, \"optional_field\", IntegerType()) ... )) 'struct&lt;1: required_field: optional string, 2: optional_field: optional int&gt;'</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class StructType(IcebergType):\n    \"\"\"A struct type in Iceberg.\n\n    Example:\n        &gt;&gt;&gt; str(StructType(\n        ...     NestedField(1, \"required_field\", StringType(), True),\n        ...     NestedField(2, \"optional_field\", IntegerType())\n        ... ))\n        'struct&lt;1: required_field: optional string, 2: optional_field: optional int&gt;'\n    \"\"\"\n\n    type: Literal[\"struct\"] = Field(default=\"struct\")\n    fields: Tuple[NestedField, ...] = Field(default_factory=tuple)\n    _hash: int = PrivateAttr()\n\n    def __init__(self, *fields: NestedField, **data: Any):\n        # In case we use positional arguments, instead of keyword args\n        if fields:\n            data[\"fields\"] = fields\n        super().__init__(**data)\n        self._hash = hash(self.fields)\n\n    def field(self, field_id: int) -&gt; Optional[NestedField]:\n        for field in self.fields:\n            if field.field_id == field_id:\n                return field\n        return None\n\n    def field_by_name(self, name: str, case_sensitive: bool = True) -&gt; Optional[NestedField]:\n        if case_sensitive:\n            name_lower = name.lower()\n            for field in self.fields:\n                if field.name.lower() == name_lower:\n                    return field\n        else:\n            for field in self.fields:\n                if field.name == name:\n                    return field\n        return None\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the StructType class.\"\"\"\n        return f\"struct&lt;{', '.join(map(str, self.fields))}&gt;\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the StructType class.\"\"\"\n        return f\"StructType(fields=({', '.join(map(repr, self.fields))},))\"\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the length of an instance of the StructType class.\"\"\"\n        return len(self.fields)\n\n    def __getnewargs__(self) -&gt; Tuple[NestedField, ...]:\n        \"\"\"Pickle the StructType class.\"\"\"\n        return self.fields\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Use the cache hash value of the StructType class.\"\"\"\n        return self._hash\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Compare the object if it is equal to another object.\"\"\"\n        return self.fields == other.fields if isinstance(other, StructType) else False\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.StructType.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Compare the object if it is equal to another object.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Compare the object if it is equal to another object.\"\"\"\n    return self.fields == other.fields if isinstance(other, StructType) else False\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.StructType.__getnewargs__","title":"<code>__getnewargs__()</code>","text":"<p>Pickle the StructType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __getnewargs__(self) -&gt; Tuple[NestedField, ...]:\n    \"\"\"Pickle the StructType class.\"\"\"\n    return self.fields\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.StructType.__hash__","title":"<code>__hash__()</code>","text":"<p>Use the cache hash value of the StructType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Use the cache hash value of the StructType class.\"\"\"\n    return self._hash\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.StructType.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of an instance of the StructType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the length of an instance of the StructType class.\"\"\"\n    return len(self.fields)\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.StructType.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the StructType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the StructType class.\"\"\"\n    return f\"StructType(fields=({', '.join(map(repr, self.fields))},))\"\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.StructType.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the StructType class.</p> Source code in <code>pyiceberg/types.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the StructType class.\"\"\"\n    return f\"struct&lt;{', '.join(map(str, self.fields))}&gt;\"\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.TimeType","title":"<code>TimeType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>A Time data type in Iceberg can be represented using an instance of this class.</p> <p>Times in Iceberg have microsecond precision and are a time of day without a date or timezone.</p> Example <p>column_foo = TimeType() isinstance(column_foo, TimeType) True column_foo TimeType()</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class TimeType(PrimitiveType):\n    \"\"\"A Time data type in Iceberg can be represented using an instance of this class.\n\n    Times in Iceberg have microsecond precision and are a time of day without a date or timezone.\n\n    Example:\n        &gt;&gt;&gt; column_foo = TimeType()\n        &gt;&gt;&gt; isinstance(column_foo, TimeType)\n        True\n        &gt;&gt;&gt; column_foo\n        TimeType()\n    \"\"\"\n\n    root: Literal[\"time\"] = Field(default=\"time\")\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.TimestampType","title":"<code>TimestampType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>A Timestamp data type in Iceberg can be represented using an instance of this class.</p> <p>Timestamps in Iceberg have microsecond precision and include a date and a time of day without a timezone.</p> Example <p>column_foo = TimestampType() isinstance(column_foo, TimestampType) True column_foo TimestampType()</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class TimestampType(PrimitiveType):\n    \"\"\"A Timestamp data type in Iceberg can be represented using an instance of this class.\n\n    Timestamps in Iceberg have microsecond precision and include a date and a time of day without a timezone.\n\n    Example:\n        &gt;&gt;&gt; column_foo = TimestampType()\n        &gt;&gt;&gt; isinstance(column_foo, TimestampType)\n        True\n        &gt;&gt;&gt; column_foo\n        TimestampType()\n    \"\"\"\n\n    root: Literal[\"timestamp\"] = Field(default=\"timestamp\")\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.TimestamptzType","title":"<code>TimestamptzType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>A Timestamptz data type in Iceberg can be represented using an instance of this class.</p> <p>Timestamptzs in Iceberg are stored as UTC and include a date and a time of day with a timezone.</p> Example <p>column_foo = TimestamptzType() isinstance(column_foo, TimestamptzType) True column_foo TimestamptzType()</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class TimestamptzType(PrimitiveType):\n    \"\"\"A Timestamptz data type in Iceberg can be represented using an instance of this class.\n\n    Timestamptzs in Iceberg are stored as UTC and include a date and a time of day with a timezone.\n\n    Example:\n        &gt;&gt;&gt; column_foo = TimestamptzType()\n        &gt;&gt;&gt; isinstance(column_foo, TimestamptzType)\n        True\n        &gt;&gt;&gt; column_foo\n        TimestamptzType()\n    \"\"\"\n\n    root: Literal[\"timestamptz\"] = Field(default=\"timestamptz\")\n</code></pre>"},{"location":"reference/pyiceberg/types/#pyiceberg.types.UUIDType","title":"<code>UUIDType</code>","text":"<p>             Bases: <code>PrimitiveType</code></p> <p>A UUID data type in Iceberg can be represented using an instance of this class.</p> <p>UUIDs in Iceberg are universally unique identifiers.</p> Example <p>column_foo = UUIDType() isinstance(column_foo, UUIDType) True column_foo UUIDType()</p> Source code in <code>pyiceberg/types.py</code> <pre><code>class UUIDType(PrimitiveType):\n    \"\"\"A UUID data type in Iceberg can be represented using an instance of this class.\n\n    UUIDs in Iceberg are universally unique identifiers.\n\n    Example:\n        &gt;&gt;&gt; column_foo = UUIDType()\n        &gt;&gt;&gt; isinstance(column_foo, UUIDType)\n        True\n        &gt;&gt;&gt; column_foo\n        UUIDType()\n    \"\"\"\n\n    root: Literal[\"uuid\"] = Field(default=\"uuid\")\n</code></pre>"},{"location":"reference/pyiceberg/avro/","title":"avro","text":""},{"location":"reference/pyiceberg/avro/decoder/","title":"decoder","text":""},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.BinaryDecoder","title":"<code>BinaryDecoder</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Decodes bytes into Python physical primitives.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>class BinaryDecoder(ABC):\n    \"\"\"Decodes bytes into Python physical primitives.\"\"\"\n\n    @abstractmethod\n    def tell(self) -&gt; int:\n        \"\"\"Return the current position.\"\"\"\n\n    @abstractmethod\n    def read(self, n: int) -&gt; bytes:\n        \"\"\"Read n bytes.\"\"\"\n\n    @abstractmethod\n    def skip(self, n: int) -&gt; None:\n        \"\"\"Skip n bytes.\"\"\"\n\n    def read_boolean(self) -&gt; bool:\n        \"\"\"Read a value from the stream as a boolean.\n\n        A boolean is written as a single byte\n        whose value is either 0 (false) or 1 (true).\n        \"\"\"\n        return ord(self.read(1)) == 1\n\n    def read_int(self) -&gt; int:\n        \"\"\"Read an int/long value.\n\n        int/long values are written using variable-length, zigzag coding.\n        \"\"\"\n        b = ord(self.read(1))\n        n = b &amp; 0x7F\n        shift = 7\n        while (b &amp; 0x80) != 0:\n            b = ord(self.read(1))\n            n |= (b &amp; 0x7F) &lt;&lt; shift\n            shift += 7\n        datum = (n &gt;&gt; 1) ^ -(n &amp; 1)\n        return datum\n\n    def read_ints(self, n: int) -&gt; Tuple[int, ...]:\n        \"\"\"Read a list of integers.\"\"\"\n        return tuple(self.read_int() for _ in range(n))\n\n    def read_int_bytes_dict(self, n: int, dest: Dict[int, bytes]) -&gt; None:\n        \"\"\"Read a dictionary of integers for keys and bytes for values into a destination dictionary.\"\"\"\n        for _ in range(n):\n            k = self.read_int()\n            v = self.read_bytes()\n            dest[k] = v\n\n    def read_float(self) -&gt; float:\n        \"\"\"Read a value from the stream as a float.\n\n        A float is written as 4 bytes.\n        The float is converted into a 32-bit integer using a method equivalent to\n        Java's floatToIntBits and then encoded in little-endian format.\n        \"\"\"\n        return float(cast(Tuple[float, ...], STRUCT_FLOAT.unpack(self.read(4)))[0])\n\n    def read_double(self) -&gt; float:\n        \"\"\"Read a value from the stream as a double.\n\n        A double is written as 8 bytes.\n        The double is converted into a 64-bit integer using a method equivalent to\n        Java's doubleToLongBits and then encoded in little-endian format.\n        \"\"\"\n        return float(cast(Tuple[float, ...], STRUCT_DOUBLE.unpack(self.read(8)))[0])\n\n    def read_bytes(self) -&gt; bytes:\n        \"\"\"Bytes are encoded as a long followed by that many bytes of data.\"\"\"\n        num_bytes = self.read_int()\n        return self.read(num_bytes) if num_bytes &gt; 0 else b\"\"\n\n    def read_utf8(self) -&gt; str:\n        \"\"\"Read an utf-8 encoded string from the stream.\n\n        A string is encoded as a long followed by\n        that many bytes of UTF-8 encoded character data.\n        \"\"\"\n        return self.read_bytes().decode(UTF8)\n\n    def skip_boolean(self) -&gt; None:\n        self.skip(1)\n\n    def skip_int(self) -&gt; None:\n        b = ord(self.read(1))\n        while (b &amp; 0x80) != 0:\n            b = ord(self.read(1))\n\n    def skip_float(self) -&gt; None:\n        self.skip(4)\n\n    def skip_double(self) -&gt; None:\n        self.skip(8)\n\n    def skip_bytes(self) -&gt; None:\n        self.skip(self.read_int())\n\n    def skip_utf8(self) -&gt; None:\n        self.skip_bytes()\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.BinaryDecoder.read","title":"<code>read(n)</code>  <code>abstractmethod</code>","text":"<p>Read n bytes.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>@abstractmethod\ndef read(self, n: int) -&gt; bytes:\n    \"\"\"Read n bytes.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.BinaryDecoder.read_boolean","title":"<code>read_boolean()</code>","text":"<p>Read a value from the stream as a boolean.</p> <p>A boolean is written as a single byte whose value is either 0 (false) or 1 (true).</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>def read_boolean(self) -&gt; bool:\n    \"\"\"Read a value from the stream as a boolean.\n\n    A boolean is written as a single byte\n    whose value is either 0 (false) or 1 (true).\n    \"\"\"\n    return ord(self.read(1)) == 1\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.BinaryDecoder.read_bytes","title":"<code>read_bytes()</code>","text":"<p>Bytes are encoded as a long followed by that many bytes of data.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>def read_bytes(self) -&gt; bytes:\n    \"\"\"Bytes are encoded as a long followed by that many bytes of data.\"\"\"\n    num_bytes = self.read_int()\n    return self.read(num_bytes) if num_bytes &gt; 0 else b\"\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.BinaryDecoder.read_double","title":"<code>read_double()</code>","text":"<p>Read a value from the stream as a double.</p> <p>A double is written as 8 bytes. The double is converted into a 64-bit integer using a method equivalent to Java's doubleToLongBits and then encoded in little-endian format.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>def read_double(self) -&gt; float:\n    \"\"\"Read a value from the stream as a double.\n\n    A double is written as 8 bytes.\n    The double is converted into a 64-bit integer using a method equivalent to\n    Java's doubleToLongBits and then encoded in little-endian format.\n    \"\"\"\n    return float(cast(Tuple[float, ...], STRUCT_DOUBLE.unpack(self.read(8)))[0])\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.BinaryDecoder.read_float","title":"<code>read_float()</code>","text":"<p>Read a value from the stream as a float.</p> <p>A float is written as 4 bytes. The float is converted into a 32-bit integer using a method equivalent to Java's floatToIntBits and then encoded in little-endian format.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>def read_float(self) -&gt; float:\n    \"\"\"Read a value from the stream as a float.\n\n    A float is written as 4 bytes.\n    The float is converted into a 32-bit integer using a method equivalent to\n    Java's floatToIntBits and then encoded in little-endian format.\n    \"\"\"\n    return float(cast(Tuple[float, ...], STRUCT_FLOAT.unpack(self.read(4)))[0])\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.BinaryDecoder.read_int","title":"<code>read_int()</code>","text":"<p>Read an int/long value.</p> <p>int/long values are written using variable-length, zigzag coding.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>def read_int(self) -&gt; int:\n    \"\"\"Read an int/long value.\n\n    int/long values are written using variable-length, zigzag coding.\n    \"\"\"\n    b = ord(self.read(1))\n    n = b &amp; 0x7F\n    shift = 7\n    while (b &amp; 0x80) != 0:\n        b = ord(self.read(1))\n        n |= (b &amp; 0x7F) &lt;&lt; shift\n        shift += 7\n    datum = (n &gt;&gt; 1) ^ -(n &amp; 1)\n    return datum\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.BinaryDecoder.read_int_bytes_dict","title":"<code>read_int_bytes_dict(n, dest)</code>","text":"<p>Read a dictionary of integers for keys and bytes for values into a destination dictionary.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>def read_int_bytes_dict(self, n: int, dest: Dict[int, bytes]) -&gt; None:\n    \"\"\"Read a dictionary of integers for keys and bytes for values into a destination dictionary.\"\"\"\n    for _ in range(n):\n        k = self.read_int()\n        v = self.read_bytes()\n        dest[k] = v\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.BinaryDecoder.read_ints","title":"<code>read_ints(n)</code>","text":"<p>Read a list of integers.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>def read_ints(self, n: int) -&gt; Tuple[int, ...]:\n    \"\"\"Read a list of integers.\"\"\"\n    return tuple(self.read_int() for _ in range(n))\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.BinaryDecoder.read_utf8","title":"<code>read_utf8()</code>","text":"<p>Read an utf-8 encoded string from the stream.</p> <p>A string is encoded as a long followed by that many bytes of UTF-8 encoded character data.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>def read_utf8(self) -&gt; str:\n    \"\"\"Read an utf-8 encoded string from the stream.\n\n    A string is encoded as a long followed by\n    that many bytes of UTF-8 encoded character data.\n    \"\"\"\n    return self.read_bytes().decode(UTF8)\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.BinaryDecoder.skip","title":"<code>skip(n)</code>  <code>abstractmethod</code>","text":"<p>Skip n bytes.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>@abstractmethod\ndef skip(self, n: int) -&gt; None:\n    \"\"\"Skip n bytes.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.BinaryDecoder.tell","title":"<code>tell()</code>  <code>abstractmethod</code>","text":"<p>Return the current position.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>@abstractmethod\ndef tell(self) -&gt; int:\n    \"\"\"Return the current position.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.StreamingBinaryDecoder","title":"<code>StreamingBinaryDecoder</code>","text":"<p>             Bases: <code>BinaryDecoder</code></p> <p>Decodes bytes into Python physical primitives.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>class StreamingBinaryDecoder(BinaryDecoder):\n    \"\"\"Decodes bytes into Python physical primitives.\"\"\"\n\n    __slots__ = \"_input_stream\"\n    _input_stream: InputStream\n\n    def __init__(self, input_stream: Union[bytes, InputStream]) -&gt; None:\n        \"\"\"Reader is a Python object on which we can call read, seek, and tell.\"\"\"\n        if isinstance(input_stream, bytes):\n            # In the case of bytes, we wrap it into a BytesIO to make it a stream\n            self._input_stream = io.BytesIO(input_stream)\n        else:\n            self._input_stream = input_stream\n\n    def tell(self) -&gt; int:\n        \"\"\"Return the current stream position.\"\"\"\n        return self._input_stream.tell()\n\n    def read(self, n: int) -&gt; bytes:\n        \"\"\"Read n bytes.\"\"\"\n        if n &lt; 0:\n            raise ValueError(f\"Requested {n} bytes to read, expected positive integer.\")\n        data: List[bytes] = []\n\n        n_remaining = n\n        while n_remaining &gt; 0:\n            data_read = self._input_stream.read(n_remaining)\n            read_len = len(data_read)\n            if read_len == n:\n                # If we read everything, we return directly\n                # otherwise we'll continue to fetch the rest\n                return data_read\n            elif read_len &lt;= 0:\n                raise EOFError(f\"EOF: read {read_len} bytes\")\n            data.append(data_read)\n            n_remaining -= read_len\n\n        return b\"\".join(data)\n\n    def skip(self, n: int) -&gt; None:\n        self._input_stream.seek(n, SEEK_CUR)\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.StreamingBinaryDecoder.__init__","title":"<code>__init__(input_stream)</code>","text":"<p>Reader is a Python object on which we can call read, seek, and tell.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>def __init__(self, input_stream: Union[bytes, InputStream]) -&gt; None:\n    \"\"\"Reader is a Python object on which we can call read, seek, and tell.\"\"\"\n    if isinstance(input_stream, bytes):\n        # In the case of bytes, we wrap it into a BytesIO to make it a stream\n        self._input_stream = io.BytesIO(input_stream)\n    else:\n        self._input_stream = input_stream\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.StreamingBinaryDecoder.read","title":"<code>read(n)</code>","text":"<p>Read n bytes.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>def read(self, n: int) -&gt; bytes:\n    \"\"\"Read n bytes.\"\"\"\n    if n &lt; 0:\n        raise ValueError(f\"Requested {n} bytes to read, expected positive integer.\")\n    data: List[bytes] = []\n\n    n_remaining = n\n    while n_remaining &gt; 0:\n        data_read = self._input_stream.read(n_remaining)\n        read_len = len(data_read)\n        if read_len == n:\n            # If we read everything, we return directly\n            # otherwise we'll continue to fetch the rest\n            return data_read\n        elif read_len &lt;= 0:\n            raise EOFError(f\"EOF: read {read_len} bytes\")\n        data.append(data_read)\n        n_remaining -= read_len\n\n    return b\"\".join(data)\n</code></pre>"},{"location":"reference/pyiceberg/avro/decoder/#pyiceberg.avro.decoder.StreamingBinaryDecoder.tell","title":"<code>tell()</code>","text":"<p>Return the current stream position.</p> Source code in <code>pyiceberg/avro/decoder.py</code> <pre><code>def tell(self) -&gt; int:\n    \"\"\"Return the current stream position.\"\"\"\n    return self._input_stream.tell()\n</code></pre>"},{"location":"reference/pyiceberg/avro/encoder/","title":"encoder","text":""},{"location":"reference/pyiceberg/avro/encoder/#pyiceberg.avro.encoder.BinaryEncoder","title":"<code>BinaryEncoder</code>","text":"<p>Encodes Python physical types into bytes.</p> Source code in <code>pyiceberg/avro/encoder.py</code> <pre><code>class BinaryEncoder:\n    \"\"\"Encodes Python physical types into bytes.\"\"\"\n\n    _output_stream: OutputStream\n\n    def __init__(self, output_stream: OutputStream) -&gt; None:\n        self._output_stream = output_stream\n\n    def write(self, b: bytes) -&gt; None:\n        self._output_stream.write(b)\n\n    def write_boolean(self, boolean: bool) -&gt; None:\n        \"\"\"Write a boolean as a single byte whose value is either 0 (false) or 1 (true).\n\n        Args:\n            boolean: The boolean to write.\n        \"\"\"\n        self.write(bytearray([bool(boolean)]))\n\n    def write_int(self, integer: int) -&gt; None:\n        \"\"\"Integer and long values are written using variable-length zig-zag coding.\"\"\"\n        datum = (integer &lt;&lt; 1) ^ (integer &gt;&gt; 63)\n        while (datum &amp; ~0x7F) != 0:\n            self.write(bytearray([(datum &amp; 0x7F) | 0x80]))\n            datum &gt;&gt;= 7\n        self.write(bytearray([datum]))\n\n    def write_float(self, f: float) -&gt; None:\n        \"\"\"Write a float as 4 bytes.\"\"\"\n        self.write(STRUCT_FLOAT.pack(f))\n\n    def write_double(self, f: float) -&gt; None:\n        \"\"\"Write a double as 8 bytes.\"\"\"\n        self.write(STRUCT_DOUBLE.pack(f))\n\n    def write_bytes(self, b: bytes) -&gt; None:\n        \"\"\"Bytes are encoded as a long followed by that many bytes of data.\"\"\"\n        self.write_int(len(b))\n        self.write(b)\n\n    def write_utf8(self, s: str) -&gt; None:\n        \"\"\"Encode a string as a long followed by that many bytes of UTF-8 encoded character data.\"\"\"\n        self.write_bytes(s.encode(UTF8))\n\n    def write_uuid(self, uuid: UUID) -&gt; None:\n        \"\"\"Write UUID as a fixed[16].\n\n        The uuid logical type represents a random generated universally unique identifier (UUID).\n        An uuid logical type annotates an Avro string. The string has to conform with RFC-4122.\n        \"\"\"\n        if len(uuid.bytes) != 16:\n            raise ValueError(f\"Expected UUID to have 16 bytes, got: len({uuid.bytes!r})\")\n        return self.write(uuid.bytes)\n</code></pre>"},{"location":"reference/pyiceberg/avro/encoder/#pyiceberg.avro.encoder.BinaryEncoder.write_boolean","title":"<code>write_boolean(boolean)</code>","text":"<p>Write a boolean as a single byte whose value is either 0 (false) or 1 (true).</p> <p>Parameters:</p> Name Type Description Default <code>boolean</code> <code>bool</code> <p>The boolean to write.</p> required Source code in <code>pyiceberg/avro/encoder.py</code> <pre><code>def write_boolean(self, boolean: bool) -&gt; None:\n    \"\"\"Write a boolean as a single byte whose value is either 0 (false) or 1 (true).\n\n    Args:\n        boolean: The boolean to write.\n    \"\"\"\n    self.write(bytearray([bool(boolean)]))\n</code></pre>"},{"location":"reference/pyiceberg/avro/encoder/#pyiceberg.avro.encoder.BinaryEncoder.write_bytes","title":"<code>write_bytes(b)</code>","text":"<p>Bytes are encoded as a long followed by that many bytes of data.</p> Source code in <code>pyiceberg/avro/encoder.py</code> <pre><code>def write_bytes(self, b: bytes) -&gt; None:\n    \"\"\"Bytes are encoded as a long followed by that many bytes of data.\"\"\"\n    self.write_int(len(b))\n    self.write(b)\n</code></pre>"},{"location":"reference/pyiceberg/avro/encoder/#pyiceberg.avro.encoder.BinaryEncoder.write_double","title":"<code>write_double(f)</code>","text":"<p>Write a double as 8 bytes.</p> Source code in <code>pyiceberg/avro/encoder.py</code> <pre><code>def write_double(self, f: float) -&gt; None:\n    \"\"\"Write a double as 8 bytes.\"\"\"\n    self.write(STRUCT_DOUBLE.pack(f))\n</code></pre>"},{"location":"reference/pyiceberg/avro/encoder/#pyiceberg.avro.encoder.BinaryEncoder.write_float","title":"<code>write_float(f)</code>","text":"<p>Write a float as 4 bytes.</p> Source code in <code>pyiceberg/avro/encoder.py</code> <pre><code>def write_float(self, f: float) -&gt; None:\n    \"\"\"Write a float as 4 bytes.\"\"\"\n    self.write(STRUCT_FLOAT.pack(f))\n</code></pre>"},{"location":"reference/pyiceberg/avro/encoder/#pyiceberg.avro.encoder.BinaryEncoder.write_int","title":"<code>write_int(integer)</code>","text":"<p>Integer and long values are written using variable-length zig-zag coding.</p> Source code in <code>pyiceberg/avro/encoder.py</code> <pre><code>def write_int(self, integer: int) -&gt; None:\n    \"\"\"Integer and long values are written using variable-length zig-zag coding.\"\"\"\n    datum = (integer &lt;&lt; 1) ^ (integer &gt;&gt; 63)\n    while (datum &amp; ~0x7F) != 0:\n        self.write(bytearray([(datum &amp; 0x7F) | 0x80]))\n        datum &gt;&gt;= 7\n    self.write(bytearray([datum]))\n</code></pre>"},{"location":"reference/pyiceberg/avro/encoder/#pyiceberg.avro.encoder.BinaryEncoder.write_utf8","title":"<code>write_utf8(s)</code>","text":"<p>Encode a string as a long followed by that many bytes of UTF-8 encoded character data.</p> Source code in <code>pyiceberg/avro/encoder.py</code> <pre><code>def write_utf8(self, s: str) -&gt; None:\n    \"\"\"Encode a string as a long followed by that many bytes of UTF-8 encoded character data.\"\"\"\n    self.write_bytes(s.encode(UTF8))\n</code></pre>"},{"location":"reference/pyiceberg/avro/encoder/#pyiceberg.avro.encoder.BinaryEncoder.write_uuid","title":"<code>write_uuid(uuid)</code>","text":"<p>Write UUID as a fixed[16].</p> <p>The uuid logical type represents a random generated universally unique identifier (UUID). An uuid logical type annotates an Avro string. The string has to conform with RFC-4122.</p> Source code in <code>pyiceberg/avro/encoder.py</code> <pre><code>def write_uuid(self, uuid: UUID) -&gt; None:\n    \"\"\"Write UUID as a fixed[16].\n\n    The uuid logical type represents a random generated universally unique identifier (UUID).\n    An uuid logical type annotates an Avro string. The string has to conform with RFC-4122.\n    \"\"\"\n    if len(uuid.bytes) != 16:\n        raise ValueError(f\"Expected UUID to have 16 bytes, got: len({uuid.bytes!r})\")\n    return self.write(uuid.bytes)\n</code></pre>"},{"location":"reference/pyiceberg/avro/file/","title":"file","text":"<p>Avro reader for reading Avro files.</p>"},{"location":"reference/pyiceberg/avro/file/#pyiceberg.avro.file.AvroFile","title":"<code>AvroFile</code>","text":"<p>             Bases: <code>Generic[D]</code></p> Source code in <code>pyiceberg/avro/file.py</code> <pre><code>class AvroFile(Generic[D]):\n    __slots__ = (\n        \"input_file\",\n        \"read_schema\",\n        \"read_types\",\n        \"read_enums\",\n        \"header\",\n        \"schema\",\n        \"reader\",\n        \"decoder\",\n        \"block\",\n    )\n    input_file: InputFile\n    read_schema: Optional[Schema]\n    read_types: Dict[int, Callable[..., StructProtocol]]\n    read_enums: Dict[int, Callable[..., Enum]]\n    header: AvroFileHeader\n    schema: Schema\n    reader: Reader\n\n    decoder: BinaryDecoder\n    block: Optional[Block[D]]\n\n    def __init__(\n        self,\n        input_file: InputFile,\n        read_schema: Optional[Schema] = None,\n        read_types: Dict[int, Callable[..., StructProtocol]] = EMPTY_DICT,\n        read_enums: Dict[int, Callable[..., Enum]] = EMPTY_DICT,\n    ) -&gt; None:\n        self.input_file = input_file\n        self.read_schema = read_schema\n        self.read_types = read_types\n        self.read_enums = read_enums\n        self.block = None\n\n    def __enter__(self) -&gt; AvroFile[D]:\n        \"\"\"Generate a reader tree for the payload within an avro file.\n\n        Return:\n            A generator returning the AvroStructs.\n        \"\"\"\n        with self.input_file.open() as f:\n            self.decoder = new_decoder(f.read())\n        self.header = self._read_header()\n        self.schema = self.header.get_schema()\n        if not self.read_schema:\n            self.read_schema = self.schema\n\n        self.reader = resolve_reader(self.schema, self.read_schema, self.read_types, self.read_enums)\n\n        return self\n\n    def __exit__(\n        self, exctype: Optional[Type[BaseException]], excinst: Optional[BaseException], exctb: Optional[TracebackType]\n    ) -&gt; None:\n        \"\"\"Perform cleanup when exiting the scope of a 'with' statement.\"\"\"\n\n    def __iter__(self) -&gt; AvroFile[D]:\n        \"\"\"Return an iterator for the AvroFile class.\"\"\"\n        return self\n\n    def _read_block(self) -&gt; int:\n        # If there is already a block, we'll have the sync bytes\n        if self.block:\n            sync_marker = self.decoder.read(SYNC_SIZE)\n            if sync_marker != self.header.sync:\n                raise ValueError(f\"Expected sync bytes {self.header.sync!r}, but got {sync_marker!r}\")\n        block_records = self.decoder.read_int()\n\n        block_bytes = self.decoder.read_bytes()\n        if codec := self.header.compression_codec():\n            block_bytes = codec.decompress(block_bytes)\n\n        self.block = Block(reader=self.reader, block_records=block_records, block_decoder=new_decoder(block_bytes))\n        return block_records\n\n    def __next__(self) -&gt; D:\n        \"\"\"Return the next item when iterating over the AvroFile class.\"\"\"\n        if self.block and self.block.has_next():\n            return next(self.block)\n\n        try:\n            new_block = self._read_block()\n        except EOFError as exc:\n            raise StopIteration from exc\n\n        if new_block &gt; 0:\n            return self.__next__()\n        raise StopIteration\n\n    def _read_header(self) -&gt; AvroFileHeader:\n        return construct_reader(META_SCHEMA, {-1: AvroFileHeader}).read(self.decoder)\n</code></pre>"},{"location":"reference/pyiceberg/avro/file/#pyiceberg.avro.file.AvroFile.__enter__","title":"<code>__enter__()</code>","text":"<p>Generate a reader tree for the payload within an avro file.</p> Return <p>A generator returning the AvroStructs.</p> Source code in <code>pyiceberg/avro/file.py</code> <pre><code>def __enter__(self) -&gt; AvroFile[D]:\n    \"\"\"Generate a reader tree for the payload within an avro file.\n\n    Return:\n        A generator returning the AvroStructs.\n    \"\"\"\n    with self.input_file.open() as f:\n        self.decoder = new_decoder(f.read())\n    self.header = self._read_header()\n    self.schema = self.header.get_schema()\n    if not self.read_schema:\n        self.read_schema = self.schema\n\n    self.reader = resolve_reader(self.schema, self.read_schema, self.read_types, self.read_enums)\n\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/avro/file/#pyiceberg.avro.file.AvroFile.__exit__","title":"<code>__exit__(exctype, excinst, exctb)</code>","text":"<p>Perform cleanup when exiting the scope of a 'with' statement.</p> Source code in <code>pyiceberg/avro/file.py</code> <pre><code>def __exit__(\n    self, exctype: Optional[Type[BaseException]], excinst: Optional[BaseException], exctb: Optional[TracebackType]\n) -&gt; None:\n    \"\"\"Perform cleanup when exiting the scope of a 'with' statement.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/file/#pyiceberg.avro.file.AvroFile.__iter__","title":"<code>__iter__()</code>","text":"<p>Return an iterator for the AvroFile class.</p> Source code in <code>pyiceberg/avro/file.py</code> <pre><code>def __iter__(self) -&gt; AvroFile[D]:\n    \"\"\"Return an iterator for the AvroFile class.\"\"\"\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/avro/file/#pyiceberg.avro.file.AvroFile.__next__","title":"<code>__next__()</code>","text":"<p>Return the next item when iterating over the AvroFile class.</p> Source code in <code>pyiceberg/avro/file.py</code> <pre><code>def __next__(self) -&gt; D:\n    \"\"\"Return the next item when iterating over the AvroFile class.\"\"\"\n    if self.block and self.block.has_next():\n        return next(self.block)\n\n    try:\n        new_block = self._read_block()\n    except EOFError as exc:\n        raise StopIteration from exc\n\n    if new_block &gt; 0:\n        return self.__next__()\n    raise StopIteration\n</code></pre>"},{"location":"reference/pyiceberg/avro/file/#pyiceberg.avro.file.AvroFileHeader","title":"<code>AvroFileHeader</code>","text":"<p>             Bases: <code>Record</code></p> Source code in <code>pyiceberg/avro/file.py</code> <pre><code>class AvroFileHeader(Record):\n    __slots__ = (\"magic\", \"meta\", \"sync\")\n    magic: bytes\n    meta: Dict[str, str]\n    sync: bytes\n\n    def compression_codec(self) -&gt; Optional[Type[Codec]]:\n        \"\"\"Get the file's compression codec algorithm from the file's metadata.\n\n        In the case of a null codec, we return a None indicating that we\n        don't need to compress/decompress.\n        \"\"\"\n        codec_name = self.meta.get(_CODEC_KEY, \"null\")\n        if codec_name not in KNOWN_CODECS:\n            raise ValueError(f\"Unsupported codec: {codec_name}\")\n\n        return KNOWN_CODECS[codec_name]\n\n    def get_schema(self) -&gt; Schema:\n        if _SCHEMA_KEY in self.meta:\n            avro_schema_string = self.meta[_SCHEMA_KEY]\n            avro_schema = json.loads(avro_schema_string)\n            return AvroSchemaConversion().avro_to_iceberg(avro_schema)\n        else:\n            raise ValueError(\"No schema found in Avro file headers\")\n</code></pre>"},{"location":"reference/pyiceberg/avro/file/#pyiceberg.avro.file.AvroFileHeader.compression_codec","title":"<code>compression_codec()</code>","text":"<p>Get the file's compression codec algorithm from the file's metadata.</p> <p>In the case of a null codec, we return a None indicating that we don't need to compress/decompress.</p> Source code in <code>pyiceberg/avro/file.py</code> <pre><code>def compression_codec(self) -&gt; Optional[Type[Codec]]:\n    \"\"\"Get the file's compression codec algorithm from the file's metadata.\n\n    In the case of a null codec, we return a None indicating that we\n    don't need to compress/decompress.\n    \"\"\"\n    codec_name = self.meta.get(_CODEC_KEY, \"null\")\n    if codec_name not in KNOWN_CODECS:\n        raise ValueError(f\"Unsupported codec: {codec_name}\")\n\n    return KNOWN_CODECS[codec_name]\n</code></pre>"},{"location":"reference/pyiceberg/avro/file/#pyiceberg.avro.file.AvroOutputFile","title":"<code>AvroOutputFile</code>","text":"<p>             Bases: <code>Generic[D]</code></p> Source code in <code>pyiceberg/avro/file.py</code> <pre><code>class AvroOutputFile(Generic[D]):\n    output_file: OutputFile\n    output_stream: OutputStream\n    file_schema: Schema\n    schema_name: str\n    encoder: BinaryEncoder\n    sync_bytes: bytes\n    writer: Writer\n\n    def __init__(\n        self,\n        output_file: OutputFile,\n        file_schema: Schema,\n        schema_name: str,\n        record_schema: Optional[Schema] = None,\n        metadata: Dict[str, str] = EMPTY_DICT,\n    ) -&gt; None:\n        self.output_file = output_file\n        self.file_schema = file_schema\n        self.schema_name = schema_name\n        self.sync_bytes = os.urandom(SYNC_SIZE)\n        self.writer = (\n            construct_writer(file_schema=self.file_schema)\n            if record_schema is None\n            else resolve_writer(record_schema=record_schema, file_schema=self.file_schema)\n        )\n        self.metadata = metadata\n\n    def __enter__(self) -&gt; AvroOutputFile[D]:\n        \"\"\"\n        Open the file and writes the header.\n\n        Returns:\n            The file object to write records to\n        \"\"\"\n        self.output_stream = self.output_file.create(overwrite=True)\n        self.encoder = BinaryEncoder(self.output_stream)\n\n        self._write_header()\n\n        return self\n\n    def __exit__(\n        self, exctype: Optional[Type[BaseException]], excinst: Optional[BaseException], exctb: Optional[TracebackType]\n    ) -&gt; None:\n        \"\"\"Perform cleanup when exiting the scope of a 'with' statement.\"\"\"\n        self.output_stream.close()\n\n    def _write_header(self) -&gt; None:\n        json_schema = json.dumps(AvroSchemaConversion().iceberg_to_avro(self.file_schema, schema_name=self.schema_name))\n        meta = {**self.metadata, _SCHEMA_KEY: json_schema, _CODEC_KEY: \"null\"}\n        header = AvroFileHeader(magic=MAGIC, meta=meta, sync=self.sync_bytes)\n        construct_writer(META_SCHEMA).write(self.encoder, header)\n\n    def write_block(self, objects: List[D]) -&gt; None:\n        in_memory = io.BytesIO()\n        block_content_encoder = BinaryEncoder(output_stream=in_memory)\n        for obj in objects:\n            self.writer.write(block_content_encoder, obj)\n        block_content = in_memory.getvalue()\n\n        self.encoder.write_int(len(objects))\n        self.encoder.write_int(len(block_content))\n        self.encoder.write(block_content)\n        self.encoder.write(self.sync_bytes)\n</code></pre>"},{"location":"reference/pyiceberg/avro/file/#pyiceberg.avro.file.AvroOutputFile.__enter__","title":"<code>__enter__()</code>","text":"<p>Open the file and writes the header.</p> <p>Returns:</p> Type Description <code>AvroOutputFile[D]</code> <p>The file object to write records to</p> Source code in <code>pyiceberg/avro/file.py</code> <pre><code>def __enter__(self) -&gt; AvroOutputFile[D]:\n    \"\"\"\n    Open the file and writes the header.\n\n    Returns:\n        The file object to write records to\n    \"\"\"\n    self.output_stream = self.output_file.create(overwrite=True)\n    self.encoder = BinaryEncoder(self.output_stream)\n\n    self._write_header()\n\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/avro/file/#pyiceberg.avro.file.AvroOutputFile.__exit__","title":"<code>__exit__(exctype, excinst, exctb)</code>","text":"<p>Perform cleanup when exiting the scope of a 'with' statement.</p> Source code in <code>pyiceberg/avro/file.py</code> <pre><code>def __exit__(\n    self, exctype: Optional[Type[BaseException]], excinst: Optional[BaseException], exctb: Optional[TracebackType]\n) -&gt; None:\n    \"\"\"Perform cleanup when exiting the scope of a 'with' statement.\"\"\"\n    self.output_stream.close()\n</code></pre>"},{"location":"reference/pyiceberg/avro/file/#pyiceberg.avro.file.Block","title":"<code>Block</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Generic[D]</code></p> Source code in <code>pyiceberg/avro/file.py</code> <pre><code>@dataclass\nclass Block(Generic[D]):\n    reader: Reader\n    block_records: int\n    block_decoder: BinaryDecoder\n    position: int = 0\n\n    def __iter__(self) -&gt; Block[D]:\n        \"\"\"Return an iterator for the Block class.\"\"\"\n        return self\n\n    def has_next(self) -&gt; bool:\n        return self.position &lt; self.block_records\n\n    def __next__(self) -&gt; D:\n        \"\"\"Return the next item when iterating over the Block class.\"\"\"\n        if self.has_next():\n            self.position += 1\n            return self.reader.read(self.block_decoder)\n        raise StopIteration\n</code></pre>"},{"location":"reference/pyiceberg/avro/file/#pyiceberg.avro.file.Block.__iter__","title":"<code>__iter__()</code>","text":"<p>Return an iterator for the Block class.</p> Source code in <code>pyiceberg/avro/file.py</code> <pre><code>def __iter__(self) -&gt; Block[D]:\n    \"\"\"Return an iterator for the Block class.\"\"\"\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/avro/file/#pyiceberg.avro.file.Block.__next__","title":"<code>__next__()</code>","text":"<p>Return the next item when iterating over the Block class.</p> Source code in <code>pyiceberg/avro/file.py</code> <pre><code>def __next__(self) -&gt; D:\n    \"\"\"Return the next item when iterating over the Block class.\"\"\"\n    if self.has_next():\n        self.position += 1\n        return self.reader.read(self.block_decoder)\n    raise StopIteration\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/","title":"reader","text":"<p>Classes for building the Reader tree.</p> <p>Constructing a reader tree from the schema makes it easy to decouple the reader implementation from the schema.</p> <p>The reader tree can be changed in such a way that the read schema is different, while respecting the read schema.</p>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.BinaryReader","title":"<code>BinaryReader</code>","text":"<p>             Bases: <code>Reader</code></p> <p>Read a binary value.</p> <p>First reads an integer, to get the length of the binary value, then reads the binary field itself.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>class BinaryReader(Reader):\n    \"\"\"Read a binary value.\n\n    First reads an integer, to get the length of the binary value,\n    then reads the binary field itself.\n    \"\"\"\n\n    def read(self, decoder: BinaryDecoder) -&gt; bytes:\n        return decoder.read_bytes()\n\n    def skip(self, decoder: BinaryDecoder) -&gt; None:\n        decoder.skip_bytes()\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.DateReader","title":"<code>DateReader</code>","text":"<p>             Bases: <code>IntegerReader</code></p> <p>Reads a day granularity date from the stream.</p> <p>The number of days from 1 January 1970.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>class DateReader(IntegerReader):\n    \"\"\"Reads a day granularity date from the stream.\n\n    The number of days from 1 January 1970.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.DecimalReader","title":"<code>DecimalReader</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Reader</code></p> <p>Reads a value as a decimal.</p> <p>Decimal bytes are decoded as signed short, int or long depending on the size of bytes.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>@dataclass(frozen=True, init=False)\nclass DecimalReader(Reader):\n    \"\"\"Reads a value as a decimal.\n\n    Decimal bytes are decoded as signed short, int or long depending on the\n    size of bytes.\n    \"\"\"\n\n    precision: int = dataclassfield()\n    scale: int = dataclassfield()\n    _length: int\n\n    def __init__(self, precision: int, scale: int):\n        object.__setattr__(self, \"precision\", precision)\n        object.__setattr__(self, \"scale\", scale)\n        object.__setattr__(self, \"_length\", decimal_required_bytes(precision))\n\n    def read(self, decoder: BinaryDecoder) -&gt; Decimal:\n        return bytes_to_decimal(decoder.read(self._length), self.scale)\n\n    def skip(self, decoder: BinaryDecoder) -&gt; None:\n        decoder.skip_bytes()\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the DecimalReader class.\"\"\"\n        return f\"DecimalReader({self.precision}, {self.scale})\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.DecimalReader.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the DecimalReader class.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the DecimalReader class.\"\"\"\n    return f\"DecimalReader({self.precision}, {self.scale})\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.FixedReader","title":"<code>FixedReader</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Reader</code></p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>@dataclass(frozen=True)\nclass FixedReader(Reader):\n    _len: int = dataclassfield()\n\n    def read(self, decoder: BinaryDecoder) -&gt; bytes:\n        return decoder.read(len(self))\n\n    def skip(self, decoder: BinaryDecoder) -&gt; None:\n        decoder.skip(len(self))\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the length of an instance of the FixedReader class.\"\"\"\n        return self._len\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the FixedReader class.\"\"\"\n        return f\"FixedReader({self._len})\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.FixedReader.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of an instance of the FixedReader class.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the length of an instance of the FixedReader class.\"\"\"\n    return self._len\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.FixedReader.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the FixedReader class.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the FixedReader class.\"\"\"\n    return f\"FixedReader({self._len})\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.IntegerReader","title":"<code>IntegerReader</code>","text":"<p>             Bases: <code>Reader</code></p> <p>Longs and ints are encoded the same way, and there is no long in Python.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>class IntegerReader(Reader):\n    \"\"\"Longs and ints are encoded the same way, and there is no long in Python.\"\"\"\n\n    def read(self, decoder: BinaryDecoder) -&gt; int:\n        return decoder.read_int()\n\n    def skip(self, decoder: BinaryDecoder) -&gt; None:\n        decoder.skip_int()\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.ListReader","title":"<code>ListReader</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Reader</code></p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>@dataclass(frozen=False, init=False)\nclass ListReader(Reader):\n    __slots__ = (\"element\", \"_is_int_list\", \"_hash\")\n    element: Reader\n\n    def __init__(self, element: Reader) -&gt; None:\n        super().__init__()\n        self.element = element\n        self._hash = hash(self.element)\n        self._is_int_list = isinstance(self.element, IntegerReader)\n\n    def read(self, decoder: BinaryDecoder) -&gt; List[Any]:\n        read_items: List[Any] = []\n        block_count = decoder.read_int()\n        while block_count != 0:\n            if block_count &lt; 0:\n                block_count = -block_count\n                _ = decoder.read_int()\n            if self._is_int_list:\n                read_items.extend(decoder.read_ints(block_count))\n            else:\n                for _ in range(block_count):\n                    read_items.append(self.element.read(decoder))\n            block_count = decoder.read_int()\n        return read_items\n\n    def skip(self, decoder: BinaryDecoder) -&gt; None:\n        _skip_map_array(decoder, lambda: self.element.skip(decoder))\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Return a hashed representation of the ListReader class.\"\"\"\n        return self._hash\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.ListReader.__hash__","title":"<code>__hash__()</code>","text":"<p>Return a hashed representation of the ListReader class.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Return a hashed representation of the ListReader class.\"\"\"\n    return self._hash\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.MapReader","title":"<code>MapReader</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Reader</code></p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>@dataclass(frozen=False, init=False)\nclass MapReader(Reader):\n    __slots__ = (\"key\", \"value\", \"_is_int_int\", \"_is_int_bytes\", \"_key_reader\", \"_value_reader\", \"_hash\")\n    key: Reader\n    value: Reader\n\n    def __init__(self, key: Reader, value: Reader) -&gt; None:\n        super().__init__()\n        self.key = key\n        self.value = value\n        if isinstance(self.key, IntegerReader):\n            self._is_int_int = isinstance(self.value, IntegerReader)\n            self._is_int_bytes = isinstance(self.value, BinaryReader)\n        else:\n            self._is_int_int = False\n            self._is_int_bytes = False\n            self._key_reader = self.key.read\n            self._value_reader = self.value.read\n        self._hash = hash((self.key, self.value))\n\n    def _read_int_int(self, decoder: BinaryDecoder) -&gt; Mapping[int, int]:\n        \"\"\"Read a mapping from int to int from the decoder.\n\n        Read a map of ints to ints from the decoder, since this is such a common\n        data type, it is optimized to be faster than the generic map reader, by\n        using a lazy dict.\n\n        The time it takes to create the python dictionary is much larger than\n        the time it takes to read the data from the decoder as an array, so the\n        lazy dict defers creating the python dictionary until it is actually\n        accessed.\n\n        \"\"\"\n        block_count = decoder.read_int()\n\n        # Often times the map is empty, so we can just return an empty dict without\n        # instancing the LazyDict\n        if block_count == 0:\n            return EMPTY_DICT\n\n        contents_array: List[Tuple[int, ...]] = []\n\n        while block_count != 0:\n            if block_count &lt; 0:\n                block_count = -block_count\n                # We ignore the block size for now\n                decoder.skip_int()\n\n            # Since the integers are encoding right next to each other\n            # just read them all at once.\n            contents_array.append(decoder.read_ints(block_count * 2))\n            block_count = decoder.read_int()\n\n        return LazyDict(contents_array)\n\n    def read(self, decoder: BinaryDecoder) -&gt; Mapping[Any, Any]:\n        read_items: dict[Any, Any] = {}\n\n        if self._is_int_int or self._is_int_bytes:\n            if self._is_int_int:\n                return self._read_int_int(decoder)\n\n            block_count = decoder.read_int()\n            while block_count != 0:\n                if block_count &lt; 0:\n                    block_count = -block_count\n                    # We ignore the block size for now\n                    _ = decoder.read_int()\n                decoder.read_int_bytes_dict(block_count, read_items)\n                block_count = decoder.read_int()\n        else:\n            block_count = decoder.read_int()\n            while block_count != 0:\n                if block_count &lt; 0:\n                    block_count = -block_count\n                    # We ignore the block size for now\n                    _ = decoder.read_int()\n                for _ in range(block_count):\n                    key = self._key_reader(decoder)\n                    read_items[key] = self._value_reader(decoder)\n                block_count = decoder.read_int()\n\n        return read_items\n\n    def skip(self, decoder: BinaryDecoder) -&gt; None:\n        def skip() -&gt; None:\n            self.key.skip(decoder)\n            self.value.skip(decoder)\n\n        _skip_map_array(decoder, skip)\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Return a hashed representation of the MapReader class.\"\"\"\n        return self._hash\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.MapReader.__hash__","title":"<code>__hash__()</code>","text":"<p>Return a hashed representation of the MapReader class.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Return a hashed representation of the MapReader class.\"\"\"\n    return self._hash\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.Reader","title":"<code>Reader</code>","text":"<p>             Bases: <code>Singleton</code></p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>class Reader(Singleton):\n    @abstractmethod\n    def read(self, decoder: BinaryDecoder) -&gt; Any: ...\n\n    @abstractmethod\n    def skip(self, decoder: BinaryDecoder) -&gt; None: ...\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the Reader class.\"\"\"\n        return f\"{self.__class__.__name__}()\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.Reader.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the Reader class.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the Reader class.\"\"\"\n    return f\"{self.__class__.__name__}()\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.StructReader","title":"<code>StructReader</code>","text":"<p>             Bases: <code>Reader</code></p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>class StructReader(Reader):\n    __slots__ = (\"field_readers\", \"create_struct\", \"struct\", \"_create_with_keyword\", \"_field_reader_functions\", \"_hash\")\n    field_readers: Tuple[Tuple[Optional[int], Reader], ...]\n    create_struct: Callable[..., StructProtocol]\n    struct: StructType\n    field_reader_functions = Tuple[Tuple[Optional[str], int, Optional[Callable[[BinaryDecoder], Any]]], ...]\n\n    def __init__(\n        self,\n        field_readers: Tuple[Tuple[Optional[int], Reader], ...],\n        create_struct: Callable[..., StructProtocol],\n        struct: StructType,\n    ) -&gt; None:\n        self.field_readers = field_readers\n        self.create_struct = create_struct\n        self.struct = struct\n\n        try:\n            # Try initializing the struct, first with the struct keyword argument\n            created_struct = self.create_struct(struct=self.struct)\n            self._create_with_keyword = True\n        except TypeError as e:\n            if \"'struct' is an invalid keyword argument for\" in str(e):\n                created_struct = self.create_struct()\n                self._create_with_keyword = False\n            else:\n                raise ValueError(f\"Unable to initialize struct: {self.create_struct}\") from e\n\n        if not isinstance(created_struct, StructProtocol):\n            raise ValueError(f\"Incompatible with StructProtocol: {self.create_struct}\")\n\n        reading_callbacks: List[Tuple[Optional[int], Callable[[BinaryDecoder], Any]]] = []\n        for pos, field in field_readers:\n            if pos is not None:\n                reading_callbacks.append((pos, field.read))\n            else:\n                reading_callbacks.append((None, field.skip))\n\n        self._field_reader_functions = tuple(reading_callbacks)\n        self._hash = hash(self._field_reader_functions)\n\n    def read(self, decoder: BinaryDecoder) -&gt; StructProtocol:\n        struct = self.create_struct(struct=self.struct) if self._create_with_keyword else self.create_struct()\n        for pos, field_reader in self._field_reader_functions:\n            if pos is not None:\n                struct[pos] = field_reader(decoder)  # later: pass reuse in here\n            else:\n                field_reader(decoder)\n\n        return struct\n\n    def skip(self, decoder: BinaryDecoder) -&gt; None:\n        for _, field in self.field_readers:\n            field.skip(decoder)\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the StructReader class.\"\"\"\n        return (\n            self.field_readers == other.field_readers and self.create_struct == other.create_struct\n            if isinstance(other, StructReader)\n            else False\n        )\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the StructReader class.\"\"\"\n        return f\"StructReader(({','.join(repr(field) for field in self.field_readers)}), {repr(self.create_struct)})\"\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Return a hashed representation of the StructReader class.\"\"\"\n        return self._hash\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.StructReader.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the StructReader class.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the StructReader class.\"\"\"\n    return (\n        self.field_readers == other.field_readers and self.create_struct == other.create_struct\n        if isinstance(other, StructReader)\n        else False\n    )\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.StructReader.__hash__","title":"<code>__hash__()</code>","text":"<p>Return a hashed representation of the StructReader class.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Return a hashed representation of the StructReader class.\"\"\"\n    return self._hash\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.StructReader.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the StructReader class.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the StructReader class.\"\"\"\n    return f\"StructReader(({','.join(repr(field) for field in self.field_readers)}), {repr(self.create_struct)})\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.TimeReader","title":"<code>TimeReader</code>","text":"<p>             Bases: <code>IntegerReader</code></p> <p>Reads a microsecond granularity timestamp from the stream.</p> <p>Long is decoded as an integer which represents the number of microseconds from the unix epoch, 1 January 1970.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>class TimeReader(IntegerReader):\n    \"\"\"Reads a microsecond granularity timestamp from the stream.\n\n    Long is decoded as an integer which represents\n    the number of microseconds from the unix epoch, 1 January 1970.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.TimestampReader","title":"<code>TimestampReader</code>","text":"<p>             Bases: <code>IntegerReader</code></p> <p>Reads a microsecond granularity timestamp from the stream.</p> <p>Long is decoded as python integer which represents the number of microseconds from the unix epoch, 1 January 1970.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>class TimestampReader(IntegerReader):\n    \"\"\"Reads a microsecond granularity timestamp from the stream.\n\n    Long is decoded as python integer which represents\n    the number of microseconds from the unix epoch, 1 January 1970.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/reader/#pyiceberg.avro.reader.TimestamptzReader","title":"<code>TimestamptzReader</code>","text":"<p>             Bases: <code>IntegerReader</code></p> <p>Reads a microsecond granularity timestamptz from the stream.</p> <p>Long is decoded as python integer which represents the number of microseconds from the unix epoch, 1 January 1970.</p> <p>Adjusted to UTC.</p> Source code in <code>pyiceberg/avro/reader.py</code> <pre><code>class TimestamptzReader(IntegerReader):\n    \"\"\"Reads a microsecond granularity timestamptz from the stream.\n\n    Long is decoded as python integer which represents\n    the number of microseconds from the unix epoch, 1 January 1970.\n\n    Adjusted to UTC.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/resolver/","title":"resolver","text":""},{"location":"reference/pyiceberg/avro/resolver/#pyiceberg.avro.resolver.ConstructWriter","title":"<code>ConstructWriter</code>","text":"<p>             Bases: <code>SchemaVisitorPerPrimitiveType[Writer]</code></p> <p>Construct a writer tree from an Iceberg schema.</p> Source code in <code>pyiceberg/avro/resolver.py</code> <pre><code>class ConstructWriter(SchemaVisitorPerPrimitiveType[Writer]):\n    \"\"\"Construct a writer tree from an Iceberg schema.\"\"\"\n\n    def schema(self, schema: Schema, struct_result: Writer) -&gt; Writer:\n        return struct_result\n\n    def struct(self, struct: StructType, field_results: List[Writer]) -&gt; Writer:\n        return StructWriter(tuple((pos, result) for pos, result in enumerate(field_results)))\n\n    def field(self, field: NestedField, field_result: Writer) -&gt; Writer:\n        return field_result if field.required else OptionWriter(field_result)\n\n    def list(self, list_type: ListType, element_result: Writer) -&gt; Writer:\n        return ListWriter(element_result)\n\n    def map(self, map_type: MapType, key_result: Writer, value_result: Writer) -&gt; Writer:\n        return MapWriter(key_result, value_result)\n\n    def visit_fixed(self, fixed_type: FixedType) -&gt; Writer:\n        return FixedWriter(len(fixed_type))\n\n    def visit_decimal(self, decimal_type: DecimalType) -&gt; Writer:\n        return DecimalWriter(decimal_type.precision, decimal_type.scale)\n\n    def visit_boolean(self, boolean_type: BooleanType) -&gt; Writer:\n        return BooleanWriter()\n\n    def visit_integer(self, integer_type: IntegerType) -&gt; Writer:\n        return IntegerWriter()\n\n    def visit_long(self, long_type: LongType) -&gt; Writer:\n        return IntegerWriter()\n\n    def visit_float(self, float_type: FloatType) -&gt; Writer:\n        return FloatWriter()\n\n    def visit_double(self, double_type: DoubleType) -&gt; Writer:\n        return DoubleWriter()\n\n    def visit_date(self, date_type: DateType) -&gt; Writer:\n        return DateWriter()\n\n    def visit_time(self, time_type: TimeType) -&gt; Writer:\n        return TimeWriter()\n\n    def visit_timestamp(self, timestamp_type: TimestampType) -&gt; Writer:\n        return TimestampWriter()\n\n    def visit_timestamptz(self, timestamptz_type: TimestamptzType) -&gt; Writer:\n        return TimestamptzWriter()\n\n    def visit_string(self, string_type: StringType) -&gt; Writer:\n        return StringWriter()\n\n    def visit_uuid(self, uuid_type: UUIDType) -&gt; Writer:\n        return UUIDWriter()\n\n    def visit_binary(self, binary_type: BinaryType) -&gt; Writer:\n        return BinaryWriter()\n</code></pre>"},{"location":"reference/pyiceberg/avro/resolver/#pyiceberg.avro.resolver.EnumReader","title":"<code>EnumReader</code>","text":"<p>             Bases: <code>Reader</code></p> <p>An Enum reader to wrap primitive values into an Enum.</p> Source code in <code>pyiceberg/avro/resolver.py</code> <pre><code>class EnumReader(Reader):\n    \"\"\"An Enum reader to wrap primitive values into an Enum.\"\"\"\n\n    __slots__ = (\"enum\", \"reader\")\n\n    enum: Callable[..., Enum]\n    reader: Reader\n\n    def __init__(self, enum: Callable[..., Enum], reader: Reader) -&gt; None:\n        self.enum = enum\n        self.reader = reader\n\n    def read(self, decoder: BinaryDecoder) -&gt; Enum:\n        return self.enum(self.reader.read(decoder))\n\n    def skip(self, decoder: BinaryDecoder) -&gt; None:\n        pass\n</code></pre>"},{"location":"reference/pyiceberg/avro/resolver/#pyiceberg.avro.resolver.construct_reader","title":"<code>construct_reader(file_schema, read_types=EMPTY_DICT)</code>","text":"<p>Construct a reader from a file schema.</p> <p>Parameters:</p> Name Type Description Default <code>file_schema</code> <code>Schema | IcebergType</code> <p>The schema of the Avro file.</p> required <code>read_types</code> <code>Dict[int, Callable[..., StructProtocol]]</code> <p>Constructors for structs for certain field-ids</p> <code>EMPTY_DICT</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If attempting to resolve an unrecognized object type.</p> Source code in <code>pyiceberg/avro/resolver.py</code> <pre><code>def construct_reader(\n    file_schema: Union[Schema, IcebergType], read_types: Dict[int, Callable[..., StructProtocol]] = EMPTY_DICT\n) -&gt; Reader:\n    \"\"\"Construct a reader from a file schema.\n\n    Args:\n        file_schema (Schema | IcebergType): The schema of the Avro file.\n        read_types (Dict[int, Callable[..., StructProtocol]]): Constructors for structs for certain field-ids\n\n    Raises:\n        NotImplementedError: If attempting to resolve an unrecognized object type.\n    \"\"\"\n    return resolve_reader(file_schema, file_schema, read_types)\n</code></pre>"},{"location":"reference/pyiceberg/avro/resolver/#pyiceberg.avro.resolver.construct_writer","title":"<code>construct_writer(file_schema)</code>","text":"<p>Construct a writer from a file schema.</p> <p>Parameters:</p> Name Type Description Default <code>file_schema</code> <code>Schema | IcebergType</code> <p>The schema of the Avro file.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If attempting to resolve an unrecognized object type.</p> Source code in <code>pyiceberg/avro/resolver.py</code> <pre><code>def construct_writer(file_schema: Union[Schema, IcebergType]) -&gt; Writer:\n    \"\"\"Construct a writer from a file schema.\n\n    Args:\n        file_schema (Schema | IcebergType): The schema of the Avro file.\n\n    Raises:\n        NotImplementedError: If attempting to resolve an unrecognized object type.\n    \"\"\"\n    return visit(file_schema, CONSTRUCT_WRITER_VISITOR)\n</code></pre>"},{"location":"reference/pyiceberg/avro/resolver/#pyiceberg.avro.resolver.resolve_reader","title":"<code>resolve_reader(file_schema, read_schema, read_types=EMPTY_DICT, read_enums=EMPTY_DICT)</code>","text":"<p>Resolve the file and read schema to produce a reader.</p> <p>Parameters:</p> Name Type Description Default <code>file_schema</code> <code>Schema | IcebergType</code> <p>The schema of the Avro file.</p> required <code>read_schema</code> <code>Schema | IcebergType</code> <p>The requested read schema which is equal, subset or superset of the file schema.</p> required <code>read_types</code> <code>Dict[int, Callable[..., StructProtocol]]</code> <p>A dict of types to use for struct data.</p> <code>EMPTY_DICT</code> <code>read_enums</code> <code>Dict[int, Callable[..., Enum]]</code> <p>A dict of fields that have to be converted to an enum.</p> <code>EMPTY_DICT</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If attempting to resolve an unrecognized object type.</p> Source code in <code>pyiceberg/avro/resolver.py</code> <pre><code>def resolve_reader(\n    file_schema: Union[Schema, IcebergType],\n    read_schema: Union[Schema, IcebergType],\n    read_types: Dict[int, Callable[..., StructProtocol]] = EMPTY_DICT,\n    read_enums: Dict[int, Callable[..., Enum]] = EMPTY_DICT,\n) -&gt; Reader:\n    \"\"\"Resolve the file and read schema to produce a reader.\n\n    Args:\n        file_schema (Schema | IcebergType): The schema of the Avro file.\n        read_schema (Schema | IcebergType): The requested read schema which is equal, subset or superset of the file schema.\n        read_types (Dict[int, Callable[..., StructProtocol]]): A dict of types to use for struct data.\n        read_enums (Dict[int, Callable[..., Enum]]): A dict of fields that have to be converted to an enum.\n\n    Raises:\n        NotImplementedError: If attempting to resolve an unrecognized object type.\n    \"\"\"\n    return visit_with_partner(file_schema, read_schema, ReadSchemaResolver(read_types, read_enums), SchemaPartnerAccessor())  # type: ignore\n</code></pre>"},{"location":"reference/pyiceberg/avro/resolver/#pyiceberg.avro.resolver.resolve_writer","title":"<code>resolve_writer(record_schema, file_schema)</code>","text":"<p>Resolve the file and read schema to produce a reader.</p> <p>Parameters:</p> Name Type Description Default <code>record_schema</code> <code>Schema | IcebergType</code> <p>The schema of the record in memory.</p> required <code>file_schema</code> <code>Schema | IcebergType</code> <p>The schema of the file that will be written</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If attempting to resolve an unrecognized object type.</p> Source code in <code>pyiceberg/avro/resolver.py</code> <pre><code>def resolve_writer(\n    record_schema: Union[Schema, IcebergType],\n    file_schema: Union[Schema, IcebergType],\n) -&gt; Writer:\n    \"\"\"Resolve the file and read schema to produce a reader.\n\n    Args:\n        record_schema (Schema | IcebergType): The schema of the record in memory.\n        file_schema (Schema | IcebergType): The schema of the file that will be written\n\n    Raises:\n        NotImplementedError: If attempting to resolve an unrecognized object type.\n    \"\"\"\n    if record_schema == file_schema:\n        return construct_writer(file_schema)\n    return visit_with_partner(file_schema, record_schema, WriteSchemaResolver(), SchemaPartnerAccessor())  # type: ignore\n</code></pre>"},{"location":"reference/pyiceberg/avro/writer/","title":"writer","text":"<p>Classes for building the Writer tree.</p> <p>Constructing a writer tree from the schema makes it easy to decouple the writing implementation from the schema.</p>"},{"location":"reference/pyiceberg/avro/writer/#pyiceberg.avro.writer.BinaryWriter","title":"<code>BinaryWriter</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Writer</code></p> <p>Variable byte length writer.</p> Source code in <code>pyiceberg/avro/writer.py</code> <pre><code>@dataclass(frozen=True)\nclass BinaryWriter(Writer):\n    \"\"\"Variable byte length writer.\"\"\"\n\n    def write(self, encoder: BinaryEncoder, val: Any) -&gt; None:\n        encoder.write_bytes(val)\n</code></pre>"},{"location":"reference/pyiceberg/avro/writer/#pyiceberg.avro.writer.DecimalWriter","title":"<code>DecimalWriter</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Writer</code></p> Source code in <code>pyiceberg/avro/writer.py</code> <pre><code>@dataclass(frozen=True)\nclass DecimalWriter(Writer):\n    precision: int = dataclassfield()\n    scale: int = dataclassfield()\n\n    def write(self, encoder: BinaryEncoder, val: Any) -&gt; None:\n        return encoder.write(decimal_to_bytes(val, byte_length=decimal_required_bytes(self.precision)))\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return string representation of this object.\"\"\"\n        return f\"DecimalWriter({self.precision}, {self.scale})\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/writer/#pyiceberg.avro.writer.DecimalWriter.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation of this object.</p> Source code in <code>pyiceberg/avro/writer.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return string representation of this object.\"\"\"\n    return f\"DecimalWriter({self.precision}, {self.scale})\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/writer/#pyiceberg.avro.writer.FixedWriter","title":"<code>FixedWriter</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Writer</code></p> Source code in <code>pyiceberg/avro/writer.py</code> <pre><code>@dataclass(frozen=True)\nclass FixedWriter(Writer):\n    _len: int = dataclassfield()\n\n    def write(self, encoder: BinaryEncoder, val: bytes) -&gt; None:\n        if len(val) != self._len:\n            raise ValueError(f\"Expected {self._len} bytes, got {len(val)}\")\n        encoder.write(val)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the length of this object.\"\"\"\n        return self._len\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return string representation of this object.\"\"\"\n        return f\"FixedWriter({self._len})\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/writer/#pyiceberg.avro.writer.FixedWriter.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of this object.</p> Source code in <code>pyiceberg/avro/writer.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the length of this object.\"\"\"\n    return self._len\n</code></pre>"},{"location":"reference/pyiceberg/avro/writer/#pyiceberg.avro.writer.FixedWriter.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation of this object.</p> Source code in <code>pyiceberg/avro/writer.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return string representation of this object.\"\"\"\n    return f\"FixedWriter({self._len})\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/writer/#pyiceberg.avro.writer.IntegerWriter","title":"<code>IntegerWriter</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Writer</code></p> <p>Longs and ints are encoded the same way, and there is no long in Python.</p> Source code in <code>pyiceberg/avro/writer.py</code> <pre><code>@dataclass(frozen=True)\nclass IntegerWriter(Writer):\n    \"\"\"Longs and ints are encoded the same way, and there is no long in Python.\"\"\"\n\n    def write(self, encoder: BinaryEncoder, val: int) -&gt; None:\n        encoder.write_int(val)\n</code></pre>"},{"location":"reference/pyiceberg/avro/writer/#pyiceberg.avro.writer.StructWriter","title":"<code>StructWriter</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Writer</code></p> Source code in <code>pyiceberg/avro/writer.py</code> <pre><code>@dataclass(frozen=True)\nclass StructWriter(Writer):\n    field_writers: Tuple[Tuple[Optional[int], Writer], ...] = dataclassfield()\n\n    def write(self, encoder: BinaryEncoder, val: Record) -&gt; None:\n        for pos, writer in self.field_writers:\n            # When pos is None, then it is a default value\n            writer.write(encoder, val[pos] if pos is not None else None)\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Implement the equality operator for this object.\"\"\"\n        return self.field_writers == other.field_writers if isinstance(other, StructWriter) else False\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return string representation of this object.\"\"\"\n        return f\"StructWriter(tuple(({','.join(repr(field) for field in self.field_writers)})))\"\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Return the hash of the writer as hash of this object.\"\"\"\n        return hash(self.field_writers)\n</code></pre>"},{"location":"reference/pyiceberg/avro/writer/#pyiceberg.avro.writer.StructWriter.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Implement the equality operator for this object.</p> Source code in <code>pyiceberg/avro/writer.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Implement the equality operator for this object.\"\"\"\n    return self.field_writers == other.field_writers if isinstance(other, StructWriter) else False\n</code></pre>"},{"location":"reference/pyiceberg/avro/writer/#pyiceberg.avro.writer.StructWriter.__hash__","title":"<code>__hash__()</code>","text":"<p>Return the hash of the writer as hash of this object.</p> Source code in <code>pyiceberg/avro/writer.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Return the hash of the writer as hash of this object.\"\"\"\n    return hash(self.field_writers)\n</code></pre>"},{"location":"reference/pyiceberg/avro/writer/#pyiceberg.avro.writer.StructWriter.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation of this object.</p> Source code in <code>pyiceberg/avro/writer.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return string representation of this object.\"\"\"\n    return f\"StructWriter(tuple(({','.join(repr(field) for field in self.field_writers)})))\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/writer/#pyiceberg.avro.writer.Writer","title":"<code>Writer</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Singleton</code></p> Source code in <code>pyiceberg/avro/writer.py</code> <pre><code>@dataclass(frozen=True)\nclass Writer(Singleton):\n    @abstractmethod\n    def write(self, encoder: BinaryEncoder, val: Any) -&gt; Any: ...\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return string representation of this object.\"\"\"\n        return f\"{self.__class__.__name__}()\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/writer/#pyiceberg.avro.writer.Writer.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation of this object.</p> Source code in <code>pyiceberg/avro/writer.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return string representation of this object.\"\"\"\n    return f\"{self.__class__.__name__}()\"\n</code></pre>"},{"location":"reference/pyiceberg/avro/codecs/","title":"codecs","text":"<p>Contains Codecs for Python Avro.</p> <p>Note that the word \"codecs\" means \"compression/decompression algorithms\" in the Avro world (https://avro.apache.org/docs/current/spec.html#Object+Container+Files), so don't confuse it with the Python's \"codecs\", which is a package mainly for converting character sets (https://docs.python.org/3/library/codecs.html).</p>"},{"location":"reference/pyiceberg/avro/codecs/bzip2/","title":"bzip2","text":""},{"location":"reference/pyiceberg/avro/codecs/codec/","title":"codec","text":""},{"location":"reference/pyiceberg/avro/codecs/codec/#pyiceberg.avro.codecs.codec.Codec","title":"<code>Codec</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract base class for all Avro codec classes.</p> Source code in <code>pyiceberg/avro/codecs/codec.py</code> <pre><code>class Codec(ABC):\n    \"\"\"Abstract base class for all Avro codec classes.\"\"\"\n\n    @staticmethod\n    @abstractmethod\n    def compress(data: bytes) -&gt; tuple[bytes, int]: ...\n\n    @staticmethod\n    @abstractmethod\n    def decompress(data: bytes) -&gt; bytes: ...\n</code></pre>"},{"location":"reference/pyiceberg/avro/codecs/deflate/","title":"deflate","text":""},{"location":"reference/pyiceberg/avro/codecs/snappy_codec/","title":"snappy_codec","text":""},{"location":"reference/pyiceberg/avro/codecs/zstandard_codec/","title":"zstandard_codec","text":""},{"location":"reference/pyiceberg/catalog/","title":"catalog","text":""},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog","title":"<code>Catalog</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Base Catalog for table operations like - create, drop, load, list and others.</p> <p>The catalog table APIs accept a table identifier, which is fully classified table name. The identifier can be a string or tuple of strings. If the identifier is a string, it is split into a tuple on '.'. If it is a tuple, it is used as-is.</p> <p>The catalog namespace APIs follow a similar convention wherein they also accept a namespace identifier that can be a string or tuple of strings.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the catalog.</p> <code>properties</code> <code>Properties</code> <p>Catalog properties.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>class Catalog(ABC):\n    \"\"\"Base Catalog for table operations like - create, drop, load, list and others.\n\n    The catalog table APIs accept a table identifier, which is fully classified table name. The identifier can be a string or\n    tuple of strings. If the identifier is a string, it is split into a tuple on '.'. If it is a tuple, it is used as-is.\n\n    The catalog namespace APIs follow a similar convention wherein they also accept a namespace identifier that can be a string\n    or tuple of strings.\n\n    Attributes:\n        name (str): Name of the catalog.\n        properties (Properties): Catalog properties.\n    \"\"\"\n\n    name: str\n    properties: Properties\n\n    def __init__(self, name: str, **properties: str):\n        self.name = name\n        self.properties = properties\n\n    def _load_file_io(self, properties: Properties = EMPTY_DICT, location: Optional[str] = None) -&gt; FileIO:\n        return load_file_io({**self.properties, **properties}, location)\n\n    @abstractmethod\n    def create_table(\n        self,\n        identifier: Union[str, Identifier],\n        schema: Union[Schema, \"pa.Schema\"],\n        location: Optional[str] = None,\n        partition_spec: PartitionSpec = UNPARTITIONED_PARTITION_SPEC,\n        sort_order: SortOrder = UNSORTED_SORT_ORDER,\n        properties: Properties = EMPTY_DICT,\n    ) -&gt; Table:\n        \"\"\"Create a table.\n\n        Args:\n            identifier (str | Identifier): Table identifier.\n            schema (Schema): Table's schema.\n            location (str | None): Location for the table. Optional Argument.\n            partition_spec (PartitionSpec): PartitionSpec for the table.\n            sort_order (SortOrder): SortOrder for the table.\n            properties (Properties): Table properties that can be a string based dictionary.\n\n        Returns:\n            Table: the created table instance.\n\n        Raises:\n            TableAlreadyExistsError: If a table with the name already exists.\n        \"\"\"\n\n    @abstractmethod\n    def load_table(self, identifier: Union[str, Identifier]) -&gt; Table:\n        \"\"\"Load the table's metadata and returns the table instance.\n\n        You can also use this method to check for table existence using 'try catalog.table() except NoSuchTableError'.\n        Note: This method doesn't scan data stored in the table.\n\n        Args:\n            identifier (str | Identifier): Table identifier.\n\n        Returns:\n            Table: the table instance with its metadata.\n\n        Raises:\n            NoSuchTableError: If a table with the name does not exist.\n        \"\"\"\n\n    @abstractmethod\n    def register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n        \"\"\"Register a new table using existing metadata.\n\n        Args:\n            identifier Union[str, Identifier]: Table identifier for the table\n            metadata_location str: The location to the metadata\n\n        Returns:\n            Table: The newly registered table\n\n        Raises:\n            TableAlreadyExistsError: If the table already exists\n        \"\"\"\n\n    @abstractmethod\n    def drop_table(self, identifier: Union[str, Identifier]) -&gt; None:\n        \"\"\"Drop a table.\n\n        Args:\n            identifier (str | Identifier): Table identifier.\n\n        Raises:\n            NoSuchTableError: If a table with the name does not exist.\n        \"\"\"\n\n    @abstractmethod\n    def rename_table(self, from_identifier: Union[str, Identifier], to_identifier: Union[str, Identifier]) -&gt; Table:\n        \"\"\"Rename a fully classified table name.\n\n        Args:\n            from_identifier (str | Identifier): Existing table identifier.\n            to_identifier (str | Identifier): New table identifier.\n\n        Returns:\n            Table: the updated table instance with its metadata.\n\n        Raises:\n            NoSuchTableError: If a table with the name does not exist.\n        \"\"\"\n\n    @abstractmethod\n    def _commit_table(self, table_request: CommitTableRequest) -&gt; CommitTableResponse:\n        \"\"\"Update one or more tables.\n\n        Args:\n            table_request (CommitTableRequest): The table requests to be carried out.\n\n        Returns:\n            CommitTableResponse: The updated metadata.\n\n        Raises:\n            NoSuchTableError: If a table with the given identifier does not exist.\n        \"\"\"\n\n    @abstractmethod\n    def create_namespace(self, namespace: Union[str, Identifier], properties: Properties = EMPTY_DICT) -&gt; None:\n        \"\"\"Create a namespace in the catalog.\n\n        Args:\n            namespace (str | Identifier): Namespace identifier.\n            properties (Properties): A string dictionary of properties for the given namespace.\n\n        Raises:\n            NamespaceAlreadyExistsError: If a namespace with the given name already exists.\n        \"\"\"\n\n    @abstractmethod\n    def drop_namespace(self, namespace: Union[str, Identifier]) -&gt; None:\n        \"\"\"Drop a namespace.\n\n        Args:\n            namespace (str | Identifier): Namespace identifier.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist.\n            NamespaceNotEmptyError: If the namespace is not empty.\n        \"\"\"\n\n    @abstractmethod\n    def list_tables(self, namespace: Union[str, Identifier]) -&gt; List[Identifier]:\n        \"\"\"List tables under the given namespace in the catalog.\n\n        If namespace not provided, will list all tables in the catalog.\n\n        Args:\n            namespace (str | Identifier): Namespace identifier to search.\n\n        Returns:\n            List[Identifier]: list of table identifiers.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist.\n        \"\"\"\n\n    @abstractmethod\n    def list_namespaces(self, namespace: Union[str, Identifier] = ()) -&gt; List[Identifier]:\n        \"\"\"List namespaces from the given namespace. If not given, list top-level namespaces from the catalog.\n\n        Args:\n            namespace (str | Identifier): Namespace identifier to search.\n\n        Returns:\n            List[Identifier]: a List of namespace identifiers.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist.\n        \"\"\"\n\n    @abstractmethod\n    def load_namespace_properties(self, namespace: Union[str, Identifier]) -&gt; Properties:\n        \"\"\"Get properties for a namespace.\n\n        Args:\n            namespace (str | Identifier): Namespace identifier.\n\n        Returns:\n            Properties: Properties for the given namespace.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist.\n        \"\"\"\n\n    @abstractmethod\n    def update_namespace_properties(\n        self, namespace: Union[str, Identifier], removals: Optional[Set[str]] = None, updates: Properties = EMPTY_DICT\n    ) -&gt; PropertiesUpdateSummary:\n        \"\"\"Remove provided property keys and updates properties for a namespace.\n\n        Args:\n            namespace (str | Identifier): Namespace identifier.\n            removals (Set[str]): Set of property keys that need to be removed. Optional Argument.\n            updates (Properties): Properties to be updated for the given namespace.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist.\n            ValueError: If removals and updates have overlapping keys.\n        \"\"\"\n\n    @staticmethod\n    def identifier_to_tuple(identifier: Union[str, Identifier]) -&gt; Identifier:\n        \"\"\"Parse an identifier to a tuple.\n\n        If the identifier is a string, it is split into a tuple on '.'. If it is a tuple, it is used as-is.\n\n        Args:\n            identifier (str | Identifier: an identifier, either a string or tuple of strings.\n\n        Returns:\n            Identifier: a tuple of strings.\n        \"\"\"\n        return identifier if isinstance(identifier, tuple) else tuple(str.split(identifier, \".\"))\n\n    @staticmethod\n    def table_name_from(identifier: Union[str, Identifier]) -&gt; str:\n        \"\"\"Extract table name from a table identifier.\n\n        Args:\n            identifier (str | Identifier: a table identifier.\n\n        Returns:\n            str: Table name.\n        \"\"\"\n        return Catalog.identifier_to_tuple(identifier)[-1]\n\n    @staticmethod\n    def namespace_from(identifier: Union[str, Identifier]) -&gt; Identifier:\n        \"\"\"Extract table namespace from a table identifier.\n\n        Args:\n            identifier (Union[str, Identifier]): a table identifier.\n\n        Returns:\n            Identifier: Namespace identifier.\n        \"\"\"\n        return Catalog.identifier_to_tuple(identifier)[:-1]\n\n    @staticmethod\n    def _check_for_overlap(removals: Optional[Set[str]], updates: Properties) -&gt; None:\n        if updates and removals:\n            overlap = set(removals) &amp; set(updates.keys())\n            if overlap:\n                raise ValueError(f\"Updates and deletes have an overlap: {overlap}\")\n\n    @staticmethod\n    def _convert_schema_if_needed(schema: Union[Schema, \"pa.Schema\"]) -&gt; Schema:\n        if isinstance(schema, Schema):\n            return schema\n        try:\n            import pyarrow as pa\n\n            from pyiceberg.io.pyarrow import _ConvertToIcebergWithoutIDs, visit_pyarrow\n\n            if isinstance(schema, pa.Schema):\n                schema: Schema = visit_pyarrow(schema, _ConvertToIcebergWithoutIDs())  # type: ignore\n                return schema\n        except ModuleNotFoundError:\n            pass\n        raise ValueError(f\"{type(schema)=}, but it must be pyiceberg.schema.Schema or pyarrow.Schema\")\n\n    def _resolve_table_location(self, location: Optional[str], database_name: str, table_name: str) -&gt; str:\n        if not location:\n            return self._get_default_warehouse_location(database_name, table_name)\n        return location\n\n    def _get_default_warehouse_location(self, database_name: str, table_name: str) -&gt; str:\n        database_properties = self.load_namespace_properties(database_name)\n        if database_location := database_properties.get(LOCATION):\n            database_location = database_location.rstrip(\"/\")\n            return f\"{database_location}/{table_name}\"\n\n        if warehouse_path := self.properties.get(WAREHOUSE_LOCATION):\n            warehouse_path = warehouse_path.rstrip(\"/\")\n            return f\"{warehouse_path}/{database_name}.db/{table_name}\"\n\n        raise ValueError(\"No default path is set, please specify a location when creating a table\")\n\n    @staticmethod\n    def identifier_to_database(\n        identifier: Union[str, Identifier], err: Union[Type[ValueError], Type[NoSuchNamespaceError]] = ValueError\n    ) -&gt; str:\n        tuple_identifier = Catalog.identifier_to_tuple(identifier)\n        if len(tuple_identifier) != 1:\n            raise err(f\"Invalid database, hierarchical namespaces are not supported: {identifier}\")\n\n        return tuple_identifier[0]\n\n    @staticmethod\n    def identifier_to_database_and_table(\n        identifier: Union[str, Identifier],\n        err: Union[Type[ValueError], Type[NoSuchTableError], Type[NoSuchNamespaceError]] = ValueError,\n    ) -&gt; Tuple[str, str]:\n        tuple_identifier = Catalog.identifier_to_tuple(identifier)\n        if len(tuple_identifier) != 2:\n            raise err(f\"Invalid path, hierarchical namespaces are not supported: {identifier}\")\n\n        return tuple_identifier[0], tuple_identifier[1]\n\n    def identifier_to_tuple_without_catalog(self, identifier: Union[str, Identifier]) -&gt; Identifier:\n        \"\"\"Convert an identifier to a tuple and drop this catalog's name from the first element.\n\n        Args:\n            identifier (str | Identifier): Table identifier.\n\n        Returns:\n            Identifier: a tuple of strings with this catalog's name removed\n        \"\"\"\n        identifier_tuple = Catalog.identifier_to_tuple(identifier)\n        if len(identifier_tuple) &gt;= 3 and identifier_tuple[0] == self.name:\n            identifier_tuple = identifier_tuple[1:]\n        return identifier_tuple\n\n    def purge_table(self, identifier: Union[str, Identifier]) -&gt; None:\n        \"\"\"Drop a table and purge all data and metadata files.\n\n        Note: This method only logs warning rather than raise exception when encountering file deletion failure.\n\n        Args:\n            identifier (str | Identifier): Table identifier.\n\n        Raises:\n            NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n        \"\"\"\n        identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n        table = self.load_table(identifier_tuple)\n        self.drop_table(identifier_tuple)\n        io = load_file_io(self.properties, table.metadata_location)\n        metadata = table.metadata\n        manifest_lists_to_delete = set()\n        manifests_to_delete: List[ManifestFile] = []\n        for snapshot in metadata.snapshots:\n            manifests_to_delete += snapshot.manifests(io)\n            if snapshot.manifest_list is not None:\n                manifest_lists_to_delete.add(snapshot.manifest_list)\n\n        manifest_paths_to_delete = {manifest.manifest_path for manifest in manifests_to_delete}\n        prev_metadata_files = {log.metadata_file for log in metadata.metadata_log}\n\n        delete_data_files(io, manifests_to_delete)\n        delete_files(io, manifest_paths_to_delete, MANIFEST)\n        delete_files(io, manifest_lists_to_delete, MANIFEST_LIST)\n        delete_files(io, prev_metadata_files, PREVIOUS_METADATA)\n        delete_files(io, {table.metadata_location}, METADATA)\n\n    @staticmethod\n    def _write_metadata(metadata: TableMetadata, io: FileIO, metadata_path: str) -&gt; None:\n        ToOutputFile.table_metadata(metadata, io.new_output(metadata_path))\n\n    @staticmethod\n    def _get_metadata_location(location: str, new_version: int = 0) -&gt; str:\n        if new_version &lt; 0:\n            raise ValueError(f\"Table metadata version: `{new_version}` must be a non-negative integer\")\n        version_str = f\"{new_version:05d}\"\n        return f\"{location}/metadata/{version_str}-{uuid.uuid4()}.metadata.json\"\n\n    @staticmethod\n    def _parse_metadata_version(metadata_location: str) -&gt; int:\n        \"\"\"Parse the version from the metadata location.\n\n        The version is the first part of the file name, before the first dash.\n        For example, the version of the metadata file\n        `s3://bucket/db/tb/metadata/00001-6c97e413-d51b-4538-ac70-12fe2a85cb83.metadata.json`\n        is 1.\n        If the path does not comply with the pattern, the version is defaulted to be -1, ensuring\n        that the next metadata file is treated as having version 0.\n\n        Args:\n            metadata_location (str): The location of the metadata file.\n\n        Returns:\n            int: The version of the metadata file. -1 if the file name does not have valid version string\n        \"\"\"\n        file_name = metadata_location.split(\"/\")[-1]\n        if file_name_match := TABLE_METADATA_FILE_NAME_REGEX.fullmatch(file_name):\n            try:\n                uuid.UUID(file_name_match.group(2))\n            except ValueError:\n                return -1\n            return int(file_name_match.group(1))\n        else:\n            return -1\n\n    def _get_updated_props_and_update_summary(\n        self, current_properties: Properties, removals: Optional[Set[str]], updates: Properties\n    ) -&gt; Tuple[PropertiesUpdateSummary, Properties]:\n        self._check_for_overlap(updates=updates, removals=removals)\n        updated_properties = dict(current_properties)\n\n        removed: Set[str] = set()\n        updated: Set[str] = set()\n\n        if removals:\n            for key in removals:\n                if key in updated_properties:\n                    updated_properties.pop(key)\n                    removed.add(key)\n        if updates:\n            for key, value in updates.items():\n                updated_properties[key] = value\n                updated.add(key)\n\n        expected_to_change = (removals or set()).difference(removed)\n        properties_update_summary = PropertiesUpdateSummary(\n            removed=list(removed or []), updated=list(updated or []), missing=list(expected_to_change)\n        )\n\n        return properties_update_summary, updated_properties\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the Catalog class.\"\"\"\n        return f\"{self.name} ({self.__class__})\"\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the Catalog class.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the Catalog class.\"\"\"\n    return f\"{self.name} ({self.__class__})\"\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.create_namespace","title":"<code>create_namespace(namespace, properties=EMPTY_DICT)</code>  <code>abstractmethod</code>","text":"<p>Create a namespace in the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier.</p> required <code>properties</code> <code>Properties</code> <p>A string dictionary of properties for the given namespace.</p> <code>EMPTY_DICT</code> <p>Raises:</p> Type Description <code>NamespaceAlreadyExistsError</code> <p>If a namespace with the given name already exists.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@abstractmethod\ndef create_namespace(self, namespace: Union[str, Identifier], properties: Properties = EMPTY_DICT) -&gt; None:\n    \"\"\"Create a namespace in the catalog.\n\n    Args:\n        namespace (str | Identifier): Namespace identifier.\n        properties (Properties): A string dictionary of properties for the given namespace.\n\n    Raises:\n        NamespaceAlreadyExistsError: If a namespace with the given name already exists.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.create_table","title":"<code>create_table(identifier, schema, location=None, partition_spec=UNPARTITIONED_PARTITION_SPEC, sort_order=UNSORTED_SORT_ORDER, properties=EMPTY_DICT)</code>  <code>abstractmethod</code>","text":"<p>Create a table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str | Identifier</code> <p>Table identifier.</p> required <code>schema</code> <code>Schema</code> <p>Table's schema.</p> required <code>location</code> <code>str | None</code> <p>Location for the table. Optional Argument.</p> <code>None</code> <code>partition_spec</code> <code>PartitionSpec</code> <p>PartitionSpec for the table.</p> <code>UNPARTITIONED_PARTITION_SPEC</code> <code>sort_order</code> <code>SortOrder</code> <p>SortOrder for the table.</p> <code>UNSORTED_SORT_ORDER</code> <code>properties</code> <code>Properties</code> <p>Table properties that can be a string based dictionary.</p> <code>EMPTY_DICT</code> <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the created table instance.</p> <p>Raises:</p> Type Description <code>TableAlreadyExistsError</code> <p>If a table with the name already exists.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@abstractmethod\ndef create_table(\n    self,\n    identifier: Union[str, Identifier],\n    schema: Union[Schema, \"pa.Schema\"],\n    location: Optional[str] = None,\n    partition_spec: PartitionSpec = UNPARTITIONED_PARTITION_SPEC,\n    sort_order: SortOrder = UNSORTED_SORT_ORDER,\n    properties: Properties = EMPTY_DICT,\n) -&gt; Table:\n    \"\"\"Create a table.\n\n    Args:\n        identifier (str | Identifier): Table identifier.\n        schema (Schema): Table's schema.\n        location (str | None): Location for the table. Optional Argument.\n        partition_spec (PartitionSpec): PartitionSpec for the table.\n        sort_order (SortOrder): SortOrder for the table.\n        properties (Properties): Table properties that can be a string based dictionary.\n\n    Returns:\n        Table: the created table instance.\n\n    Raises:\n        TableAlreadyExistsError: If a table with the name already exists.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.drop_namespace","title":"<code>drop_namespace(namespace)</code>  <code>abstractmethod</code>","text":"<p>Drop a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier.</p> required <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist.</p> <code>NamespaceNotEmptyError</code> <p>If the namespace is not empty.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@abstractmethod\ndef drop_namespace(self, namespace: Union[str, Identifier]) -&gt; None:\n    \"\"\"Drop a namespace.\n\n    Args:\n        namespace (str | Identifier): Namespace identifier.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist.\n        NamespaceNotEmptyError: If the namespace is not empty.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.drop_table","title":"<code>drop_table(identifier)</code>  <code>abstractmethod</code>","text":"<p>Drop a table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str | Identifier</code> <p>Table identifier.</p> required <p>Raises:</p> Type Description <code>NoSuchTableError</code> <p>If a table with the name does not exist.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@abstractmethod\ndef drop_table(self, identifier: Union[str, Identifier]) -&gt; None:\n    \"\"\"Drop a table.\n\n    Args:\n        identifier (str | Identifier): Table identifier.\n\n    Raises:\n        NoSuchTableError: If a table with the name does not exist.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.identifier_to_tuple","title":"<code>identifier_to_tuple(identifier)</code>  <code>staticmethod</code>","text":"<p>Parse an identifier to a tuple.</p> <p>If the identifier is a string, it is split into a tuple on '.'. If it is a tuple, it is used as-is.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str | Identifier</code> <p>an identifier, either a string or tuple of strings.</p> required <p>Returns:</p> Name Type Description <code>Identifier</code> <code>Identifier</code> <p>a tuple of strings.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@staticmethod\ndef identifier_to_tuple(identifier: Union[str, Identifier]) -&gt; Identifier:\n    \"\"\"Parse an identifier to a tuple.\n\n    If the identifier is a string, it is split into a tuple on '.'. If it is a tuple, it is used as-is.\n\n    Args:\n        identifier (str | Identifier: an identifier, either a string or tuple of strings.\n\n    Returns:\n        Identifier: a tuple of strings.\n    \"\"\"\n    return identifier if isinstance(identifier, tuple) else tuple(str.split(identifier, \".\"))\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.identifier_to_tuple_without_catalog","title":"<code>identifier_to_tuple_without_catalog(identifier)</code>","text":"<p>Convert an identifier to a tuple and drop this catalog's name from the first element.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str | Identifier</code> <p>Table identifier.</p> required <p>Returns:</p> Name Type Description <code>Identifier</code> <code>Identifier</code> <p>a tuple of strings with this catalog's name removed</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>def identifier_to_tuple_without_catalog(self, identifier: Union[str, Identifier]) -&gt; Identifier:\n    \"\"\"Convert an identifier to a tuple and drop this catalog's name from the first element.\n\n    Args:\n        identifier (str | Identifier): Table identifier.\n\n    Returns:\n        Identifier: a tuple of strings with this catalog's name removed\n    \"\"\"\n    identifier_tuple = Catalog.identifier_to_tuple(identifier)\n    if len(identifier_tuple) &gt;= 3 and identifier_tuple[0] == self.name:\n        identifier_tuple = identifier_tuple[1:]\n    return identifier_tuple\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.list_namespaces","title":"<code>list_namespaces(namespace=())</code>  <code>abstractmethod</code>","text":"<p>List namespaces from the given namespace. If not given, list top-level namespaces from the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier to search.</p> <code>()</code> <p>Returns:</p> Type Description <code>List[Identifier]</code> <p>List[Identifier]: a List of namespace identifiers.</p> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@abstractmethod\ndef list_namespaces(self, namespace: Union[str, Identifier] = ()) -&gt; List[Identifier]:\n    \"\"\"List namespaces from the given namespace. If not given, list top-level namespaces from the catalog.\n\n    Args:\n        namespace (str | Identifier): Namespace identifier to search.\n\n    Returns:\n        List[Identifier]: a List of namespace identifiers.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.list_tables","title":"<code>list_tables(namespace)</code>  <code>abstractmethod</code>","text":"<p>List tables under the given namespace in the catalog.</p> <p>If namespace not provided, will list all tables in the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier to search.</p> required <p>Returns:</p> Type Description <code>List[Identifier]</code> <p>List[Identifier]: list of table identifiers.</p> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@abstractmethod\ndef list_tables(self, namespace: Union[str, Identifier]) -&gt; List[Identifier]:\n    \"\"\"List tables under the given namespace in the catalog.\n\n    If namespace not provided, will list all tables in the catalog.\n\n    Args:\n        namespace (str | Identifier): Namespace identifier to search.\n\n    Returns:\n        List[Identifier]: list of table identifiers.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.load_namespace_properties","title":"<code>load_namespace_properties(namespace)</code>  <code>abstractmethod</code>","text":"<p>Get properties for a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier.</p> required <p>Returns:</p> Name Type Description <code>Properties</code> <code>Properties</code> <p>Properties for the given namespace.</p> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@abstractmethod\ndef load_namespace_properties(self, namespace: Union[str, Identifier]) -&gt; Properties:\n    \"\"\"Get properties for a namespace.\n\n    Args:\n        namespace (str | Identifier): Namespace identifier.\n\n    Returns:\n        Properties: Properties for the given namespace.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.load_table","title":"<code>load_table(identifier)</code>  <code>abstractmethod</code>","text":"<p>Load the table's metadata and returns the table instance.</p> <p>You can also use this method to check for table existence using 'try catalog.table() except NoSuchTableError'. Note: This method doesn't scan data stored in the table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str | Identifier</code> <p>Table identifier.</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the table instance with its metadata.</p> <p>Raises:</p> Type Description <code>NoSuchTableError</code> <p>If a table with the name does not exist.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@abstractmethod\ndef load_table(self, identifier: Union[str, Identifier]) -&gt; Table:\n    \"\"\"Load the table's metadata and returns the table instance.\n\n    You can also use this method to check for table existence using 'try catalog.table() except NoSuchTableError'.\n    Note: This method doesn't scan data stored in the table.\n\n    Args:\n        identifier (str | Identifier): Table identifier.\n\n    Returns:\n        Table: the table instance with its metadata.\n\n    Raises:\n        NoSuchTableError: If a table with the name does not exist.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.namespace_from","title":"<code>namespace_from(identifier)</code>  <code>staticmethod</code>","text":"<p>Extract table namespace from a table identifier.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>a table identifier.</p> required <p>Returns:</p> Name Type Description <code>Identifier</code> <code>Identifier</code> <p>Namespace identifier.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@staticmethod\ndef namespace_from(identifier: Union[str, Identifier]) -&gt; Identifier:\n    \"\"\"Extract table namespace from a table identifier.\n\n    Args:\n        identifier (Union[str, Identifier]): a table identifier.\n\n    Returns:\n        Identifier: Namespace identifier.\n    \"\"\"\n    return Catalog.identifier_to_tuple(identifier)[:-1]\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.purge_table","title":"<code>purge_table(identifier)</code>","text":"<p>Drop a table and purge all data and metadata files.</p> <p>Note: This method only logs warning rather than raise exception when encountering file deletion failure.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str | Identifier</code> <p>Table identifier.</p> required <p>Raises:</p> Type Description <code>NoSuchTableError</code> <p>If a table with the name does not exist, or the identifier is invalid.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>def purge_table(self, identifier: Union[str, Identifier]) -&gt; None:\n    \"\"\"Drop a table and purge all data and metadata files.\n\n    Note: This method only logs warning rather than raise exception when encountering file deletion failure.\n\n    Args:\n        identifier (str | Identifier): Table identifier.\n\n    Raises:\n        NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n    \"\"\"\n    identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n    table = self.load_table(identifier_tuple)\n    self.drop_table(identifier_tuple)\n    io = load_file_io(self.properties, table.metadata_location)\n    metadata = table.metadata\n    manifest_lists_to_delete = set()\n    manifests_to_delete: List[ManifestFile] = []\n    for snapshot in metadata.snapshots:\n        manifests_to_delete += snapshot.manifests(io)\n        if snapshot.manifest_list is not None:\n            manifest_lists_to_delete.add(snapshot.manifest_list)\n\n    manifest_paths_to_delete = {manifest.manifest_path for manifest in manifests_to_delete}\n    prev_metadata_files = {log.metadata_file for log in metadata.metadata_log}\n\n    delete_data_files(io, manifests_to_delete)\n    delete_files(io, manifest_paths_to_delete, MANIFEST)\n    delete_files(io, manifest_lists_to_delete, MANIFEST_LIST)\n    delete_files(io, prev_metadata_files, PREVIOUS_METADATA)\n    delete_files(io, {table.metadata_location}, METADATA)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.register_table","title":"<code>register_table(identifier, metadata_location)</code>  <code>abstractmethod</code>","text":"<p>Register a new table using existing metadata.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier for the table</p> required <code>metadata_location</code> <code>str</code> <p>The location to the metadata</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>The newly registered table</p> <p>Raises:</p> Type Description <code>TableAlreadyExistsError</code> <p>If the table already exists</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@abstractmethod\ndef register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n    \"\"\"Register a new table using existing metadata.\n\n    Args:\n        identifier Union[str, Identifier]: Table identifier for the table\n        metadata_location str: The location to the metadata\n\n    Returns:\n        Table: The newly registered table\n\n    Raises:\n        TableAlreadyExistsError: If the table already exists\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.rename_table","title":"<code>rename_table(from_identifier, to_identifier)</code>  <code>abstractmethod</code>","text":"<p>Rename a fully classified table name.</p> <p>Parameters:</p> Name Type Description Default <code>from_identifier</code> <code>str | Identifier</code> <p>Existing table identifier.</p> required <code>to_identifier</code> <code>str | Identifier</code> <p>New table identifier.</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the updated table instance with its metadata.</p> <p>Raises:</p> Type Description <code>NoSuchTableError</code> <p>If a table with the name does not exist.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@abstractmethod\ndef rename_table(self, from_identifier: Union[str, Identifier], to_identifier: Union[str, Identifier]) -&gt; Table:\n    \"\"\"Rename a fully classified table name.\n\n    Args:\n        from_identifier (str | Identifier): Existing table identifier.\n        to_identifier (str | Identifier): New table identifier.\n\n    Returns:\n        Table: the updated table instance with its metadata.\n\n    Raises:\n        NoSuchTableError: If a table with the name does not exist.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.table_name_from","title":"<code>table_name_from(identifier)</code>  <code>staticmethod</code>","text":"<p>Extract table name from a table identifier.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str | Identifier</code> <p>a table identifier.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Table name.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@staticmethod\ndef table_name_from(identifier: Union[str, Identifier]) -&gt; str:\n    \"\"\"Extract table name from a table identifier.\n\n    Args:\n        identifier (str | Identifier: a table identifier.\n\n    Returns:\n        str: Table name.\n    \"\"\"\n    return Catalog.identifier_to_tuple(identifier)[-1]\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.Catalog.update_namespace_properties","title":"<code>update_namespace_properties(namespace, removals=None, updates=EMPTY_DICT)</code>  <code>abstractmethod</code>","text":"<p>Remove provided property keys and updates properties for a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier.</p> required <code>removals</code> <code>Set[str]</code> <p>Set of property keys that need to be removed. Optional Argument.</p> <code>None</code> <code>updates</code> <code>Properties</code> <p>Properties to be updated for the given namespace.</p> <code>EMPTY_DICT</code> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist.</p> <code>ValueError</code> <p>If removals and updates have overlapping keys.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>@abstractmethod\ndef update_namespace_properties(\n    self, namespace: Union[str, Identifier], removals: Optional[Set[str]] = None, updates: Properties = EMPTY_DICT\n) -&gt; PropertiesUpdateSummary:\n    \"\"\"Remove provided property keys and updates properties for a namespace.\n\n    Args:\n        namespace (str | Identifier): Namespace identifier.\n        removals (Set[str]): Set of property keys that need to be removed. Optional Argument.\n        updates (Properties): Properties to be updated for the given namespace.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist.\n        ValueError: If removals and updates have overlapping keys.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.delete_data_files","title":"<code>delete_data_files(io, manifests_to_delete)</code>","text":"<p>Delete data files linked to given manifests.</p> <p>Log warnings if failing to delete any file.</p> <p>Parameters:</p> Name Type Description Default <code>io</code> <code>FileIO</code> <p>The FileIO used to delete the object.</p> required <code>manifests_to_delete</code> <code>List[ManifestFile]</code> <p>A list of manifest contains paths of data files to be deleted.</p> required Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>def delete_data_files(io: FileIO, manifests_to_delete: List[ManifestFile]) -&gt; None:\n    \"\"\"Delete data files linked to given manifests.\n\n    Log warnings if failing to delete any file.\n\n    Args:\n        io: The FileIO used to delete the object.\n        manifests_to_delete: A list of manifest contains paths of data files to be deleted.\n    \"\"\"\n    deleted_files: dict[str, bool] = {}\n    for manifest_file in manifests_to_delete:\n        for entry in manifest_file.fetch_manifest_entry(io, discard_deleted=False):\n            path = entry.data_file.file_path\n            if not deleted_files.get(path, False):\n                try:\n                    io.delete(path)\n                except OSError as exc:\n                    logger.warning(msg=f\"Failed to delete data file {path}\", exc_info=exc)\n                deleted_files[path] = True\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.delete_files","title":"<code>delete_files(io, files_to_delete, file_type)</code>","text":"<p>Delete files.</p> <p>Log warnings if failing to delete any file.</p> <p>Parameters:</p> Name Type Description Default <code>io</code> <code>FileIO</code> <p>The FileIO used to delete the object.</p> required <code>files_to_delete</code> <code>Set[str]</code> <p>A set of file paths to be deleted.</p> required <code>file_type</code> <code>str</code> <p>The type of the file.</p> required Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>def delete_files(io: FileIO, files_to_delete: Set[str], file_type: str) -&gt; None:\n    \"\"\"Delete files.\n\n    Log warnings if failing to delete any file.\n\n    Args:\n        io: The FileIO used to delete the object.\n        files_to_delete: A set of file paths to be deleted.\n        file_type: The type of the file.\n    \"\"\"\n    for file in files_to_delete:\n        try:\n            io.delete(file)\n        except OSError as exc:\n            logger.warning(msg=f\"Failed to delete {file_type} file {file}\", exc_info=exc)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.infer_catalog_type","title":"<code>infer_catalog_type(name, catalog_properties)</code>","text":"<p>Try to infer the type based on the dict.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the catalog.</p> required <code>catalog_properties</code> <code>RecursiveDict</code> <p>Catalog properties.</p> required <p>Returns:</p> Type Description <code>Optional[CatalogType]</code> <p>The inferred type based on the provided properties.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Raises a ValueError in case properties are missing, or the wrong type.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>def infer_catalog_type(name: str, catalog_properties: RecursiveDict) -&gt; Optional[CatalogType]:\n    \"\"\"Try to infer the type based on the dict.\n\n    Args:\n        name: Name of the catalog.\n        catalog_properties: Catalog properties.\n\n    Returns:\n        The inferred type based on the provided properties.\n\n    Raises:\n        ValueError: Raises a ValueError in case properties are missing, or the wrong type.\n    \"\"\"\n    if uri := catalog_properties.get(\"uri\"):\n        if isinstance(uri, str):\n            if uri.startswith(\"http\"):\n                return CatalogType.REST\n            elif uri.startswith(\"thrift\"):\n                return CatalogType.HIVE\n            elif uri.startswith((\"sqlite\", \"postgresql\")):\n                return CatalogType.SQL\n            else:\n                raise ValueError(f\"Could not infer the catalog type from the uri: {uri}\")\n        else:\n            raise ValueError(f\"Expects the URI to be a string, got: {type(uri)}\")\n    raise ValueError(\n        f\"URI missing, please provide using --uri, the config or environment variable PYICEBERG_CATALOG__{name.upper()}__URI\"\n    )\n</code></pre>"},{"location":"reference/pyiceberg/catalog/#pyiceberg.catalog.load_catalog","title":"<code>load_catalog(name=None, **properties)</code>","text":"<p>Load the catalog based on the properties.</p> <p>Will look up the properties from the config, based on the name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>The name of the catalog.</p> <code>None</code> <code>properties</code> <code>Optional[str]</code> <p>The properties that are used next to the configuration.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Catalog</code> <p>An initialized Catalog.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Raises a ValueError in case properties are missing or malformed, or if it could not determine the catalog based on the properties.</p> Source code in <code>pyiceberg/catalog/__init__.py</code> <pre><code>def load_catalog(name: Optional[str] = None, **properties: Optional[str]) -&gt; Catalog:\n    \"\"\"Load the catalog based on the properties.\n\n    Will look up the properties from the config, based on the name.\n\n    Args:\n        name: The name of the catalog.\n        properties: The properties that are used next to the configuration.\n\n    Returns:\n        An initialized Catalog.\n\n    Raises:\n        ValueError: Raises a ValueError in case properties are missing or malformed,\n            or if it could not determine the catalog based on the properties.\n    \"\"\"\n    if name is None:\n        name = _ENV_CONFIG.get_default_catalog_name()\n\n    env = _ENV_CONFIG.get_catalog_config(name)\n    conf: RecursiveDict = merge_config(env or {}, cast(RecursiveDict, properties))\n\n    catalog_type: Optional[CatalogType]\n    provided_catalog_type = conf.get(TYPE)\n\n    catalog_type = None\n    if provided_catalog_type and isinstance(provided_catalog_type, str):\n        catalog_type = CatalogType[provided_catalog_type.upper()]\n    elif not provided_catalog_type:\n        catalog_type = infer_catalog_type(name, conf)\n\n    if catalog_type:\n        return AVAILABLE_CATALOGS[catalog_type](name, cast(Dict[str, str], conf))\n\n    raise ValueError(f\"Could not initialize catalog with the following properties: {properties}\")\n</code></pre>"},{"location":"reference/pyiceberg/catalog/dynamodb/","title":"dynamodb","text":""},{"location":"reference/pyiceberg/catalog/dynamodb/#pyiceberg.catalog.dynamodb.DynamoDbCatalog","title":"<code>DynamoDbCatalog</code>","text":"<p>             Bases: <code>Catalog</code></p> Source code in <code>pyiceberg/catalog/dynamodb.py</code> <pre><code>class DynamoDbCatalog(Catalog):\n    def __init__(self, name: str, **properties: str):\n        super().__init__(name, **properties)\n        session = boto3.Session(\n            profile_name=properties.get(\"profile_name\"),\n            region_name=properties.get(\"region_name\"),\n            botocore_session=properties.get(\"botocore_session\"),\n            aws_access_key_id=properties.get(\"aws_access_key_id\"),\n            aws_secret_access_key=properties.get(\"aws_secret_access_key\"),\n            aws_session_token=properties.get(\"aws_session_token\"),\n        )\n        self.dynamodb = session.client(DYNAMODB_CLIENT)\n        self.dynamodb_table_name = self.properties.get(DYNAMODB_TABLE_NAME, DYNAMODB_TABLE_NAME_DEFAULT)\n        self._ensure_catalog_table_exists_or_create()\n\n    def _ensure_catalog_table_exists_or_create(self) -&gt; None:\n        if self._dynamodb_table_exists():\n            return None\n\n        try:\n            self.dynamodb.create_table(\n                TableName=self.dynamodb_table_name,\n                AttributeDefinitions=CREATE_CATALOG_ATTRIBUTE_DEFINITIONS,\n                KeySchema=CREATE_CATALOG_KEY_SCHEMA,\n                GlobalSecondaryIndexes=CREATE_CATALOG_GLOBAL_SECONDARY_INDEXES,\n                BillingMode=DYNAMODB_PAY_PER_REQUEST,\n            )\n        except (\n            self.dynamodb.exceptions.ResourceInUseException,\n            self.dynamodb.exceptions.LimitExceededException,\n            self.dynamodb.exceptions.InternalServerError,\n        ) as e:\n            raise GenericDynamoDbError(e.message) from e\n\n    def _dynamodb_table_exists(self) -&gt; bool:\n        try:\n            response = self.dynamodb.describe_table(TableName=self.dynamodb_table_name)\n        except self.dynamodb.exceptions.ResourceNotFoundException:\n            return False\n        except self.dynamodb.exceptions.InternalServerError as e:\n            raise GenericDynamoDbError(e.message) from e\n\n        if response[\"Table\"][\"TableStatus\"] != ACTIVE:\n            raise GenericDynamoDbError(f\"DynamoDB table for catalog {self.dynamodb_table_name} is not {ACTIVE}\")\n        else:\n            return True\n\n    def create_table(\n        self,\n        identifier: Union[str, Identifier],\n        schema: Union[Schema, \"pa.Schema\"],\n        location: Optional[str] = None,\n        partition_spec: PartitionSpec = UNPARTITIONED_PARTITION_SPEC,\n        sort_order: SortOrder = UNSORTED_SORT_ORDER,\n        properties: Properties = EMPTY_DICT,\n    ) -&gt; Table:\n        \"\"\"\n        Create an Iceberg table.\n\n        Args:\n            identifier: Table identifier.\n            schema: Table's schema.\n            location: Location for the table. Optional Argument.\n            partition_spec: PartitionSpec for the table.\n            sort_order: SortOrder for the table.\n            properties: Table properties that can be a string based dictionary.\n\n        Returns:\n            Table: the created table instance.\n\n        Raises:\n            AlreadyExistsError: If a table with the name already exists.\n            ValueError: If the identifier is invalid, or no path is given to store metadata.\n\n        \"\"\"\n        schema: Schema = self._convert_schema_if_needed(schema)  # type: ignore\n\n        database_name, table_name = self.identifier_to_database_and_table(identifier)\n\n        location = self._resolve_table_location(location, database_name, table_name)\n        metadata_location = self._get_metadata_location(location=location)\n        metadata = new_table_metadata(\n            location=location, schema=schema, partition_spec=partition_spec, sort_order=sort_order, properties=properties\n        )\n        io = load_file_io(properties=self.properties, location=metadata_location)\n        self._write_metadata(metadata, io, metadata_location)\n\n        self._ensure_namespace_exists(database_name=database_name)\n\n        try:\n            self._put_dynamo_item(\n                item=_get_create_table_item(\n                    database_name=database_name, table_name=table_name, properties=properties, metadata_location=metadata_location\n                ),\n                condition_expression=f\"attribute_not_exists({DYNAMODB_COL_IDENTIFIER})\",\n            )\n        except ConditionalCheckFailedException as e:\n            raise TableAlreadyExistsError(f\"Table {database_name}.{table_name} already exists\") from e\n\n        return self.load_table(identifier=identifier)\n\n    def register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n        \"\"\"Register a new table using existing metadata.\n\n        Args:\n            identifier Union[str, Identifier]: Table identifier for the table\n            metadata_location str: The location to the metadata\n\n        Returns:\n            Table: The newly registered table\n\n        Raises:\n            TableAlreadyExistsError: If the table already exists\n        \"\"\"\n        raise NotImplementedError\n\n    def _commit_table(self, table_request: CommitTableRequest) -&gt; CommitTableResponse:\n        \"\"\"Update the table.\n\n        Args:\n            table_request (CommitTableRequest): The table requests to be carried out.\n\n        Returns:\n            CommitTableResponse: The updated metadata.\n\n        Raises:\n            NoSuchTableError: If a table with the given identifier does not exist.\n        \"\"\"\n        raise NotImplementedError\n\n    def load_table(self, identifier: Union[str, Identifier]) -&gt; Table:\n        \"\"\"\n        Load the table's metadata and returns the table instance.\n\n        You can also use this method to check for table existence using 'try catalog.table() except TableNotFoundError'.\n        Note: This method doesn't scan data stored in the table.\n\n        Args:\n            identifier: Table identifier.\n\n        Returns:\n            Table: the table instance with its metadata.\n\n        Raises:\n            NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n        \"\"\"\n        identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n        database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n        dynamo_table_item = self._get_iceberg_table_item(database_name=database_name, table_name=table_name)\n        return self._convert_dynamo_table_item_to_iceberg_table(dynamo_table_item=dynamo_table_item)\n\n    def drop_table(self, identifier: Union[str, Identifier]) -&gt; None:\n        \"\"\"Drop a table.\n\n        Args:\n            identifier: Table identifier.\n\n        Raises:\n            NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n        \"\"\"\n        identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n        database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n\n        try:\n            self._delete_dynamo_item(\n                namespace=database_name,\n                identifier=f\"{database_name}.{table_name}\",\n                condition_expression=f\"attribute_exists({DYNAMODB_COL_IDENTIFIER})\",\n            )\n        except ConditionalCheckFailedException as e:\n            raise NoSuchTableError(f\"Table does not exist: {database_name}.{table_name}\") from e\n\n    def rename_table(self, from_identifier: Union[str, Identifier], to_identifier: Union[str, Identifier]) -&gt; Table:\n        \"\"\"Rename a fully classified table name.\n\n        This method can only rename Iceberg tables in AWS Glue.\n\n        Args:\n            from_identifier: Existing table identifier.\n            to_identifier: New table identifier.\n\n        Returns:\n            Table: the updated table instance with its metadata.\n\n        Raises:\n            ValueError: When from table identifier is invalid.\n            NoSuchTableError: When a table with the name does not exist.\n            NoSuchIcebergTableError: When from table is not a valid iceberg table.\n            NoSuchPropertyException: When from table miss some required properties.\n            NoSuchNamespaceError: When the destination namespace doesn't exist.\n        \"\"\"\n        from_identifier_tuple = self.identifier_to_tuple_without_catalog(from_identifier)\n        from_database_name, from_table_name = self.identifier_to_database_and_table(from_identifier_tuple, NoSuchTableError)\n        to_database_name, to_table_name = self.identifier_to_database_and_table(to_identifier)\n\n        from_table_item = self._get_iceberg_table_item(database_name=from_database_name, table_name=from_table_name)\n\n        try:\n            # Verify that from_identifier is a valid iceberg table\n            self._convert_dynamo_table_item_to_iceberg_table(dynamo_table_item=from_table_item)\n        except NoSuchPropertyException as e:\n            raise NoSuchPropertyException(\n                f\"Failed to rename table {from_database_name}.{from_table_name} since it is missing required properties\"\n            ) from e\n        except NoSuchIcebergTableError as e:\n            raise NoSuchIcebergTableError(\n                f\"Failed to rename table {from_database_name}.{from_table_name} since it is not a valid iceberg table\"\n            ) from e\n\n        self._ensure_namespace_exists(database_name=from_database_name)\n        self._ensure_namespace_exists(database_name=to_database_name)\n\n        try:\n            self._put_dynamo_item(\n                item=_get_rename_table_item(\n                    from_dynamo_table_item=from_table_item, to_database_name=to_database_name, to_table_name=to_table_name\n                ),\n                condition_expression=f\"attribute_not_exists({DYNAMODB_COL_IDENTIFIER})\",\n            )\n        except ConditionalCheckFailedException as e:\n            raise TableAlreadyExistsError(f\"Table {to_database_name}.{to_table_name} already exists\") from e\n\n        try:\n            self.drop_table(from_identifier_tuple)\n        except (NoSuchTableError, GenericDynamoDbError) as e:\n            log_message = f\"Failed to drop old table {from_database_name}.{from_table_name}. \"\n\n            try:\n                self.drop_table(to_identifier)\n                log_message += f\"Rolled back table creation for {to_database_name}.{to_table_name}.\"\n            except (NoSuchTableError, GenericDynamoDbError):\n                log_message += (\n                    f\"Failed to roll back table creation for {to_database_name}.{to_table_name}. \" f\"Please clean up manually\"\n                )\n\n            raise ValueError(log_message) from e\n\n        return self.load_table(to_identifier)\n\n    def create_namespace(self, namespace: Union[str, Identifier], properties: Properties = EMPTY_DICT) -&gt; None:\n        \"\"\"Create a namespace in the catalog.\n\n        Args:\n            namespace: Namespace identifier.\n            properties: A string dictionary of properties for the given namespace.\n\n        Raises:\n            ValueError: If the identifier is invalid.\n            AlreadyExistsError: If a namespace with the given name already exists.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace)\n\n        try:\n            self._put_dynamo_item(\n                item=_get_create_database_item(database_name=database_name, properties=properties),\n                condition_expression=f\"attribute_not_exists({DYNAMODB_COL_NAMESPACE})\",\n            )\n        except ConditionalCheckFailedException as e:\n            raise NamespaceAlreadyExistsError(f\"Database {database_name} already exists\") from e\n\n    def drop_namespace(self, namespace: Union[str, Identifier]) -&gt; None:\n        \"\"\"Drop a namespace.\n\n        A Glue namespace can only be dropped if it is empty.\n\n        Args:\n            namespace: Namespace identifier.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist, or the identifier is invalid.\n            NamespaceNotEmptyError: If the namespace is not empty.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n        table_identifiers = self.list_tables(namespace=database_name)\n\n        if len(table_identifiers) &gt; 0:\n            raise NamespaceNotEmptyError(f\"Database {database_name} is not empty\")\n\n        try:\n            self._delete_dynamo_item(\n                namespace=database_name,\n                identifier=DYNAMODB_NAMESPACE,\n                condition_expression=f\"attribute_exists({DYNAMODB_COL_IDENTIFIER})\",\n            )\n        except ConditionalCheckFailedException as e:\n            raise NoSuchNamespaceError(f\"Database does not exist: {database_name}\") from e\n\n    def list_tables(self, namespace: Union[str, Identifier]) -&gt; List[Identifier]:\n        \"\"\"List tables under the given namespace in the catalog (including non-Iceberg tables).\n\n        Args:\n            namespace (str | Identifier): Namespace identifier to search.\n\n        Returns:\n            List[Identifier]: list of table identifiers.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n\n        paginator = self.dynamodb.get_paginator(\"query\")\n\n        try:\n            page_iterator = paginator.paginate(\n                TableName=self.dynamodb_table_name,\n                IndexName=DYNAMODB_NAMESPACE_GSI,\n                KeyConditionExpression=f\"{DYNAMODB_COL_NAMESPACE} = :namespace \",\n                ExpressionAttributeValues={\n                    \":namespace\": {\n                        \"S\": database_name,\n                    }\n                },\n            )\n        except (\n            self.dynamodb.exceptions.ProvisionedThroughputExceededException,\n            self.dynamodb.exceptions.RequestLimitExceeded,\n            self.dynamodb.exceptions.InternalServerError,\n            self.dynamodb.exceptions.ResourceNotFoundException,\n        ) as e:\n            raise GenericDynamoDbError(e.message) from e\n\n        table_identifiers = []\n        for page in page_iterator:\n            for item in page[\"Items\"]:\n                _dict = _convert_dynamo_item_to_regular_dict(item)\n                identifier_col = _dict[DYNAMODB_COL_IDENTIFIER]\n                if identifier_col == DYNAMODB_NAMESPACE:\n                    continue\n\n                table_identifiers.append(self.identifier_to_tuple(identifier_col))\n\n        return table_identifiers\n\n    def list_namespaces(self, namespace: Union[str, Identifier] = ()) -&gt; List[Identifier]:\n        \"\"\"List top-level namespaces from the catalog.\n\n        We do not support hierarchical namespace.\n\n        Returns:\n            List[Identifier]: a List of namespace identifiers.\n        \"\"\"\n        # Hierarchical namespace is not supported. Return an empty list\n        if namespace:\n            return []\n\n        paginator = self.dynamodb.get_paginator(\"query\")\n\n        try:\n            page_iterator = paginator.paginate(\n                TableName=self.dynamodb_table_name,\n                ConsistentRead=True,\n                KeyConditionExpression=f\"{DYNAMODB_COL_IDENTIFIER} = :identifier\",\n                ExpressionAttributeValues={\n                    \":identifier\": {\n                        \"S\": DYNAMODB_NAMESPACE,\n                    }\n                },\n            )\n        except (\n            self.dynamodb.exceptions.ProvisionedThroughputExceededException,\n            self.dynamodb.exceptions.RequestLimitExceeded,\n            self.dynamodb.exceptions.InternalServerError,\n            self.dynamodb.exceptions.ResourceNotFoundException,\n        ) as e:\n            raise GenericDynamoDbError(e.message) from e\n\n        database_identifiers = []\n        for page in page_iterator:\n            for item in page[\"Items\"]:\n                _dict = _convert_dynamo_item_to_regular_dict(item)\n                namespace_col = _dict[DYNAMODB_COL_NAMESPACE]\n                database_identifiers.append(self.identifier_to_tuple(namespace_col))\n\n        return database_identifiers\n\n    def load_namespace_properties(self, namespace: Union[str, Identifier]) -&gt; Properties:\n        \"\"\"\n        Get properties for a namespace.\n\n        Args:\n            namespace: Namespace identifier.\n\n        Returns:\n            Properties: Properties for the given namespace.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist, or identifier is invalid.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n        namespace_item = self._get_iceberg_namespace_item(database_name=database_name)\n        namespace_dict = _convert_dynamo_item_to_regular_dict(namespace_item)\n        return _get_namespace_properties(namespace_dict=namespace_dict)\n\n    def update_namespace_properties(\n        self, namespace: Union[str, Identifier], removals: Optional[Set[str]] = None, updates: Properties = EMPTY_DICT\n    ) -&gt; PropertiesUpdateSummary:\n        \"\"\"\n        Remove or update provided property keys for a namespace.\n\n        Args:\n            namespace: Namespace identifier\n            removals: Set of property keys that need to be removed. Optional Argument.\n            updates: Properties to be updated for the given namespace.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist\uff0c or identifier is invalid.\n            ValueError: If removals and updates have overlapping keys.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n        namespace_item = self._get_iceberg_namespace_item(database_name=database_name)\n        namespace_dict = _convert_dynamo_item_to_regular_dict(namespace_item)\n        current_properties = _get_namespace_properties(namespace_dict=namespace_dict)\n\n        properties_update_summary, updated_properties = self._get_updated_props_and_update_summary(\n            current_properties=current_properties, removals=removals, updates=updates\n        )\n\n        try:\n            self._put_dynamo_item(\n                item=_get_update_database_item(\n                    namespace_item=namespace_item,\n                    updated_properties=updated_properties,\n                ),\n                condition_expression=f\"attribute_exists({DYNAMODB_COL_NAMESPACE})\",\n            )\n        except ConditionalCheckFailedException as e:\n            raise NoSuchNamespaceError(f\"Database {database_name} does not exist\") from e\n\n        return properties_update_summary\n\n    def _get_iceberg_table_item(self, database_name: str, table_name: str) -&gt; Dict[str, Any]:\n        try:\n            return self._get_dynamo_item(identifier=f\"{database_name}.{table_name}\", namespace=database_name)\n        except ValueError as e:\n            raise NoSuchTableError(f\"Table does not exist: {database_name}.{table_name}\") from e\n\n    def _get_iceberg_namespace_item(self, database_name: str) -&gt; Dict[str, Any]:\n        try:\n            return self._get_dynamo_item(identifier=DYNAMODB_NAMESPACE, namespace=database_name)\n        except ValueError as e:\n            raise NoSuchNamespaceError(f\"Namespace does not exist: {database_name}\") from e\n\n    def _ensure_namespace_exists(self, database_name: str) -&gt; Dict[str, Any]:\n        return self._get_iceberg_namespace_item(database_name)\n\n    def _get_dynamo_item(self, identifier: str, namespace: str) -&gt; Dict[str, Any]:\n        try:\n            response = self.dynamodb.get_item(\n                TableName=self.dynamodb_table_name,\n                ConsistentRead=True,\n                Key={\n                    DYNAMODB_COL_IDENTIFIER: {\n                        \"S\": identifier,\n                    },\n                    DYNAMODB_COL_NAMESPACE: {\n                        \"S\": namespace,\n                    },\n                },\n            )\n            if ITEM in response:\n                return response[ITEM]\n            else:\n                raise ValueError(f\"Item not found. identifier: {identifier} - namespace: {namespace}\")\n        except self.dynamodb.exceptions.ResourceNotFoundException as e:\n            raise ValueError(f\"Item not found. identifier: {identifier} - namespace: {namespace}\") from e\n        except (\n            self.dynamodb.exceptions.ProvisionedThroughputExceededException,\n            self.dynamodb.exceptions.RequestLimitExceeded,\n            self.dynamodb.exceptions.InternalServerError,\n        ) as e:\n            raise GenericDynamoDbError(e.message) from e\n\n    def _put_dynamo_item(self, item: Dict[str, Any], condition_expression: str) -&gt; None:\n        try:\n            self.dynamodb.put_item(TableName=self.dynamodb_table_name, Item=item, ConditionExpression=condition_expression)\n        except self.dynamodb.exceptions.ConditionalCheckFailedException as e:\n            raise ConditionalCheckFailedException(f\"Condition expression check failed: {condition_expression} - {item}\") from e\n        except (\n            self.dynamodb.exceptions.ProvisionedThroughputExceededException,\n            self.dynamodb.exceptions.RequestLimitExceeded,\n            self.dynamodb.exceptions.InternalServerError,\n            self.dynamodb.exceptions.ResourceNotFoundException,\n            self.dynamodb.exceptions.ItemCollectionSizeLimitExceededException,\n            self.dynamodb.exceptions.TransactionConflictException,\n        ) as e:\n            raise GenericDynamoDbError(e.message) from e\n\n    def _delete_dynamo_item(self, namespace: str, identifier: str, condition_expression: str) -&gt; None:\n        try:\n            self.dynamodb.delete_item(\n                TableName=self.dynamodb_table_name,\n                Key={\n                    DYNAMODB_COL_IDENTIFIER: {\n                        \"S\": identifier,\n                    },\n                    DYNAMODB_COL_NAMESPACE: {\n                        \"S\": namespace,\n                    },\n                },\n                ConditionExpression=condition_expression,\n            )\n        except self.dynamodb.exceptions.ConditionalCheckFailedException as e:\n            raise ConditionalCheckFailedException(\n                f\"Condition expression check failed: {condition_expression} - {identifier}\"\n            ) from e\n        except (\n            self.dynamodb.exceptions.ProvisionedThroughputExceededException,\n            self.dynamodb.exceptions.RequestLimitExceeded,\n            self.dynamodb.exceptions.InternalServerError,\n            self.dynamodb.exceptions.ResourceNotFoundException,\n            self.dynamodb.exceptions.ItemCollectionSizeLimitExceededException,\n            self.dynamodb.exceptions.TransactionConflictException,\n        ) as e:\n            raise GenericDynamoDbError(e.message) from e\n\n    def _convert_dynamo_table_item_to_iceberg_table(self, dynamo_table_item: Dict[str, Any]) -&gt; Table:\n        table_dict = _convert_dynamo_item_to_regular_dict(dynamo_table_item)\n\n        for prop in [_add_property_prefix(prop) for prop in (TABLE_TYPE, METADATA_LOCATION)] + [\n            DYNAMODB_COL_IDENTIFIER,\n            DYNAMODB_COL_NAMESPACE,\n            DYNAMODB_COL_CREATED_AT,\n        ]:\n            if prop not in table_dict.keys():\n                raise NoSuchPropertyException(f\"Iceberg required property {prop} is missing: {dynamo_table_item}\")\n\n        table_type = table_dict[_add_property_prefix(TABLE_TYPE)]\n        identifier = table_dict[DYNAMODB_COL_IDENTIFIER]\n        metadata_location = table_dict[_add_property_prefix(METADATA_LOCATION)]\n        database_name, table_name = self.identifier_to_database_and_table(identifier, NoSuchTableError)\n\n        if table_type.lower() != ICEBERG:\n            raise NoSuchIcebergTableError(\n                f\"Property table_type is {table_type}, expected {ICEBERG}: \" f\"{database_name}.{table_name}\"\n            )\n\n        io = load_file_io(properties=self.properties, location=metadata_location)\n        file = io.new_input(metadata_location)\n        metadata = FromInputFile.table_metadata(file)\n        return Table(\n            identifier=(self.name, database_name, table_name),\n            metadata=metadata,\n            metadata_location=metadata_location,\n            io=self._load_file_io(metadata.properties, metadata_location),\n            catalog=self,\n        )\n</code></pre>"},{"location":"reference/pyiceberg/catalog/dynamodb/#pyiceberg.catalog.dynamodb.DynamoDbCatalog.create_namespace","title":"<code>create_namespace(namespace, properties=EMPTY_DICT)</code>","text":"<p>Create a namespace in the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Union[str, Identifier]</code> <p>Namespace identifier.</p> required <code>properties</code> <code>Properties</code> <p>A string dictionary of properties for the given namespace.</p> <code>EMPTY_DICT</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the identifier is invalid.</p> <code>AlreadyExistsError</code> <p>If a namespace with the given name already exists.</p> Source code in <code>pyiceberg/catalog/dynamodb.py</code> <pre><code>def create_namespace(self, namespace: Union[str, Identifier], properties: Properties = EMPTY_DICT) -&gt; None:\n    \"\"\"Create a namespace in the catalog.\n\n    Args:\n        namespace: Namespace identifier.\n        properties: A string dictionary of properties for the given namespace.\n\n    Raises:\n        ValueError: If the identifier is invalid.\n        AlreadyExistsError: If a namespace with the given name already exists.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace)\n\n    try:\n        self._put_dynamo_item(\n            item=_get_create_database_item(database_name=database_name, properties=properties),\n            condition_expression=f\"attribute_not_exists({DYNAMODB_COL_NAMESPACE})\",\n        )\n    except ConditionalCheckFailedException as e:\n        raise NamespaceAlreadyExistsError(f\"Database {database_name} already exists\") from e\n</code></pre>"},{"location":"reference/pyiceberg/catalog/dynamodb/#pyiceberg.catalog.dynamodb.DynamoDbCatalog.create_table","title":"<code>create_table(identifier, schema, location=None, partition_spec=UNPARTITIONED_PARTITION_SPEC, sort_order=UNSORTED_SORT_ORDER, properties=EMPTY_DICT)</code>","text":"<p>Create an Iceberg table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier.</p> required <code>schema</code> <code>Union[Schema, Schema]</code> <p>Table's schema.</p> required <code>location</code> <code>Optional[str]</code> <p>Location for the table. Optional Argument.</p> <code>None</code> <code>partition_spec</code> <code>PartitionSpec</code> <p>PartitionSpec for the table.</p> <code>UNPARTITIONED_PARTITION_SPEC</code> <code>sort_order</code> <code>SortOrder</code> <p>SortOrder for the table.</p> <code>UNSORTED_SORT_ORDER</code> <code>properties</code> <code>Properties</code> <p>Table properties that can be a string based dictionary.</p> <code>EMPTY_DICT</code> <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the created table instance.</p> <p>Raises:</p> Type Description <code>AlreadyExistsError</code> <p>If a table with the name already exists.</p> <code>ValueError</code> <p>If the identifier is invalid, or no path is given to store metadata.</p> Source code in <code>pyiceberg/catalog/dynamodb.py</code> <pre><code>def create_table(\n    self,\n    identifier: Union[str, Identifier],\n    schema: Union[Schema, \"pa.Schema\"],\n    location: Optional[str] = None,\n    partition_spec: PartitionSpec = UNPARTITIONED_PARTITION_SPEC,\n    sort_order: SortOrder = UNSORTED_SORT_ORDER,\n    properties: Properties = EMPTY_DICT,\n) -&gt; Table:\n    \"\"\"\n    Create an Iceberg table.\n\n    Args:\n        identifier: Table identifier.\n        schema: Table's schema.\n        location: Location for the table. Optional Argument.\n        partition_spec: PartitionSpec for the table.\n        sort_order: SortOrder for the table.\n        properties: Table properties that can be a string based dictionary.\n\n    Returns:\n        Table: the created table instance.\n\n    Raises:\n        AlreadyExistsError: If a table with the name already exists.\n        ValueError: If the identifier is invalid, or no path is given to store metadata.\n\n    \"\"\"\n    schema: Schema = self._convert_schema_if_needed(schema)  # type: ignore\n\n    database_name, table_name = self.identifier_to_database_and_table(identifier)\n\n    location = self._resolve_table_location(location, database_name, table_name)\n    metadata_location = self._get_metadata_location(location=location)\n    metadata = new_table_metadata(\n        location=location, schema=schema, partition_spec=partition_spec, sort_order=sort_order, properties=properties\n    )\n    io = load_file_io(properties=self.properties, location=metadata_location)\n    self._write_metadata(metadata, io, metadata_location)\n\n    self._ensure_namespace_exists(database_name=database_name)\n\n    try:\n        self._put_dynamo_item(\n            item=_get_create_table_item(\n                database_name=database_name, table_name=table_name, properties=properties, metadata_location=metadata_location\n            ),\n            condition_expression=f\"attribute_not_exists({DYNAMODB_COL_IDENTIFIER})\",\n        )\n    except ConditionalCheckFailedException as e:\n        raise TableAlreadyExistsError(f\"Table {database_name}.{table_name} already exists\") from e\n\n    return self.load_table(identifier=identifier)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/dynamodb/#pyiceberg.catalog.dynamodb.DynamoDbCatalog.drop_namespace","title":"<code>drop_namespace(namespace)</code>","text":"<p>Drop a namespace.</p> <p>A Glue namespace can only be dropped if it is empty.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Union[str, Identifier]</code> <p>Namespace identifier.</p> required <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist, or the identifier is invalid.</p> <code>NamespaceNotEmptyError</code> <p>If the namespace is not empty.</p> Source code in <code>pyiceberg/catalog/dynamodb.py</code> <pre><code>def drop_namespace(self, namespace: Union[str, Identifier]) -&gt; None:\n    \"\"\"Drop a namespace.\n\n    A Glue namespace can only be dropped if it is empty.\n\n    Args:\n        namespace: Namespace identifier.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist, or the identifier is invalid.\n        NamespaceNotEmptyError: If the namespace is not empty.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n    table_identifiers = self.list_tables(namespace=database_name)\n\n    if len(table_identifiers) &gt; 0:\n        raise NamespaceNotEmptyError(f\"Database {database_name} is not empty\")\n\n    try:\n        self._delete_dynamo_item(\n            namespace=database_name,\n            identifier=DYNAMODB_NAMESPACE,\n            condition_expression=f\"attribute_exists({DYNAMODB_COL_IDENTIFIER})\",\n        )\n    except ConditionalCheckFailedException as e:\n        raise NoSuchNamespaceError(f\"Database does not exist: {database_name}\") from e\n</code></pre>"},{"location":"reference/pyiceberg/catalog/dynamodb/#pyiceberg.catalog.dynamodb.DynamoDbCatalog.drop_table","title":"<code>drop_table(identifier)</code>","text":"<p>Drop a table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier.</p> required <p>Raises:</p> Type Description <code>NoSuchTableError</code> <p>If a table with the name does not exist, or the identifier is invalid.</p> Source code in <code>pyiceberg/catalog/dynamodb.py</code> <pre><code>def drop_table(self, identifier: Union[str, Identifier]) -&gt; None:\n    \"\"\"Drop a table.\n\n    Args:\n        identifier: Table identifier.\n\n    Raises:\n        NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n    \"\"\"\n    identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n    database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n\n    try:\n        self._delete_dynamo_item(\n            namespace=database_name,\n            identifier=f\"{database_name}.{table_name}\",\n            condition_expression=f\"attribute_exists({DYNAMODB_COL_IDENTIFIER})\",\n        )\n    except ConditionalCheckFailedException as e:\n        raise NoSuchTableError(f\"Table does not exist: {database_name}.{table_name}\") from e\n</code></pre>"},{"location":"reference/pyiceberg/catalog/dynamodb/#pyiceberg.catalog.dynamodb.DynamoDbCatalog.list_namespaces","title":"<code>list_namespaces(namespace=())</code>","text":"<p>List top-level namespaces from the catalog.</p> <p>We do not support hierarchical namespace.</p> <p>Returns:</p> Type Description <code>List[Identifier]</code> <p>List[Identifier]: a List of namespace identifiers.</p> Source code in <code>pyiceberg/catalog/dynamodb.py</code> <pre><code>def list_namespaces(self, namespace: Union[str, Identifier] = ()) -&gt; List[Identifier]:\n    \"\"\"List top-level namespaces from the catalog.\n\n    We do not support hierarchical namespace.\n\n    Returns:\n        List[Identifier]: a List of namespace identifiers.\n    \"\"\"\n    # Hierarchical namespace is not supported. Return an empty list\n    if namespace:\n        return []\n\n    paginator = self.dynamodb.get_paginator(\"query\")\n\n    try:\n        page_iterator = paginator.paginate(\n            TableName=self.dynamodb_table_name,\n            ConsistentRead=True,\n            KeyConditionExpression=f\"{DYNAMODB_COL_IDENTIFIER} = :identifier\",\n            ExpressionAttributeValues={\n                \":identifier\": {\n                    \"S\": DYNAMODB_NAMESPACE,\n                }\n            },\n        )\n    except (\n        self.dynamodb.exceptions.ProvisionedThroughputExceededException,\n        self.dynamodb.exceptions.RequestLimitExceeded,\n        self.dynamodb.exceptions.InternalServerError,\n        self.dynamodb.exceptions.ResourceNotFoundException,\n    ) as e:\n        raise GenericDynamoDbError(e.message) from e\n\n    database_identifiers = []\n    for page in page_iterator:\n        for item in page[\"Items\"]:\n            _dict = _convert_dynamo_item_to_regular_dict(item)\n            namespace_col = _dict[DYNAMODB_COL_NAMESPACE]\n            database_identifiers.append(self.identifier_to_tuple(namespace_col))\n\n    return database_identifiers\n</code></pre>"},{"location":"reference/pyiceberg/catalog/dynamodb/#pyiceberg.catalog.dynamodb.DynamoDbCatalog.list_tables","title":"<code>list_tables(namespace)</code>","text":"<p>List tables under the given namespace in the catalog (including non-Iceberg tables).</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier to search.</p> required <p>Returns:</p> Type Description <code>List[Identifier]</code> <p>List[Identifier]: list of table identifiers.</p> Source code in <code>pyiceberg/catalog/dynamodb.py</code> <pre><code>def list_tables(self, namespace: Union[str, Identifier]) -&gt; List[Identifier]:\n    \"\"\"List tables under the given namespace in the catalog (including non-Iceberg tables).\n\n    Args:\n        namespace (str | Identifier): Namespace identifier to search.\n\n    Returns:\n        List[Identifier]: list of table identifiers.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n\n    paginator = self.dynamodb.get_paginator(\"query\")\n\n    try:\n        page_iterator = paginator.paginate(\n            TableName=self.dynamodb_table_name,\n            IndexName=DYNAMODB_NAMESPACE_GSI,\n            KeyConditionExpression=f\"{DYNAMODB_COL_NAMESPACE} = :namespace \",\n            ExpressionAttributeValues={\n                \":namespace\": {\n                    \"S\": database_name,\n                }\n            },\n        )\n    except (\n        self.dynamodb.exceptions.ProvisionedThroughputExceededException,\n        self.dynamodb.exceptions.RequestLimitExceeded,\n        self.dynamodb.exceptions.InternalServerError,\n        self.dynamodb.exceptions.ResourceNotFoundException,\n    ) as e:\n        raise GenericDynamoDbError(e.message) from e\n\n    table_identifiers = []\n    for page in page_iterator:\n        for item in page[\"Items\"]:\n            _dict = _convert_dynamo_item_to_regular_dict(item)\n            identifier_col = _dict[DYNAMODB_COL_IDENTIFIER]\n            if identifier_col == DYNAMODB_NAMESPACE:\n                continue\n\n            table_identifiers.append(self.identifier_to_tuple(identifier_col))\n\n    return table_identifiers\n</code></pre>"},{"location":"reference/pyiceberg/catalog/dynamodb/#pyiceberg.catalog.dynamodb.DynamoDbCatalog.load_namespace_properties","title":"<code>load_namespace_properties(namespace)</code>","text":"<p>Get properties for a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Union[str, Identifier]</code> <p>Namespace identifier.</p> required <p>Returns:</p> Name Type Description <code>Properties</code> <code>Properties</code> <p>Properties for the given namespace.</p> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist, or identifier is invalid.</p> Source code in <code>pyiceberg/catalog/dynamodb.py</code> <pre><code>def load_namespace_properties(self, namespace: Union[str, Identifier]) -&gt; Properties:\n    \"\"\"\n    Get properties for a namespace.\n\n    Args:\n        namespace: Namespace identifier.\n\n    Returns:\n        Properties: Properties for the given namespace.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist, or identifier is invalid.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n    namespace_item = self._get_iceberg_namespace_item(database_name=database_name)\n    namespace_dict = _convert_dynamo_item_to_regular_dict(namespace_item)\n    return _get_namespace_properties(namespace_dict=namespace_dict)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/dynamodb/#pyiceberg.catalog.dynamodb.DynamoDbCatalog.load_table","title":"<code>load_table(identifier)</code>","text":"<p>Load the table's metadata and returns the table instance.</p> <p>You can also use this method to check for table existence using 'try catalog.table() except TableNotFoundError'. Note: This method doesn't scan data stored in the table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier.</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the table instance with its metadata.</p> <p>Raises:</p> Type Description <code>NoSuchTableError</code> <p>If a table with the name does not exist, or the identifier is invalid.</p> Source code in <code>pyiceberg/catalog/dynamodb.py</code> <pre><code>def load_table(self, identifier: Union[str, Identifier]) -&gt; Table:\n    \"\"\"\n    Load the table's metadata and returns the table instance.\n\n    You can also use this method to check for table existence using 'try catalog.table() except TableNotFoundError'.\n    Note: This method doesn't scan data stored in the table.\n\n    Args:\n        identifier: Table identifier.\n\n    Returns:\n        Table: the table instance with its metadata.\n\n    Raises:\n        NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n    \"\"\"\n    identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n    database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n    dynamo_table_item = self._get_iceberg_table_item(database_name=database_name, table_name=table_name)\n    return self._convert_dynamo_table_item_to_iceberg_table(dynamo_table_item=dynamo_table_item)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/dynamodb/#pyiceberg.catalog.dynamodb.DynamoDbCatalog.register_table","title":"<code>register_table(identifier, metadata_location)</code>","text":"<p>Register a new table using existing metadata.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier for the table</p> required <code>metadata_location</code> <code>str</code> <p>The location to the metadata</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>The newly registered table</p> <p>Raises:</p> Type Description <code>TableAlreadyExistsError</code> <p>If the table already exists</p> Source code in <code>pyiceberg/catalog/dynamodb.py</code> <pre><code>def register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n    \"\"\"Register a new table using existing metadata.\n\n    Args:\n        identifier Union[str, Identifier]: Table identifier for the table\n        metadata_location str: The location to the metadata\n\n    Returns:\n        Table: The newly registered table\n\n    Raises:\n        TableAlreadyExistsError: If the table already exists\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pyiceberg/catalog/dynamodb/#pyiceberg.catalog.dynamodb.DynamoDbCatalog.rename_table","title":"<code>rename_table(from_identifier, to_identifier)</code>","text":"<p>Rename a fully classified table name.</p> <p>This method can only rename Iceberg tables in AWS Glue.</p> <p>Parameters:</p> Name Type Description Default <code>from_identifier</code> <code>Union[str, Identifier]</code> <p>Existing table identifier.</p> required <code>to_identifier</code> <code>Union[str, Identifier]</code> <p>New table identifier.</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the updated table instance with its metadata.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When from table identifier is invalid.</p> <code>NoSuchTableError</code> <p>When a table with the name does not exist.</p> <code>NoSuchIcebergTableError</code> <p>When from table is not a valid iceberg table.</p> <code>NoSuchPropertyException</code> <p>When from table miss some required properties.</p> <code>NoSuchNamespaceError</code> <p>When the destination namespace doesn't exist.</p> Source code in <code>pyiceberg/catalog/dynamodb.py</code> <pre><code>def rename_table(self, from_identifier: Union[str, Identifier], to_identifier: Union[str, Identifier]) -&gt; Table:\n    \"\"\"Rename a fully classified table name.\n\n    This method can only rename Iceberg tables in AWS Glue.\n\n    Args:\n        from_identifier: Existing table identifier.\n        to_identifier: New table identifier.\n\n    Returns:\n        Table: the updated table instance with its metadata.\n\n    Raises:\n        ValueError: When from table identifier is invalid.\n        NoSuchTableError: When a table with the name does not exist.\n        NoSuchIcebergTableError: When from table is not a valid iceberg table.\n        NoSuchPropertyException: When from table miss some required properties.\n        NoSuchNamespaceError: When the destination namespace doesn't exist.\n    \"\"\"\n    from_identifier_tuple = self.identifier_to_tuple_without_catalog(from_identifier)\n    from_database_name, from_table_name = self.identifier_to_database_and_table(from_identifier_tuple, NoSuchTableError)\n    to_database_name, to_table_name = self.identifier_to_database_and_table(to_identifier)\n\n    from_table_item = self._get_iceberg_table_item(database_name=from_database_name, table_name=from_table_name)\n\n    try:\n        # Verify that from_identifier is a valid iceberg table\n        self._convert_dynamo_table_item_to_iceberg_table(dynamo_table_item=from_table_item)\n    except NoSuchPropertyException as e:\n        raise NoSuchPropertyException(\n            f\"Failed to rename table {from_database_name}.{from_table_name} since it is missing required properties\"\n        ) from e\n    except NoSuchIcebergTableError as e:\n        raise NoSuchIcebergTableError(\n            f\"Failed to rename table {from_database_name}.{from_table_name} since it is not a valid iceberg table\"\n        ) from e\n\n    self._ensure_namespace_exists(database_name=from_database_name)\n    self._ensure_namespace_exists(database_name=to_database_name)\n\n    try:\n        self._put_dynamo_item(\n            item=_get_rename_table_item(\n                from_dynamo_table_item=from_table_item, to_database_name=to_database_name, to_table_name=to_table_name\n            ),\n            condition_expression=f\"attribute_not_exists({DYNAMODB_COL_IDENTIFIER})\",\n        )\n    except ConditionalCheckFailedException as e:\n        raise TableAlreadyExistsError(f\"Table {to_database_name}.{to_table_name} already exists\") from e\n\n    try:\n        self.drop_table(from_identifier_tuple)\n    except (NoSuchTableError, GenericDynamoDbError) as e:\n        log_message = f\"Failed to drop old table {from_database_name}.{from_table_name}. \"\n\n        try:\n            self.drop_table(to_identifier)\n            log_message += f\"Rolled back table creation for {to_database_name}.{to_table_name}.\"\n        except (NoSuchTableError, GenericDynamoDbError):\n            log_message += (\n                f\"Failed to roll back table creation for {to_database_name}.{to_table_name}. \" f\"Please clean up manually\"\n            )\n\n        raise ValueError(log_message) from e\n\n    return self.load_table(to_identifier)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/dynamodb/#pyiceberg.catalog.dynamodb.DynamoDbCatalog.update_namespace_properties","title":"<code>update_namespace_properties(namespace, removals=None, updates=EMPTY_DICT)</code>","text":"<p>Remove or update provided property keys for a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Union[str, Identifier]</code> <p>Namespace identifier</p> required <code>removals</code> <code>Optional[Set[str]]</code> <p>Set of property keys that need to be removed. Optional Argument.</p> <code>None</code> <code>updates</code> <code>Properties</code> <p>Properties to be updated for the given namespace.</p> <code>EMPTY_DICT</code> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist\uff0c or identifier is invalid.</p> <code>ValueError</code> <p>If removals and updates have overlapping keys.</p> Source code in <code>pyiceberg/catalog/dynamodb.py</code> <pre><code>def update_namespace_properties(\n    self, namespace: Union[str, Identifier], removals: Optional[Set[str]] = None, updates: Properties = EMPTY_DICT\n) -&gt; PropertiesUpdateSummary:\n    \"\"\"\n    Remove or update provided property keys for a namespace.\n\n    Args:\n        namespace: Namespace identifier\n        removals: Set of property keys that need to be removed. Optional Argument.\n        updates: Properties to be updated for the given namespace.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist\uff0c or identifier is invalid.\n        ValueError: If removals and updates have overlapping keys.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n    namespace_item = self._get_iceberg_namespace_item(database_name=database_name)\n    namespace_dict = _convert_dynamo_item_to_regular_dict(namespace_item)\n    current_properties = _get_namespace_properties(namespace_dict=namespace_dict)\n\n    properties_update_summary, updated_properties = self._get_updated_props_and_update_summary(\n        current_properties=current_properties, removals=removals, updates=updates\n    )\n\n    try:\n        self._put_dynamo_item(\n            item=_get_update_database_item(\n                namespace_item=namespace_item,\n                updated_properties=updated_properties,\n            ),\n            condition_expression=f\"attribute_exists({DYNAMODB_COL_NAMESPACE})\",\n        )\n    except ConditionalCheckFailedException as e:\n        raise NoSuchNamespaceError(f\"Database {database_name} does not exist\") from e\n\n    return properties_update_summary\n</code></pre>"},{"location":"reference/pyiceberg/catalog/glue/","title":"glue","text":""},{"location":"reference/pyiceberg/catalog/glue/#pyiceberg.catalog.glue.GlueCatalog","title":"<code>GlueCatalog</code>","text":"<p>             Bases: <code>Catalog</code></p> Source code in <code>pyiceberg/catalog/glue.py</code> <pre><code>class GlueCatalog(Catalog):\n    def __init__(self, name: str, **properties: Any):\n        super().__init__(name, **properties)\n\n        session = boto3.Session(\n            profile_name=properties.get(\"profile_name\"),\n            region_name=properties.get(\"region_name\"),\n            botocore_session=properties.get(\"botocore_session\"),\n            aws_access_key_id=properties.get(\"aws_access_key_id\"),\n            aws_secret_access_key=properties.get(\"aws_secret_access_key\"),\n            aws_session_token=properties.get(\"aws_session_token\"),\n        )\n        self.glue: GlueClient = session.client(\"glue\")\n\n    def _convert_glue_to_iceberg(self, glue_table: TableTypeDef) -&gt; Table:\n        properties: Properties = glue_table[\"Parameters\"]\n\n        assert glue_table[\"DatabaseName\"]\n        assert glue_table[\"Parameters\"]\n        database_name = glue_table[\"DatabaseName\"]\n        table_name = glue_table[\"Name\"]\n\n        if TABLE_TYPE not in properties:\n            raise NoSuchPropertyException(\n                f\"Property {TABLE_TYPE} missing, could not determine type: {database_name}.{table_name}\"\n            )\n        glue_table_type = properties[TABLE_TYPE]\n\n        if glue_table_type.lower() != ICEBERG:\n            raise NoSuchIcebergTableError(\n                f\"Property table_type is {glue_table_type}, expected {ICEBERG}: {database_name}.{table_name}\"\n            )\n\n        if METADATA_LOCATION not in properties:\n            raise NoSuchPropertyException(\n                f\"Table property {METADATA_LOCATION} is missing, cannot find metadata for: {database_name}.{table_name}\"\n            )\n        metadata_location = properties[METADATA_LOCATION]\n\n        io = load_file_io(properties=self.properties, location=metadata_location)\n        file = io.new_input(metadata_location)\n        metadata = FromInputFile.table_metadata(file)\n        return Table(\n            identifier=(self.name, database_name, table_name),\n            metadata=metadata,\n            metadata_location=metadata_location,\n            io=self._load_file_io(metadata.properties, metadata_location),\n            catalog=self,\n        )\n\n    def _create_glue_table(self, database_name: str, table_name: str, table_input: TableInputTypeDef) -&gt; None:\n        try:\n            self.glue.create_table(DatabaseName=database_name, TableInput=table_input)\n        except self.glue.exceptions.AlreadyExistsException as e:\n            raise TableAlreadyExistsError(f\"Table {database_name}.{table_name} already exists\") from e\n        except self.glue.exceptions.EntityNotFoundException as e:\n            raise NoSuchNamespaceError(f\"Database {database_name} does not exist\") from e\n\n    def _update_glue_table(self, database_name: str, table_name: str, table_input: TableInputTypeDef, version_id: str) -&gt; None:\n        try:\n            self.glue.update_table(\n                DatabaseName=database_name,\n                TableInput=table_input,\n                SkipArchive=self.properties.get(GLUE_SKIP_ARCHIVE, GLUE_SKIP_ARCHIVE_DEFAULT),\n                VersionId=version_id,\n            )\n        except self.glue.exceptions.EntityNotFoundException as e:\n            raise NoSuchTableError(f\"Table does not exist: {database_name}.{table_name} (Glue table version {version_id})\") from e\n        except self.glue.exceptions.ConcurrentModificationException as e:\n            raise CommitFailedException(\n                f\"Cannot commit {database_name}.{table_name} because Glue detected concurrent update to table version {version_id}\"\n            ) from e\n\n    def _get_glue_table(self, database_name: str, table_name: str) -&gt; TableTypeDef:\n        try:\n            load_table_response = self.glue.get_table(DatabaseName=database_name, Name=table_name)\n            return load_table_response[\"Table\"]\n        except self.glue.exceptions.EntityNotFoundException as e:\n            raise NoSuchTableError(f\"Table does not exist: {database_name}.{table_name}\") from e\n\n    def create_table(\n        self,\n        identifier: Union[str, Identifier],\n        schema: Union[Schema, \"pa.Schema\"],\n        location: Optional[str] = None,\n        partition_spec: PartitionSpec = UNPARTITIONED_PARTITION_SPEC,\n        sort_order: SortOrder = UNSORTED_SORT_ORDER,\n        properties: Properties = EMPTY_DICT,\n    ) -&gt; Table:\n        \"\"\"\n        Create an Iceberg table.\n\n        Args:\n            identifier: Table identifier.\n            schema: Table's schema.\n            location: Location for the table. Optional Argument.\n            partition_spec: PartitionSpec for the table.\n            sort_order: SortOrder for the table.\n            properties: Table properties that can be a string based dictionary.\n\n        Returns:\n            Table: the created table instance.\n\n        Raises:\n            AlreadyExistsError: If a table with the name already exists.\n            ValueError: If the identifier is invalid, or no path is given to store metadata.\n\n        \"\"\"\n        schema: Schema = self._convert_schema_if_needed(schema)  # type: ignore\n\n        database_name, table_name = self.identifier_to_database_and_table(identifier)\n\n        location = self._resolve_table_location(location, database_name, table_name)\n        metadata_location = self._get_metadata_location(location=location)\n        metadata = new_table_metadata(\n            location=location, schema=schema, partition_spec=partition_spec, sort_order=sort_order, properties=properties\n        )\n        io = load_file_io(properties=self.properties, location=metadata_location)\n        self._write_metadata(metadata, io, metadata_location)\n\n        table_input = _construct_table_input(table_name, metadata_location, properties, metadata)\n        database_name, table_name = self.identifier_to_database_and_table(identifier)\n        self._create_glue_table(database_name=database_name, table_name=table_name, table_input=table_input)\n\n        return self.load_table(identifier=identifier)\n\n    def register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n        \"\"\"Register a new table using existing metadata.\n\n        Args:\n            identifier Union[str, Identifier]: Table identifier for the table\n            metadata_location str: The location to the metadata\n\n        Returns:\n            Table: The newly registered table\n\n        Raises:\n            TableAlreadyExistsError: If the table already exists\n        \"\"\"\n        raise NotImplementedError\n\n    def _commit_table(self, table_request: CommitTableRequest) -&gt; CommitTableResponse:\n        \"\"\"Update the table.\n\n        Args:\n            table_request (CommitTableRequest): The table requests to be carried out.\n\n        Returns:\n            CommitTableResponse: The updated metadata.\n\n        Raises:\n            NoSuchTableError: If a table with the given identifier does not exist.\n            CommitFailedException: If the commit failed.\n        \"\"\"\n        identifier_tuple = self.identifier_to_tuple_without_catalog(\n            tuple(table_request.identifier.namespace.root + [table_request.identifier.name])\n        )\n        database_name, table_name = self.identifier_to_database_and_table(identifier_tuple)\n\n        current_glue_table = self._get_glue_table(database_name=database_name, table_name=table_name)\n        glue_table_version_id = current_glue_table.get(\"VersionId\")\n        if not glue_table_version_id:\n            raise CommitFailedException(f\"Cannot commit {database_name}.{table_name} because Glue table version id is missing\")\n        current_table = self._convert_glue_to_iceberg(glue_table=current_glue_table)\n        base_metadata = current_table.metadata\n\n        # Validate the update requirements\n        for requirement in table_request.requirements:\n            requirement.validate(base_metadata)\n\n        updated_metadata = update_table_metadata(base_metadata, table_request.updates)\n        if updated_metadata == base_metadata:\n            # no changes, do nothing\n            return CommitTableResponse(metadata=base_metadata, metadata_location=current_table.metadata_location)\n\n        # write new metadata\n        new_metadata_version = self._parse_metadata_version(current_table.metadata_location) + 1\n        new_metadata_location = self._get_metadata_location(current_table.metadata.location, new_metadata_version)\n        self._write_metadata(updated_metadata, current_table.io, new_metadata_location)\n\n        update_table_input = _construct_table_input(\n            table_name=table_name,\n            metadata_location=new_metadata_location,\n            properties=current_table.properties,\n            metadata=updated_metadata,\n            glue_table=current_glue_table,\n            prev_metadata_location=current_table.metadata_location,\n        )\n\n        # Pass `version_id` to implement optimistic locking: it ensures updates are rejected if concurrent\n        # modifications occur. See more details at https://iceberg.apache.org/docs/latest/aws/#optimistic-locking\n        self._update_glue_table(\n            database_name=database_name,\n            table_name=table_name,\n            table_input=update_table_input,\n            version_id=glue_table_version_id,\n        )\n\n        return CommitTableResponse(metadata=updated_metadata, metadata_location=new_metadata_location)\n\n    def load_table(self, identifier: Union[str, Identifier]) -&gt; Table:\n        \"\"\"Load the table's metadata and returns the table instance.\n\n        You can also use this method to check for table existence using 'try catalog.table() except TableNotFoundError'.\n        Note: This method doesn't scan data stored in the table.\n\n        Args:\n            identifier: Table identifier.\n\n        Returns:\n            Table: the table instance with its metadata.\n\n        Raises:\n            NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n        \"\"\"\n        identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n        database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n\n        return self._convert_glue_to_iceberg(self._get_glue_table(database_name=database_name, table_name=table_name))\n\n    def drop_table(self, identifier: Union[str, Identifier]) -&gt; None:\n        \"\"\"Drop a table.\n\n        Args:\n            identifier: Table identifier.\n\n        Raises:\n            NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n        \"\"\"\n        identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n        database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n        try:\n            self.glue.delete_table(DatabaseName=database_name, Name=table_name)\n        except self.glue.exceptions.EntityNotFoundException as e:\n            raise NoSuchTableError(f\"Table does not exist: {database_name}.{table_name}\") from e\n\n    def rename_table(self, from_identifier: Union[str, Identifier], to_identifier: Union[str, Identifier]) -&gt; Table:\n        \"\"\"Rename a fully classified table name.\n\n        This method can only rename Iceberg tables in AWS Glue.\n\n        Args:\n            from_identifier: Existing table identifier.\n            to_identifier: New table identifier.\n\n        Returns:\n            Table: the updated table instance with its metadata.\n\n        Raises:\n            ValueError: When from table identifier is invalid.\n            NoSuchTableError: When a table with the name does not exist.\n            NoSuchIcebergTableError: When from table is not a valid iceberg table.\n            NoSuchPropertyException: When from table miss some required properties.\n            NoSuchNamespaceError: When the destination namespace doesn't exist.\n        \"\"\"\n        from_identifier_tuple = self.identifier_to_tuple_without_catalog(from_identifier)\n        from_database_name, from_table_name = self.identifier_to_database_and_table(from_identifier_tuple, NoSuchTableError)\n        to_database_name, to_table_name = self.identifier_to_database_and_table(to_identifier)\n        try:\n            get_table_response = self.glue.get_table(DatabaseName=from_database_name, Name=from_table_name)\n        except self.glue.exceptions.EntityNotFoundException as e:\n            raise NoSuchTableError(f\"Table does not exist: {from_database_name}.{from_table_name}\") from e\n\n        glue_table = get_table_response[\"Table\"]\n\n        try:\n            # verify that from_identifier is a valid iceberg table\n            self._convert_glue_to_iceberg(glue_table=glue_table)\n        except NoSuchPropertyException as e:\n            raise NoSuchPropertyException(\n                f\"Failed to rename table {from_database_name}.{from_table_name} since it is missing required properties\"\n            ) from e\n        except NoSuchIcebergTableError as e:\n            raise NoSuchIcebergTableError(\n                f\"Failed to rename table {from_database_name}.{from_table_name} since it is not a valid iceberg table\"\n            ) from e\n\n        rename_table_input = _construct_rename_table_input(to_table_name=to_table_name, glue_table=glue_table)\n        self._create_glue_table(database_name=to_database_name, table_name=to_table_name, table_input=rename_table_input)\n\n        try:\n            self.drop_table(from_identifier)\n        except Exception as e:\n            log_message = f\"Failed to drop old table {from_database_name}.{from_table_name}. \"\n\n            try:\n                self.drop_table(to_identifier)\n                log_message += f\"Rolled back table creation for {to_database_name}.{to_table_name}.\"\n            except NoSuchTableError:\n                log_message += (\n                    f\"Failed to roll back table creation for {to_database_name}.{to_table_name}. \" f\"Please clean up manually\"\n                )\n\n            raise ValueError(log_message) from e\n\n        return self.load_table(to_identifier)\n\n    def create_namespace(self, namespace: Union[str, Identifier], properties: Properties = EMPTY_DICT) -&gt; None:\n        \"\"\"Create a namespace in the catalog.\n\n        Args:\n            namespace: Namespace identifier.\n            properties: A string dictionary of properties for the given namespace.\n\n        Raises:\n            ValueError: If the identifier is invalid.\n            AlreadyExistsError: If a namespace with the given name already exists.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace)\n        try:\n            self.glue.create_database(DatabaseInput=_construct_database_input(database_name, properties))\n        except self.glue.exceptions.AlreadyExistsException as e:\n            raise NamespaceAlreadyExistsError(f\"Database {database_name} already exists\") from e\n\n    def drop_namespace(self, namespace: Union[str, Identifier]) -&gt; None:\n        \"\"\"Drop a namespace.\n\n        A Glue namespace can only be dropped if it is empty.\n\n        Args:\n            namespace: Namespace identifier.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist, or the identifier is invalid.\n            NamespaceNotEmptyError: If the namespace is not empty.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n        try:\n            table_list = self.list_tables(namespace=database_name)\n        except NoSuchNamespaceError as e:\n            raise NoSuchNamespaceError(f\"Database does not exist: {database_name}\") from e\n\n        if len(table_list) &gt; 0:\n            raise NamespaceNotEmptyError(f\"Database {database_name} is not empty\")\n\n        self.glue.delete_database(Name=database_name)\n\n    def list_tables(self, namespace: Union[str, Identifier]) -&gt; List[Identifier]:\n        \"\"\"List tables under the given namespace in the catalog (including non-Iceberg tables).\n\n        Args:\n            namespace (str | Identifier): Namespace identifier to search.\n\n        Returns:\n            List[Identifier]: list of table identifiers.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist, or the identifier is invalid.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n        table_list: List[TableTypeDef] = []\n        next_token: Optional[str] = None\n        try:\n            while True:\n                table_list_response = (\n                    self.glue.get_tables(DatabaseName=database_name)\n                    if not next_token\n                    else self.glue.get_tables(DatabaseName=database_name, NextToken=next_token)\n                )\n                table_list.extend(table_list_response[\"TableList\"])\n                next_token = table_list_response.get(\"NextToken\")\n                if not next_token:\n                    break\n\n        except self.glue.exceptions.EntityNotFoundException as e:\n            raise NoSuchNamespaceError(f\"Database does not exist: {database_name}\") from e\n        return [(database_name, table[\"Name\"]) for table in table_list]\n\n    def list_namespaces(self, namespace: Union[str, Identifier] = ()) -&gt; List[Identifier]:\n        \"\"\"List namespaces from the given namespace. If not given, list top-level namespaces from the catalog.\n\n        Returns:\n            List[Identifier]: a List of namespace identifiers.\n        \"\"\"\n        # Hierarchical namespace is not supported. Return an empty list\n        if namespace:\n            return []\n\n        database_list: List[DatabaseTypeDef] = []\n        next_token: Optional[str] = None\n\n        while True:\n            databases_response = self.glue.get_databases() if not next_token else self.glue.get_databases(NextToken=next_token)\n            database_list.extend(databases_response[\"DatabaseList\"])\n            next_token = databases_response.get(\"NextToken\")\n            if not next_token:\n                break\n\n        return [self.identifier_to_tuple(database[\"Name\"]) for database in database_list]\n\n    def load_namespace_properties(self, namespace: Union[str, Identifier]) -&gt; Properties:\n        \"\"\"Get properties for a namespace.\n\n        Args:\n            namespace: Namespace identifier.\n\n        Returns:\n            Properties: Properties for the given namespace.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist, or identifier is invalid.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n        try:\n            database_response = self.glue.get_database(Name=database_name)\n        except self.glue.exceptions.EntityNotFoundException as e:\n            raise NoSuchNamespaceError(f\"Database does not exist: {database_name}\") from e\n        except self.glue.exceptions.InvalidInputException as e:\n            raise NoSuchNamespaceError(f\"Invalid input for namespace {database_name}\") from e\n\n        database = database_response[\"Database\"]\n\n        properties = dict(database.get(\"Parameters\", {}))\n        if \"LocationUri\" in database:\n            properties[\"location\"] = database[\"LocationUri\"]\n        if \"Description\" in database:\n            properties[\"Description\"] = database[\"Description\"]\n\n        return properties\n\n    def update_namespace_properties(\n        self, namespace: Union[str, Identifier], removals: Optional[Set[str]] = None, updates: Properties = EMPTY_DICT\n    ) -&gt; PropertiesUpdateSummary:\n        \"\"\"Remove provided property keys and updates properties for a namespace.\n\n        Args:\n            namespace: Namespace identifier.\n            removals: Set of property keys that need to be removed. Optional Argument.\n            updates: Properties to be updated for the given namespace.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist\uff0c or identifier is invalid.\n            ValueError: If removals and updates have overlapping keys.\n        \"\"\"\n        current_properties = self.load_namespace_properties(namespace=namespace)\n        properties_update_summary, updated_properties = self._get_updated_props_and_update_summary(\n            current_properties=current_properties, removals=removals, updates=updates\n        )\n\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n        self.glue.update_database(Name=database_name, DatabaseInput=_construct_database_input(database_name, updated_properties))\n\n        return properties_update_summary\n</code></pre>"},{"location":"reference/pyiceberg/catalog/glue/#pyiceberg.catalog.glue.GlueCatalog.create_namespace","title":"<code>create_namespace(namespace, properties=EMPTY_DICT)</code>","text":"<p>Create a namespace in the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Union[str, Identifier]</code> <p>Namespace identifier.</p> required <code>properties</code> <code>Properties</code> <p>A string dictionary of properties for the given namespace.</p> <code>EMPTY_DICT</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the identifier is invalid.</p> <code>AlreadyExistsError</code> <p>If a namespace with the given name already exists.</p> Source code in <code>pyiceberg/catalog/glue.py</code> <pre><code>def create_namespace(self, namespace: Union[str, Identifier], properties: Properties = EMPTY_DICT) -&gt; None:\n    \"\"\"Create a namespace in the catalog.\n\n    Args:\n        namespace: Namespace identifier.\n        properties: A string dictionary of properties for the given namespace.\n\n    Raises:\n        ValueError: If the identifier is invalid.\n        AlreadyExistsError: If a namespace with the given name already exists.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace)\n    try:\n        self.glue.create_database(DatabaseInput=_construct_database_input(database_name, properties))\n    except self.glue.exceptions.AlreadyExistsException as e:\n        raise NamespaceAlreadyExistsError(f\"Database {database_name} already exists\") from e\n</code></pre>"},{"location":"reference/pyiceberg/catalog/glue/#pyiceberg.catalog.glue.GlueCatalog.create_table","title":"<code>create_table(identifier, schema, location=None, partition_spec=UNPARTITIONED_PARTITION_SPEC, sort_order=UNSORTED_SORT_ORDER, properties=EMPTY_DICT)</code>","text":"<p>Create an Iceberg table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier.</p> required <code>schema</code> <code>Union[Schema, Schema]</code> <p>Table's schema.</p> required <code>location</code> <code>Optional[str]</code> <p>Location for the table. Optional Argument.</p> <code>None</code> <code>partition_spec</code> <code>PartitionSpec</code> <p>PartitionSpec for the table.</p> <code>UNPARTITIONED_PARTITION_SPEC</code> <code>sort_order</code> <code>SortOrder</code> <p>SortOrder for the table.</p> <code>UNSORTED_SORT_ORDER</code> <code>properties</code> <code>Properties</code> <p>Table properties that can be a string based dictionary.</p> <code>EMPTY_DICT</code> <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the created table instance.</p> <p>Raises:</p> Type Description <code>AlreadyExistsError</code> <p>If a table with the name already exists.</p> <code>ValueError</code> <p>If the identifier is invalid, or no path is given to store metadata.</p> Source code in <code>pyiceberg/catalog/glue.py</code> <pre><code>def create_table(\n    self,\n    identifier: Union[str, Identifier],\n    schema: Union[Schema, \"pa.Schema\"],\n    location: Optional[str] = None,\n    partition_spec: PartitionSpec = UNPARTITIONED_PARTITION_SPEC,\n    sort_order: SortOrder = UNSORTED_SORT_ORDER,\n    properties: Properties = EMPTY_DICT,\n) -&gt; Table:\n    \"\"\"\n    Create an Iceberg table.\n\n    Args:\n        identifier: Table identifier.\n        schema: Table's schema.\n        location: Location for the table. Optional Argument.\n        partition_spec: PartitionSpec for the table.\n        sort_order: SortOrder for the table.\n        properties: Table properties that can be a string based dictionary.\n\n    Returns:\n        Table: the created table instance.\n\n    Raises:\n        AlreadyExistsError: If a table with the name already exists.\n        ValueError: If the identifier is invalid, or no path is given to store metadata.\n\n    \"\"\"\n    schema: Schema = self._convert_schema_if_needed(schema)  # type: ignore\n\n    database_name, table_name = self.identifier_to_database_and_table(identifier)\n\n    location = self._resolve_table_location(location, database_name, table_name)\n    metadata_location = self._get_metadata_location(location=location)\n    metadata = new_table_metadata(\n        location=location, schema=schema, partition_spec=partition_spec, sort_order=sort_order, properties=properties\n    )\n    io = load_file_io(properties=self.properties, location=metadata_location)\n    self._write_metadata(metadata, io, metadata_location)\n\n    table_input = _construct_table_input(table_name, metadata_location, properties, metadata)\n    database_name, table_name = self.identifier_to_database_and_table(identifier)\n    self._create_glue_table(database_name=database_name, table_name=table_name, table_input=table_input)\n\n    return self.load_table(identifier=identifier)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/glue/#pyiceberg.catalog.glue.GlueCatalog.drop_namespace","title":"<code>drop_namespace(namespace)</code>","text":"<p>Drop a namespace.</p> <p>A Glue namespace can only be dropped if it is empty.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Union[str, Identifier]</code> <p>Namespace identifier.</p> required <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist, or the identifier is invalid.</p> <code>NamespaceNotEmptyError</code> <p>If the namespace is not empty.</p> Source code in <code>pyiceberg/catalog/glue.py</code> <pre><code>def drop_namespace(self, namespace: Union[str, Identifier]) -&gt; None:\n    \"\"\"Drop a namespace.\n\n    A Glue namespace can only be dropped if it is empty.\n\n    Args:\n        namespace: Namespace identifier.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist, or the identifier is invalid.\n        NamespaceNotEmptyError: If the namespace is not empty.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n    try:\n        table_list = self.list_tables(namespace=database_name)\n    except NoSuchNamespaceError as e:\n        raise NoSuchNamespaceError(f\"Database does not exist: {database_name}\") from e\n\n    if len(table_list) &gt; 0:\n        raise NamespaceNotEmptyError(f\"Database {database_name} is not empty\")\n\n    self.glue.delete_database(Name=database_name)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/glue/#pyiceberg.catalog.glue.GlueCatalog.drop_table","title":"<code>drop_table(identifier)</code>","text":"<p>Drop a table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier.</p> required <p>Raises:</p> Type Description <code>NoSuchTableError</code> <p>If a table with the name does not exist, or the identifier is invalid.</p> Source code in <code>pyiceberg/catalog/glue.py</code> <pre><code>def drop_table(self, identifier: Union[str, Identifier]) -&gt; None:\n    \"\"\"Drop a table.\n\n    Args:\n        identifier: Table identifier.\n\n    Raises:\n        NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n    \"\"\"\n    identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n    database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n    try:\n        self.glue.delete_table(DatabaseName=database_name, Name=table_name)\n    except self.glue.exceptions.EntityNotFoundException as e:\n        raise NoSuchTableError(f\"Table does not exist: {database_name}.{table_name}\") from e\n</code></pre>"},{"location":"reference/pyiceberg/catalog/glue/#pyiceberg.catalog.glue.GlueCatalog.list_namespaces","title":"<code>list_namespaces(namespace=())</code>","text":"<p>List namespaces from the given namespace. If not given, list top-level namespaces from the catalog.</p> <p>Returns:</p> Type Description <code>List[Identifier]</code> <p>List[Identifier]: a List of namespace identifiers.</p> Source code in <code>pyiceberg/catalog/glue.py</code> <pre><code>def list_namespaces(self, namespace: Union[str, Identifier] = ()) -&gt; List[Identifier]:\n    \"\"\"List namespaces from the given namespace. If not given, list top-level namespaces from the catalog.\n\n    Returns:\n        List[Identifier]: a List of namespace identifiers.\n    \"\"\"\n    # Hierarchical namespace is not supported. Return an empty list\n    if namespace:\n        return []\n\n    database_list: List[DatabaseTypeDef] = []\n    next_token: Optional[str] = None\n\n    while True:\n        databases_response = self.glue.get_databases() if not next_token else self.glue.get_databases(NextToken=next_token)\n        database_list.extend(databases_response[\"DatabaseList\"])\n        next_token = databases_response.get(\"NextToken\")\n        if not next_token:\n            break\n\n    return [self.identifier_to_tuple(database[\"Name\"]) for database in database_list]\n</code></pre>"},{"location":"reference/pyiceberg/catalog/glue/#pyiceberg.catalog.glue.GlueCatalog.list_tables","title":"<code>list_tables(namespace)</code>","text":"<p>List tables under the given namespace in the catalog (including non-Iceberg tables).</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier to search.</p> required <p>Returns:</p> Type Description <code>List[Identifier]</code> <p>List[Identifier]: list of table identifiers.</p> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist, or the identifier is invalid.</p> Source code in <code>pyiceberg/catalog/glue.py</code> <pre><code>def list_tables(self, namespace: Union[str, Identifier]) -&gt; List[Identifier]:\n    \"\"\"List tables under the given namespace in the catalog (including non-Iceberg tables).\n\n    Args:\n        namespace (str | Identifier): Namespace identifier to search.\n\n    Returns:\n        List[Identifier]: list of table identifiers.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist, or the identifier is invalid.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n    table_list: List[TableTypeDef] = []\n    next_token: Optional[str] = None\n    try:\n        while True:\n            table_list_response = (\n                self.glue.get_tables(DatabaseName=database_name)\n                if not next_token\n                else self.glue.get_tables(DatabaseName=database_name, NextToken=next_token)\n            )\n            table_list.extend(table_list_response[\"TableList\"])\n            next_token = table_list_response.get(\"NextToken\")\n            if not next_token:\n                break\n\n    except self.glue.exceptions.EntityNotFoundException as e:\n        raise NoSuchNamespaceError(f\"Database does not exist: {database_name}\") from e\n    return [(database_name, table[\"Name\"]) for table in table_list]\n</code></pre>"},{"location":"reference/pyiceberg/catalog/glue/#pyiceberg.catalog.glue.GlueCatalog.load_namespace_properties","title":"<code>load_namespace_properties(namespace)</code>","text":"<p>Get properties for a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Union[str, Identifier]</code> <p>Namespace identifier.</p> required <p>Returns:</p> Name Type Description <code>Properties</code> <code>Properties</code> <p>Properties for the given namespace.</p> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist, or identifier is invalid.</p> Source code in <code>pyiceberg/catalog/glue.py</code> <pre><code>def load_namespace_properties(self, namespace: Union[str, Identifier]) -&gt; Properties:\n    \"\"\"Get properties for a namespace.\n\n    Args:\n        namespace: Namespace identifier.\n\n    Returns:\n        Properties: Properties for the given namespace.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist, or identifier is invalid.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n    try:\n        database_response = self.glue.get_database(Name=database_name)\n    except self.glue.exceptions.EntityNotFoundException as e:\n        raise NoSuchNamespaceError(f\"Database does not exist: {database_name}\") from e\n    except self.glue.exceptions.InvalidInputException as e:\n        raise NoSuchNamespaceError(f\"Invalid input for namespace {database_name}\") from e\n\n    database = database_response[\"Database\"]\n\n    properties = dict(database.get(\"Parameters\", {}))\n    if \"LocationUri\" in database:\n        properties[\"location\"] = database[\"LocationUri\"]\n    if \"Description\" in database:\n        properties[\"Description\"] = database[\"Description\"]\n\n    return properties\n</code></pre>"},{"location":"reference/pyiceberg/catalog/glue/#pyiceberg.catalog.glue.GlueCatalog.load_table","title":"<code>load_table(identifier)</code>","text":"<p>Load the table's metadata and returns the table instance.</p> <p>You can also use this method to check for table existence using 'try catalog.table() except TableNotFoundError'. Note: This method doesn't scan data stored in the table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier.</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the table instance with its metadata.</p> <p>Raises:</p> Type Description <code>NoSuchTableError</code> <p>If a table with the name does not exist, or the identifier is invalid.</p> Source code in <code>pyiceberg/catalog/glue.py</code> <pre><code>def load_table(self, identifier: Union[str, Identifier]) -&gt; Table:\n    \"\"\"Load the table's metadata and returns the table instance.\n\n    You can also use this method to check for table existence using 'try catalog.table() except TableNotFoundError'.\n    Note: This method doesn't scan data stored in the table.\n\n    Args:\n        identifier: Table identifier.\n\n    Returns:\n        Table: the table instance with its metadata.\n\n    Raises:\n        NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n    \"\"\"\n    identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n    database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n\n    return self._convert_glue_to_iceberg(self._get_glue_table(database_name=database_name, table_name=table_name))\n</code></pre>"},{"location":"reference/pyiceberg/catalog/glue/#pyiceberg.catalog.glue.GlueCatalog.register_table","title":"<code>register_table(identifier, metadata_location)</code>","text":"<p>Register a new table using existing metadata.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier for the table</p> required <code>metadata_location</code> <code>str</code> <p>The location to the metadata</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>The newly registered table</p> <p>Raises:</p> Type Description <code>TableAlreadyExistsError</code> <p>If the table already exists</p> Source code in <code>pyiceberg/catalog/glue.py</code> <pre><code>def register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n    \"\"\"Register a new table using existing metadata.\n\n    Args:\n        identifier Union[str, Identifier]: Table identifier for the table\n        metadata_location str: The location to the metadata\n\n    Returns:\n        Table: The newly registered table\n\n    Raises:\n        TableAlreadyExistsError: If the table already exists\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pyiceberg/catalog/glue/#pyiceberg.catalog.glue.GlueCatalog.rename_table","title":"<code>rename_table(from_identifier, to_identifier)</code>","text":"<p>Rename a fully classified table name.</p> <p>This method can only rename Iceberg tables in AWS Glue.</p> <p>Parameters:</p> Name Type Description Default <code>from_identifier</code> <code>Union[str, Identifier]</code> <p>Existing table identifier.</p> required <code>to_identifier</code> <code>Union[str, Identifier]</code> <p>New table identifier.</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the updated table instance with its metadata.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When from table identifier is invalid.</p> <code>NoSuchTableError</code> <p>When a table with the name does not exist.</p> <code>NoSuchIcebergTableError</code> <p>When from table is not a valid iceberg table.</p> <code>NoSuchPropertyException</code> <p>When from table miss some required properties.</p> <code>NoSuchNamespaceError</code> <p>When the destination namespace doesn't exist.</p> Source code in <code>pyiceberg/catalog/glue.py</code> <pre><code>def rename_table(self, from_identifier: Union[str, Identifier], to_identifier: Union[str, Identifier]) -&gt; Table:\n    \"\"\"Rename a fully classified table name.\n\n    This method can only rename Iceberg tables in AWS Glue.\n\n    Args:\n        from_identifier: Existing table identifier.\n        to_identifier: New table identifier.\n\n    Returns:\n        Table: the updated table instance with its metadata.\n\n    Raises:\n        ValueError: When from table identifier is invalid.\n        NoSuchTableError: When a table with the name does not exist.\n        NoSuchIcebergTableError: When from table is not a valid iceberg table.\n        NoSuchPropertyException: When from table miss some required properties.\n        NoSuchNamespaceError: When the destination namespace doesn't exist.\n    \"\"\"\n    from_identifier_tuple = self.identifier_to_tuple_without_catalog(from_identifier)\n    from_database_name, from_table_name = self.identifier_to_database_and_table(from_identifier_tuple, NoSuchTableError)\n    to_database_name, to_table_name = self.identifier_to_database_and_table(to_identifier)\n    try:\n        get_table_response = self.glue.get_table(DatabaseName=from_database_name, Name=from_table_name)\n    except self.glue.exceptions.EntityNotFoundException as e:\n        raise NoSuchTableError(f\"Table does not exist: {from_database_name}.{from_table_name}\") from e\n\n    glue_table = get_table_response[\"Table\"]\n\n    try:\n        # verify that from_identifier is a valid iceberg table\n        self._convert_glue_to_iceberg(glue_table=glue_table)\n    except NoSuchPropertyException as e:\n        raise NoSuchPropertyException(\n            f\"Failed to rename table {from_database_name}.{from_table_name} since it is missing required properties\"\n        ) from e\n    except NoSuchIcebergTableError as e:\n        raise NoSuchIcebergTableError(\n            f\"Failed to rename table {from_database_name}.{from_table_name} since it is not a valid iceberg table\"\n        ) from e\n\n    rename_table_input = _construct_rename_table_input(to_table_name=to_table_name, glue_table=glue_table)\n    self._create_glue_table(database_name=to_database_name, table_name=to_table_name, table_input=rename_table_input)\n\n    try:\n        self.drop_table(from_identifier)\n    except Exception as e:\n        log_message = f\"Failed to drop old table {from_database_name}.{from_table_name}. \"\n\n        try:\n            self.drop_table(to_identifier)\n            log_message += f\"Rolled back table creation for {to_database_name}.{to_table_name}.\"\n        except NoSuchTableError:\n            log_message += (\n                f\"Failed to roll back table creation for {to_database_name}.{to_table_name}. \" f\"Please clean up manually\"\n            )\n\n        raise ValueError(log_message) from e\n\n    return self.load_table(to_identifier)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/glue/#pyiceberg.catalog.glue.GlueCatalog.update_namespace_properties","title":"<code>update_namespace_properties(namespace, removals=None, updates=EMPTY_DICT)</code>","text":"<p>Remove provided property keys and updates properties for a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Union[str, Identifier]</code> <p>Namespace identifier.</p> required <code>removals</code> <code>Optional[Set[str]]</code> <p>Set of property keys that need to be removed. Optional Argument.</p> <code>None</code> <code>updates</code> <code>Properties</code> <p>Properties to be updated for the given namespace.</p> <code>EMPTY_DICT</code> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist\uff0c or identifier is invalid.</p> <code>ValueError</code> <p>If removals and updates have overlapping keys.</p> Source code in <code>pyiceberg/catalog/glue.py</code> <pre><code>def update_namespace_properties(\n    self, namespace: Union[str, Identifier], removals: Optional[Set[str]] = None, updates: Properties = EMPTY_DICT\n) -&gt; PropertiesUpdateSummary:\n    \"\"\"Remove provided property keys and updates properties for a namespace.\n\n    Args:\n        namespace: Namespace identifier.\n        removals: Set of property keys that need to be removed. Optional Argument.\n        updates: Properties to be updated for the given namespace.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist\uff0c or identifier is invalid.\n        ValueError: If removals and updates have overlapping keys.\n    \"\"\"\n    current_properties = self.load_namespace_properties(namespace=namespace)\n    properties_update_summary, updated_properties = self._get_updated_props_and_update_summary(\n        current_properties=current_properties, removals=removals, updates=updates\n    )\n\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n    self.glue.update_database(Name=database_name, DatabaseInput=_construct_database_input(database_name, updated_properties))\n\n    return properties_update_summary\n</code></pre>"},{"location":"reference/pyiceberg/catalog/hive/","title":"hive","text":""},{"location":"reference/pyiceberg/catalog/hive/#pyiceberg.catalog.hive.HiveCatalog","title":"<code>HiveCatalog</code>","text":"<p>             Bases: <code>Catalog</code></p> Source code in <code>pyiceberg/catalog/hive.py</code> <pre><code>class HiveCatalog(Catalog):\n    _client: _HiveClient\n\n    def __init__(self, name: str, **properties: str):\n        super().__init__(name, **properties)\n        self._client = _HiveClient(properties[\"uri\"])\n\n    def _convert_hive_into_iceberg(self, table: HiveTable, io: FileIO) -&gt; Table:\n        properties: Dict[str, str] = table.parameters\n        if TABLE_TYPE not in properties:\n            raise NoSuchTableError(f\"Property table_type missing, could not determine type: {table.dbName}.{table.tableName}\")\n\n        table_type = properties[TABLE_TYPE]\n        if table_type.lower() != ICEBERG:\n            raise NoSuchIcebergTableError(\n                f\"Property table_type is {table_type}, expected {ICEBERG}: {table.dbName}.{table.tableName}\"\n            )\n\n        if prop_metadata_location := properties.get(METADATA_LOCATION):\n            metadata_location = prop_metadata_location\n        else:\n            raise NoSuchTableError(f\"Table property {METADATA_LOCATION} is missing\")\n\n        file = io.new_input(metadata_location)\n        metadata = FromInputFile.table_metadata(file)\n        return Table(\n            identifier=(self.name, table.dbName, table.tableName),\n            metadata=metadata,\n            metadata_location=metadata_location,\n            io=self._load_file_io(metadata.properties, metadata_location),\n            catalog=self,\n        )\n\n    def create_table(\n        self,\n        identifier: Union[str, Identifier],\n        schema: Union[Schema, \"pa.Schema\"],\n        location: Optional[str] = None,\n        partition_spec: PartitionSpec = UNPARTITIONED_PARTITION_SPEC,\n        sort_order: SortOrder = UNSORTED_SORT_ORDER,\n        properties: Properties = EMPTY_DICT,\n    ) -&gt; Table:\n        \"\"\"Create a table.\n\n        Args:\n            identifier: Table identifier.\n            schema: Table's schema.\n            location: Location for the table. Optional Argument.\n            partition_spec: PartitionSpec for the table.\n            sort_order: SortOrder for the table.\n            properties: Table properties that can be a string based dictionary.\n\n        Returns:\n            Table: the created table instance.\n\n        Raises:\n            AlreadyExistsError: If a table with the name already exists.\n            ValueError: If the identifier is invalid.\n        \"\"\"\n        schema: Schema = self._convert_schema_if_needed(schema)  # type: ignore\n\n        properties = {**DEFAULT_PROPERTIES, **properties}\n        database_name, table_name = self.identifier_to_database_and_table(identifier)\n        current_time_millis = int(time.time() * 1000)\n\n        location = self._resolve_table_location(location, database_name, table_name)\n\n        metadata_location = self._get_metadata_location(location=location)\n        metadata = new_table_metadata(\n            location=location,\n            schema=schema,\n            partition_spec=partition_spec,\n            sort_order=sort_order,\n            properties=properties,\n        )\n        io = load_file_io({**self.properties, **properties}, location=location)\n        self._write_metadata(metadata, io, metadata_location)\n\n        tbl = HiveTable(\n            dbName=database_name,\n            tableName=table_name,\n            owner=properties[OWNER] if properties and OWNER in properties else getpass.getuser(),\n            createTime=current_time_millis // 1000,\n            lastAccessTime=current_time_millis // 1000,\n            sd=_construct_hive_storage_descriptor(schema, location),\n            tableType=EXTERNAL_TABLE,\n            parameters=_construct_parameters(metadata_location),\n        )\n        try:\n            with self._client as open_client:\n                open_client.create_table(tbl)\n                hive_table = open_client.get_table(dbname=database_name, tbl_name=table_name)\n        except AlreadyExistsException as e:\n            raise TableAlreadyExistsError(f\"Table {database_name}.{table_name} already exists\") from e\n\n        return self._convert_hive_into_iceberg(hive_table, io)\n\n    def register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n        \"\"\"Register a new table using existing metadata.\n\n        Args:\n            identifier Union[str, Identifier]: Table identifier for the table\n            metadata_location str: The location to the metadata\n\n        Returns:\n            Table: The newly registered table\n\n        Raises:\n            TableAlreadyExistsError: If the table already exists\n        \"\"\"\n        raise NotImplementedError\n\n    def _create_lock_request(self, database_name: str, table_name: str) -&gt; LockRequest:\n        lock_component: LockComponent = LockComponent(\n            level=LockLevel.TABLE, type=LockType.EXCLUSIVE, dbname=database_name, tablename=table_name, isTransactional=True\n        )\n\n        lock_request: LockRequest = LockRequest(component=[lock_component], user=getpass.getuser(), hostname=socket.gethostname())\n\n        return lock_request\n\n    def _commit_table(self, table_request: CommitTableRequest) -&gt; CommitTableResponse:\n        \"\"\"Update the table.\n\n        Args:\n            table_request (CommitTableRequest): The table requests to be carried out.\n\n        Returns:\n            CommitTableResponse: The updated metadata.\n\n        Raises:\n            NoSuchTableError: If a table with the given identifier does not exist.\n        \"\"\"\n        identifier_tuple = self.identifier_to_tuple_without_catalog(\n            tuple(table_request.identifier.namespace.root + [table_request.identifier.name])\n        )\n        current_table = self.load_table(identifier_tuple)\n        database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n        base_metadata = current_table.metadata\n        for requirement in table_request.requirements:\n            requirement.validate(base_metadata)\n\n        updated_metadata = update_table_metadata(base_metadata, table_request.updates)\n        if updated_metadata == base_metadata:\n            # no changes, do nothing\n            return CommitTableResponse(metadata=base_metadata, metadata_location=current_table.metadata_location)\n\n        # write new metadata\n        new_metadata_version = self._parse_metadata_version(current_table.metadata_location) + 1\n        new_metadata_location = self._get_metadata_location(current_table.metadata.location, new_metadata_version)\n        self._write_metadata(updated_metadata, current_table.io, new_metadata_location)\n\n        # commit to hive\n        # https://github.com/apache/hive/blob/master/standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift#L1232\n        with self._client as open_client:\n            lock: LockResponse = open_client.lock(self._create_lock_request(database_name, table_name))\n\n            try:\n                if lock.state != LockState.ACQUIRED:\n                    raise CommitFailedException(f\"Failed to acquire lock for {table_request.identifier}, state: {lock.state}\")\n\n                tbl = open_client.get_table(dbname=database_name, tbl_name=table_name)\n                tbl.parameters = _construct_parameters(\n                    metadata_location=new_metadata_location, previous_metadata_location=current_table.metadata_location\n                )\n                open_client.alter_table(dbname=database_name, tbl_name=table_name, new_tbl=tbl)\n            except NoSuchObjectException as e:\n                raise NoSuchTableError(f\"Table does not exist: {table_name}\") from e\n            finally:\n                open_client.unlock(UnlockRequest(lockid=lock.lockid))\n\n        return CommitTableResponse(metadata=updated_metadata, metadata_location=new_metadata_location)\n\n    def load_table(self, identifier: Union[str, Identifier]) -&gt; Table:\n        \"\"\"Load the table's metadata and return the table instance.\n\n        You can also use this method to check for table existence using 'try catalog.table() except TableNotFoundError'.\n        Note: This method doesn't scan data stored in the table.\n\n        Args:\n            identifier: Table identifier.\n\n        Returns:\n            Table: the table instance with its metadata.\n\n        Raises:\n            NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n        \"\"\"\n        identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n        database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n        try:\n            with self._client as open_client:\n                hive_table = open_client.get_table(dbname=database_name, tbl_name=table_name)\n        except NoSuchObjectException as e:\n            raise NoSuchTableError(f\"Table does not exists: {table_name}\") from e\n\n        io = load_file_io({**self.properties, **hive_table.parameters}, hive_table.sd.location)\n        return self._convert_hive_into_iceberg(hive_table, io)\n\n    def drop_table(self, identifier: Union[str, Identifier]) -&gt; None:\n        \"\"\"Drop a table.\n\n        Args:\n            identifier: Table identifier.\n\n        Raises:\n            NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n        \"\"\"\n        identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n        database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n        try:\n            with self._client as open_client:\n                open_client.drop_table(dbname=database_name, name=table_name, deleteData=False)\n        except NoSuchObjectException as e:\n            # When the namespace doesn't exist, it throws the same error\n            raise NoSuchTableError(f\"Table does not exists: {table_name}\") from e\n\n    def purge_table(self, identifier: Union[str, Identifier]) -&gt; None:\n        # This requires to traverse the reachability set, and drop all the data files.\n        raise NotImplementedError(\"Not yet implemented\")\n\n    def rename_table(self, from_identifier: Union[str, Identifier], to_identifier: Union[str, Identifier]) -&gt; Table:\n        \"\"\"Rename a fully classified table name.\n\n        Args:\n            from_identifier: Existing table identifier.\n            to_identifier: New table identifier.\n\n        Returns:\n            Table: the updated table instance with its metadata.\n\n        Raises:\n            ValueError: When from table identifier is invalid.\n            NoSuchTableError: When a table with the name does not exist.\n            NoSuchNamespaceError: When the destination namespace doesn't exist.\n        \"\"\"\n        from_identifier_tuple = self.identifier_to_tuple_without_catalog(from_identifier)\n        from_database_name, from_table_name = self.identifier_to_database_and_table(from_identifier_tuple, NoSuchTableError)\n        to_database_name, to_table_name = self.identifier_to_database_and_table(to_identifier)\n        try:\n            with self._client as open_client:\n                tbl = open_client.get_table(dbname=from_database_name, tbl_name=from_table_name)\n                tbl.dbName = to_database_name\n                tbl.tableName = to_table_name\n                open_client.alter_table(dbname=from_database_name, tbl_name=from_table_name, new_tbl=tbl)\n        except NoSuchObjectException as e:\n            raise NoSuchTableError(f\"Table does not exist: {from_table_name}\") from e\n        except InvalidOperationException as e:\n            raise NoSuchNamespaceError(f\"Database does not exists: {to_database_name}\") from e\n        return self.load_table(to_identifier)\n\n    def create_namespace(self, namespace: Union[str, Identifier], properties: Properties = EMPTY_DICT) -&gt; None:\n        \"\"\"Create a namespace in the catalog.\n\n        Args:\n            namespace: Namespace identifier.\n            properties: A string dictionary of properties for the given namespace.\n\n        Raises:\n            ValueError: If the identifier is invalid.\n            AlreadyExistsError: If a namespace with the given name already exists.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace)\n        hive_database = HiveDatabase(name=database_name, parameters=properties)\n\n        try:\n            with self._client as open_client:\n                open_client.create_database(_annotate_namespace(hive_database, properties))\n        except AlreadyExistsException as e:\n            raise NamespaceAlreadyExistsError(f\"Database {database_name} already exists\") from e\n\n    def drop_namespace(self, namespace: Union[str, Identifier]) -&gt; None:\n        \"\"\"Drop a namespace.\n\n        Args:\n            namespace: Namespace identifier.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist, or the identifier is invalid.\n            NamespaceNotEmptyError: If the namespace is not empty.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n        try:\n            with self._client as open_client:\n                open_client.drop_database(database_name, deleteData=False, cascade=False)\n        except InvalidOperationException as e:\n            raise NamespaceNotEmptyError(f\"Database {database_name} is not empty\") from e\n        except MetaException as e:\n            raise NoSuchNamespaceError(f\"Database does not exists: {database_name}\") from e\n\n    def list_tables(self, namespace: Union[str, Identifier]) -&gt; List[Identifier]:\n        \"\"\"List tables under the given namespace in the catalog (including non-Iceberg tables).\n\n        When the database doesn't exist, it will just return an empty list.\n\n        Args:\n            namespace: Database to list.\n\n        Returns:\n            List[Identifier]: list of table identifiers.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist, or the identifier is invalid.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n        with self._client as open_client:\n            return [(database_name, table_name) for table_name in open_client.get_all_tables(db_name=database_name)]\n\n    def list_namespaces(self, namespace: Union[str, Identifier] = ()) -&gt; List[Identifier]:\n        \"\"\"List namespaces from the given namespace. If not given, list top-level namespaces from the catalog.\n\n        Returns:\n            List[Identifier]: a List of namespace identifiers.\n        \"\"\"\n        # Hierarchical namespace is not supported. Return an empty list\n        if namespace:\n            return []\n\n        with self._client as open_client:\n            return list(map(self.identifier_to_tuple, open_client.get_all_databases()))\n\n    def load_namespace_properties(self, namespace: Union[str, Identifier]) -&gt; Properties:\n        \"\"\"Get properties for a namespace.\n\n        Args:\n            namespace: Namespace identifier.\n\n        Returns:\n            Properties: Properties for the given namespace.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist, or identifier is invalid.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n        try:\n            with self._client as open_client:\n                database = open_client.get_database(name=database_name)\n                properties = database.parameters\n                properties[LOCATION] = database.locationUri\n                if comment := database.description:\n                    properties[COMMENT] = comment\n                return properties\n        except NoSuchObjectException as e:\n            raise NoSuchNamespaceError(f\"Database does not exists: {database_name}\") from e\n\n    def update_namespace_properties(\n        self, namespace: Union[str, Identifier], removals: Optional[Set[str]] = None, updates: Properties = EMPTY_DICT\n    ) -&gt; PropertiesUpdateSummary:\n        \"\"\"Remove provided property keys and update properties for a namespace.\n\n        Args:\n            namespace: Namespace identifier.\n            removals: Set of property keys that need to be removed. Optional Argument.\n            updates: Properties to be updated for the given namespace.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist\n            ValueError: If removals and updates have overlapping keys.\n        \"\"\"\n        self._check_for_overlap(updates=updates, removals=removals)\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n        with self._client as open_client:\n            try:\n                database = open_client.get_database(database_name)\n                parameters = database.parameters\n            except NoSuchObjectException as e:\n                raise NoSuchNamespaceError(f\"Database does not exists: {database_name}\") from e\n\n            removed: Set[str] = set()\n            updated: Set[str] = set()\n\n            if removals:\n                for key in removals:\n                    if key in parameters:\n                        parameters[key] = None\n                        removed.add(key)\n            if updates:\n                for key, value in updates.items():\n                    parameters[key] = value\n                    updated.add(key)\n\n            open_client.alter_database(database_name, _annotate_namespace(database, parameters))\n\n        expected_to_change = (removals or set()).difference(removed)\n\n        return PropertiesUpdateSummary(removed=list(removed or []), updated=list(updated or []), missing=list(expected_to_change))\n</code></pre>"},{"location":"reference/pyiceberg/catalog/hive/#pyiceberg.catalog.hive.HiveCatalog.create_namespace","title":"<code>create_namespace(namespace, properties=EMPTY_DICT)</code>","text":"<p>Create a namespace in the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Union[str, Identifier]</code> <p>Namespace identifier.</p> required <code>properties</code> <code>Properties</code> <p>A string dictionary of properties for the given namespace.</p> <code>EMPTY_DICT</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the identifier is invalid.</p> <code>AlreadyExistsError</code> <p>If a namespace with the given name already exists.</p> Source code in <code>pyiceberg/catalog/hive.py</code> <pre><code>def create_namespace(self, namespace: Union[str, Identifier], properties: Properties = EMPTY_DICT) -&gt; None:\n    \"\"\"Create a namespace in the catalog.\n\n    Args:\n        namespace: Namespace identifier.\n        properties: A string dictionary of properties for the given namespace.\n\n    Raises:\n        ValueError: If the identifier is invalid.\n        AlreadyExistsError: If a namespace with the given name already exists.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace)\n    hive_database = HiveDatabase(name=database_name, parameters=properties)\n\n    try:\n        with self._client as open_client:\n            open_client.create_database(_annotate_namespace(hive_database, properties))\n    except AlreadyExistsException as e:\n        raise NamespaceAlreadyExistsError(f\"Database {database_name} already exists\") from e\n</code></pre>"},{"location":"reference/pyiceberg/catalog/hive/#pyiceberg.catalog.hive.HiveCatalog.create_table","title":"<code>create_table(identifier, schema, location=None, partition_spec=UNPARTITIONED_PARTITION_SPEC, sort_order=UNSORTED_SORT_ORDER, properties=EMPTY_DICT)</code>","text":"<p>Create a table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier.</p> required <code>schema</code> <code>Union[Schema, Schema]</code> <p>Table's schema.</p> required <code>location</code> <code>Optional[str]</code> <p>Location for the table. Optional Argument.</p> <code>None</code> <code>partition_spec</code> <code>PartitionSpec</code> <p>PartitionSpec for the table.</p> <code>UNPARTITIONED_PARTITION_SPEC</code> <code>sort_order</code> <code>SortOrder</code> <p>SortOrder for the table.</p> <code>UNSORTED_SORT_ORDER</code> <code>properties</code> <code>Properties</code> <p>Table properties that can be a string based dictionary.</p> <code>EMPTY_DICT</code> <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the created table instance.</p> <p>Raises:</p> Type Description <code>AlreadyExistsError</code> <p>If a table with the name already exists.</p> <code>ValueError</code> <p>If the identifier is invalid.</p> Source code in <code>pyiceberg/catalog/hive.py</code> <pre><code>def create_table(\n    self,\n    identifier: Union[str, Identifier],\n    schema: Union[Schema, \"pa.Schema\"],\n    location: Optional[str] = None,\n    partition_spec: PartitionSpec = UNPARTITIONED_PARTITION_SPEC,\n    sort_order: SortOrder = UNSORTED_SORT_ORDER,\n    properties: Properties = EMPTY_DICT,\n) -&gt; Table:\n    \"\"\"Create a table.\n\n    Args:\n        identifier: Table identifier.\n        schema: Table's schema.\n        location: Location for the table. Optional Argument.\n        partition_spec: PartitionSpec for the table.\n        sort_order: SortOrder for the table.\n        properties: Table properties that can be a string based dictionary.\n\n    Returns:\n        Table: the created table instance.\n\n    Raises:\n        AlreadyExistsError: If a table with the name already exists.\n        ValueError: If the identifier is invalid.\n    \"\"\"\n    schema: Schema = self._convert_schema_if_needed(schema)  # type: ignore\n\n    properties = {**DEFAULT_PROPERTIES, **properties}\n    database_name, table_name = self.identifier_to_database_and_table(identifier)\n    current_time_millis = int(time.time() * 1000)\n\n    location = self._resolve_table_location(location, database_name, table_name)\n\n    metadata_location = self._get_metadata_location(location=location)\n    metadata = new_table_metadata(\n        location=location,\n        schema=schema,\n        partition_spec=partition_spec,\n        sort_order=sort_order,\n        properties=properties,\n    )\n    io = load_file_io({**self.properties, **properties}, location=location)\n    self._write_metadata(metadata, io, metadata_location)\n\n    tbl = HiveTable(\n        dbName=database_name,\n        tableName=table_name,\n        owner=properties[OWNER] if properties and OWNER in properties else getpass.getuser(),\n        createTime=current_time_millis // 1000,\n        lastAccessTime=current_time_millis // 1000,\n        sd=_construct_hive_storage_descriptor(schema, location),\n        tableType=EXTERNAL_TABLE,\n        parameters=_construct_parameters(metadata_location),\n    )\n    try:\n        with self._client as open_client:\n            open_client.create_table(tbl)\n            hive_table = open_client.get_table(dbname=database_name, tbl_name=table_name)\n    except AlreadyExistsException as e:\n        raise TableAlreadyExistsError(f\"Table {database_name}.{table_name} already exists\") from e\n\n    return self._convert_hive_into_iceberg(hive_table, io)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/hive/#pyiceberg.catalog.hive.HiveCatalog.drop_namespace","title":"<code>drop_namespace(namespace)</code>","text":"<p>Drop a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Union[str, Identifier]</code> <p>Namespace identifier.</p> required <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist, or the identifier is invalid.</p> <code>NamespaceNotEmptyError</code> <p>If the namespace is not empty.</p> Source code in <code>pyiceberg/catalog/hive.py</code> <pre><code>def drop_namespace(self, namespace: Union[str, Identifier]) -&gt; None:\n    \"\"\"Drop a namespace.\n\n    Args:\n        namespace: Namespace identifier.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist, or the identifier is invalid.\n        NamespaceNotEmptyError: If the namespace is not empty.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n    try:\n        with self._client as open_client:\n            open_client.drop_database(database_name, deleteData=False, cascade=False)\n    except InvalidOperationException as e:\n        raise NamespaceNotEmptyError(f\"Database {database_name} is not empty\") from e\n    except MetaException as e:\n        raise NoSuchNamespaceError(f\"Database does not exists: {database_name}\") from e\n</code></pre>"},{"location":"reference/pyiceberg/catalog/hive/#pyiceberg.catalog.hive.HiveCatalog.drop_table","title":"<code>drop_table(identifier)</code>","text":"<p>Drop a table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier.</p> required <p>Raises:</p> Type Description <code>NoSuchTableError</code> <p>If a table with the name does not exist, or the identifier is invalid.</p> Source code in <code>pyiceberg/catalog/hive.py</code> <pre><code>def drop_table(self, identifier: Union[str, Identifier]) -&gt; None:\n    \"\"\"Drop a table.\n\n    Args:\n        identifier: Table identifier.\n\n    Raises:\n        NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n    \"\"\"\n    identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n    database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n    try:\n        with self._client as open_client:\n            open_client.drop_table(dbname=database_name, name=table_name, deleteData=False)\n    except NoSuchObjectException as e:\n        # When the namespace doesn't exist, it throws the same error\n        raise NoSuchTableError(f\"Table does not exists: {table_name}\") from e\n</code></pre>"},{"location":"reference/pyiceberg/catalog/hive/#pyiceberg.catalog.hive.HiveCatalog.list_namespaces","title":"<code>list_namespaces(namespace=())</code>","text":"<p>List namespaces from the given namespace. If not given, list top-level namespaces from the catalog.</p> <p>Returns:</p> Type Description <code>List[Identifier]</code> <p>List[Identifier]: a List of namespace identifiers.</p> Source code in <code>pyiceberg/catalog/hive.py</code> <pre><code>def list_namespaces(self, namespace: Union[str, Identifier] = ()) -&gt; List[Identifier]:\n    \"\"\"List namespaces from the given namespace. If not given, list top-level namespaces from the catalog.\n\n    Returns:\n        List[Identifier]: a List of namespace identifiers.\n    \"\"\"\n    # Hierarchical namespace is not supported. Return an empty list\n    if namespace:\n        return []\n\n    with self._client as open_client:\n        return list(map(self.identifier_to_tuple, open_client.get_all_databases()))\n</code></pre>"},{"location":"reference/pyiceberg/catalog/hive/#pyiceberg.catalog.hive.HiveCatalog.list_tables","title":"<code>list_tables(namespace)</code>","text":"<p>List tables under the given namespace in the catalog (including non-Iceberg tables).</p> <p>When the database doesn't exist, it will just return an empty list.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Union[str, Identifier]</code> <p>Database to list.</p> required <p>Returns:</p> Type Description <code>List[Identifier]</code> <p>List[Identifier]: list of table identifiers.</p> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist, or the identifier is invalid.</p> Source code in <code>pyiceberg/catalog/hive.py</code> <pre><code>def list_tables(self, namespace: Union[str, Identifier]) -&gt; List[Identifier]:\n    \"\"\"List tables under the given namespace in the catalog (including non-Iceberg tables).\n\n    When the database doesn't exist, it will just return an empty list.\n\n    Args:\n        namespace: Database to list.\n\n    Returns:\n        List[Identifier]: list of table identifiers.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist, or the identifier is invalid.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n    with self._client as open_client:\n        return [(database_name, table_name) for table_name in open_client.get_all_tables(db_name=database_name)]\n</code></pre>"},{"location":"reference/pyiceberg/catalog/hive/#pyiceberg.catalog.hive.HiveCatalog.load_namespace_properties","title":"<code>load_namespace_properties(namespace)</code>","text":"<p>Get properties for a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Union[str, Identifier]</code> <p>Namespace identifier.</p> required <p>Returns:</p> Name Type Description <code>Properties</code> <code>Properties</code> <p>Properties for the given namespace.</p> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist, or identifier is invalid.</p> Source code in <code>pyiceberg/catalog/hive.py</code> <pre><code>def load_namespace_properties(self, namespace: Union[str, Identifier]) -&gt; Properties:\n    \"\"\"Get properties for a namespace.\n\n    Args:\n        namespace: Namespace identifier.\n\n    Returns:\n        Properties: Properties for the given namespace.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist, or identifier is invalid.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n    try:\n        with self._client as open_client:\n            database = open_client.get_database(name=database_name)\n            properties = database.parameters\n            properties[LOCATION] = database.locationUri\n            if comment := database.description:\n                properties[COMMENT] = comment\n            return properties\n    except NoSuchObjectException as e:\n        raise NoSuchNamespaceError(f\"Database does not exists: {database_name}\") from e\n</code></pre>"},{"location":"reference/pyiceberg/catalog/hive/#pyiceberg.catalog.hive.HiveCatalog.load_table","title":"<code>load_table(identifier)</code>","text":"<p>Load the table's metadata and return the table instance.</p> <p>You can also use this method to check for table existence using 'try catalog.table() except TableNotFoundError'. Note: This method doesn't scan data stored in the table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier.</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the table instance with its metadata.</p> <p>Raises:</p> Type Description <code>NoSuchTableError</code> <p>If a table with the name does not exist, or the identifier is invalid.</p> Source code in <code>pyiceberg/catalog/hive.py</code> <pre><code>def load_table(self, identifier: Union[str, Identifier]) -&gt; Table:\n    \"\"\"Load the table's metadata and return the table instance.\n\n    You can also use this method to check for table existence using 'try catalog.table() except TableNotFoundError'.\n    Note: This method doesn't scan data stored in the table.\n\n    Args:\n        identifier: Table identifier.\n\n    Returns:\n        Table: the table instance with its metadata.\n\n    Raises:\n        NoSuchTableError: If a table with the name does not exist, or the identifier is invalid.\n    \"\"\"\n    identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n    database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n    try:\n        with self._client as open_client:\n            hive_table = open_client.get_table(dbname=database_name, tbl_name=table_name)\n    except NoSuchObjectException as e:\n        raise NoSuchTableError(f\"Table does not exists: {table_name}\") from e\n\n    io = load_file_io({**self.properties, **hive_table.parameters}, hive_table.sd.location)\n    return self._convert_hive_into_iceberg(hive_table, io)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/hive/#pyiceberg.catalog.hive.HiveCatalog.register_table","title":"<code>register_table(identifier, metadata_location)</code>","text":"<p>Register a new table using existing metadata.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier for the table</p> required <code>metadata_location</code> <code>str</code> <p>The location to the metadata</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>The newly registered table</p> <p>Raises:</p> Type Description <code>TableAlreadyExistsError</code> <p>If the table already exists</p> Source code in <code>pyiceberg/catalog/hive.py</code> <pre><code>def register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n    \"\"\"Register a new table using existing metadata.\n\n    Args:\n        identifier Union[str, Identifier]: Table identifier for the table\n        metadata_location str: The location to the metadata\n\n    Returns:\n        Table: The newly registered table\n\n    Raises:\n        TableAlreadyExistsError: If the table already exists\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pyiceberg/catalog/hive/#pyiceberg.catalog.hive.HiveCatalog.rename_table","title":"<code>rename_table(from_identifier, to_identifier)</code>","text":"<p>Rename a fully classified table name.</p> <p>Parameters:</p> Name Type Description Default <code>from_identifier</code> <code>Union[str, Identifier]</code> <p>Existing table identifier.</p> required <code>to_identifier</code> <code>Union[str, Identifier]</code> <p>New table identifier.</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the updated table instance with its metadata.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When from table identifier is invalid.</p> <code>NoSuchTableError</code> <p>When a table with the name does not exist.</p> <code>NoSuchNamespaceError</code> <p>When the destination namespace doesn't exist.</p> Source code in <code>pyiceberg/catalog/hive.py</code> <pre><code>def rename_table(self, from_identifier: Union[str, Identifier], to_identifier: Union[str, Identifier]) -&gt; Table:\n    \"\"\"Rename a fully classified table name.\n\n    Args:\n        from_identifier: Existing table identifier.\n        to_identifier: New table identifier.\n\n    Returns:\n        Table: the updated table instance with its metadata.\n\n    Raises:\n        ValueError: When from table identifier is invalid.\n        NoSuchTableError: When a table with the name does not exist.\n        NoSuchNamespaceError: When the destination namespace doesn't exist.\n    \"\"\"\n    from_identifier_tuple = self.identifier_to_tuple_without_catalog(from_identifier)\n    from_database_name, from_table_name = self.identifier_to_database_and_table(from_identifier_tuple, NoSuchTableError)\n    to_database_name, to_table_name = self.identifier_to_database_and_table(to_identifier)\n    try:\n        with self._client as open_client:\n            tbl = open_client.get_table(dbname=from_database_name, tbl_name=from_table_name)\n            tbl.dbName = to_database_name\n            tbl.tableName = to_table_name\n            open_client.alter_table(dbname=from_database_name, tbl_name=from_table_name, new_tbl=tbl)\n    except NoSuchObjectException as e:\n        raise NoSuchTableError(f\"Table does not exist: {from_table_name}\") from e\n    except InvalidOperationException as e:\n        raise NoSuchNamespaceError(f\"Database does not exists: {to_database_name}\") from e\n    return self.load_table(to_identifier)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/hive/#pyiceberg.catalog.hive.HiveCatalog.update_namespace_properties","title":"<code>update_namespace_properties(namespace, removals=None, updates=EMPTY_DICT)</code>","text":"<p>Remove provided property keys and update properties for a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>Union[str, Identifier]</code> <p>Namespace identifier.</p> required <code>removals</code> <code>Optional[Set[str]]</code> <p>Set of property keys that need to be removed. Optional Argument.</p> <code>None</code> <code>updates</code> <code>Properties</code> <p>Properties to be updated for the given namespace.</p> <code>EMPTY_DICT</code> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist</p> <code>ValueError</code> <p>If removals and updates have overlapping keys.</p> Source code in <code>pyiceberg/catalog/hive.py</code> <pre><code>def update_namespace_properties(\n    self, namespace: Union[str, Identifier], removals: Optional[Set[str]] = None, updates: Properties = EMPTY_DICT\n) -&gt; PropertiesUpdateSummary:\n    \"\"\"Remove provided property keys and update properties for a namespace.\n\n    Args:\n        namespace: Namespace identifier.\n        removals: Set of property keys that need to be removed. Optional Argument.\n        updates: Properties to be updated for the given namespace.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist\n        ValueError: If removals and updates have overlapping keys.\n    \"\"\"\n    self._check_for_overlap(updates=updates, removals=removals)\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n    with self._client as open_client:\n        try:\n            database = open_client.get_database(database_name)\n            parameters = database.parameters\n        except NoSuchObjectException as e:\n            raise NoSuchNamespaceError(f\"Database does not exists: {database_name}\") from e\n\n        removed: Set[str] = set()\n        updated: Set[str] = set()\n\n        if removals:\n            for key in removals:\n                if key in parameters:\n                    parameters[key] = None\n                    removed.add(key)\n        if updates:\n            for key, value in updates.items():\n                parameters[key] = value\n                updated.add(key)\n\n        open_client.alter_database(database_name, _annotate_namespace(database, parameters))\n\n    expected_to_change = (removals or set()).difference(removed)\n\n    return PropertiesUpdateSummary(removed=list(removed or []), updated=list(updated or []), missing=list(expected_to_change))\n</code></pre>"},{"location":"reference/pyiceberg/catalog/noop/","title":"noop","text":""},{"location":"reference/pyiceberg/catalog/noop/#pyiceberg.catalog.noop.NoopCatalog","title":"<code>NoopCatalog</code>","text":"<p>             Bases: <code>Catalog</code></p> Source code in <code>pyiceberg/catalog/noop.py</code> <pre><code>class NoopCatalog(Catalog):\n    def create_table(\n        self,\n        identifier: Union[str, Identifier],\n        schema: Union[Schema, \"pa.Schema\"],\n        location: Optional[str] = None,\n        partition_spec: PartitionSpec = UNPARTITIONED_PARTITION_SPEC,\n        sort_order: SortOrder = UNSORTED_SORT_ORDER,\n        properties: Properties = EMPTY_DICT,\n    ) -&gt; Table:\n        raise NotImplementedError\n\n    def load_table(self, identifier: Union[str, Identifier]) -&gt; Table:\n        raise NotImplementedError\n\n    def register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n        \"\"\"Register a new table using existing metadata.\n\n        Args:\n            identifier Union[str, Identifier]: Table identifier for the table\n            metadata_location str: The location to the metadata\n\n        Returns:\n            Table: The newly registered table\n\n        Raises:\n            TableAlreadyExistsError: If the table already exists\n        \"\"\"\n        raise NotImplementedError\n\n    def drop_table(self, identifier: Union[str, Identifier]) -&gt; None:\n        raise NotImplementedError\n\n    def rename_table(self, from_identifier: Union[str, Identifier], to_identifier: Union[str, Identifier]) -&gt; Table:\n        raise NotImplementedError\n\n    def _commit_table(self, table_request: CommitTableRequest) -&gt; CommitTableResponse:\n        raise NotImplementedError\n\n    def create_namespace(self, namespace: Union[str, Identifier], properties: Properties = EMPTY_DICT) -&gt; None:\n        raise NotImplementedError\n\n    def drop_namespace(self, namespace: Union[str, Identifier]) -&gt; None:\n        raise NotImplementedError\n\n    def list_tables(self, namespace: Union[str, Identifier]) -&gt; List[Identifier]:\n        raise NotImplementedError\n\n    def list_namespaces(self, namespace: Union[str, Identifier] = ()) -&gt; List[Identifier]:\n        raise NotImplementedError\n\n    def load_namespace_properties(self, namespace: Union[str, Identifier]) -&gt; Properties:\n        raise NotImplementedError\n\n    def update_namespace_properties(\n        self, namespace: Union[str, Identifier], removals: Optional[Set[str]] = None, updates: Properties = EMPTY_DICT\n    ) -&gt; PropertiesUpdateSummary:\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pyiceberg/catalog/noop/#pyiceberg.catalog.noop.NoopCatalog.register_table","title":"<code>register_table(identifier, metadata_location)</code>","text":"<p>Register a new table using existing metadata.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier for the table</p> required <code>metadata_location</code> <code>str</code> <p>The location to the metadata</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>The newly registered table</p> <p>Raises:</p> Type Description <code>TableAlreadyExistsError</code> <p>If the table already exists</p> Source code in <code>pyiceberg/catalog/noop.py</code> <pre><code>def register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n    \"\"\"Register a new table using existing metadata.\n\n    Args:\n        identifier Union[str, Identifier]: Table identifier for the table\n        metadata_location str: The location to the metadata\n\n    Returns:\n        Table: The newly registered table\n\n    Raises:\n        TableAlreadyExistsError: If the table already exists\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pyiceberg/catalog/rest/","title":"rest","text":""},{"location":"reference/pyiceberg/catalog/rest/#pyiceberg.catalog.rest.RestCatalog","title":"<code>RestCatalog</code>","text":"<p>             Bases: <code>Catalog</code></p> Source code in <code>pyiceberg/catalog/rest.py</code> <pre><code>class RestCatalog(Catalog):\n    uri: str\n    _session: Session\n\n    def __init__(self, name: str, **properties: str):\n        \"\"\"Rest Catalog.\n\n        You either need to provide a client_id and client_secret, or an already valid token.\n\n        Args:\n            name: Name to identify the catalog.\n            properties: Properties that are passed along to the configuration.\n        \"\"\"\n        super().__init__(name, **properties)\n        self.uri = properties[URI]\n        self._fetch_config()\n        self._session = self._create_session()\n\n    def _create_session(self) -&gt; Session:\n        \"\"\"Create a request session with provided catalog configuration.\"\"\"\n        session = Session()\n\n        # Sets the client side and server side SSL cert verification, if provided as properties.\n        if ssl_config := self.properties.get(SSL):\n            if ssl_ca_bundle := ssl_config.get(CA_BUNDLE):  # type: ignore\n                session.verify = ssl_ca_bundle\n            if ssl_client := ssl_config.get(CLIENT):  # type: ignore\n                if all(k in ssl_client for k in (CERT, KEY)):\n                    session.cert = (ssl_client[CERT], ssl_client[KEY])\n                elif ssl_client_cert := ssl_client.get(CERT):\n                    session.cert = ssl_client_cert\n\n        # If we have credentials, but not a token, we want to fetch a token\n        if TOKEN not in self.properties and CREDENTIAL in self.properties:\n            self.properties[TOKEN] = self._fetch_access_token(session, self.properties[CREDENTIAL])\n\n        # Set Auth token for subsequent calls in the session\n        if token := self.properties.get(TOKEN):\n            session.headers[AUTHORIZATION_HEADER] = f\"{BEARER_PREFIX} {token}\"\n\n        # Set HTTP headers\n        session.headers[\"Content-type\"] = \"application/json\"\n        session.headers[\"X-Client-Version\"] = ICEBERG_REST_SPEC_VERSION\n        session.headers[\"User-Agent\"] = f\"PyIceberg/{__version__}\"\n\n        # Configure SigV4 Request Signing\n        if str(self.properties.get(SIGV4, False)).lower() == \"true\":\n            self._init_sigv4(session)\n\n        return session\n\n    def _check_valid_namespace_identifier(self, identifier: Union[str, Identifier]) -&gt; Identifier:\n        \"\"\"Check if the identifier has at least one element.\"\"\"\n        identifier_tuple = Catalog.identifier_to_tuple(identifier)\n        if len(identifier_tuple) &lt; 1:\n            raise NoSuchNamespaceError(f\"Empty namespace identifier: {identifier}\")\n        return identifier_tuple\n\n    def url(self, endpoint: str, prefixed: bool = True, **kwargs: Any) -&gt; str:\n        \"\"\"Construct the endpoint.\n\n        Args:\n            endpoint: Resource identifier that points to the REST catalog.\n            prefixed: If the prefix return by the config needs to be appended.\n\n        Returns:\n            The base url of the rest catalog.\n        \"\"\"\n        url = self.uri\n        url = url + \"v1/\" if url.endswith(\"/\") else url + \"/v1/\"\n\n        if prefixed:\n            url += self.properties.get(PREFIX, \"\")\n            url = url if url.endswith(\"/\") else url + \"/\"\n\n        return url + endpoint.format(**kwargs)\n\n    @property\n    def auth_url(self) -&gt; str:\n        if url := self.properties.get(AUTH_URL):\n            return url\n        else:\n            return self.url(Endpoints.get_token, prefixed=False)\n\n    def _fetch_access_token(self, session: Session, credential: str) -&gt; str:\n        if SEMICOLON in credential:\n            client_id, client_secret = credential.split(SEMICOLON)\n        else:\n            client_id, client_secret = None, credential\n        data = {GRANT_TYPE: CLIENT_CREDENTIALS, CLIENT_ID: client_id, CLIENT_SECRET: client_secret, SCOPE: CATALOG_SCOPE}\n        # Uses application/x-www-form-urlencoded by default\n        response = session.post(url=self.auth_url, data=data)\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(exc, {400: OAuthError, 401: OAuthError})\n\n        return TokenResponse(**response.json()).access_token\n\n    def _fetch_config(self) -&gt; None:\n        params = {}\n        if warehouse_location := self.properties.get(WAREHOUSE_LOCATION):\n            params[WAREHOUSE_LOCATION] = warehouse_location\n\n        with self._create_session() as session:\n            response = session.get(self.url(Endpoints.get_config, prefixed=False), params=params)\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(exc, {})\n        config_response = ConfigResponse(**response.json())\n\n        config = config_response.defaults\n        config.update(self.properties)\n        config.update(config_response.overrides)\n        self.properties = config\n\n        # Update URI based on overrides\n        self.uri = config[URI]\n\n    def _identifier_to_validated_tuple(self, identifier: Union[str, Identifier]) -&gt; Identifier:\n        identifier_tuple = self.identifier_to_tuple(identifier)\n        if len(identifier_tuple) &lt;= 1:\n            raise NoSuchTableError(f\"Missing namespace or invalid identifier: {'.'.join(identifier_tuple)}\")\n        return identifier_tuple\n\n    def _split_identifier_for_path(self, identifier: Union[str, Identifier, TableIdentifier]) -&gt; Properties:\n        if isinstance(identifier, TableIdentifier):\n            return {\"namespace\": NAMESPACE_SEPARATOR.join(identifier.namespace.root[1:]), \"table\": identifier.name}\n        identifier_tuple = self._identifier_to_validated_tuple(identifier)\n        return {\"namespace\": NAMESPACE_SEPARATOR.join(identifier_tuple[:-1]), \"table\": identifier_tuple[-1]}\n\n    def _split_identifier_for_json(self, identifier: Union[str, Identifier]) -&gt; Dict[str, Union[Identifier, str]]:\n        identifier_tuple = self._identifier_to_validated_tuple(identifier)\n        return {\"namespace\": identifier_tuple[:-1], \"name\": identifier_tuple[-1]}\n\n    def _handle_non_200_response(self, exc: HTTPError, error_handler: Dict[int, Type[Exception]]) -&gt; None:\n        exception: Type[Exception]\n\n        if exc.response is None:\n            raise ValueError(\"Did not receive a response\")\n\n        code = exc.response.status_code\n        if code in error_handler:\n            exception = error_handler[code]\n        elif code == 400:\n            exception = BadRequestError\n        elif code == 401:\n            exception = UnauthorizedError\n        elif code == 403:\n            exception = ForbiddenError\n        elif code == 422:\n            exception = RESTError\n        elif code == 419:\n            exception = AuthorizationExpiredError\n        elif code == 501:\n            exception = NotImplementedError\n        elif code == 503:\n            exception = ServiceUnavailableError\n        elif 500 &lt;= code &lt; 600:\n            exception = ServerError\n        else:\n            exception = RESTError\n\n        try:\n            if exception == OAuthError:\n                # The OAuthErrorResponse has a different format\n                error = OAuthErrorResponse(**exc.response.json())\n                response = str(error.error)\n                if description := error.error_description:\n                    response += f\": {description}\"\n                if uri := error.error_uri:\n                    response += f\" ({uri})\"\n            else:\n                error = ErrorResponse(**exc.response.json()).error\n                response = f\"{error.type}: {error.message}\"\n        except JSONDecodeError:\n            # In the case we don't have a proper response\n            response = f\"RESTError {exc.response.status_code}: Could not decode json payload: {exc.response.text}\"\n        except ValidationError as e:\n            # In the case we don't have a proper response\n            errs = \", \".join(err[\"msg\"] for err in e.errors())\n            response = (\n                f\"RESTError {exc.response.status_code}: Received unexpected JSON Payload: {exc.response.text}, errors: {errs}\"\n            )\n\n        raise exception(response) from exc\n\n    def _init_sigv4(self, session: Session) -&gt; None:\n        from urllib import parse\n\n        import boto3\n        from botocore.auth import SigV4Auth\n        from botocore.awsrequest import AWSRequest\n        from requests import PreparedRequest\n        from requests.adapters import HTTPAdapter\n\n        class SigV4Adapter(HTTPAdapter):\n            def __init__(self, **properties: str):\n                super().__init__()\n                self._properties = properties\n\n            def add_headers(self, request: PreparedRequest, **kwargs: Any) -&gt; None:  # pylint: disable=W0613\n                boto_session = boto3.Session()\n                credentials = boto_session.get_credentials().get_frozen_credentials()\n                region = self._properties.get(SIGV4_REGION, boto_session.region_name)\n                service = self._properties.get(SIGV4_SERVICE, \"execute-api\")\n\n                url = str(request.url).split(\"?\")[0]\n                query = str(parse.urlsplit(request.url).query)\n                params = dict(parse.parse_qsl(query))\n\n                # remove the connection header as it will be updated after signing\n                del request.headers[\"connection\"]\n\n                aws_request = AWSRequest(\n                    method=request.method, url=url, params=params, data=request.body, headers=dict(request.headers)\n                )\n\n                SigV4Auth(credentials, service, region).add_auth(aws_request)\n                original_header = request.headers\n                signed_headers = aws_request.headers\n                relocated_headers = {}\n\n                # relocate headers if there is a conflict with signed headers\n                for header, value in original_header.items():\n                    if header in signed_headers and signed_headers[header] != value:\n                        relocated_headers[f\"Original-{header}\"] = value\n\n                request.headers.update(relocated_headers)\n                request.headers.update(signed_headers)\n\n        session.mount(self.uri, SigV4Adapter(**self.properties))\n\n    def _response_to_table(self, identifier_tuple: Tuple[str, ...], table_response: TableResponse) -&gt; Table:\n        return Table(\n            identifier=(self.name,) + identifier_tuple if self.name else identifier_tuple,\n            metadata_location=table_response.metadata_location,\n            metadata=table_response.metadata,\n            io=self._load_file_io(\n                {**table_response.metadata.properties, **table_response.config}, table_response.metadata_location\n            ),\n            catalog=self,\n        )\n\n    def create_table(\n        self,\n        identifier: Union[str, Identifier],\n        schema: Union[Schema, \"pa.Schema\"],\n        location: Optional[str] = None,\n        partition_spec: PartitionSpec = UNPARTITIONED_PARTITION_SPEC,\n        sort_order: SortOrder = UNSORTED_SORT_ORDER,\n        properties: Properties = EMPTY_DICT,\n    ) -&gt; Table:\n        iceberg_schema = self._convert_schema_if_needed(schema)\n        fresh_schema = assign_fresh_schema_ids(iceberg_schema)\n        fresh_partition_spec = assign_fresh_partition_spec_ids(partition_spec, iceberg_schema, fresh_schema)\n        fresh_sort_order = assign_fresh_sort_order_ids(sort_order, iceberg_schema, fresh_schema)\n\n        namespace_and_table = self._split_identifier_for_path(identifier)\n        request = CreateTableRequest(\n            name=namespace_and_table[\"table\"],\n            location=location,\n            table_schema=fresh_schema,\n            partition_spec=fresh_partition_spec,\n            write_order=fresh_sort_order,\n            properties=properties,\n        )\n        serialized_json = request.model_dump_json().encode(UTF8)\n        response = self._session.post(\n            self.url(Endpoints.create_table, namespace=namespace_and_table[\"namespace\"]),\n            data=serialized_json,\n        )\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(exc, {409: TableAlreadyExistsError})\n\n        table_response = TableResponse(**response.json())\n        return self._response_to_table(self.identifier_to_tuple(identifier), table_response)\n\n    def register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n        \"\"\"Register a new table using existing metadata.\n\n        Args:\n            identifier Union[str, Identifier]: Table identifier for the table\n            metadata_location str: The location to the metadata\n\n        Returns:\n            Table: The newly registered table\n\n        Raises:\n            TableAlreadyExistsError: If the table already exists\n        \"\"\"\n        namespace_and_table = self._split_identifier_for_path(identifier)\n        request = RegisterTableRequest(\n            name=namespace_and_table[\"table\"],\n            metadata_location=metadata_location,\n        )\n        serialized_json = request.model_dump_json().encode(UTF8)\n        response = self._session.post(\n            self.url(Endpoints.register_table, namespace=namespace_and_table[\"namespace\"]),\n            data=serialized_json,\n        )\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(exc, {409: TableAlreadyExistsError})\n\n        table_response = TableResponse(**response.json())\n        return self._response_to_table(self.identifier_to_tuple(identifier), table_response)\n\n    def list_tables(self, namespace: Union[str, Identifier]) -&gt; List[Identifier]:\n        namespace_tuple = self._check_valid_namespace_identifier(namespace)\n        namespace_concat = NAMESPACE_SEPARATOR.join(namespace_tuple)\n        response = self._session.get(self.url(Endpoints.list_tables, namespace=namespace_concat))\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(exc, {404: NoSuchNamespaceError})\n        return [(*table.namespace, table.name) for table in ListTablesResponse(**response.json()).identifiers]\n\n    def load_table(self, identifier: Union[str, Identifier]) -&gt; Table:\n        identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n        response = self._session.get(\n            self.url(Endpoints.load_table, prefixed=True, **self._split_identifier_for_path(identifier_tuple))\n        )\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(exc, {404: NoSuchTableError})\n\n        table_response = TableResponse(**response.json())\n        return self._response_to_table(identifier_tuple, table_response)\n\n    def drop_table(self, identifier: Union[str, Identifier], purge_requested: bool = False) -&gt; None:\n        identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n        response = self._session.delete(\n            self.url(\n                Endpoints.drop_table, prefixed=True, purge=purge_requested, **self._split_identifier_for_path(identifier_tuple)\n            ),\n        )\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(exc, {404: NoSuchTableError})\n\n    def purge_table(self, identifier: Union[str, Identifier]) -&gt; None:\n        self.drop_table(identifier=identifier, purge_requested=True)\n\n    def rename_table(self, from_identifier: Union[str, Identifier], to_identifier: Union[str, Identifier]) -&gt; Table:\n        from_identifier_tuple = self.identifier_to_tuple_without_catalog(from_identifier)\n        payload = {\n            \"source\": self._split_identifier_for_json(from_identifier_tuple),\n            \"destination\": self._split_identifier_for_json(to_identifier),\n        }\n        response = self._session.post(self.url(Endpoints.rename_table), json=payload)\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(exc, {404: NoSuchTableError, 409: TableAlreadyExistsError})\n\n        return self.load_table(to_identifier)\n\n    def _commit_table(self, table_request: CommitTableRequest) -&gt; CommitTableResponse:\n        \"\"\"Update the table.\n\n        Args:\n            table_request (CommitTableRequest): The table requests to be carried out.\n\n        Returns:\n            CommitTableResponse: The updated metadata.\n\n        Raises:\n            NoSuchTableError: If a table with the given identifier does not exist.\n        \"\"\"\n        response = self._session.post(\n            self.url(Endpoints.update_table, prefixed=True, **self._split_identifier_for_path(table_request.identifier)),\n            data=table_request.model_dump_json().encode(UTF8),\n        )\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(\n                exc,\n                {\n                    409: CommitFailedException,\n                    500: CommitStateUnknownException,\n                    502: CommitStateUnknownException,\n                    504: CommitStateUnknownException,\n                },\n            )\n        return CommitTableResponse(**response.json())\n\n    def create_namespace(self, namespace: Union[str, Identifier], properties: Properties = EMPTY_DICT) -&gt; None:\n        namespace_tuple = self._check_valid_namespace_identifier(namespace)\n        payload = {\"namespace\": namespace_tuple, \"properties\": properties}\n        response = self._session.post(self.url(Endpoints.create_namespace), json=payload)\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(exc, {404: NoSuchNamespaceError, 409: NamespaceAlreadyExistsError})\n\n    def drop_namespace(self, namespace: Union[str, Identifier]) -&gt; None:\n        namespace_tuple = self._check_valid_namespace_identifier(namespace)\n        namespace = NAMESPACE_SEPARATOR.join(namespace_tuple)\n        response = self._session.delete(self.url(Endpoints.drop_namespace, namespace=namespace))\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(exc, {404: NoSuchNamespaceError})\n\n    def list_namespaces(self, namespace: Union[str, Identifier] = ()) -&gt; List[Identifier]:\n        namespace_tuple = self.identifier_to_tuple(namespace)\n        response = self._session.get(\n            self.url(\n                f\"{Endpoints.list_namespaces}?parent={NAMESPACE_SEPARATOR.join(namespace_tuple)}\"\n                if namespace_tuple\n                else Endpoints.list_namespaces\n            ),\n        )\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(exc, {})\n\n        namespaces = ListNamespaceResponse(**response.json())\n        return [namespace_tuple + child_namespace for child_namespace in namespaces.namespaces]\n\n    def load_namespace_properties(self, namespace: Union[str, Identifier]) -&gt; Properties:\n        namespace_tuple = self._check_valid_namespace_identifier(namespace)\n        namespace = NAMESPACE_SEPARATOR.join(namespace_tuple)\n        response = self._session.get(self.url(Endpoints.load_namespace_metadata, namespace=namespace))\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(exc, {404: NoSuchNamespaceError})\n\n        return NamespaceResponse(**response.json()).properties\n\n    def update_namespace_properties(\n        self, namespace: Union[str, Identifier], removals: Optional[Set[str]] = None, updates: Properties = EMPTY_DICT\n    ) -&gt; PropertiesUpdateSummary:\n        namespace_tuple = self._check_valid_namespace_identifier(namespace)\n        namespace = NAMESPACE_SEPARATOR.join(namespace_tuple)\n        payload = {\"removals\": list(removals or []), \"updates\": updates}\n        response = self._session.post(self.url(Endpoints.update_namespace_properties, namespace=namespace), json=payload)\n        try:\n            response.raise_for_status()\n        except HTTPError as exc:\n            self._handle_non_200_response(exc, {404: NoSuchNamespaceError})\n        parsed_response = UpdateNamespacePropertiesResponse(**response.json())\n        return PropertiesUpdateSummary(\n            removed=parsed_response.removed,\n            updated=parsed_response.updated,\n            missing=parsed_response.missing,\n        )\n</code></pre>"},{"location":"reference/pyiceberg/catalog/rest/#pyiceberg.catalog.rest.RestCatalog.__init__","title":"<code>__init__(name, **properties)</code>","text":"<p>Rest Catalog.</p> <p>You either need to provide a client_id and client_secret, or an already valid token.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name to identify the catalog.</p> required <code>properties</code> <code>str</code> <p>Properties that are passed along to the configuration.</p> <code>{}</code> Source code in <code>pyiceberg/catalog/rest.py</code> <pre><code>def __init__(self, name: str, **properties: str):\n    \"\"\"Rest Catalog.\n\n    You either need to provide a client_id and client_secret, or an already valid token.\n\n    Args:\n        name: Name to identify the catalog.\n        properties: Properties that are passed along to the configuration.\n    \"\"\"\n    super().__init__(name, **properties)\n    self.uri = properties[URI]\n    self._fetch_config()\n    self._session = self._create_session()\n</code></pre>"},{"location":"reference/pyiceberg/catalog/rest/#pyiceberg.catalog.rest.RestCatalog.register_table","title":"<code>register_table(identifier, metadata_location)</code>","text":"<p>Register a new table using existing metadata.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier for the table</p> required <code>metadata_location</code> <code>str</code> <p>The location to the metadata</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>The newly registered table</p> <p>Raises:</p> Type Description <code>TableAlreadyExistsError</code> <p>If the table already exists</p> Source code in <code>pyiceberg/catalog/rest.py</code> <pre><code>def register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n    \"\"\"Register a new table using existing metadata.\n\n    Args:\n        identifier Union[str, Identifier]: Table identifier for the table\n        metadata_location str: The location to the metadata\n\n    Returns:\n        Table: The newly registered table\n\n    Raises:\n        TableAlreadyExistsError: If the table already exists\n    \"\"\"\n    namespace_and_table = self._split_identifier_for_path(identifier)\n    request = RegisterTableRequest(\n        name=namespace_and_table[\"table\"],\n        metadata_location=metadata_location,\n    )\n    serialized_json = request.model_dump_json().encode(UTF8)\n    response = self._session.post(\n        self.url(Endpoints.register_table, namespace=namespace_and_table[\"namespace\"]),\n        data=serialized_json,\n    )\n    try:\n        response.raise_for_status()\n    except HTTPError as exc:\n        self._handle_non_200_response(exc, {409: TableAlreadyExistsError})\n\n    table_response = TableResponse(**response.json())\n    return self._response_to_table(self.identifier_to_tuple(identifier), table_response)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/rest/#pyiceberg.catalog.rest.RestCatalog.url","title":"<code>url(endpoint, prefixed=True, **kwargs)</code>","text":"<p>Construct the endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>endpoint</code> <code>str</code> <p>Resource identifier that points to the REST catalog.</p> required <code>prefixed</code> <code>bool</code> <p>If the prefix return by the config needs to be appended.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>The base url of the rest catalog.</p> Source code in <code>pyiceberg/catalog/rest.py</code> <pre><code>def url(self, endpoint: str, prefixed: bool = True, **kwargs: Any) -&gt; str:\n    \"\"\"Construct the endpoint.\n\n    Args:\n        endpoint: Resource identifier that points to the REST catalog.\n        prefixed: If the prefix return by the config needs to be appended.\n\n    Returns:\n        The base url of the rest catalog.\n    \"\"\"\n    url = self.uri\n    url = url + \"v1/\" if url.endswith(\"/\") else url + \"/v1/\"\n\n    if prefixed:\n        url += self.properties.get(PREFIX, \"\")\n        url = url if url.endswith(\"/\") else url + \"/\"\n\n    return url + endpoint.format(**kwargs)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/sql/","title":"sql","text":""},{"location":"reference/pyiceberg/catalog/sql/#pyiceberg.catalog.sql.SqlCatalog","title":"<code>SqlCatalog</code>","text":"<p>             Bases: <code>Catalog</code></p> Source code in <code>pyiceberg/catalog/sql.py</code> <pre><code>class SqlCatalog(Catalog):\n    def __init__(self, name: str, **properties: str):\n        super().__init__(name, **properties)\n\n        if not (uri_prop := self.properties.get(\"uri\")):\n            raise NoSuchPropertyException(\"SQL connection URI is required\")\n        echo = bool(self.properties.get(\"echo\", False))\n        self.engine = create_engine(uri_prop, echo=echo)\n\n        self._ensure_tables_exist()\n\n    def _ensure_tables_exist(self) -&gt; None:\n        with Session(self.engine) as session:\n            for table in [IcebergTables, IcebergNamespaceProperties]:\n                stmt = select(1).select_from(table)\n                try:\n                    session.scalar(stmt)\n                except (\n                    OperationalError,\n                    ProgrammingError,\n                ):  # sqlalchemy returns OperationalError in case of sqlite and ProgrammingError with postgres.\n                    self.create_tables()\n                    return\n\n    def create_tables(self) -&gt; None:\n        SqlCatalogBaseTable.metadata.create_all(self.engine)\n\n    def destroy_tables(self) -&gt; None:\n        SqlCatalogBaseTable.metadata.drop_all(self.engine)\n\n    def _convert_orm_to_iceberg(self, orm_table: IcebergTables) -&gt; Table:\n        # Check for expected properties.\n        if not (metadata_location := orm_table.metadata_location):\n            raise NoSuchTableError(f\"Table property {METADATA_LOCATION} is missing\")\n        if not (table_namespace := orm_table.table_namespace):\n            raise NoSuchTableError(f\"Table property {IcebergTables.table_namespace} is missing\")\n        if not (table_name := orm_table.table_name):\n            raise NoSuchTableError(f\"Table property {IcebergTables.table_name} is missing\")\n\n        io = load_file_io(properties=self.properties, location=metadata_location)\n        file = io.new_input(metadata_location)\n        metadata = FromInputFile.table_metadata(file)\n        return Table(\n            identifier=(self.name, table_namespace, table_name),\n            metadata=metadata,\n            metadata_location=metadata_location,\n            io=self._load_file_io(metadata.properties, metadata_location),\n            catalog=self,\n        )\n\n    def create_table(\n        self,\n        identifier: Union[str, Identifier],\n        schema: Union[Schema, \"pa.Schema\"],\n        location: Optional[str] = None,\n        partition_spec: PartitionSpec = UNPARTITIONED_PARTITION_SPEC,\n        sort_order: SortOrder = UNSORTED_SORT_ORDER,\n        properties: Properties = EMPTY_DICT,\n    ) -&gt; Table:\n        \"\"\"\n        Create an Iceberg table.\n\n        Args:\n            identifier: Table identifier.\n            schema: Table's schema.\n            location: Location for the table. Optional Argument.\n            partition_spec: PartitionSpec for the table.\n            sort_order: SortOrder for the table.\n            properties: Table properties that can be a string based dictionary.\n\n        Returns:\n            Table: the created table instance.\n\n        Raises:\n            AlreadyExistsError: If a table with the name already exists.\n            ValueError: If the identifier is invalid, or no path is given to store metadata.\n\n        \"\"\"\n        schema: Schema = self._convert_schema_if_needed(schema)  # type: ignore\n\n        database_name, table_name = self.identifier_to_database_and_table(identifier)\n        if not self._namespace_exists(database_name):\n            raise NoSuchNamespaceError(f\"Namespace does not exist: {database_name}\")\n\n        location = self._resolve_table_location(location, database_name, table_name)\n        metadata_location = self._get_metadata_location(location=location)\n        metadata = new_table_metadata(\n            location=location, schema=schema, partition_spec=partition_spec, sort_order=sort_order, properties=properties\n        )\n        io = load_file_io(properties=self.properties, location=metadata_location)\n        self._write_metadata(metadata, io, metadata_location)\n\n        with Session(self.engine) as session:\n            try:\n                session.add(\n                    IcebergTables(\n                        catalog_name=self.name,\n                        table_namespace=database_name,\n                        table_name=table_name,\n                        metadata_location=metadata_location,\n                        previous_metadata_location=None,\n                    )\n                )\n                session.commit()\n            except IntegrityError as e:\n                raise TableAlreadyExistsError(f\"Table {database_name}.{table_name} already exists\") from e\n\n        return self.load_table(identifier=identifier)\n\n    def register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n        \"\"\"Register a new table using existing metadata.\n\n        Args:\n            identifier Union[str, Identifier]: Table identifier for the table\n            metadata_location str: The location to the metadata\n\n        Returns:\n            Table: The newly registered table\n\n        Raises:\n            TableAlreadyExistsError: If the table already exists\n            NoSuchNamespaceError: If namespace does not exist\n        \"\"\"\n        database_name, table_name = self.identifier_to_database_and_table(identifier)\n        if not self._namespace_exists(database_name):\n            raise NoSuchNamespaceError(f\"Namespace does not exist: {database_name}\")\n\n        with Session(self.engine) as session:\n            try:\n                session.add(\n                    IcebergTables(\n                        catalog_name=self.name,\n                        table_namespace=database_name,\n                        table_name=table_name,\n                        metadata_location=metadata_location,\n                        previous_metadata_location=None,\n                    )\n                )\n                session.commit()\n            except IntegrityError as e:\n                raise TableAlreadyExistsError(f\"Table {database_name}.{table_name} already exists\") from e\n\n        return self.load_table(identifier=identifier)\n\n    def load_table(self, identifier: Union[str, Identifier]) -&gt; Table:\n        \"\"\"Load the table's metadata and return the table instance.\n\n        You can also use this method to check for table existence using 'try catalog.table() except NoSuchTableError'.\n        Note: This method doesn't scan data stored in the table.\n\n        Args:\n            identifier (str | Identifier): Table identifier.\n\n        Returns:\n            Table: the table instance with its metadata.\n\n        Raises:\n            NoSuchTableError: If a table with the name does not exist.\n        \"\"\"\n        identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n        database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n        with Session(self.engine) as session:\n            stmt = select(IcebergTables).where(\n                IcebergTables.catalog_name == self.name,\n                IcebergTables.table_namespace == database_name,\n                IcebergTables.table_name == table_name,\n            )\n            result = session.scalar(stmt)\n        if result:\n            return self._convert_orm_to_iceberg(result)\n        raise NoSuchTableError(f\"Table does not exist: {database_name}.{table_name}\")\n\n    def drop_table(self, identifier: Union[str, Identifier]) -&gt; None:\n        \"\"\"Drop a table.\n\n        Args:\n            identifier (str | Identifier): Table identifier.\n\n        Raises:\n            NoSuchTableError: If a table with the name does not exist.\n        \"\"\"\n        identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n        database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n        with Session(self.engine) as session:\n            if self.engine.dialect.supports_sane_rowcount:\n                res = session.execute(\n                    delete(IcebergTables).where(\n                        IcebergTables.catalog_name == self.name,\n                        IcebergTables.table_namespace == database_name,\n                        IcebergTables.table_name == table_name,\n                    )\n                )\n                if res.rowcount &lt; 1:\n                    raise NoSuchTableError(f\"Table does not exist: {database_name}.{table_name}\")\n            else:\n                try:\n                    tbl = (\n                        session.query(IcebergTables)\n                        .with_for_update(of=IcebergTables)\n                        .filter(\n                            IcebergTables.catalog_name == self.name,\n                            IcebergTables.table_namespace == database_name,\n                            IcebergTables.table_name == table_name,\n                        )\n                        .one()\n                    )\n                    session.delete(tbl)\n                except NoResultFound as e:\n                    raise NoSuchTableError(f\"Table does not exist: {database_name}.{table_name}\") from e\n            session.commit()\n\n    def rename_table(self, from_identifier: Union[str, Identifier], to_identifier: Union[str, Identifier]) -&gt; Table:\n        \"\"\"Rename a fully classified table name.\n\n        Args:\n            from_identifier (str | Identifier): Existing table identifier.\n            to_identifier (str | Identifier): New table identifier.\n\n        Returns:\n            Table: the updated table instance with its metadata.\n\n        Raises:\n            NoSuchTableError: If a table with the name does not exist.\n            TableAlreadyExistsError: If a table with the new name already exist.\n            NoSuchNamespaceError: If the target namespace does not exist.\n        \"\"\"\n        from_identifier_tuple = self.identifier_to_tuple_without_catalog(from_identifier)\n        from_database_name, from_table_name = self.identifier_to_database_and_table(from_identifier_tuple, NoSuchTableError)\n        to_database_name, to_table_name = self.identifier_to_database_and_table(to_identifier)\n        if not self._namespace_exists(to_database_name):\n            raise NoSuchNamespaceError(f\"Namespace does not exist: {to_database_name}\")\n        with Session(self.engine) as session:\n            try:\n                if self.engine.dialect.supports_sane_rowcount:\n                    stmt = (\n                        update(IcebergTables)\n                        .where(\n                            IcebergTables.catalog_name == self.name,\n                            IcebergTables.table_namespace == from_database_name,\n                            IcebergTables.table_name == from_table_name,\n                        )\n                        .values(table_namespace=to_database_name, table_name=to_table_name)\n                    )\n                    result = session.execute(stmt)\n                    if result.rowcount &lt; 1:\n                        raise NoSuchTableError(f\"Table does not exist: {from_table_name}\")\n                else:\n                    try:\n                        tbl = (\n                            session.query(IcebergTables)\n                            .with_for_update(of=IcebergTables)\n                            .filter(\n                                IcebergTables.catalog_name == self.name,\n                                IcebergTables.table_namespace == from_database_name,\n                                IcebergTables.table_name == from_table_name,\n                            )\n                            .one()\n                        )\n                        tbl.table_namespace = to_database_name\n                        tbl.table_name = to_table_name\n                    except NoResultFound as e:\n                        raise NoSuchTableError(f\"Table does not exist: {from_table_name}\") from e\n                session.commit()\n            except IntegrityError as e:\n                raise TableAlreadyExistsError(f\"Table {to_database_name}.{to_table_name} already exists\") from e\n        return self.load_table(to_identifier)\n\n    def _commit_table(self, table_request: CommitTableRequest) -&gt; CommitTableResponse:\n        \"\"\"Update one or more tables.\n\n        Args:\n            table_request (CommitTableRequest): The table requests to be carried out.\n\n        Returns:\n            CommitTableResponse: The updated metadata.\n\n        Raises:\n            NoSuchTableError: If a table with the given identifier does not exist.\n            CommitFailedException: If the commit failed.\n        \"\"\"\n        identifier_tuple = self.identifier_to_tuple_without_catalog(\n            tuple(table_request.identifier.namespace.root + [table_request.identifier.name])\n        )\n        current_table = self.load_table(identifier_tuple)\n        database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n        base_metadata = current_table.metadata\n        for requirement in table_request.requirements:\n            requirement.validate(base_metadata)\n\n        updated_metadata = update_table_metadata(base_metadata, table_request.updates)\n        if updated_metadata == base_metadata:\n            # no changes, do nothing\n            return CommitTableResponse(metadata=base_metadata, metadata_location=current_table.metadata_location)\n\n        # write new metadata\n        new_metadata_version = self._parse_metadata_version(current_table.metadata_location) + 1\n        new_metadata_location = self._get_metadata_location(current_table.metadata.location, new_metadata_version)\n        self._write_metadata(updated_metadata, current_table.io, new_metadata_location)\n\n        with Session(self.engine) as session:\n            if self.engine.dialect.supports_sane_rowcount:\n                stmt = (\n                    update(IcebergTables)\n                    .where(\n                        IcebergTables.catalog_name == self.name,\n                        IcebergTables.table_namespace == database_name,\n                        IcebergTables.table_name == table_name,\n                        IcebergTables.metadata_location == current_table.metadata_location,\n                    )\n                    .values(metadata_location=new_metadata_location, previous_metadata_location=current_table.metadata_location)\n                )\n                result = session.execute(stmt)\n                if result.rowcount &lt; 1:\n                    raise CommitFailedException(f\"Table has been updated by another process: {database_name}.{table_name}\")\n            else:\n                try:\n                    tbl = (\n                        session.query(IcebergTables)\n                        .with_for_update(of=IcebergTables)\n                        .filter(\n                            IcebergTables.catalog_name == self.name,\n                            IcebergTables.table_namespace == database_name,\n                            IcebergTables.table_name == table_name,\n                            IcebergTables.metadata_location == current_table.metadata_location,\n                        )\n                        .one()\n                    )\n                    tbl.metadata_location = new_metadata_location\n                    tbl.previous_metadata_location = current_table.metadata_location\n                except NoResultFound as e:\n                    raise CommitFailedException(f\"Table has been updated by another process: {database_name}.{table_name}\") from e\n            session.commit()\n\n        return CommitTableResponse(metadata=updated_metadata, metadata_location=new_metadata_location)\n\n    def _namespace_exists(self, identifier: Union[str, Identifier]) -&gt; bool:\n        namespace = self.identifier_to_database(identifier)\n        with Session(self.engine) as session:\n            stmt = (\n                select(IcebergTables)\n                .where(IcebergTables.catalog_name == self.name, IcebergTables.table_namespace == namespace)\n                .limit(1)\n            )\n            result = session.execute(stmt).all()\n            if result:\n                return True\n            stmt = (\n                select(IcebergNamespaceProperties)\n                .where(\n                    IcebergNamespaceProperties.catalog_name == self.name,\n                    IcebergNamespaceProperties.namespace == namespace,\n                )\n                .limit(1)\n            )\n            result = session.execute(stmt).all()\n            if result:\n                return True\n        return False\n\n    def create_namespace(self, namespace: Union[str, Identifier], properties: Properties = EMPTY_DICT) -&gt; None:\n        \"\"\"Create a namespace in the catalog.\n\n        Args:\n            namespace (str | Identifier): Namespace identifier.\n            properties (Properties): A string dictionary of properties for the given namespace.\n\n        Raises:\n            NamespaceAlreadyExistsError: If a namespace with the given name already exists.\n        \"\"\"\n        if not properties:\n            properties = IcebergNamespaceProperties.NAMESPACE_MINIMAL_PROPERTIES\n        database_name = self.identifier_to_database(namespace)\n        if self._namespace_exists(database_name):\n            raise NamespaceAlreadyExistsError(f\"Database {database_name} already exists\")\n\n        create_properties = properties if properties else IcebergNamespaceProperties.NAMESPACE_MINIMAL_PROPERTIES\n        with Session(self.engine) as session:\n            for key, value in create_properties.items():\n                session.add(\n                    IcebergNamespaceProperties(\n                        catalog_name=self.name, namespace=database_name, property_key=key, property_value=value\n                    )\n                )\n            session.commit()\n\n    def drop_namespace(self, namespace: Union[str, Identifier]) -&gt; None:\n        \"\"\"Drop a namespace.\n\n        Args:\n            namespace (str | Identifier): Namespace identifier.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist.\n            NamespaceNotEmptyError: If the namespace is not empty.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n        if self._namespace_exists(database_name):\n            if tables := self.list_tables(database_name):\n                raise NamespaceNotEmptyError(f\"Database {database_name} is not empty. {len(tables)} tables exist.\")\n\n            with Session(self.engine) as session:\n                session.execute(\n                    delete(IcebergNamespaceProperties).where(\n                        IcebergNamespaceProperties.catalog_name == self.name,\n                        IcebergNamespaceProperties.namespace == database_name,\n                    )\n                )\n                session.commit()\n\n    def list_tables(self, namespace: Union[str, Identifier]) -&gt; List[Identifier]:\n        \"\"\"List tables under the given namespace in the catalog.\n\n        If namespace not provided, will list all tables in the catalog.\n\n        Args:\n            namespace (str | Identifier): Namespace identifier to search.\n\n        Returns:\n            List[Identifier]: list of table identifiers.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n\n        stmt = select(IcebergTables).where(\n            IcebergTables.catalog_name == self.name, IcebergTables.table_namespace == database_name\n        )\n        with Session(self.engine) as session:\n            result = session.scalars(stmt)\n            return [(table.table_namespace, table.table_name) for table in result]\n\n    def list_namespaces(self, namespace: Union[str, Identifier] = ()) -&gt; List[Identifier]:\n        \"\"\"List namespaces from the given namespace. If not given, list top-level namespaces from the catalog.\n\n        Args:\n            namespace (str | Identifier): Namespace identifier to search.\n\n        Returns:\n            List[Identifier]: a List of namespace identifiers.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist.\n        \"\"\"\n        if namespace and not self._namespace_exists(namespace):\n            raise NoSuchNamespaceError(f\"Namespace does not exist: {namespace}\")\n\n        table_stmt = select(IcebergTables.table_namespace).where(IcebergTables.catalog_name == self.name)\n        namespace_stmt = select(IcebergNamespaceProperties.namespace).where(IcebergNamespaceProperties.catalog_name == self.name)\n        if namespace:\n            database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n            table_stmt = table_stmt.where(IcebergTables.table_namespace.like(database_name))\n            namespace_stmt = namespace_stmt.where(IcebergNamespaceProperties.namespace.like(database_name))\n        stmt = union(\n            table_stmt,\n            namespace_stmt,\n        )\n        with Session(self.engine) as session:\n            return [self.identifier_to_tuple(namespace_col) for namespace_col in session.execute(stmt).scalars()]\n\n    def load_namespace_properties(self, namespace: Union[str, Identifier]) -&gt; Properties:\n        \"\"\"Get properties for a namespace.\n\n        Args:\n            namespace (str | Identifier): Namespace identifier.\n\n        Returns:\n            Properties: Properties for the given namespace.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n\n        stmt = select(IcebergNamespaceProperties).where(\n            IcebergNamespaceProperties.catalog_name == self.name, IcebergNamespaceProperties.namespace == database_name\n        )\n        with Session(self.engine) as session:\n            result = session.scalars(stmt)\n            return {props.property_key: props.property_value for props in result}\n\n    def update_namespace_properties(\n        self, namespace: Union[str, Identifier], removals: Optional[Set[str]] = None, updates: Properties = EMPTY_DICT\n    ) -&gt; PropertiesUpdateSummary:\n        \"\"\"Remove provided property keys and update properties for a namespace.\n\n        Args:\n            namespace (str | Identifier): Namespace identifier.\n            removals (Set[str]): Set of property keys that need to be removed. Optional Argument.\n            updates (Properties): Properties to be updated for the given namespace.\n\n        Raises:\n            NoSuchNamespaceError: If a namespace with the given name does not exist.\n            ValueError: If removals and updates have overlapping keys.\n        \"\"\"\n        database_name = self.identifier_to_database(namespace)\n        if not self._namespace_exists(database_name):\n            raise NoSuchNamespaceError(f\"Database {database_name} does not exists\")\n\n        current_properties = self.load_namespace_properties(namespace=namespace)\n        properties_update_summary = self._get_updated_props_and_update_summary(\n            current_properties=current_properties, removals=removals, updates=updates\n        )[0]\n\n        with Session(self.engine) as session:\n            if removals:\n                delete_stmt = delete(IcebergNamespaceProperties).where(\n                    IcebergNamespaceProperties.catalog_name == self.name,\n                    IcebergNamespaceProperties.namespace == database_name,\n                    IcebergNamespaceProperties.property_key.in_(removals),\n                )\n                session.execute(delete_stmt)\n\n            if updates:\n                # SQLAlchemy does not (yet) support engine agnostic UPSERT\n                # https://docs.sqlalchemy.org/en/20/orm/queryguide/dml.html#orm-upsert-statements\n                # This is not a problem since it runs in a single transaction\n                delete_stmt = delete(IcebergNamespaceProperties).where(\n                    IcebergNamespaceProperties.catalog_name == self.name,\n                    IcebergNamespaceProperties.namespace == database_name,\n                    IcebergNamespaceProperties.property_key.in_(set(updates.keys())),\n                )\n                session.execute(delete_stmt)\n                insert_stmt = insert(IcebergNamespaceProperties)\n                for property_key, property_value in updates.items():\n                    insert_stmt = insert_stmt.values(\n                        catalog_name=self.name, namespace=database_name, property_key=property_key, property_value=property_value\n                    )\n                session.execute(insert_stmt)\n            session.commit()\n        return properties_update_summary\n</code></pre>"},{"location":"reference/pyiceberg/catalog/sql/#pyiceberg.catalog.sql.SqlCatalog.create_namespace","title":"<code>create_namespace(namespace, properties=EMPTY_DICT)</code>","text":"<p>Create a namespace in the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier.</p> required <code>properties</code> <code>Properties</code> <p>A string dictionary of properties for the given namespace.</p> <code>EMPTY_DICT</code> <p>Raises:</p> Type Description <code>NamespaceAlreadyExistsError</code> <p>If a namespace with the given name already exists.</p> Source code in <code>pyiceberg/catalog/sql.py</code> <pre><code>def create_namespace(self, namespace: Union[str, Identifier], properties: Properties = EMPTY_DICT) -&gt; None:\n    \"\"\"Create a namespace in the catalog.\n\n    Args:\n        namespace (str | Identifier): Namespace identifier.\n        properties (Properties): A string dictionary of properties for the given namespace.\n\n    Raises:\n        NamespaceAlreadyExistsError: If a namespace with the given name already exists.\n    \"\"\"\n    if not properties:\n        properties = IcebergNamespaceProperties.NAMESPACE_MINIMAL_PROPERTIES\n    database_name = self.identifier_to_database(namespace)\n    if self._namespace_exists(database_name):\n        raise NamespaceAlreadyExistsError(f\"Database {database_name} already exists\")\n\n    create_properties = properties if properties else IcebergNamespaceProperties.NAMESPACE_MINIMAL_PROPERTIES\n    with Session(self.engine) as session:\n        for key, value in create_properties.items():\n            session.add(\n                IcebergNamespaceProperties(\n                    catalog_name=self.name, namespace=database_name, property_key=key, property_value=value\n                )\n            )\n        session.commit()\n</code></pre>"},{"location":"reference/pyiceberg/catalog/sql/#pyiceberg.catalog.sql.SqlCatalog.create_table","title":"<code>create_table(identifier, schema, location=None, partition_spec=UNPARTITIONED_PARTITION_SPEC, sort_order=UNSORTED_SORT_ORDER, properties=EMPTY_DICT)</code>","text":"<p>Create an Iceberg table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier.</p> required <code>schema</code> <code>Union[Schema, Schema]</code> <p>Table's schema.</p> required <code>location</code> <code>Optional[str]</code> <p>Location for the table. Optional Argument.</p> <code>None</code> <code>partition_spec</code> <code>PartitionSpec</code> <p>PartitionSpec for the table.</p> <code>UNPARTITIONED_PARTITION_SPEC</code> <code>sort_order</code> <code>SortOrder</code> <p>SortOrder for the table.</p> <code>UNSORTED_SORT_ORDER</code> <code>properties</code> <code>Properties</code> <p>Table properties that can be a string based dictionary.</p> <code>EMPTY_DICT</code> <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the created table instance.</p> <p>Raises:</p> Type Description <code>AlreadyExistsError</code> <p>If a table with the name already exists.</p> <code>ValueError</code> <p>If the identifier is invalid, or no path is given to store metadata.</p> Source code in <code>pyiceberg/catalog/sql.py</code> <pre><code>def create_table(\n    self,\n    identifier: Union[str, Identifier],\n    schema: Union[Schema, \"pa.Schema\"],\n    location: Optional[str] = None,\n    partition_spec: PartitionSpec = UNPARTITIONED_PARTITION_SPEC,\n    sort_order: SortOrder = UNSORTED_SORT_ORDER,\n    properties: Properties = EMPTY_DICT,\n) -&gt; Table:\n    \"\"\"\n    Create an Iceberg table.\n\n    Args:\n        identifier: Table identifier.\n        schema: Table's schema.\n        location: Location for the table. Optional Argument.\n        partition_spec: PartitionSpec for the table.\n        sort_order: SortOrder for the table.\n        properties: Table properties that can be a string based dictionary.\n\n    Returns:\n        Table: the created table instance.\n\n    Raises:\n        AlreadyExistsError: If a table with the name already exists.\n        ValueError: If the identifier is invalid, or no path is given to store metadata.\n\n    \"\"\"\n    schema: Schema = self._convert_schema_if_needed(schema)  # type: ignore\n\n    database_name, table_name = self.identifier_to_database_and_table(identifier)\n    if not self._namespace_exists(database_name):\n        raise NoSuchNamespaceError(f\"Namespace does not exist: {database_name}\")\n\n    location = self._resolve_table_location(location, database_name, table_name)\n    metadata_location = self._get_metadata_location(location=location)\n    metadata = new_table_metadata(\n        location=location, schema=schema, partition_spec=partition_spec, sort_order=sort_order, properties=properties\n    )\n    io = load_file_io(properties=self.properties, location=metadata_location)\n    self._write_metadata(metadata, io, metadata_location)\n\n    with Session(self.engine) as session:\n        try:\n            session.add(\n                IcebergTables(\n                    catalog_name=self.name,\n                    table_namespace=database_name,\n                    table_name=table_name,\n                    metadata_location=metadata_location,\n                    previous_metadata_location=None,\n                )\n            )\n            session.commit()\n        except IntegrityError as e:\n            raise TableAlreadyExistsError(f\"Table {database_name}.{table_name} already exists\") from e\n\n    return self.load_table(identifier=identifier)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/sql/#pyiceberg.catalog.sql.SqlCatalog.drop_namespace","title":"<code>drop_namespace(namespace)</code>","text":"<p>Drop a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier.</p> required <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist.</p> <code>NamespaceNotEmptyError</code> <p>If the namespace is not empty.</p> Source code in <code>pyiceberg/catalog/sql.py</code> <pre><code>def drop_namespace(self, namespace: Union[str, Identifier]) -&gt; None:\n    \"\"\"Drop a namespace.\n\n    Args:\n        namespace (str | Identifier): Namespace identifier.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist.\n        NamespaceNotEmptyError: If the namespace is not empty.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n    if self._namespace_exists(database_name):\n        if tables := self.list_tables(database_name):\n            raise NamespaceNotEmptyError(f\"Database {database_name} is not empty. {len(tables)} tables exist.\")\n\n        with Session(self.engine) as session:\n            session.execute(\n                delete(IcebergNamespaceProperties).where(\n                    IcebergNamespaceProperties.catalog_name == self.name,\n                    IcebergNamespaceProperties.namespace == database_name,\n                )\n            )\n            session.commit()\n</code></pre>"},{"location":"reference/pyiceberg/catalog/sql/#pyiceberg.catalog.sql.SqlCatalog.drop_table","title":"<code>drop_table(identifier)</code>","text":"<p>Drop a table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str | Identifier</code> <p>Table identifier.</p> required <p>Raises:</p> Type Description <code>NoSuchTableError</code> <p>If a table with the name does not exist.</p> Source code in <code>pyiceberg/catalog/sql.py</code> <pre><code>def drop_table(self, identifier: Union[str, Identifier]) -&gt; None:\n    \"\"\"Drop a table.\n\n    Args:\n        identifier (str | Identifier): Table identifier.\n\n    Raises:\n        NoSuchTableError: If a table with the name does not exist.\n    \"\"\"\n    identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n    database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n    with Session(self.engine) as session:\n        if self.engine.dialect.supports_sane_rowcount:\n            res = session.execute(\n                delete(IcebergTables).where(\n                    IcebergTables.catalog_name == self.name,\n                    IcebergTables.table_namespace == database_name,\n                    IcebergTables.table_name == table_name,\n                )\n            )\n            if res.rowcount &lt; 1:\n                raise NoSuchTableError(f\"Table does not exist: {database_name}.{table_name}\")\n        else:\n            try:\n                tbl = (\n                    session.query(IcebergTables)\n                    .with_for_update(of=IcebergTables)\n                    .filter(\n                        IcebergTables.catalog_name == self.name,\n                        IcebergTables.table_namespace == database_name,\n                        IcebergTables.table_name == table_name,\n                    )\n                    .one()\n                )\n                session.delete(tbl)\n            except NoResultFound as e:\n                raise NoSuchTableError(f\"Table does not exist: {database_name}.{table_name}\") from e\n        session.commit()\n</code></pre>"},{"location":"reference/pyiceberg/catalog/sql/#pyiceberg.catalog.sql.SqlCatalog.list_namespaces","title":"<code>list_namespaces(namespace=())</code>","text":"<p>List namespaces from the given namespace. If not given, list top-level namespaces from the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier to search.</p> <code>()</code> <p>Returns:</p> Type Description <code>List[Identifier]</code> <p>List[Identifier]: a List of namespace identifiers.</p> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist.</p> Source code in <code>pyiceberg/catalog/sql.py</code> <pre><code>def list_namespaces(self, namespace: Union[str, Identifier] = ()) -&gt; List[Identifier]:\n    \"\"\"List namespaces from the given namespace. If not given, list top-level namespaces from the catalog.\n\n    Args:\n        namespace (str | Identifier): Namespace identifier to search.\n\n    Returns:\n        List[Identifier]: a List of namespace identifiers.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist.\n    \"\"\"\n    if namespace and not self._namespace_exists(namespace):\n        raise NoSuchNamespaceError(f\"Namespace does not exist: {namespace}\")\n\n    table_stmt = select(IcebergTables.table_namespace).where(IcebergTables.catalog_name == self.name)\n    namespace_stmt = select(IcebergNamespaceProperties.namespace).where(IcebergNamespaceProperties.catalog_name == self.name)\n    if namespace:\n        database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n        table_stmt = table_stmt.where(IcebergTables.table_namespace.like(database_name))\n        namespace_stmt = namespace_stmt.where(IcebergNamespaceProperties.namespace.like(database_name))\n    stmt = union(\n        table_stmt,\n        namespace_stmt,\n    )\n    with Session(self.engine) as session:\n        return [self.identifier_to_tuple(namespace_col) for namespace_col in session.execute(stmt).scalars()]\n</code></pre>"},{"location":"reference/pyiceberg/catalog/sql/#pyiceberg.catalog.sql.SqlCatalog.list_tables","title":"<code>list_tables(namespace)</code>","text":"<p>List tables under the given namespace in the catalog.</p> <p>If namespace not provided, will list all tables in the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier to search.</p> required <p>Returns:</p> Type Description <code>List[Identifier]</code> <p>List[Identifier]: list of table identifiers.</p> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist.</p> Source code in <code>pyiceberg/catalog/sql.py</code> <pre><code>def list_tables(self, namespace: Union[str, Identifier]) -&gt; List[Identifier]:\n    \"\"\"List tables under the given namespace in the catalog.\n\n    If namespace not provided, will list all tables in the catalog.\n\n    Args:\n        namespace (str | Identifier): Namespace identifier to search.\n\n    Returns:\n        List[Identifier]: list of table identifiers.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n\n    stmt = select(IcebergTables).where(\n        IcebergTables.catalog_name == self.name, IcebergTables.table_namespace == database_name\n    )\n    with Session(self.engine) as session:\n        result = session.scalars(stmt)\n        return [(table.table_namespace, table.table_name) for table in result]\n</code></pre>"},{"location":"reference/pyiceberg/catalog/sql/#pyiceberg.catalog.sql.SqlCatalog.load_namespace_properties","title":"<code>load_namespace_properties(namespace)</code>","text":"<p>Get properties for a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier.</p> required <p>Returns:</p> Name Type Description <code>Properties</code> <code>Properties</code> <p>Properties for the given namespace.</p> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist.</p> Source code in <code>pyiceberg/catalog/sql.py</code> <pre><code>def load_namespace_properties(self, namespace: Union[str, Identifier]) -&gt; Properties:\n    \"\"\"Get properties for a namespace.\n\n    Args:\n        namespace (str | Identifier): Namespace identifier.\n\n    Returns:\n        Properties: Properties for the given namespace.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace, NoSuchNamespaceError)\n\n    stmt = select(IcebergNamespaceProperties).where(\n        IcebergNamespaceProperties.catalog_name == self.name, IcebergNamespaceProperties.namespace == database_name\n    )\n    with Session(self.engine) as session:\n        result = session.scalars(stmt)\n        return {props.property_key: props.property_value for props in result}\n</code></pre>"},{"location":"reference/pyiceberg/catalog/sql/#pyiceberg.catalog.sql.SqlCatalog.load_table","title":"<code>load_table(identifier)</code>","text":"<p>Load the table's metadata and return the table instance.</p> <p>You can also use this method to check for table existence using 'try catalog.table() except NoSuchTableError'. Note: This method doesn't scan data stored in the table.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str | Identifier</code> <p>Table identifier.</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the table instance with its metadata.</p> <p>Raises:</p> Type Description <code>NoSuchTableError</code> <p>If a table with the name does not exist.</p> Source code in <code>pyiceberg/catalog/sql.py</code> <pre><code>def load_table(self, identifier: Union[str, Identifier]) -&gt; Table:\n    \"\"\"Load the table's metadata and return the table instance.\n\n    You can also use this method to check for table existence using 'try catalog.table() except NoSuchTableError'.\n    Note: This method doesn't scan data stored in the table.\n\n    Args:\n        identifier (str | Identifier): Table identifier.\n\n    Returns:\n        Table: the table instance with its metadata.\n\n    Raises:\n        NoSuchTableError: If a table with the name does not exist.\n    \"\"\"\n    identifier_tuple = self.identifier_to_tuple_without_catalog(identifier)\n    database_name, table_name = self.identifier_to_database_and_table(identifier_tuple, NoSuchTableError)\n    with Session(self.engine) as session:\n        stmt = select(IcebergTables).where(\n            IcebergTables.catalog_name == self.name,\n            IcebergTables.table_namespace == database_name,\n            IcebergTables.table_name == table_name,\n        )\n        result = session.scalar(stmt)\n    if result:\n        return self._convert_orm_to_iceberg(result)\n    raise NoSuchTableError(f\"Table does not exist: {database_name}.{table_name}\")\n</code></pre>"},{"location":"reference/pyiceberg/catalog/sql/#pyiceberg.catalog.sql.SqlCatalog.register_table","title":"<code>register_table(identifier, metadata_location)</code>","text":"<p>Register a new table using existing metadata.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Union[str, Identifier]</code> <p>Table identifier for the table</p> required <code>metadata_location</code> <code>str</code> <p>The location to the metadata</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>The newly registered table</p> <p>Raises:</p> Type Description <code>TableAlreadyExistsError</code> <p>If the table already exists</p> <code>NoSuchNamespaceError</code> <p>If namespace does not exist</p> Source code in <code>pyiceberg/catalog/sql.py</code> <pre><code>def register_table(self, identifier: Union[str, Identifier], metadata_location: str) -&gt; Table:\n    \"\"\"Register a new table using existing metadata.\n\n    Args:\n        identifier Union[str, Identifier]: Table identifier for the table\n        metadata_location str: The location to the metadata\n\n    Returns:\n        Table: The newly registered table\n\n    Raises:\n        TableAlreadyExistsError: If the table already exists\n        NoSuchNamespaceError: If namespace does not exist\n    \"\"\"\n    database_name, table_name = self.identifier_to_database_and_table(identifier)\n    if not self._namespace_exists(database_name):\n        raise NoSuchNamespaceError(f\"Namespace does not exist: {database_name}\")\n\n    with Session(self.engine) as session:\n        try:\n            session.add(\n                IcebergTables(\n                    catalog_name=self.name,\n                    table_namespace=database_name,\n                    table_name=table_name,\n                    metadata_location=metadata_location,\n                    previous_metadata_location=None,\n                )\n            )\n            session.commit()\n        except IntegrityError as e:\n            raise TableAlreadyExistsError(f\"Table {database_name}.{table_name} already exists\") from e\n\n    return self.load_table(identifier=identifier)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/sql/#pyiceberg.catalog.sql.SqlCatalog.rename_table","title":"<code>rename_table(from_identifier, to_identifier)</code>","text":"<p>Rename a fully classified table name.</p> <p>Parameters:</p> Name Type Description Default <code>from_identifier</code> <code>str | Identifier</code> <p>Existing table identifier.</p> required <code>to_identifier</code> <code>str | Identifier</code> <p>New table identifier.</p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>the updated table instance with its metadata.</p> <p>Raises:</p> Type Description <code>NoSuchTableError</code> <p>If a table with the name does not exist.</p> <code>TableAlreadyExistsError</code> <p>If a table with the new name already exist.</p> <code>NoSuchNamespaceError</code> <p>If the target namespace does not exist.</p> Source code in <code>pyiceberg/catalog/sql.py</code> <pre><code>def rename_table(self, from_identifier: Union[str, Identifier], to_identifier: Union[str, Identifier]) -&gt; Table:\n    \"\"\"Rename a fully classified table name.\n\n    Args:\n        from_identifier (str | Identifier): Existing table identifier.\n        to_identifier (str | Identifier): New table identifier.\n\n    Returns:\n        Table: the updated table instance with its metadata.\n\n    Raises:\n        NoSuchTableError: If a table with the name does not exist.\n        TableAlreadyExistsError: If a table with the new name already exist.\n        NoSuchNamespaceError: If the target namespace does not exist.\n    \"\"\"\n    from_identifier_tuple = self.identifier_to_tuple_without_catalog(from_identifier)\n    from_database_name, from_table_name = self.identifier_to_database_and_table(from_identifier_tuple, NoSuchTableError)\n    to_database_name, to_table_name = self.identifier_to_database_and_table(to_identifier)\n    if not self._namespace_exists(to_database_name):\n        raise NoSuchNamespaceError(f\"Namespace does not exist: {to_database_name}\")\n    with Session(self.engine) as session:\n        try:\n            if self.engine.dialect.supports_sane_rowcount:\n                stmt = (\n                    update(IcebergTables)\n                    .where(\n                        IcebergTables.catalog_name == self.name,\n                        IcebergTables.table_namespace == from_database_name,\n                        IcebergTables.table_name == from_table_name,\n                    )\n                    .values(table_namespace=to_database_name, table_name=to_table_name)\n                )\n                result = session.execute(stmt)\n                if result.rowcount &lt; 1:\n                    raise NoSuchTableError(f\"Table does not exist: {from_table_name}\")\n            else:\n                try:\n                    tbl = (\n                        session.query(IcebergTables)\n                        .with_for_update(of=IcebergTables)\n                        .filter(\n                            IcebergTables.catalog_name == self.name,\n                            IcebergTables.table_namespace == from_database_name,\n                            IcebergTables.table_name == from_table_name,\n                        )\n                        .one()\n                    )\n                    tbl.table_namespace = to_database_name\n                    tbl.table_name = to_table_name\n                except NoResultFound as e:\n                    raise NoSuchTableError(f\"Table does not exist: {from_table_name}\") from e\n            session.commit()\n        except IntegrityError as e:\n            raise TableAlreadyExistsError(f\"Table {to_database_name}.{to_table_name} already exists\") from e\n    return self.load_table(to_identifier)\n</code></pre>"},{"location":"reference/pyiceberg/catalog/sql/#pyiceberg.catalog.sql.SqlCatalog.update_namespace_properties","title":"<code>update_namespace_properties(namespace, removals=None, updates=EMPTY_DICT)</code>","text":"<p>Remove provided property keys and update properties for a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace</code> <code>str | Identifier</code> <p>Namespace identifier.</p> required <code>removals</code> <code>Set[str]</code> <p>Set of property keys that need to be removed. Optional Argument.</p> <code>None</code> <code>updates</code> <code>Properties</code> <p>Properties to be updated for the given namespace.</p> <code>EMPTY_DICT</code> <p>Raises:</p> Type Description <code>NoSuchNamespaceError</code> <p>If a namespace with the given name does not exist.</p> <code>ValueError</code> <p>If removals and updates have overlapping keys.</p> Source code in <code>pyiceberg/catalog/sql.py</code> <pre><code>def update_namespace_properties(\n    self, namespace: Union[str, Identifier], removals: Optional[Set[str]] = None, updates: Properties = EMPTY_DICT\n) -&gt; PropertiesUpdateSummary:\n    \"\"\"Remove provided property keys and update properties for a namespace.\n\n    Args:\n        namespace (str | Identifier): Namespace identifier.\n        removals (Set[str]): Set of property keys that need to be removed. Optional Argument.\n        updates (Properties): Properties to be updated for the given namespace.\n\n    Raises:\n        NoSuchNamespaceError: If a namespace with the given name does not exist.\n        ValueError: If removals and updates have overlapping keys.\n    \"\"\"\n    database_name = self.identifier_to_database(namespace)\n    if not self._namespace_exists(database_name):\n        raise NoSuchNamespaceError(f\"Database {database_name} does not exists\")\n\n    current_properties = self.load_namespace_properties(namespace=namespace)\n    properties_update_summary = self._get_updated_props_and_update_summary(\n        current_properties=current_properties, removals=removals, updates=updates\n    )[0]\n\n    with Session(self.engine) as session:\n        if removals:\n            delete_stmt = delete(IcebergNamespaceProperties).where(\n                IcebergNamespaceProperties.catalog_name == self.name,\n                IcebergNamespaceProperties.namespace == database_name,\n                IcebergNamespaceProperties.property_key.in_(removals),\n            )\n            session.execute(delete_stmt)\n\n        if updates:\n            # SQLAlchemy does not (yet) support engine agnostic UPSERT\n            # https://docs.sqlalchemy.org/en/20/orm/queryguide/dml.html#orm-upsert-statements\n            # This is not a problem since it runs in a single transaction\n            delete_stmt = delete(IcebergNamespaceProperties).where(\n                IcebergNamespaceProperties.catalog_name == self.name,\n                IcebergNamespaceProperties.namespace == database_name,\n                IcebergNamespaceProperties.property_key.in_(set(updates.keys())),\n            )\n            session.execute(delete_stmt)\n            insert_stmt = insert(IcebergNamespaceProperties)\n            for property_key, property_value in updates.items():\n                insert_stmt = insert_stmt.values(\n                    catalog_name=self.name, namespace=database_name, property_key=property_key, property_value=property_value\n                )\n            session.execute(insert_stmt)\n        session.commit()\n    return properties_update_summary\n</code></pre>"},{"location":"reference/pyiceberg/cli/","title":"cli","text":""},{"location":"reference/pyiceberg/cli/console/","title":"console","text":""},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.create","title":"<code>create()</code>","text":"<p>Operation to create a namespace.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@run.group()\ndef create() -&gt; None:\n    \"\"\"Operation to create a namespace.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.describe","title":"<code>describe(ctx, entity, identifier)</code>","text":"<p>Describe a namespace or a table.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@run.command()\n@click.option(\"--entity\", type=click.Choice([\"any\", \"namespace\", \"table\"]), default=\"any\")\n@click.argument(\"identifier\")\n@click.pass_context\n@catch_exception()\ndef describe(ctx: Context, entity: Literal[\"name\", \"namespace\", \"table\"], identifier: str) -&gt; None:\n    \"\"\"Describe a namespace or a table.\"\"\"\n    catalog, output = _catalog_and_output(ctx)\n    identifier_tuple = Catalog.identifier_to_tuple(identifier)\n\n    is_namespace = False\n    if entity in {\"namespace\", \"any\"} and len(identifier_tuple) &gt; 0:\n        try:\n            namespace_properties = catalog.load_namespace_properties(identifier_tuple)\n            output.describe_properties(namespace_properties)\n            is_namespace = True\n        except NoSuchNamespaceError as exc:\n            if entity != \"any\" or len(identifier_tuple) == 1:  # type: ignore\n                raise exc\n\n    is_table = False\n    if entity in {\"table\", \"any\"} and len(identifier_tuple) &gt; 1:\n        try:\n            catalog_table = catalog.load_table(identifier)\n            output.describe_table(catalog_table)\n            is_table = True\n        except NoSuchTableError as exc:\n            if entity != \"any\":\n                raise exc\n\n    if is_namespace is False and is_table is False:\n        raise NoSuchTableError(f\"Table or namespace does not exist: {identifier}\")\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.drop","title":"<code>drop()</code>","text":"<p>Operations to drop a namespace or table.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@run.group()\ndef drop() -&gt; None:\n    \"\"\"Operations to drop a namespace or table.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.files","title":"<code>files(ctx, identifier, history)</code>","text":"<p>List all the files of the table.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@run.command()\n@click.argument(\"identifier\")\n@click.option(\"--history\", is_flag=True)\n@click.pass_context\n@catch_exception()\ndef files(ctx: Context, identifier: str, history: bool) -&gt; None:\n    \"\"\"List all the files of the table.\"\"\"\n    catalog, output = _catalog_and_output(ctx)\n\n    catalog_table = catalog.load_table(identifier)\n    output.files(catalog_table, history)\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.get","title":"<code>get()</code>","text":"<p>Fetch properties on tables/namespaces.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@properties.group()\ndef get() -&gt; None:\n    \"\"\"Fetch properties on tables/namespaces.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.get_namespace","title":"<code>get_namespace(ctx, identifier, property_name)</code>","text":"<p>Fetch properties on a namespace.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@get.command(\"namespace\")\n@click.argument(\"identifier\")\n@click.argument(\"property_name\", required=False)\n@click.pass_context\n@catch_exception()\ndef get_namespace(ctx: Context, identifier: str, property_name: str) -&gt; None:\n    \"\"\"Fetch properties on a namespace.\"\"\"\n    catalog, output = _catalog_and_output(ctx)\n    identifier_tuple = Catalog.identifier_to_tuple(identifier)\n\n    namespace_properties = catalog.load_namespace_properties(identifier_tuple)\n    assert namespace_properties\n\n    if property_name:\n        if property_value := namespace_properties.get(property_name):\n            output.text(property_value)\n        else:\n            raise NoSuchPropertyException(f\"Could not find property {property_name} on namespace {identifier}\")\n    else:\n        output.describe_properties(namespace_properties)\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.get_table","title":"<code>get_table(ctx, identifier, property_name)</code>","text":"<p>Fetch properties on a table.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@get.command(\"table\")\n@click.argument(\"identifier\")\n@click.argument(\"property_name\", required=False)\n@click.pass_context\n@catch_exception()\ndef get_table(ctx: Context, identifier: str, property_name: str) -&gt; None:\n    \"\"\"Fetch properties on a table.\"\"\"\n    catalog, output = _catalog_and_output(ctx)\n    identifier_tuple = Catalog.identifier_to_tuple(identifier)\n\n    metadata = catalog.load_table(identifier_tuple).metadata\n    assert metadata\n\n    if property_name:\n        if property_value := metadata.properties.get(property_name):\n            output.text(property_value)\n        else:\n            raise NoSuchPropertyException(f\"Could not find property {property_name} on table {identifier}\")\n    else:\n        output.describe_properties(metadata.properties)\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.list","title":"<code>list(ctx, parent)</code>","text":"<p>List tables or namespaces.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@run.command()\n@click.pass_context\n@click.argument(\"parent\", required=False)\n@catch_exception()\ndef list(ctx: Context, parent: Optional[str]) -&gt; None:  # pylint: disable=redefined-builtin\n    \"\"\"List tables or namespaces.\"\"\"\n    catalog, output = _catalog_and_output(ctx)\n\n    identifiers = catalog.list_namespaces(parent or ())\n    if not identifiers and parent:\n        identifiers = catalog.list_tables(parent)\n    output.identifiers(identifiers)\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.list_refs","title":"<code>list_refs(ctx, identifier, type, verbose)</code>","text":"<p>List all the refs in the provided table.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@run.command()\n@click.argument(\"identifier\")\n@click.option(\"--type\", required=False)\n@click.option(\"--verbose\", type=click.BOOL)\n@click.pass_context\n@catch_exception()\ndef list_refs(ctx: Context, identifier: str, type: str, verbose: bool) -&gt; None:\n    \"\"\"List all the refs in the provided table.\"\"\"\n    catalog, output = _catalog_and_output(ctx)\n    table = catalog.load_table(identifier)\n    refs = table.refs()\n    if type:\n        type = type.lower()\n        if type not in {\"branch\", \"tag\"}:\n            raise ValueError(f\"Type must be either branch or tag, got: {type}\")\n\n    relevant_refs = [\n        (ref_name, ref.snapshot_ref_type, _retention_properties(ref, table.properties))\n        for (ref_name, ref) in refs.items()\n        if not type or ref.snapshot_ref_type == type\n    ]\n\n    output.describe_refs(relevant_refs)\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.location","title":"<code>location(ctx, identifier)</code>","text":"<p>Return the location of the table.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@run.command()\n@click.argument(\"identifier\")\n@click.pass_context\n@catch_exception()\ndef location(ctx: Context, identifier: str) -&gt; None:\n    \"\"\"Return the location of the table.\"\"\"\n    catalog, output = _catalog_and_output(ctx)\n    table = catalog.load_table(identifier)\n    output.text(table.location())\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.namespace","title":"<code>namespace(ctx, identifier, property_name)</code>","text":"<p>Remove a property from a namespace.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@remove.command()  # type: ignore\n@click.argument(\"identifier\")\n@click.argument(\"property_name\")\n@click.pass_context\n@catch_exception()\ndef namespace(ctx: Context, identifier: str, property_name: str) -&gt; None:  # noqa: F811\n    \"\"\"Remove a property from a namespace.\"\"\"\n    catalog, output = _catalog_and_output(ctx)\n\n    result = catalog.update_namespace_properties(identifier, removals={property_name})\n\n    if result.removed == [property_name]:\n        output.text(f\"Property {property_name} removed from {identifier}\")\n    else:\n        raise NoSuchPropertyException(f\"Property {property_name} does not exist on {identifier}\")\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.properties","title":"<code>properties()</code>","text":"<p>Properties on tables/namespaces.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@run.group()\ndef properties() -&gt; None:\n    \"\"\"Properties on tables/namespaces.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.remove","title":"<code>remove()</code>","text":"<p>Remove a property from tables/namespaces.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@properties.group()\ndef remove() -&gt; None:\n    \"\"\"Remove a property from tables/namespaces.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.rename","title":"<code>rename(ctx, from_identifier, to_identifier)</code>","text":"<p>Rename a table.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@run.command()\n@click.argument(\"from_identifier\")\n@click.argument(\"to_identifier\")\n@click.pass_context\n@catch_exception()\ndef rename(ctx: Context, from_identifier: str, to_identifier: str) -&gt; None:\n    \"\"\"Rename a table.\"\"\"\n    catalog, output = _catalog_and_output(ctx)\n\n    catalog.rename_table(from_identifier, to_identifier)\n    output.text(f\"Renamed table from {from_identifier} to {to_identifier}\")\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.schema","title":"<code>schema(ctx, identifier)</code>","text":"<p>Get the schema of the table.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@run.command()\n@click.argument(\"identifier\")\n@click.pass_context\n@catch_exception()\ndef schema(ctx: Context, identifier: str) -&gt; None:\n    \"\"\"Get the schema of the table.\"\"\"\n    catalog, output = _catalog_and_output(ctx)\n    table = catalog.load_table(identifier)\n    output.schema(table.schema())\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.set","title":"<code>set()</code>","text":"<p>Set a property on tables/namespaces.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@properties.group()\ndef set() -&gt; None:\n    \"\"\"Set a property on tables/namespaces.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.spec","title":"<code>spec(ctx, identifier)</code>","text":"<p>Return the partition spec of the table.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@run.command()\n@click.argument(\"identifier\")\n@click.pass_context\n@catch_exception()\ndef spec(ctx: Context, identifier: str) -&gt; None:\n    \"\"\"Return the partition spec of the table.\"\"\"\n    catalog, output = _catalog_and_output(ctx)\n    table = catalog.load_table(identifier)\n    output.spec(table.spec())\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.table","title":"<code>table(ctx, identifier, property_name)</code>","text":"<p>Remove a property from a table.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@remove.command()  # type: ignore\n@click.argument(\"identifier\")\n@click.argument(\"property_name\")\n@click.pass_context\n@catch_exception()\ndef table(ctx: Context, identifier: str, property_name: str) -&gt; None:  # noqa: F811\n    \"\"\"Remove a property from a table.\"\"\"\n    catalog, output = _catalog_and_output(ctx)\n    table = catalog.load_table(identifier)\n    if property_name in table.metadata.properties:\n        output.exception(NotImplementedError(\"Writing is WIP\"))\n        ctx.exit(1)\n    else:\n        raise NoSuchPropertyException(f\"Property {property_name} does not exist on {identifier}\")\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.uuid","title":"<code>uuid(ctx, identifier)</code>","text":"<p>Return the UUID of the table.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@run.command()\n@click.argument(\"identifier\")\n@click.pass_context\n@catch_exception()\ndef uuid(ctx: Context, identifier: str) -&gt; None:\n    \"\"\"Return the UUID of the table.\"\"\"\n    catalog, output = _catalog_and_output(ctx)\n    metadata = catalog.load_table(identifier).metadata\n    output.uuid(metadata.table_uuid)\n</code></pre>"},{"location":"reference/pyiceberg/cli/console/#pyiceberg.cli.console.version","title":"<code>version(ctx)</code>","text":"<p>Print pyiceberg version.</p> Source code in <code>pyiceberg/cli/console.py</code> <pre><code>@run.command()\n@click.pass_context\n@catch_exception()\ndef version(ctx: Context) -&gt; None:\n    \"\"\"Print pyiceberg version.\"\"\"\n    ctx.obj[\"output\"].version(__version__)\n</code></pre>"},{"location":"reference/pyiceberg/cli/output/","title":"output","text":""},{"location":"reference/pyiceberg/cli/output/#pyiceberg.cli.output.ConsoleOutput","title":"<code>ConsoleOutput</code>","text":"<p>             Bases: <code>Output</code></p> <p>Writes to the console.</p> Source code in <code>pyiceberg/cli/output.py</code> <pre><code>class ConsoleOutput(Output):\n    \"\"\"Writes to the console.\"\"\"\n\n    verbose: bool\n\n    def __init__(self, **properties: Any) -&gt; None:\n        self.verbose = properties.get(\"verbose\", False)\n\n    @property\n    def _table(self) -&gt; RichTable:\n        return RichTable.grid(padding=(0, 2))\n\n    def exception(self, ex: Exception) -&gt; None:\n        if self.verbose:\n            Console(stderr=True).print_exception()\n        else:\n            Console(stderr=True).print(ex)\n\n    def identifiers(self, identifiers: List[Identifier]) -&gt; None:\n        table = self._table\n        for identifier in identifiers:\n            table.add_row(\".\".join(identifier))\n\n        Console().print(table)\n\n    def describe_table(self, table: Table) -&gt; None:\n        metadata = table.metadata\n        table_properties = self._table\n\n        for key, value in metadata.properties.items():\n            table_properties.add_row(key, value)\n\n        schema_tree = Tree(f\"Schema, id={table.metadata.current_schema_id}\")\n        for field in table.schema().fields:\n            schema_tree.add(str(field))\n\n        snapshot_tree = Tree(\"Snapshots\")\n        for snapshot in metadata.snapshots:\n            manifest_list_str = f\": {snapshot.manifest_list}\" if snapshot.manifest_list else \"\"\n            snapshot_tree.add(f\"Snapshot {snapshot.snapshot_id}, schema {snapshot.schema_id}{manifest_list_str}\")\n\n        output_table = self._table\n        output_table.add_row(\"Table format version\", str(metadata.format_version))\n        output_table.add_row(\"Metadata location\", table.metadata_location)\n        output_table.add_row(\"Table UUID\", str(table.metadata.table_uuid))\n        output_table.add_row(\"Last Updated\", str(metadata.last_updated_ms))\n        output_table.add_row(\"Partition spec\", str(table.spec()))\n        output_table.add_row(\"Sort order\", str(table.sort_order()))\n        output_table.add_row(\"Current schema\", schema_tree)\n        output_table.add_row(\"Current snapshot\", str(table.current_snapshot()))\n        output_table.add_row(\"Snapshots\", snapshot_tree)\n        output_table.add_row(\"Properties\", table_properties)\n        Console().print(output_table)\n\n    def files(self, table: Table, history: bool) -&gt; None:\n        if history:\n            snapshots = table.metadata.snapshots\n        else:\n            if snapshot := table.current_snapshot():\n                snapshots = [snapshot]\n            else:\n                snapshots = []\n\n        snapshot_tree = Tree(f\"Snapshots: {'.'.join(table.identifier)}\")\n        io = table.io\n\n        for snapshot in snapshots:\n            manifest_list_str = f\": {snapshot.manifest_list}\" if snapshot.manifest_list else \"\"\n            list_tree = snapshot_tree.add(f\"Snapshot {snapshot.snapshot_id}, schema {snapshot.schema_id}{manifest_list_str}\")\n\n            manifest_list = snapshot.manifests(io)\n            for manifest in manifest_list:\n                manifest_tree = list_tree.add(f\"Manifest: {manifest.manifest_path}\")\n                for manifest_entry in manifest.fetch_manifest_entry(io, discard_deleted=False):\n                    manifest_tree.add(f\"Datafile: {manifest_entry.data_file.file_path}\")\n        Console().print(snapshot_tree)\n\n    def describe_properties(self, properties: Properties) -&gt; None:\n        output_table = self._table\n        for k, v in properties.items():\n            output_table.add_row(k, v)\n        Console().print(output_table)\n\n    def text(self, response: str) -&gt; None:\n        Console().print(response)\n\n    def schema(self, schema: Schema) -&gt; None:\n        output_table = self._table\n        for field in schema.fields:\n            output_table.add_row(field.name, str(field.field_type), field.doc or \"\")\n        Console().print(output_table)\n\n    def spec(self, spec: PartitionSpec) -&gt; None:\n        Console().print(str(spec))\n\n    def uuid(self, uuid: Optional[UUID]) -&gt; None:\n        Console().print(str(uuid) if uuid else \"missing\")\n\n    def version(self, version: str) -&gt; None:\n        Console().print(version)\n\n    def describe_refs(self, ref_details: List[Tuple[str, SnapshotRefType, Dict[str, str]]]) -&gt; None:\n        refs_table = RichTable(title=\"Snapshot Refs\")\n        refs_table.add_column(\"Ref\")\n        refs_table.add_column(\"Type\")\n        refs_table.add_column(\"Max ref age ms\")\n        refs_table.add_column(\"Min snapshots to keep\")\n        refs_table.add_column(\"Max snapshot age ms\")\n        for name, type, ref_detail in ref_details:\n            refs_table.add_row(\n                name, type, ref_detail[\"max_ref_age_ms\"], ref_detail[\"min_snapshots_to_keep\"], ref_detail[\"max_snapshot_age_ms\"]\n            )\n        Console().print(refs_table)\n</code></pre>"},{"location":"reference/pyiceberg/cli/output/#pyiceberg.cli.output.JsonOutput","title":"<code>JsonOutput</code>","text":"<p>             Bases: <code>Output</code></p> <p>Writes json to stdout.</p> Source code in <code>pyiceberg/cli/output.py</code> <pre><code>class JsonOutput(Output):\n    \"\"\"Writes json to stdout.\"\"\"\n\n    verbose: bool\n\n    def __init__(self, **properties: Any) -&gt; None:\n        self.verbose = properties.get(\"verbose\", False)\n\n    def _out(self, d: Any) -&gt; None:\n        print(json.dumps(d))\n\n    def exception(self, ex: Exception) -&gt; None:\n        self._out({\"type\": ex.__class__.__name__, \"message\": str(ex)})\n\n    def identifiers(self, identifiers: List[Identifier]) -&gt; None:\n        self._out([\".\".join(identifier) for identifier in identifiers])\n\n    def describe_table(self, table: Table) -&gt; None:\n        class FauxTable(IcebergBaseModel):\n            \"\"\"Just to encode it using Pydantic.\"\"\"\n\n            identifier: Identifier\n            metadata_location: str\n            metadata: TableMetadata\n\n        print(\n            FauxTable(\n                identifier=table.identifier, metadata=table.metadata, metadata_location=table.metadata_location\n            ).model_dump_json()\n        )\n\n    def describe_properties(self, properties: Properties) -&gt; None:\n        self._out(properties)\n\n    def text(self, response: str) -&gt; None:\n        print(json.dumps(response))\n\n    def schema(self, schema: Schema) -&gt; None:\n        print(schema.model_dump_json())\n\n    def files(self, table: Table, history: bool) -&gt; None:\n        pass\n\n    def spec(self, spec: PartitionSpec) -&gt; None:\n        print(spec.model_dump_json())\n\n    def uuid(self, uuid: Optional[UUID]) -&gt; None:\n        self._out({\"uuid\": str(uuid) if uuid else \"missing\"})\n\n    def version(self, version: str) -&gt; None:\n        self._out({\"version\": version})\n\n    def describe_refs(self, refs: List[Tuple[str, SnapshotRefType, Dict[str, str]]]) -&gt; None:\n        self._out([\n            {\"name\": name, \"type\": type, detail_key: detail_val}\n            for name, type, detail in refs\n            for detail_key, detail_val in detail.items()\n        ])\n</code></pre>"},{"location":"reference/pyiceberg/cli/output/#pyiceberg.cli.output.Output","title":"<code>Output</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Output interface for exporting.</p> Source code in <code>pyiceberg/cli/output.py</code> <pre><code>class Output(ABC):\n    \"\"\"Output interface for exporting.\"\"\"\n\n    @abstractmethod\n    def exception(self, ex: Exception) -&gt; None: ...\n\n    @abstractmethod\n    def identifiers(self, identifiers: List[Identifier]) -&gt; None: ...\n\n    @abstractmethod\n    def describe_table(self, table: Table) -&gt; None: ...\n\n    @abstractmethod\n    def files(self, table: Table, history: bool) -&gt; None: ...\n\n    @abstractmethod\n    def describe_properties(self, properties: Properties) -&gt; None: ...\n\n    @abstractmethod\n    def text(self, response: str) -&gt; None: ...\n\n    @abstractmethod\n    def schema(self, schema: Schema) -&gt; None: ...\n\n    @abstractmethod\n    def spec(self, spec: PartitionSpec) -&gt; None: ...\n\n    @abstractmethod\n    def uuid(self, uuid: Optional[UUID]) -&gt; None: ...\n\n    @abstractmethod\n    def version(self, version: str) -&gt; None: ...\n\n    @abstractmethod\n    def describe_refs(self, refs: List[Tuple[str, SnapshotRefType, Dict[str, str]]]) -&gt; None: ...\n</code></pre>"},{"location":"reference/pyiceberg/expressions/","title":"expressions","text":""},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.AlwaysFalse","title":"<code>AlwaysFalse</code>","text":"<p>             Bases: <code>BooleanExpression</code>, <code>Singleton</code></p> <p>FALSE expression.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class AlwaysFalse(BooleanExpression, Singleton):\n    \"\"\"FALSE expression.\"\"\"\n\n    def __invert__(self) -&gt; AlwaysTrue:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return AlwaysTrue()\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the AlwaysFalse class.\"\"\"\n        return \"AlwaysFalse()\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the AlwaysFalse class.\"\"\"\n        return \"AlwaysFalse()\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.AlwaysFalse.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; AlwaysTrue:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return AlwaysTrue()\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.AlwaysFalse.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the AlwaysFalse class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the AlwaysFalse class.\"\"\"\n    return \"AlwaysFalse()\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.AlwaysFalse.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the AlwaysFalse class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the AlwaysFalse class.\"\"\"\n    return \"AlwaysFalse()\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.AlwaysTrue","title":"<code>AlwaysTrue</code>","text":"<p>             Bases: <code>BooleanExpression</code>, <code>Singleton</code></p> <p>TRUE expression.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class AlwaysTrue(BooleanExpression, Singleton):\n    \"\"\"TRUE expression.\"\"\"\n\n    def __invert__(self) -&gt; AlwaysFalse:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return AlwaysFalse()\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the AlwaysTrue class.\"\"\"\n        return \"AlwaysTrue()\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the AlwaysTrue class.\"\"\"\n        return \"AlwaysTrue()\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.AlwaysTrue.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; AlwaysFalse:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return AlwaysFalse()\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.AlwaysTrue.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the AlwaysTrue class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the AlwaysTrue class.\"\"\"\n    return \"AlwaysTrue()\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.AlwaysTrue.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the AlwaysTrue class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the AlwaysTrue class.\"\"\"\n    return \"AlwaysTrue()\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.And","title":"<code>And</code>","text":"<p>             Bases: <code>BooleanExpression</code></p> <p>AND operation expression - logical conjunction.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class And(BooleanExpression):\n    \"\"\"AND operation expression - logical conjunction.\"\"\"\n\n    left: BooleanExpression\n    right: BooleanExpression\n\n    def __new__(cls, left: BooleanExpression, right: BooleanExpression, *rest: BooleanExpression) -&gt; BooleanExpression:  # type: ignore\n        if rest:\n            return reduce(And, (left, right, *rest))\n        if left is AlwaysFalse() or right is AlwaysFalse():\n            return AlwaysFalse()\n        elif left is AlwaysTrue():\n            return right\n        elif right is AlwaysTrue():\n            return left\n        else:\n            obj = super().__new__(cls)\n            obj.left = left\n            obj.right = right\n            return obj\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the And class.\"\"\"\n        return self.left == other.left and self.right == other.right if isinstance(other, And) else False\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the And class.\"\"\"\n        return f\"And(left={str(self.left)}, right={str(self.right)})\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the And class.\"\"\"\n        return f\"And(left={repr(self.left)}, right={repr(self.right)})\"\n\n    def __invert__(self) -&gt; BooleanExpression:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        # De Morgan's law: not (A and B) = (not A) or (not B)\n        return Or(~self.left, ~self.right)\n\n    def __getnewargs__(self) -&gt; Tuple[BooleanExpression, BooleanExpression]:\n        \"\"\"Pickle the And class.\"\"\"\n        return (self.left, self.right)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.And.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the And class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the And class.\"\"\"\n    return self.left == other.left and self.right == other.right if isinstance(other, And) else False\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.And.__getnewargs__","title":"<code>__getnewargs__()</code>","text":"<p>Pickle the And class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __getnewargs__(self) -&gt; Tuple[BooleanExpression, BooleanExpression]:\n    \"\"\"Pickle the And class.\"\"\"\n    return (self.left, self.right)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.And.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BooleanExpression:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    # De Morgan's law: not (A and B) = (not A) or (not B)\n    return Or(~self.left, ~self.right)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.And.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the And class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the And class.\"\"\"\n    return f\"And(left={repr(self.left)}, right={repr(self.right)})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.And.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the And class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the And class.\"\"\"\n    return f\"And(left={str(self.left)}, right={str(self.right)})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BooleanExpression","title":"<code>BooleanExpression</code>","text":"<p>             Bases: <code>ABC</code></p> <p>An expression that evaluates to a boolean.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BooleanExpression(ABC):\n    \"\"\"An expression that evaluates to a boolean.\"\"\"\n\n    @abstractmethod\n    def __invert__(self) -&gt; BooleanExpression:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BooleanExpression.__invert__","title":"<code>__invert__()</code>  <code>abstractmethod</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>@abstractmethod\ndef __invert__(self) -&gt; BooleanExpression:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Bound","title":"<code>Bound</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Represents a bound value expression.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class Bound(ABC):\n    \"\"\"Represents a bound value expression.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundEqualTo","title":"<code>BoundEqualTo</code>","text":"<p>             Bases: <code>BoundLiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundEqualTo(BoundLiteralPredicate[L]):\n    def __invert__(self) -&gt; BoundNotEqualTo[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundNotEqualTo[L](self.term, self.literal)\n\n    @property\n    def as_unbound(self) -&gt; Type[EqualTo[L]]:\n        return EqualTo\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundEqualTo.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundNotEqualTo[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundNotEqualTo[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundGreaterThan","title":"<code>BoundGreaterThan</code>","text":"<p>             Bases: <code>BoundLiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundGreaterThan(BoundLiteralPredicate[L]):\n    def __invert__(self) -&gt; BoundLessThanOrEqual[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundLessThanOrEqual(self.term, self.literal)\n\n    @property\n    def as_unbound(self) -&gt; Type[GreaterThan[L]]:\n        return GreaterThan[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundGreaterThan.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundLessThanOrEqual[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundLessThanOrEqual(self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundGreaterThanOrEqual","title":"<code>BoundGreaterThanOrEqual</code>","text":"<p>             Bases: <code>BoundLiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundGreaterThanOrEqual(BoundLiteralPredicate[L]):\n    def __invert__(self) -&gt; BoundLessThan[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundLessThan[L](self.term, self.literal)\n\n    @property\n    def as_unbound(self) -&gt; Type[GreaterThanOrEqual[L]]:\n        return GreaterThanOrEqual[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundGreaterThanOrEqual.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundLessThan[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundLessThan[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundIn","title":"<code>BoundIn</code>","text":"<p>             Bases: <code>BoundSetPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundIn(BoundSetPredicate[L]):\n    def __new__(cls, term: BoundTerm[L], literals: Set[Literal[L]]) -&gt; BooleanExpression:  # type: ignore  # pylint: disable=W0221\n        count = len(literals)\n        if count == 0:\n            return AlwaysFalse()\n        elif count == 1:\n            return BoundEqualTo(term, next(iter(literals)))\n        else:\n            return super().__new__(cls)\n\n    def __invert__(self) -&gt; BoundNotIn[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundNotIn(self.term, self.literals)\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the BoundIn class.\"\"\"\n        return self.term == other.term and self.literals == other.literals if isinstance(other, self.__class__) else False\n\n    @property\n    def as_unbound(self) -&gt; Type[In[L]]:\n        return In\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundIn.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the BoundIn class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the BoundIn class.\"\"\"\n    return self.term == other.term and self.literals == other.literals if isinstance(other, self.__class__) else False\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundIn.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundNotIn[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundNotIn(self.term, self.literals)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundIsNaN","title":"<code>BoundIsNaN</code>","text":"<p>             Bases: <code>BoundUnaryPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundIsNaN(BoundUnaryPredicate[L]):\n    def __new__(cls, term: BoundTerm[L]) -&gt; BooleanExpression:  # type: ignore  # pylint: disable=W0221\n        bound_type = term.ref().field.field_type\n        if isinstance(bound_type, (FloatType, DoubleType)):\n            return super().__new__(cls)\n        return AlwaysFalse()\n\n    def __invert__(self) -&gt; BoundNotNaN[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundNotNaN(self.term)\n\n    @property\n    def as_unbound(self) -&gt; Type[IsNaN]:\n        return IsNaN\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundIsNaN.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundNotNaN[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundNotNaN(self.term)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundIsNull","title":"<code>BoundIsNull</code>","text":"<p>             Bases: <code>BoundUnaryPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundIsNull(BoundUnaryPredicate[L]):\n    def __new__(cls, term: BoundTerm[L]) -&gt; BooleanExpression:  # type: ignore  # pylint: disable=W0221\n        if term.ref().field.required:\n            return AlwaysFalse()\n        return super().__new__(cls)\n\n    def __invert__(self) -&gt; BoundNotNull[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundNotNull(self.term)\n\n    @property\n    def as_unbound(self) -&gt; Type[IsNull]:\n        return IsNull\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundIsNull.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundNotNull[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundNotNull(self.term)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundLessThan","title":"<code>BoundLessThan</code>","text":"<p>             Bases: <code>BoundLiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundLessThan(BoundLiteralPredicate[L]):\n    def __invert__(self) -&gt; BoundGreaterThanOrEqual[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundGreaterThanOrEqual[L](self.term, self.literal)\n\n    @property\n    def as_unbound(self) -&gt; Type[LessThan[L]]:\n        return LessThan[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundLessThan.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundGreaterThanOrEqual[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundGreaterThanOrEqual[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundLessThanOrEqual","title":"<code>BoundLessThanOrEqual</code>","text":"<p>             Bases: <code>BoundLiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundLessThanOrEqual(BoundLiteralPredicate[L]):\n    def __invert__(self) -&gt; BoundGreaterThan[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundGreaterThan[L](self.term, self.literal)\n\n    @property\n    def as_unbound(self) -&gt; Type[LessThanOrEqual[L]]:\n        return LessThanOrEqual[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundLessThanOrEqual.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundGreaterThan[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundGreaterThan[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundLiteralPredicate","title":"<code>BoundLiteralPredicate</code>","text":"<p>             Bases: <code>BoundPredicate[L]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundLiteralPredicate(BoundPredicate[L], ABC):\n    literal: Literal[L]\n\n    def __init__(self, term: BoundTerm[L], literal: Literal[L]):  # pylint: disable=W0621\n        # Since we don't know the type of BoundPredicate[L], we have to ignore this one\n        super().__init__(term)  # type: ignore\n        self.literal = literal  # pylint: disable=W0621\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the BoundLiteralPredicate class.\"\"\"\n        if isinstance(other, self.__class__):\n            return self.term == other.term and self.literal == other.literal\n        return False\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the BoundLiteralPredicate class.\"\"\"\n        return f\"{str(self.__class__.__name__)}(term={repr(self.term)}, literal={repr(self.literal)})\"\n\n    @property\n    @abstractmethod\n    def as_unbound(self) -&gt; Type[LiteralPredicate[L]]: ...\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundLiteralPredicate.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the BoundLiteralPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the BoundLiteralPredicate class.\"\"\"\n    if isinstance(other, self.__class__):\n        return self.term == other.term and self.literal == other.literal\n    return False\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundLiteralPredicate.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the BoundLiteralPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the BoundLiteralPredicate class.\"\"\"\n    return f\"{str(self.__class__.__name__)}(term={repr(self.term)}, literal={repr(self.literal)})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundNotEqualTo","title":"<code>BoundNotEqualTo</code>","text":"<p>             Bases: <code>BoundLiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundNotEqualTo(BoundLiteralPredicate[L]):\n    def __invert__(self) -&gt; BoundEqualTo[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundEqualTo[L](self.term, self.literal)\n\n    @property\n    def as_unbound(self) -&gt; Type[NotEqualTo[L]]:\n        return NotEqualTo\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundNotEqualTo.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundEqualTo[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundEqualTo[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundNotIn","title":"<code>BoundNotIn</code>","text":"<p>             Bases: <code>BoundSetPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundNotIn(BoundSetPredicate[L]):\n    def __new__(  # type: ignore  # pylint: disable=W0221\n        cls,\n        term: BoundTerm[L],\n        literals: Set[Literal[L]],\n    ) -&gt; BooleanExpression:\n        count = len(literals)\n        if count == 0:\n            return AlwaysTrue()\n        elif count == 1:\n            return BoundNotEqualTo(term, next(iter(literals)))\n        else:\n            return super().__new__(cls)\n\n    def __invert__(self) -&gt; BoundIn[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundIn(self.term, self.literals)\n\n    @property\n    def as_unbound(self) -&gt; Type[NotIn[L]]:\n        return NotIn\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundNotIn.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundIn[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundIn(self.term, self.literals)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundNotNaN","title":"<code>BoundNotNaN</code>","text":"<p>             Bases: <code>BoundUnaryPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundNotNaN(BoundUnaryPredicate[L]):\n    def __new__(cls, term: BoundTerm[L]) -&gt; BooleanExpression:  # type: ignore  # pylint: disable=W0221\n        bound_type = term.ref().field.field_type\n        if isinstance(bound_type, (FloatType, DoubleType)):\n            return super().__new__(cls)\n        return AlwaysTrue()\n\n    def __invert__(self) -&gt; BoundIsNaN[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundIsNaN(self.term)\n\n    @property\n    def as_unbound(self) -&gt; Type[NotNaN]:\n        return NotNaN\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundNotNaN.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundIsNaN[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundIsNaN(self.term)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundNotNull","title":"<code>BoundNotNull</code>","text":"<p>             Bases: <code>BoundUnaryPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundNotNull(BoundUnaryPredicate[L]):\n    def __new__(cls, term: BoundTerm[L]):  # type: ignore  # pylint: disable=W0221\n        if term.ref().field.required:\n            return AlwaysTrue()\n        return super().__new__(cls)\n\n    def __invert__(self) -&gt; BoundIsNull[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundIsNull(self.term)\n\n    @property\n    def as_unbound(self) -&gt; Type[NotNull]:\n        return NotNull\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundNotNull.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundIsNull[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundIsNull(self.term)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundNotStartsWith","title":"<code>BoundNotStartsWith</code>","text":"<p>             Bases: <code>BoundLiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundNotStartsWith(BoundLiteralPredicate[L]):\n    def __invert__(self) -&gt; BoundStartsWith[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundStartsWith[L](self.term, self.literal)\n\n    @property\n    def as_unbound(self) -&gt; Type[NotStartsWith[L]]:\n        return NotStartsWith[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundNotStartsWith.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundStartsWith[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundStartsWith[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundPredicate","title":"<code>BoundPredicate</code>","text":"<p>             Bases: <code>Generic[L]</code>, <code>Bound</code>, <code>BooleanExpression</code>, <code>ABC</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundPredicate(Generic[L], Bound, BooleanExpression, ABC):\n    term: BoundTerm[L]\n\n    def __init__(self, term: BoundTerm[L]):\n        self.term = term\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the BoundPredicate class.\"\"\"\n        if isinstance(other, self.__class__):\n            return self.term == other.term\n        return False\n\n    @property\n    @abstractmethod\n    def as_unbound(self) -&gt; Type[UnboundPredicate[Any]]: ...\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundPredicate.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the BoundPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the BoundPredicate class.\"\"\"\n    if isinstance(other, self.__class__):\n        return self.term == other.term\n    return False\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundReference","title":"<code>BoundReference</code>","text":"<p>             Bases: <code>BoundTerm[L]</code></p> <p>A reference bound to a field in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>NestedField</code> <p>A referenced field in an Iceberg schema.</p> required <code>accessor</code> <code>Accessor</code> <p>An Accessor object to access the value at the field's position.</p> required Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundReference(BoundTerm[L]):\n    \"\"\"A reference bound to a field in a schema.\n\n    Args:\n        field (NestedField): A referenced field in an Iceberg schema.\n        accessor (Accessor): An Accessor object to access the value at the field's position.\n    \"\"\"\n\n    field: NestedField\n    accessor: Accessor\n\n    def __init__(self, field: NestedField, accessor: Accessor):\n        self.field = field\n        self.accessor = accessor\n\n    def eval(self, struct: StructProtocol) -&gt; L:\n        \"\"\"Return the value at the referenced field's position in an object that abides by the StructProtocol.\n\n        Args:\n            struct (StructProtocol): A row object that abides by the StructProtocol and returns values given a position.\n        Returns:\n            Any: The value at the referenced field's position in `struct`.\n        \"\"\"\n        return self.accessor.get(struct)\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the BoundReference class.\"\"\"\n        return self.field == other.field if isinstance(other, BoundReference) else False\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the BoundReference class.\"\"\"\n        return f\"BoundReference(field={repr(self.field)}, accessor={repr(self.accessor)})\"\n\n    def ref(self) -&gt; BoundReference[L]:\n        return self\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundReference.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the BoundReference class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the BoundReference class.\"\"\"\n    return self.field == other.field if isinstance(other, BoundReference) else False\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundReference.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the BoundReference class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the BoundReference class.\"\"\"\n    return f\"BoundReference(field={repr(self.field)}, accessor={repr(self.accessor)})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundReference.eval","title":"<code>eval(struct)</code>","text":"<p>Return the value at the referenced field's position in an object that abides by the StructProtocol.</p> <p>Parameters:</p> Name Type Description Default <code>struct</code> <code>StructProtocol</code> <p>A row object that abides by the StructProtocol and returns values given a position.</p> required <p>Returns:     Any: The value at the referenced field's position in <code>struct</code>.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def eval(self, struct: StructProtocol) -&gt; L:\n    \"\"\"Return the value at the referenced field's position in an object that abides by the StructProtocol.\n\n    Args:\n        struct (StructProtocol): A row object that abides by the StructProtocol and returns values given a position.\n    Returns:\n        Any: The value at the referenced field's position in `struct`.\n    \"\"\"\n    return self.accessor.get(struct)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundSetPredicate","title":"<code>BoundSetPredicate</code>","text":"<p>             Bases: <code>BoundPredicate[L]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundSetPredicate(BoundPredicate[L], ABC):\n    literals: Set[Literal[L]]\n\n    def __init__(self, term: BoundTerm[L], literals: Set[Literal[L]]):\n        # Since we don't know the type of BoundPredicate[L], we have to ignore this one\n        super().__init__(term)  # type: ignore\n        self.literals = _to_literal_set(literals)  # pylint: disable=W0621\n\n    @cached_property\n    def value_set(self) -&gt; Set[L]:\n        return {lit.value for lit in self.literals}\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the BoundSetPredicate class.\"\"\"\n        # Sort to make it deterministic\n        return f\"{str(self.__class__.__name__)}({str(self.term)}, {{{', '.join(sorted([str(literal) for literal in self.literals]))}}})\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the BoundSetPredicate class.\"\"\"\n        # Sort to make it deterministic\n        return f\"{str(self.__class__.__name__)}({repr(self.term)}, {{{', '.join(sorted([repr(literal) for literal in self.literals]))}}})\"\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the BoundSetPredicate class.\"\"\"\n        return self.term == other.term and self.literals == other.literals if isinstance(other, self.__class__) else False\n\n    def __getnewargs__(self) -&gt; Tuple[BoundTerm[L], Set[Literal[L]]]:\n        \"\"\"Pickle the BoundSetPredicate class.\"\"\"\n        return (self.term, self.literals)\n\n    @property\n    @abstractmethod\n    def as_unbound(self) -&gt; Type[SetPredicate[L]]: ...\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundSetPredicate.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the BoundSetPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the BoundSetPredicate class.\"\"\"\n    return self.term == other.term and self.literals == other.literals if isinstance(other, self.__class__) else False\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundSetPredicate.__getnewargs__","title":"<code>__getnewargs__()</code>","text":"<p>Pickle the BoundSetPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __getnewargs__(self) -&gt; Tuple[BoundTerm[L], Set[Literal[L]]]:\n    \"\"\"Pickle the BoundSetPredicate class.\"\"\"\n    return (self.term, self.literals)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundSetPredicate.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the BoundSetPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the BoundSetPredicate class.\"\"\"\n    # Sort to make it deterministic\n    return f\"{str(self.__class__.__name__)}({repr(self.term)}, {{{', '.join(sorted([repr(literal) for literal in self.literals]))}}})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundSetPredicate.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the BoundSetPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the BoundSetPredicate class.\"\"\"\n    # Sort to make it deterministic\n    return f\"{str(self.__class__.__name__)}({str(self.term)}, {{{', '.join(sorted([str(literal) for literal in self.literals]))}}})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundStartsWith","title":"<code>BoundStartsWith</code>","text":"<p>             Bases: <code>BoundLiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundStartsWith(BoundLiteralPredicate[L]):\n    def __invert__(self) -&gt; BoundNotStartsWith[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return BoundNotStartsWith[L](self.term, self.literal)\n\n    @property\n    def as_unbound(self) -&gt; Type[StartsWith[L]]:\n        return StartsWith[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundStartsWith.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BoundNotStartsWith[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return BoundNotStartsWith[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundTerm","title":"<code>BoundTerm</code>","text":"<p>             Bases: <code>Term[L]</code>, <code>Bound</code>, <code>ABC</code></p> <p>Represents a bound term.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundTerm(Term[L], Bound, ABC):\n    \"\"\"Represents a bound term.\"\"\"\n\n    @abstractmethod\n    def ref(self) -&gt; BoundReference[L]:\n        \"\"\"Return the bound reference.\"\"\"\n\n    @abstractmethod\n    def eval(self, struct: StructProtocol) -&gt; L:  # pylint: disable=W0613\n        \"\"\"Return the value at the referenced field's position in an object that abides by the StructProtocol.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundTerm.eval","title":"<code>eval(struct)</code>  <code>abstractmethod</code>","text":"<p>Return the value at the referenced field's position in an object that abides by the StructProtocol.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>@abstractmethod\ndef eval(self, struct: StructProtocol) -&gt; L:  # pylint: disable=W0613\n    \"\"\"Return the value at the referenced field's position in an object that abides by the StructProtocol.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundTerm.ref","title":"<code>ref()</code>  <code>abstractmethod</code>","text":"<p>Return the bound reference.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>@abstractmethod\ndef ref(self) -&gt; BoundReference[L]:\n    \"\"\"Return the bound reference.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundUnaryPredicate","title":"<code>BoundUnaryPredicate</code>","text":"<p>             Bases: <code>BoundPredicate[L]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class BoundUnaryPredicate(BoundPredicate[L], ABC):\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the BoundUnaryPredicate class.\"\"\"\n        return f\"{str(self.__class__.__name__)}(term={repr(self.term)})\"\n\n    @property\n    @abstractmethod\n    def as_unbound(self) -&gt; Type[UnaryPredicate]: ...\n\n    def __getnewargs__(self) -&gt; Tuple[BoundTerm[L]]:\n        \"\"\"Pickle the BoundUnaryPredicate class.\"\"\"\n        return (self.term,)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundUnaryPredicate.__getnewargs__","title":"<code>__getnewargs__()</code>","text":"<p>Pickle the BoundUnaryPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __getnewargs__(self) -&gt; Tuple[BoundTerm[L]]:\n    \"\"\"Pickle the BoundUnaryPredicate class.\"\"\"\n    return (self.term,)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.BoundUnaryPredicate.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the BoundUnaryPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the BoundUnaryPredicate class.\"\"\"\n    return f\"{str(self.__class__.__name__)}(term={repr(self.term)})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.EqualTo","title":"<code>EqualTo</code>","text":"<p>             Bases: <code>LiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class EqualTo(LiteralPredicate[L]):\n    def __invert__(self) -&gt; NotEqualTo[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return NotEqualTo[L](self.term, self.literal)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundEqualTo[L]]:\n        return BoundEqualTo[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.EqualTo.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; NotEqualTo[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return NotEqualTo[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.GreaterThan","title":"<code>GreaterThan</code>","text":"<p>             Bases: <code>LiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class GreaterThan(LiteralPredicate[L]):\n    def __invert__(self) -&gt; LessThanOrEqual[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return LessThanOrEqual[L](self.term, self.literal)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundGreaterThan[L]]:\n        return BoundGreaterThan[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.GreaterThan.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; LessThanOrEqual[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return LessThanOrEqual[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.GreaterThanOrEqual","title":"<code>GreaterThanOrEqual</code>","text":"<p>             Bases: <code>LiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class GreaterThanOrEqual(LiteralPredicate[L]):\n    def __invert__(self) -&gt; LessThan[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return LessThan[L](self.term, self.literal)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundGreaterThanOrEqual[L]]:\n        return BoundGreaterThanOrEqual[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.GreaterThanOrEqual.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; LessThan[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return LessThan[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.In","title":"<code>In</code>","text":"<p>             Bases: <code>SetPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class In(SetPredicate[L]):\n    def __new__(  # type: ignore  # pylint: disable=W0221\n        cls, term: Union[str, UnboundTerm[Any]], literals: Union[Iterable[L], Iterable[Literal[L]]]\n    ) -&gt; BooleanExpression:\n        literals_set: Set[Literal[L]] = _to_literal_set(literals)\n        count = len(literals_set)\n        if count == 0:\n            return AlwaysFalse()\n        elif count == 1:\n            return EqualTo(term, next(iter(literals)))  # type: ignore\n        else:\n            return super().__new__(cls)\n\n    def __invert__(self) -&gt; NotIn[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return NotIn[L](self.term, self.literals)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundIn[L]]:\n        return BoundIn[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.In.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; NotIn[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return NotIn[L](self.term, self.literals)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.IsNaN","title":"<code>IsNaN</code>","text":"<p>             Bases: <code>UnaryPredicate</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class IsNaN(UnaryPredicate):\n    def __invert__(self) -&gt; NotNaN:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return NotNaN(self.term)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundIsNaN[L]]:\n        return BoundIsNaN[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.IsNaN.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; NotNaN:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return NotNaN(self.term)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.IsNull","title":"<code>IsNull</code>","text":"<p>             Bases: <code>UnaryPredicate</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class IsNull(UnaryPredicate):\n    def __invert__(self) -&gt; NotNull:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return NotNull(self.term)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundIsNull[L]]:\n        return BoundIsNull[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.IsNull.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; NotNull:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return NotNull(self.term)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.LessThan","title":"<code>LessThan</code>","text":"<p>             Bases: <code>LiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class LessThan(LiteralPredicate[L]):\n    def __invert__(self) -&gt; GreaterThanOrEqual[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return GreaterThanOrEqual[L](self.term, self.literal)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundLessThan[L]]:\n        return BoundLessThan[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.LessThan.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; GreaterThanOrEqual[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return GreaterThanOrEqual[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.LessThanOrEqual","title":"<code>LessThanOrEqual</code>","text":"<p>             Bases: <code>LiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class LessThanOrEqual(LiteralPredicate[L]):\n    def __invert__(self) -&gt; GreaterThan[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return GreaterThan[L](self.term, self.literal)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundLessThanOrEqual[L]]:\n        return BoundLessThanOrEqual[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.LessThanOrEqual.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; GreaterThan[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return GreaterThan[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.LiteralPredicate","title":"<code>LiteralPredicate</code>","text":"<p>             Bases: <code>UnboundPredicate[L]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class LiteralPredicate(UnboundPredicate[L], ABC):\n    literal: Literal[L]\n\n    def __init__(self, term: Union[str, UnboundTerm[Any]], literal: Union[L, Literal[L]]):  # pylint: disable=W0621\n        super().__init__(term)\n        self.literal = _to_literal(literal)  # pylint: disable=W0621\n\n    def bind(self, schema: Schema, case_sensitive: bool = True) -&gt; BoundLiteralPredicate[L]:\n        bound_term = self.term.bind(schema, case_sensitive)\n        lit = self.literal.to(bound_term.ref().field.field_type)\n\n        if isinstance(lit, AboveMax):\n            if isinstance(self, (LessThan, LessThanOrEqual, NotEqualTo)):\n                return AlwaysTrue()  # type: ignore\n            elif isinstance(self, (GreaterThan, GreaterThanOrEqual, EqualTo)):\n                return AlwaysFalse()  # type: ignore\n        elif isinstance(lit, BelowMin):\n            if isinstance(self, (GreaterThan, GreaterThanOrEqual, NotEqualTo)):\n                return AlwaysTrue()  # type: ignore\n            elif isinstance(self, (LessThan, LessThanOrEqual, EqualTo)):\n                return AlwaysFalse()  # type: ignore\n\n        return self.as_bound(bound_term, lit)\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the LiteralPredicate class.\"\"\"\n        if isinstance(other, self.__class__):\n            return self.term == other.term and self.literal == other.literal\n        return False\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the LiteralPredicate class.\"\"\"\n        return f\"{str(self.__class__.__name__)}(term={repr(self.term)}, literal={repr(self.literal)})\"\n\n    @property\n    @abstractmethod\n    def as_bound(self) -&gt; Type[BoundLiteralPredicate[L]]: ...\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.LiteralPredicate.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the LiteralPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the LiteralPredicate class.\"\"\"\n    if isinstance(other, self.__class__):\n        return self.term == other.term and self.literal == other.literal\n    return False\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.LiteralPredicate.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the LiteralPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the LiteralPredicate class.\"\"\"\n    return f\"{str(self.__class__.__name__)}(term={repr(self.term)}, literal={repr(self.literal)})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Not","title":"<code>Not</code>","text":"<p>             Bases: <code>BooleanExpression</code></p> <p>NOT operation expression - logical negation.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class Not(BooleanExpression):\n    \"\"\"NOT operation expression - logical negation.\"\"\"\n\n    child: BooleanExpression\n\n    def __new__(cls, child: BooleanExpression) -&gt; BooleanExpression:  # type: ignore\n        if child is AlwaysTrue():\n            return AlwaysFalse()\n        elif child is AlwaysFalse():\n            return AlwaysTrue()\n        elif isinstance(child, Not):\n            return child.child\n        obj = super().__new__(cls)\n        obj.child = child\n        return obj\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the Not class.\"\"\"\n        return f\"Not(child={repr(self.child)})\"\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the Not class.\"\"\"\n        return self.child == other.child if isinstance(other, Not) else False\n\n    def __invert__(self) -&gt; BooleanExpression:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return self.child\n\n    def __getnewargs__(self) -&gt; Tuple[BooleanExpression]:\n        \"\"\"Pickle the Not class.\"\"\"\n        return (self.child,)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Not.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the Not class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the Not class.\"\"\"\n    return self.child == other.child if isinstance(other, Not) else False\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Not.__getnewargs__","title":"<code>__getnewargs__()</code>","text":"<p>Pickle the Not class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __getnewargs__(self) -&gt; Tuple[BooleanExpression]:\n    \"\"\"Pickle the Not class.\"\"\"\n    return (self.child,)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Not.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BooleanExpression:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return self.child\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Not.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the Not class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the Not class.\"\"\"\n    return f\"Not(child={repr(self.child)})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.NotEqualTo","title":"<code>NotEqualTo</code>","text":"<p>             Bases: <code>LiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class NotEqualTo(LiteralPredicate[L]):\n    def __invert__(self) -&gt; EqualTo[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return EqualTo[L](self.term, self.literal)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundNotEqualTo[L]]:\n        return BoundNotEqualTo[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.NotEqualTo.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; EqualTo[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return EqualTo[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.NotIn","title":"<code>NotIn</code>","text":"<p>             Bases: <code>SetPredicate[L]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class NotIn(SetPredicate[L], ABC):\n    def __new__(  # type: ignore  # pylint: disable=W0221\n        cls, term: Union[str, UnboundTerm[Any]], literals: Union[Iterable[L], Iterable[Literal[L]]]\n    ) -&gt; BooleanExpression:\n        literals_set: Set[Literal[L]] = _to_literal_set(literals)\n        count = len(literals_set)\n        if count == 0:\n            return AlwaysTrue()\n        elif count == 1:\n            return NotEqualTo(term, next(iter(literals_set)))\n        else:\n            return super().__new__(cls)\n\n    def __invert__(self) -&gt; In[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return In[L](self.term, self.literals)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundNotIn[L]]:\n        return BoundNotIn[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.NotIn.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; In[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return In[L](self.term, self.literals)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.NotNaN","title":"<code>NotNaN</code>","text":"<p>             Bases: <code>UnaryPredicate</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class NotNaN(UnaryPredicate):\n    def __invert__(self) -&gt; IsNaN:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return IsNaN(self.term)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundNotNaN[L]]:\n        return BoundNotNaN[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.NotNaN.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; IsNaN:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return IsNaN(self.term)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.NotNull","title":"<code>NotNull</code>","text":"<p>             Bases: <code>UnaryPredicate</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class NotNull(UnaryPredicate):\n    def __invert__(self) -&gt; IsNull:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return IsNull(self.term)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundNotNull[L]]:\n        return BoundNotNull[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.NotNull.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; IsNull:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return IsNull(self.term)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.NotStartsWith","title":"<code>NotStartsWith</code>","text":"<p>             Bases: <code>LiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class NotStartsWith(LiteralPredicate[L]):\n    def __invert__(self) -&gt; StartsWith[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return StartsWith[L](self.term, self.literal)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundNotStartsWith[L]]:\n        return BoundNotStartsWith[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.NotStartsWith.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; StartsWith[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return StartsWith[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Or","title":"<code>Or</code>","text":"<p>             Bases: <code>BooleanExpression</code></p> <p>OR operation expression - logical disjunction.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class Or(BooleanExpression):\n    \"\"\"OR operation expression - logical disjunction.\"\"\"\n\n    left: BooleanExpression\n    right: BooleanExpression\n\n    def __new__(cls, left: BooleanExpression, right: BooleanExpression, *rest: BooleanExpression) -&gt; BooleanExpression:  # type: ignore\n        if rest:\n            return reduce(Or, (left, right, *rest))\n        if left is AlwaysTrue() or right is AlwaysTrue():\n            return AlwaysTrue()\n        elif left is AlwaysFalse():\n            return right\n        elif right is AlwaysFalse():\n            return left\n        else:\n            obj = super().__new__(cls)\n            obj.left = left\n            obj.right = right\n            return obj\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the Or class.\"\"\"\n        return self.left == other.left and self.right == other.right if isinstance(other, Or) else False\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the Or class.\"\"\"\n        return f\"Or(left={repr(self.left)}, right={repr(self.right)})\"\n\n    def __invert__(self) -&gt; BooleanExpression:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        # De Morgan's law: not (A or B) = (not A) and (not B)\n        return And(~self.left, ~self.right)\n\n    def __getnewargs__(self) -&gt; Tuple[BooleanExpression, BooleanExpression]:\n        \"\"\"Pickle the Or class.\"\"\"\n        return (self.left, self.right)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Or.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the Or class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the Or class.\"\"\"\n    return self.left == other.left and self.right == other.right if isinstance(other, Or) else False\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Or.__getnewargs__","title":"<code>__getnewargs__()</code>","text":"<p>Pickle the Or class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __getnewargs__(self) -&gt; Tuple[BooleanExpression, BooleanExpression]:\n    \"\"\"Pickle the Or class.\"\"\"\n    return (self.left, self.right)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Or.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; BooleanExpression:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    # De Morgan's law: not (A or B) = (not A) and (not B)\n    return And(~self.left, ~self.right)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Or.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the Or class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the Or class.\"\"\"\n    return f\"Or(left={repr(self.left)}, right={repr(self.right)})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Reference","title":"<code>Reference</code>","text":"<p>             Bases: <code>UnboundTerm[Any]</code></p> <p>A reference not yet bound to a field in a schema.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the field.</p> required Note <p>An unbound reference is sometimes referred to as a \"named\" reference.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class Reference(UnboundTerm[Any]):\n    \"\"\"A reference not yet bound to a field in a schema.\n\n    Args:\n        name (str): The name of the field.\n\n    Note:\n        An unbound reference is sometimes referred to as a \"named\" reference.\n    \"\"\"\n\n    name: str\n\n    def __init__(self, name: str) -&gt; None:\n        self.name = name\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the Reference class.\"\"\"\n        return f\"Reference(name={repr(self.name)})\"\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the Reference class.\"\"\"\n        return self.name == other.name if isinstance(other, Reference) else False\n\n    def bind(self, schema: Schema, case_sensitive: bool = True) -&gt; BoundReference[L]:\n        \"\"\"Bind the reference to an Iceberg schema.\n\n        Args:\n            schema (Schema): An Iceberg schema.\n            case_sensitive (bool): Whether to consider case when binding the reference to the field.\n\n        Raises:\n            ValueError: If an empty name is provided.\n\n        Returns:\n            BoundReference: A reference bound to the specific field in the Iceberg schema.\n        \"\"\"\n        field = schema.find_field(name_or_id=self.name, case_sensitive=case_sensitive)\n        accessor = schema.accessor_for_field(field.field_id)\n        return self.as_bound(field=field, accessor=accessor)  # type: ignore\n\n    @property\n    def as_bound(self) -&gt; Type[BoundReference[L]]:\n        return BoundReference[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Reference.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the Reference class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the Reference class.\"\"\"\n    return self.name == other.name if isinstance(other, Reference) else False\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Reference.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the Reference class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the Reference class.\"\"\"\n    return f\"Reference(name={repr(self.name)})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Reference.bind","title":"<code>bind(schema, case_sensitive=True)</code>","text":"<p>Bind the reference to an Iceberg schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>Schema</code> <p>An Iceberg schema.</p> required <code>case_sensitive</code> <code>bool</code> <p>Whether to consider case when binding the reference to the field.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an empty name is provided.</p> <p>Returns:</p> Name Type Description <code>BoundReference</code> <code>BoundReference[L]</code> <p>A reference bound to the specific field in the Iceberg schema.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def bind(self, schema: Schema, case_sensitive: bool = True) -&gt; BoundReference[L]:\n    \"\"\"Bind the reference to an Iceberg schema.\n\n    Args:\n        schema (Schema): An Iceberg schema.\n        case_sensitive (bool): Whether to consider case when binding the reference to the field.\n\n    Raises:\n        ValueError: If an empty name is provided.\n\n    Returns:\n        BoundReference: A reference bound to the specific field in the Iceberg schema.\n    \"\"\"\n    field = schema.find_field(name_or_id=self.name, case_sensitive=case_sensitive)\n    accessor = schema.accessor_for_field(field.field_id)\n    return self.as_bound(field=field, accessor=accessor)  # type: ignore\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.SetPredicate","title":"<code>SetPredicate</code>","text":"<p>             Bases: <code>UnboundPredicate[L]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class SetPredicate(UnboundPredicate[L], ABC):\n    literals: Set[Literal[L]]\n\n    def __init__(self, term: Union[str, UnboundTerm[Any]], literals: Union[Iterable[L], Iterable[Literal[L]]]):\n        super().__init__(term)\n        self.literals = _to_literal_set(literals)\n\n    def bind(self, schema: Schema, case_sensitive: bool = True) -&gt; BoundSetPredicate[L]:\n        bound_term = self.term.bind(schema, case_sensitive)\n        return self.as_bound(bound_term, {lit.to(bound_term.ref().field.field_type) for lit in self.literals})\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the SetPredicate class.\"\"\"\n        # Sort to make it deterministic\n        return f\"{str(self.__class__.__name__)}({str(self.term)}, {{{', '.join(sorted([str(literal) for literal in self.literals]))}}})\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the SetPredicate class.\"\"\"\n        # Sort to make it deterministic\n        return f\"{str(self.__class__.__name__)}({repr(self.term)}, {{{', '.join(sorted([repr(literal) for literal in self.literals]))}}})\"\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the SetPredicate class.\"\"\"\n        return self.term == other.term and self.literals == other.literals if isinstance(other, self.__class__) else False\n\n    def __getnewargs__(self) -&gt; Tuple[UnboundTerm[L], Set[Literal[L]]]:\n        \"\"\"Pickle the SetPredicate class.\"\"\"\n        return (self.term, self.literals)\n\n    @property\n    @abstractmethod\n    def as_bound(self) -&gt; Type[BoundSetPredicate[L]]:\n        return BoundSetPredicate[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.SetPredicate.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the SetPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the SetPredicate class.\"\"\"\n    return self.term == other.term and self.literals == other.literals if isinstance(other, self.__class__) else False\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.SetPredicate.__getnewargs__","title":"<code>__getnewargs__()</code>","text":"<p>Pickle the SetPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __getnewargs__(self) -&gt; Tuple[UnboundTerm[L], Set[Literal[L]]]:\n    \"\"\"Pickle the SetPredicate class.\"\"\"\n    return (self.term, self.literals)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.SetPredicate.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the SetPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the SetPredicate class.\"\"\"\n    # Sort to make it deterministic\n    return f\"{str(self.__class__.__name__)}({repr(self.term)}, {{{', '.join(sorted([repr(literal) for literal in self.literals]))}}})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.SetPredicate.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the SetPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the SetPredicate class.\"\"\"\n    # Sort to make it deterministic\n    return f\"{str(self.__class__.__name__)}({str(self.term)}, {{{', '.join(sorted([str(literal) for literal in self.literals]))}}})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.StartsWith","title":"<code>StartsWith</code>","text":"<p>             Bases: <code>LiteralPredicate[L]</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class StartsWith(LiteralPredicate[L]):\n    def __invert__(self) -&gt; NotStartsWith[L]:\n        \"\"\"Transform the Expression into its negated version.\"\"\"\n        return NotStartsWith[L](self.term, self.literal)\n\n    @property\n    def as_bound(self) -&gt; Type[BoundStartsWith[L]]:\n        return BoundStartsWith[L]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.StartsWith.__invert__","title":"<code>__invert__()</code>","text":"<p>Transform the Expression into its negated version.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __invert__(self) -&gt; NotStartsWith[L]:\n    \"\"\"Transform the Expression into its negated version.\"\"\"\n    return NotStartsWith[L](self.term, self.literal)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Term","title":"<code>Term</code>","text":"<p>             Bases: <code>Generic[L]</code>, <code>ABC</code></p> <p>A simple expression that evaluates to a value.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class Term(Generic[L], ABC):\n    \"\"\"A simple expression that evaluates to a value.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.UnaryPredicate","title":"<code>UnaryPredicate</code>","text":"<p>             Bases: <code>UnboundPredicate[Any]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class UnaryPredicate(UnboundPredicate[Any], ABC):\n    def bind(self, schema: Schema, case_sensitive: bool = True) -&gt; BoundUnaryPredicate[Any]:\n        bound_term = self.term.bind(schema, case_sensitive)\n        return self.as_bound(bound_term)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the UnaryPredicate class.\"\"\"\n        return f\"{str(self.__class__.__name__)}(term={repr(self.term)})\"\n\n    @property\n    @abstractmethod\n    def as_bound(self) -&gt; Type[BoundUnaryPredicate[Any]]: ...\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.UnaryPredicate.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the UnaryPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the UnaryPredicate class.\"\"\"\n    return f\"{str(self.__class__.__name__)}(term={repr(self.term)})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.Unbound","title":"<code>Unbound</code>","text":"<p>             Bases: <code>Generic[B]</code>, <code>ABC</code></p> <p>Represents an unbound value expression.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class Unbound(Generic[B], ABC):\n    \"\"\"Represents an unbound value expression.\"\"\"\n\n    @abstractmethod\n    def bind(self, schema: Schema, case_sensitive: bool = True) -&gt; B: ...\n\n    @property\n    @abstractmethod\n    def as_bound(self) -&gt; Type[Bound]: ...\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.UnboundPredicate","title":"<code>UnboundPredicate</code>","text":"<p>             Bases: <code>Generic[L]</code>, <code>Unbound[BooleanExpression]</code>, <code>BooleanExpression</code>, <code>ABC</code></p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class UnboundPredicate(Generic[L], Unbound[BooleanExpression], BooleanExpression, ABC):\n    term: UnboundTerm[Any]\n\n    def __init__(self, term: Union[str, UnboundTerm[Any]]):\n        self.term = _to_unbound_term(term)\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the UnboundPredicate class.\"\"\"\n        return self.term == other.term if isinstance(other, self.__class__) else False\n\n    @abstractmethod\n    def bind(self, schema: Schema, case_sensitive: bool = True) -&gt; BooleanExpression: ...\n\n    @property\n    @abstractmethod\n    def as_bound(self) -&gt; Type[BoundPredicate[L]]: ...\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.UnboundPredicate.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the UnboundPredicate class.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the UnboundPredicate class.\"\"\"\n    return self.term == other.term if isinstance(other, self.__class__) else False\n</code></pre>"},{"location":"reference/pyiceberg/expressions/#pyiceberg.expressions.UnboundTerm","title":"<code>UnboundTerm</code>","text":"<p>             Bases: <code>Term[Any]</code>, <code>Unbound[BoundTerm[L]]</code>, <code>ABC</code></p> <p>Represents an unbound term.</p> Source code in <code>pyiceberg/expressions/__init__.py</code> <pre><code>class UnboundTerm(Term[Any], Unbound[BoundTerm[L]], ABC):\n    \"\"\"Represents an unbound term.\"\"\"\n\n    @abstractmethod\n    def bind(self, schema: Schema, case_sensitive: bool = True) -&gt; BoundTerm[L]: ...\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/","title":"literals","text":""},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.AboveMax","title":"<code>AboveMax</code>","text":"<p>             Bases: <code>Literal[L]</code></p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>class AboveMax(Literal[L]):\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the AboveMax class.\"\"\"\n        return f\"{self.__class__.__name__}()\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the AboveMax class.\"\"\"\n        return self.__class__.__name__\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.AboveMax.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the AboveMax class.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the AboveMax class.\"\"\"\n    return f\"{self.__class__.__name__}()\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.AboveMax.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the AboveMax class.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the AboveMax class.\"\"\"\n    return self.__class__.__name__\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.BelowMin","title":"<code>BelowMin</code>","text":"<p>             Bases: <code>Literal[L]</code></p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>class BelowMin(Literal[L]):\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the BelowMin class.\"\"\"\n        return f\"{self.__class__.__name__}()\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the BelowMin class.\"\"\"\n        return self.__class__.__name__\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.BelowMin.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the BelowMin class.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the BelowMin class.\"\"\"\n    return f\"{self.__class__.__name__}()\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.BelowMin.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the BelowMin class.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the BelowMin class.\"\"\"\n    return self.__class__.__name__\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.FloatLiteral","title":"<code>FloatLiteral</code>","text":"<p>             Bases: <code>Literal[float]</code></p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>class FloatLiteral(Literal[float]):\n    def __init__(self, value: float) -&gt; None:\n        super().__init__(value, float)\n        self._value32 = struct.unpack(\"&lt;f\", struct.pack(\"&lt;f\", value))[0]\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the FloatLiteral class.\"\"\"\n        return self._value32 == other\n\n    def __lt__(self, other: Any) -&gt; bool:\n        \"\"\"Return if one instance of the FloatLiteral class is less than another instance.\"\"\"\n        return self._value32 &lt; other\n\n    def __gt__(self, other: Any) -&gt; bool:\n        \"\"\"Return if one instance of the FloatLiteral class is greater than another instance.\"\"\"\n        return self._value32 &gt; other\n\n    def __le__(self, other: Any) -&gt; bool:\n        \"\"\"Return if one instance of the FloatLiteral class is less than or equal to another instance.\"\"\"\n        return self._value32 &lt;= other\n\n    def __ge__(self, other: Any) -&gt; bool:\n        \"\"\"Return if one instance of the FloatLiteral class is greater than or equal to another instance.\"\"\"\n        return self._value32 &gt;= other\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Return a hashed representation of the FloatLiteral class.\"\"\"\n        return hash(self._value32)\n\n    @singledispatchmethod\n    def to(self, type_var: IcebergType) -&gt; Literal:  # type: ignore\n        raise TypeError(f\"Cannot convert FloatLiteral into {type_var}\")\n\n    @to.register(FloatType)\n    def _(self, _: FloatType) -&gt; Literal[float]:\n        return self\n\n    @to.register(DoubleType)\n    def _(self, _: DoubleType) -&gt; Literal[float]:\n        return DoubleLiteral(self.value)\n\n    @to.register(DecimalType)\n    def _(self, type_var: DecimalType) -&gt; Literal[Decimal]:\n        return DecimalLiteral(Decimal(self.value).quantize(Decimal((0, (1,), -type_var.scale)), rounding=ROUND_HALF_UP))\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.FloatLiteral.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the FloatLiteral class.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the FloatLiteral class.\"\"\"\n    return self._value32 == other\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.FloatLiteral.__ge__","title":"<code>__ge__(other)</code>","text":"<p>Return if one instance of the FloatLiteral class is greater than or equal to another instance.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __ge__(self, other: Any) -&gt; bool:\n    \"\"\"Return if one instance of the FloatLiteral class is greater than or equal to another instance.\"\"\"\n    return self._value32 &gt;= other\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.FloatLiteral.__gt__","title":"<code>__gt__(other)</code>","text":"<p>Return if one instance of the FloatLiteral class is greater than another instance.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __gt__(self, other: Any) -&gt; bool:\n    \"\"\"Return if one instance of the FloatLiteral class is greater than another instance.\"\"\"\n    return self._value32 &gt; other\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.FloatLiteral.__hash__","title":"<code>__hash__()</code>","text":"<p>Return a hashed representation of the FloatLiteral class.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Return a hashed representation of the FloatLiteral class.\"\"\"\n    return hash(self._value32)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.FloatLiteral.__le__","title":"<code>__le__(other)</code>","text":"<p>Return if one instance of the FloatLiteral class is less than or equal to another instance.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __le__(self, other: Any) -&gt; bool:\n    \"\"\"Return if one instance of the FloatLiteral class is less than or equal to another instance.\"\"\"\n    return self._value32 &lt;= other\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.FloatLiteral.__lt__","title":"<code>__lt__(other)</code>","text":"<p>Return if one instance of the FloatLiteral class is less than another instance.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __lt__(self, other: Any) -&gt; bool:\n    \"\"\"Return if one instance of the FloatLiteral class is less than another instance.\"\"\"\n    return self._value32 &lt; other\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.Literal","title":"<code>Literal</code>","text":"<p>             Bases: <code>Generic[L]</code>, <code>ABC</code></p> <p>Literal which has a value and can be converted between types.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>class Literal(Generic[L], ABC):\n    \"\"\"Literal which has a value and can be converted between types.\"\"\"\n\n    _value: L\n\n    def __init__(self, value: L, value_type: Type[L]):\n        if value is None or not isinstance(value, value_type):\n            raise TypeError(f\"Invalid literal value: {value!r} (not a {value_type})\")\n        if isinstance(value, float) and isnan(value):\n            raise ValueError(\"Cannot create expression literal from NaN.\")\n        self._value = value\n\n    @property\n    def value(self) -&gt; L:\n        return self._value\n\n    @singledispatchmethod\n    @abstractmethod\n    def to(self, type_var: IcebergType) -&gt; Literal[L]: ...  # pragma: no cover\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the Literal class.\"\"\"\n        return f\"{type(self).__name__}({self.value!r})\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the Literal class.\"\"\"\n        return str(self.value)\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Return a hashed representation of the Literal class.\"\"\"\n        return hash(self.value)\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the Literal class.\"\"\"\n        if not isinstance(other, Literal):\n            return False\n        return self.value == other.value\n\n    def __ne__(self, other: Any) -&gt; bool:\n        \"\"\"Return the inequality of two instances of the Literal class.\"\"\"\n        return not self.__eq__(other)\n\n    def __lt__(self, other: Any) -&gt; bool:\n        \"\"\"Return if one instance of the Literal class is less than another instance.\"\"\"\n        return self.value &lt; other.value\n\n    def __gt__(self, other: Any) -&gt; bool:\n        \"\"\"Return if one instance of the Literal class is greater than another instance.\"\"\"\n        return self.value &gt; other.value\n\n    def __le__(self, other: Any) -&gt; bool:\n        \"\"\"Return if one instance of the Literal class is less than or equal to another instance.\"\"\"\n        return self.value &lt;= other.value\n\n    def __ge__(self, other: Any) -&gt; bool:\n        \"\"\"Return if one instance of the Literal class is greater than or equal to another instance.\"\"\"\n        return self.value &gt;= other.value\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.Literal.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the Literal class.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the Literal class.\"\"\"\n    if not isinstance(other, Literal):\n        return False\n    return self.value == other.value\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.Literal.__ge__","title":"<code>__ge__(other)</code>","text":"<p>Return if one instance of the Literal class is greater than or equal to another instance.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __ge__(self, other: Any) -&gt; bool:\n    \"\"\"Return if one instance of the Literal class is greater than or equal to another instance.\"\"\"\n    return self.value &gt;= other.value\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.Literal.__gt__","title":"<code>__gt__(other)</code>","text":"<p>Return if one instance of the Literal class is greater than another instance.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __gt__(self, other: Any) -&gt; bool:\n    \"\"\"Return if one instance of the Literal class is greater than another instance.\"\"\"\n    return self.value &gt; other.value\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.Literal.__hash__","title":"<code>__hash__()</code>","text":"<p>Return a hashed representation of the Literal class.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Return a hashed representation of the Literal class.\"\"\"\n    return hash(self.value)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.Literal.__le__","title":"<code>__le__(other)</code>","text":"<p>Return if one instance of the Literal class is less than or equal to another instance.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __le__(self, other: Any) -&gt; bool:\n    \"\"\"Return if one instance of the Literal class is less than or equal to another instance.\"\"\"\n    return self.value &lt;= other.value\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.Literal.__lt__","title":"<code>__lt__(other)</code>","text":"<p>Return if one instance of the Literal class is less than another instance.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __lt__(self, other: Any) -&gt; bool:\n    \"\"\"Return if one instance of the Literal class is less than another instance.\"\"\"\n    return self.value &lt; other.value\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.Literal.__ne__","title":"<code>__ne__(other)</code>","text":"<p>Return the inequality of two instances of the Literal class.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __ne__(self, other: Any) -&gt; bool:\n    \"\"\"Return the inequality of two instances of the Literal class.\"\"\"\n    return not self.__eq__(other)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.Literal.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the Literal class.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the Literal class.\"\"\"\n    return f\"{type(self).__name__}({self.value!r})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.Literal.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the Literal class.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the Literal class.\"\"\"\n    return str(self.value)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.StringLiteral","title":"<code>StringLiteral</code>","text":"<p>             Bases: <code>Literal[str]</code></p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>class StringLiteral(Literal[str]):\n    def __init__(self, value: str) -&gt; None:\n        super().__init__(value, str)\n\n    @singledispatchmethod\n    def to(self, type_var: IcebergType) -&gt; Literal:  # type: ignore\n        raise TypeError(f\"Cannot convert StringLiteral into {type_var}\")\n\n    @to.register(StringType)\n    def _(self, _: StringType) -&gt; Literal[str]:\n        return self\n\n    @to.register(IntegerType)\n    def _(self, type_var: IntegerType) -&gt; Literal[int]:\n        try:\n            number = int(float(self.value))\n\n            if IntegerType.max &lt; number:\n                return IntAboveMax()\n            elif IntegerType.min &gt; number:\n                return IntBelowMin()\n            return LongLiteral(number)\n        except ValueError as e:\n            raise ValueError(f\"Could not convert {self.value} into a {type_var}\") from e\n\n    @to.register(LongType)\n    def _(self, type_var: LongType) -&gt; Literal[int]:\n        try:\n            long_value = int(float(self.value))\n            if LongType.max &lt; long_value:\n                return LongAboveMax()\n            elif LongType.min &gt; long_value:\n                return LongBelowMin()\n            else:\n                return LongLiteral(long_value)\n        except (TypeError, ValueError) as e:\n            raise ValueError(f\"Could not convert {self.value} into a {type_var}\") from e\n\n    @to.register(DateType)\n    def _(self, type_var: DateType) -&gt; Literal[int]:\n        try:\n            return DateLiteral(date_str_to_days(self.value))\n        except (TypeError, ValueError) as e:\n            raise ValueError(f\"Could not convert {self.value} into a {type_var}\") from e\n\n    @to.register(TimeType)\n    def _(self, type_var: TimeType) -&gt; Literal[int]:\n        try:\n            return TimeLiteral(time_str_to_micros(self.value))\n        except (TypeError, ValueError) as e:\n            raise ValueError(f\"Could not convert {self.value} into a {type_var}\") from e\n\n    @to.register(TimestampType)\n    def _(self, _: TimestampType) -&gt; Literal[int]:\n        return TimestampLiteral(timestamp_to_micros(self.value))\n\n    @to.register(TimestamptzType)\n    def _(self, _: TimestamptzType) -&gt; Literal[int]:\n        return TimestampLiteral(timestamptz_to_micros(self.value))\n\n    @to.register(UUIDType)\n    def _(self, _: UUIDType) -&gt; Literal[bytes]:\n        return UUIDLiteral(UUID(self.value).bytes)\n\n    @to.register(DecimalType)\n    def _(self, type_var: DecimalType) -&gt; Literal[Decimal]:\n        dec = Decimal(self.value)\n        scale = abs(int(dec.as_tuple().exponent))\n        if type_var.scale == scale:\n            return DecimalLiteral(dec)\n        else:\n            raise ValueError(f\"Could not convert {self.value} into a {type_var}, scales differ {type_var.scale} &lt;&gt; {scale}\")\n\n    @to.register(BooleanType)\n    def _(self, type_var: BooleanType) -&gt; Literal[bool]:\n        value_upper = self.value.upper()\n        if value_upper in [\"TRUE\", \"FALSE\"]:\n            return BooleanLiteral(value_upper == \"TRUE\")\n        else:\n            raise ValueError(f\"Could not convert {self.value} into a {type_var}\")\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the StringLiteral class.\"\"\"\n        return f\"literal({repr(self.value)})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.StringLiteral.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the StringLiteral class.</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the StringLiteral class.\"\"\"\n    return f\"literal({repr(self.value)})\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/literals/#pyiceberg.expressions.literals.literal","title":"<code>literal(value)</code>","text":"<p>Construct an Iceberg Literal based on Python primitive data type.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Python primitive type</code> <p>the value to be associated with literal.</p> required Example <p>from pyiceberg.expressions.literals import literal.</p> <p>literal(123) LongLiteral(123)</p> Source code in <code>pyiceberg/expressions/literals.py</code> <pre><code>def literal(value: L) -&gt; Literal[L]:\n    \"\"\"\n    Construct an Iceberg Literal based on Python primitive data type.\n\n    Args:\n        value (Python primitive type): the value to be associated with literal.\n\n    Example:\n        from pyiceberg.expressions.literals import literal.\n        &gt;&gt;&gt; literal(123)\n        LongLiteral(123)\n    \"\"\"\n    if isinstance(value, float):\n        return DoubleLiteral(value)  # type: ignore\n    elif isinstance(value, bool):\n        return BooleanLiteral(value)\n    elif isinstance(value, int):\n        return LongLiteral(value)\n    elif isinstance(value, str):\n        return StringLiteral(value)\n    elif isinstance(value, UUID):\n        return UUIDLiteral(value.bytes)  # type: ignore\n    elif isinstance(value, bytes):\n        return BinaryLiteral(value)\n    elif isinstance(value, Decimal):\n        return DecimalLiteral(value)\n    else:\n        raise TypeError(f\"Invalid literal value: {repr(value)}\")\n</code></pre>"},{"location":"reference/pyiceberg/expressions/parser/","title":"parser","text":""},{"location":"reference/pyiceberg/expressions/parser/#pyiceberg.expressions.parser.parse","title":"<code>parse(expr)</code>","text":"<p>Parse a boolean expression.</p> Source code in <code>pyiceberg/expressions/parser.py</code> <pre><code>def parse(expr: str) -&gt; BooleanExpression:\n    \"\"\"Parse a boolean expression.\"\"\"\n    return boolean_expression.parse_string(expr, parse_all=True)[0]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/","title":"visitors","text":""},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BindVisitor","title":"<code>BindVisitor</code>","text":"<p>             Bases: <code>BooleanExpressionVisitor[BooleanExpression]</code></p> <p>Rewrites a boolean expression by replacing unbound references with references to fields in a struct schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>Schema</code> <p>A schema to use when binding the expression.</p> required <code>case_sensitive</code> <code>bool</code> <p>Whether to consider case when binding a reference to a field in a schema, defaults to True.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>In the case a predicate is already bound.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>class BindVisitor(BooleanExpressionVisitor[BooleanExpression]):\n    \"\"\"Rewrites a boolean expression by replacing unbound references with references to fields in a struct schema.\n\n    Args:\n      schema (Schema): A schema to use when binding the expression.\n      case_sensitive (bool): Whether to consider case when binding a reference to a field in a schema, defaults to True.\n\n    Raises:\n        TypeError: In the case a predicate is already bound.\n    \"\"\"\n\n    schema: Schema\n    case_sensitive: bool\n\n    def __init__(self, schema: Schema, case_sensitive: bool) -&gt; None:\n        self.schema = schema\n        self.case_sensitive = case_sensitive\n\n    def visit_true(self) -&gt; BooleanExpression:\n        return AlwaysTrue()\n\n    def visit_false(self) -&gt; BooleanExpression:\n        return AlwaysFalse()\n\n    def visit_not(self, child_result: BooleanExpression) -&gt; BooleanExpression:\n        return Not(child=child_result)\n\n    def visit_and(self, left_result: BooleanExpression, right_result: BooleanExpression) -&gt; BooleanExpression:\n        return And(left=left_result, right=right_result)\n\n    def visit_or(self, left_result: BooleanExpression, right_result: BooleanExpression) -&gt; BooleanExpression:\n        return Or(left=left_result, right=right_result)\n\n    def visit_unbound_predicate(self, predicate: UnboundPredicate[L]) -&gt; BooleanExpression:\n        return predicate.bind(self.schema, case_sensitive=self.case_sensitive)\n\n    def visit_bound_predicate(self, predicate: BoundPredicate[L]) -&gt; BooleanExpression:\n        raise TypeError(f\"Found already bound predicate: {predicate}\")\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BooleanExpressionVisitor","title":"<code>BooleanExpressionVisitor</code>","text":"<p>             Bases: <code>Generic[T]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>class BooleanExpressionVisitor(Generic[T], ABC):\n    @abstractmethod\n    def visit_true(self) -&gt; T:\n        \"\"\"Visit method for an AlwaysTrue boolean expression.\n\n        Note: This visit method has no arguments since AlwaysTrue instances have no context.\n        \"\"\"\n\n    @abstractmethod\n    def visit_false(self) -&gt; T:\n        \"\"\"Visit method for an AlwaysFalse boolean expression.\n\n        Note: This visit method has no arguments since AlwaysFalse instances have no context.\n        \"\"\"\n\n    @abstractmethod\n    def visit_not(self, child_result: T) -&gt; T:\n        \"\"\"Visit method for a Not boolean expression.\n\n        Args:\n            child_result (T): The result of visiting the child of the Not boolean expression.\n        \"\"\"\n\n    @abstractmethod\n    def visit_and(self, left_result: T, right_result: T) -&gt; T:\n        \"\"\"Visit method for an And boolean expression.\n\n        Args:\n            left_result (T): The result of visiting the left side of the expression.\n            right_result (T): The result of visiting the right side of the expression.\n        \"\"\"\n\n    @abstractmethod\n    def visit_or(self, left_result: T, right_result: T) -&gt; T:\n        \"\"\"Visit method for an Or boolean expression.\n\n        Args:\n            left_result (T): The result of visiting the left side of the expression.\n            right_result (T): The result of visiting the right side of the expression.\n        \"\"\"\n\n    @abstractmethod\n    def visit_unbound_predicate(self, predicate: UnboundPredicate[L]) -&gt; T:\n        \"\"\"Visit method for an unbound predicate in an expression tree.\n\n        Args:\n            predicate (UnboundPredicate[L): An instance of an UnboundPredicate.\n        \"\"\"\n\n    @abstractmethod\n    def visit_bound_predicate(self, predicate: BoundPredicate[L]) -&gt; T:\n        \"\"\"Visit method for a bound predicate in an expression tree.\n\n        Args:\n            predicate (BoundPredicate[L]): An instance of a BoundPredicate.\n        \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BooleanExpressionVisitor.visit_and","title":"<code>visit_and(left_result, right_result)</code>  <code>abstractmethod</code>","text":"<p>Visit method for an And boolean expression.</p> <p>Parameters:</p> Name Type Description Default <code>left_result</code> <code>T</code> <p>The result of visiting the left side of the expression.</p> required <code>right_result</code> <code>T</code> <p>The result of visiting the right side of the expression.</p> required Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_and(self, left_result: T, right_result: T) -&gt; T:\n    \"\"\"Visit method for an And boolean expression.\n\n    Args:\n        left_result (T): The result of visiting the left side of the expression.\n        right_result (T): The result of visiting the right side of the expression.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BooleanExpressionVisitor.visit_bound_predicate","title":"<code>visit_bound_predicate(predicate)</code>  <code>abstractmethod</code>","text":"<p>Visit method for a bound predicate in an expression tree.</p> <p>Parameters:</p> Name Type Description Default <code>predicate</code> <code>BoundPredicate[L]</code> <p>An instance of a BoundPredicate.</p> required Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_bound_predicate(self, predicate: BoundPredicate[L]) -&gt; T:\n    \"\"\"Visit method for a bound predicate in an expression tree.\n\n    Args:\n        predicate (BoundPredicate[L]): An instance of a BoundPredicate.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BooleanExpressionVisitor.visit_false","title":"<code>visit_false()</code>  <code>abstractmethod</code>","text":"<p>Visit method for an AlwaysFalse boolean expression.</p> <p>Note: This visit method has no arguments since AlwaysFalse instances have no context.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_false(self) -&gt; T:\n    \"\"\"Visit method for an AlwaysFalse boolean expression.\n\n    Note: This visit method has no arguments since AlwaysFalse instances have no context.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BooleanExpressionVisitor.visit_not","title":"<code>visit_not(child_result)</code>  <code>abstractmethod</code>","text":"<p>Visit method for a Not boolean expression.</p> <p>Parameters:</p> Name Type Description Default <code>child_result</code> <code>T</code> <p>The result of visiting the child of the Not boolean expression.</p> required Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_not(self, child_result: T) -&gt; T:\n    \"\"\"Visit method for a Not boolean expression.\n\n    Args:\n        child_result (T): The result of visiting the child of the Not boolean expression.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BooleanExpressionVisitor.visit_or","title":"<code>visit_or(left_result, right_result)</code>  <code>abstractmethod</code>","text":"<p>Visit method for an Or boolean expression.</p> <p>Parameters:</p> Name Type Description Default <code>left_result</code> <code>T</code> <p>The result of visiting the left side of the expression.</p> required <code>right_result</code> <code>T</code> <p>The result of visiting the right side of the expression.</p> required Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_or(self, left_result: T, right_result: T) -&gt; T:\n    \"\"\"Visit method for an Or boolean expression.\n\n    Args:\n        left_result (T): The result of visiting the left side of the expression.\n        right_result (T): The result of visiting the right side of the expression.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BooleanExpressionVisitor.visit_true","title":"<code>visit_true()</code>  <code>abstractmethod</code>","text":"<p>Visit method for an AlwaysTrue boolean expression.</p> <p>Note: This visit method has no arguments since AlwaysTrue instances have no context.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_true(self) -&gt; T:\n    \"\"\"Visit method for an AlwaysTrue boolean expression.\n\n    Note: This visit method has no arguments since AlwaysTrue instances have no context.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BooleanExpressionVisitor.visit_unbound_predicate","title":"<code>visit_unbound_predicate(predicate)</code>  <code>abstractmethod</code>","text":"<p>Visit method for an unbound predicate in an expression tree.</p> <p>Parameters:</p> Name Type Description Default <code>predicate</code> <code>UnboundPredicate[L</code> <p>An instance of an UnboundPredicate.</p> required Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_unbound_predicate(self, predicate: UnboundPredicate[L]) -&gt; T:\n    \"\"\"Visit method for an unbound predicate in an expression tree.\n\n    Args:\n        predicate (UnboundPredicate[L): An instance of an UnboundPredicate.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor","title":"<code>BoundBooleanExpressionVisitor</code>","text":"<p>             Bases: <code>BooleanExpressionVisitor[T]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>class BoundBooleanExpressionVisitor(BooleanExpressionVisitor[T], ABC):\n    @abstractmethod\n    def visit_in(self, term: BoundTerm[L], literals: Set[L]) -&gt; T:\n        \"\"\"Visit a bound In predicate.\"\"\"\n\n    @abstractmethod\n    def visit_not_in(self, term: BoundTerm[L], literals: Set[L]) -&gt; T:\n        \"\"\"Visit a bound NotIn predicate.\"\"\"\n\n    @abstractmethod\n    def visit_is_nan(self, term: BoundTerm[L]) -&gt; T:\n        \"\"\"Visit a bound IsNan predicate.\"\"\"\n\n    @abstractmethod\n    def visit_not_nan(self, term: BoundTerm[L]) -&gt; T:\n        \"\"\"Visit a bound NotNan predicate.\"\"\"\n\n    @abstractmethod\n    def visit_is_null(self, term: BoundTerm[L]) -&gt; T:\n        \"\"\"Visit a bound IsNull predicate.\"\"\"\n\n    @abstractmethod\n    def visit_not_null(self, term: BoundTerm[L]) -&gt; T:\n        \"\"\"Visit a bound NotNull predicate.\"\"\"\n\n    @abstractmethod\n    def visit_equal(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n        \"\"\"Visit a bound Equal predicate.\"\"\"\n\n    @abstractmethod\n    def visit_not_equal(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n        \"\"\"Visit a bound NotEqual predicate.\"\"\"\n\n    @abstractmethod\n    def visit_greater_than_or_equal(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n        \"\"\"Visit a bound GreaterThanOrEqual predicate.\"\"\"\n\n    @abstractmethod\n    def visit_greater_than(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n        \"\"\"Visit a bound GreaterThan predicate.\"\"\"\n\n    @abstractmethod\n    def visit_less_than(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n        \"\"\"Visit a bound LessThan predicate.\"\"\"\n\n    @abstractmethod\n    def visit_less_than_or_equal(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n        \"\"\"Visit a bound LessThanOrEqual predicate.\"\"\"\n\n    @abstractmethod\n    def visit_true(self) -&gt; T:\n        \"\"\"Visit a bound True predicate.\"\"\"\n\n    @abstractmethod\n    def visit_false(self) -&gt; T:\n        \"\"\"Visit a bound False predicate.\"\"\"\n\n    @abstractmethod\n    def visit_not(self, child_result: T) -&gt; T:\n        \"\"\"Visit a bound Not predicate.\"\"\"\n\n    @abstractmethod\n    def visit_and(self, left_result: T, right_result: T) -&gt; T:\n        \"\"\"Visit a bound And predicate.\"\"\"\n\n    @abstractmethod\n    def visit_or(self, left_result: T, right_result: T) -&gt; T:\n        \"\"\"Visit a bound Or predicate.\"\"\"\n\n    @abstractmethod\n    def visit_starts_with(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n        \"\"\"Visit bound StartsWith predicate.\"\"\"\n\n    @abstractmethod\n    def visit_not_starts_with(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n        \"\"\"Visit bound NotStartsWith predicate.\"\"\"\n\n    def visit_unbound_predicate(self, predicate: UnboundPredicate[L]) -&gt; T:\n        \"\"\"Visit an unbound predicate.\n\n        Args:\n            predicate (UnboundPredicate[L]): An unbound predicate.\n        Raises:\n            TypeError: This always raises since an unbound predicate is not expected in a bound boolean expression.\n        \"\"\"\n        raise TypeError(f\"Not a bound predicate: {predicate}\")\n\n    def visit_bound_predicate(self, predicate: BoundPredicate[L]) -&gt; T:\n        \"\"\"Visit a bound predicate.\n\n        Args:\n            predicate (BoundPredicate[L]): A bound predicate.\n        \"\"\"\n        return visit_bound_predicate(predicate, self)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_and","title":"<code>visit_and(left_result, right_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound And predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_and(self, left_result: T, right_result: T) -&gt; T:\n    \"\"\"Visit a bound And predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_bound_predicate","title":"<code>visit_bound_predicate(predicate)</code>","text":"<p>Visit a bound predicate.</p> <p>Parameters:</p> Name Type Description Default <code>predicate</code> <code>BoundPredicate[L]</code> <p>A bound predicate.</p> required Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>def visit_bound_predicate(self, predicate: BoundPredicate[L]) -&gt; T:\n    \"\"\"Visit a bound predicate.\n\n    Args:\n        predicate (BoundPredicate[L]): A bound predicate.\n    \"\"\"\n    return visit_bound_predicate(predicate, self)\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_equal","title":"<code>visit_equal(term, literal)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound Equal predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_equal(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n    \"\"\"Visit a bound Equal predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_false","title":"<code>visit_false()</code>  <code>abstractmethod</code>","text":"<p>Visit a bound False predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_false(self) -&gt; T:\n    \"\"\"Visit a bound False predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_greater_than","title":"<code>visit_greater_than(term, literal)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound GreaterThan predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_greater_than(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n    \"\"\"Visit a bound GreaterThan predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_greater_than_or_equal","title":"<code>visit_greater_than_or_equal(term, literal)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound GreaterThanOrEqual predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_greater_than_or_equal(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n    \"\"\"Visit a bound GreaterThanOrEqual predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_in","title":"<code>visit_in(term, literals)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound In predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_in(self, term: BoundTerm[L], literals: Set[L]) -&gt; T:\n    \"\"\"Visit a bound In predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_is_nan","title":"<code>visit_is_nan(term)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound IsNan predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_is_nan(self, term: BoundTerm[L]) -&gt; T:\n    \"\"\"Visit a bound IsNan predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_is_null","title":"<code>visit_is_null(term)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound IsNull predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_is_null(self, term: BoundTerm[L]) -&gt; T:\n    \"\"\"Visit a bound IsNull predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_less_than","title":"<code>visit_less_than(term, literal)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound LessThan predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_less_than(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n    \"\"\"Visit a bound LessThan predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_less_than_or_equal","title":"<code>visit_less_than_or_equal(term, literal)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound LessThanOrEqual predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_less_than_or_equal(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n    \"\"\"Visit a bound LessThanOrEqual predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_not","title":"<code>visit_not(child_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound Not predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_not(self, child_result: T) -&gt; T:\n    \"\"\"Visit a bound Not predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_not_equal","title":"<code>visit_not_equal(term, literal)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound NotEqual predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_not_equal(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n    \"\"\"Visit a bound NotEqual predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_not_in","title":"<code>visit_not_in(term, literals)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound NotIn predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_not_in(self, term: BoundTerm[L], literals: Set[L]) -&gt; T:\n    \"\"\"Visit a bound NotIn predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_not_nan","title":"<code>visit_not_nan(term)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound NotNan predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_not_nan(self, term: BoundTerm[L]) -&gt; T:\n    \"\"\"Visit a bound NotNan predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_not_null","title":"<code>visit_not_null(term)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound NotNull predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_not_null(self, term: BoundTerm[L]) -&gt; T:\n    \"\"\"Visit a bound NotNull predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_not_starts_with","title":"<code>visit_not_starts_with(term, literal)</code>  <code>abstractmethod</code>","text":"<p>Visit bound NotStartsWith predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_not_starts_with(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n    \"\"\"Visit bound NotStartsWith predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_or","title":"<code>visit_or(left_result, right_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a bound Or predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_or(self, left_result: T, right_result: T) -&gt; T:\n    \"\"\"Visit a bound Or predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_starts_with","title":"<code>visit_starts_with(term, literal)</code>  <code>abstractmethod</code>","text":"<p>Visit bound StartsWith predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_starts_with(self, term: BoundTerm[L], literal: Literal[L]) -&gt; T:\n    \"\"\"Visit bound StartsWith predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_true","title":"<code>visit_true()</code>  <code>abstractmethod</code>","text":"<p>Visit a bound True predicate.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@abstractmethod\ndef visit_true(self) -&gt; T:\n    \"\"\"Visit a bound True predicate.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.BoundBooleanExpressionVisitor.visit_unbound_predicate","title":"<code>visit_unbound_predicate(predicate)</code>","text":"<p>Visit an unbound predicate.</p> <p>Parameters:</p> Name Type Description Default <code>predicate</code> <code>UnboundPredicate[L]</code> <p>An unbound predicate.</p> required <p>Raises:     TypeError: This always raises since an unbound predicate is not expected in a bound boolean expression.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>def visit_unbound_predicate(self, predicate: UnboundPredicate[L]) -&gt; T:\n    \"\"\"Visit an unbound predicate.\n\n    Args:\n        predicate (UnboundPredicate[L]): An unbound predicate.\n    Raises:\n        TypeError: This always raises since an unbound predicate is not expected in a bound boolean expression.\n    \"\"\"\n    raise TypeError(f\"Not a bound predicate: {predicate}\")\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.bind","title":"<code>bind(schema, expression, case_sensitive)</code>","text":"<p>Travers over an expression to bind the predicates to the schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>Schema</code> <p>A schema to use when binding the expression.</p> required <code>expression</code> <code>BooleanExpression</code> <p>An expression containing UnboundPredicates that can be bound.</p> required <code>case_sensitive</code> <code>bool</code> <p>Whether to consider case when binding a reference to a field in a schema, defaults to True.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>In the case a predicate is already bound.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>def bind(schema: Schema, expression: BooleanExpression, case_sensitive: bool) -&gt; BooleanExpression:\n    \"\"\"Travers over an expression to bind the predicates to the schema.\n\n    Args:\n      schema (Schema): A schema to use when binding the expression.\n      expression (BooleanExpression): An expression containing UnboundPredicates that can be bound.\n      case_sensitive (bool): Whether to consider case when binding a reference to a field in a schema, defaults to True.\n\n    Raises:\n        TypeError: In the case a predicate is already bound.\n    \"\"\"\n    return visit(expression, BindVisitor(schema, case_sensitive))\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.expression_to_plain_format","title":"<code>expression_to_plain_format(expressions, cast_int_to_datetime=False)</code>","text":"<p>Format a Disjunctive Normal Form expression.</p> <p>These are the formats that the expression can be fed into:</p> <ul> <li>https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html</li> <li>https://docs.dask.org/en/stable/generated/dask.dataframe.read_parquet.html</li> </ul> <p>Contrary to normal DNF that may contain Not expressions, but here they should have been rewritten. This can be done using <code>rewrite_not(...)</code>.</p> <p>Keep in mind that this is only used for page skipping, and still needs to filter on a row level.</p> <p>Parameters:</p> Name Type Description Default <code>expressions</code> <code>Tuple[BooleanExpression, ...]</code> <p>Expression in Disjunctive Normal Form.</p> required <p>Returns:</p> Type Description <code>List[List[Tuple[str, str, Any]]]</code> <p>Formatter filter compatible with Dask and PyArrow.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>def expression_to_plain_format(\n    expressions: Tuple[BooleanExpression, ...], cast_int_to_datetime: bool = False\n) -&gt; List[List[Tuple[str, str, Any]]]:\n    \"\"\"Format a Disjunctive Normal Form expression.\n\n    These are the formats that the expression can be fed into:\n\n    - https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html\n    - https://docs.dask.org/en/stable/generated/dask.dataframe.read_parquet.html\n\n    Contrary to normal DNF that may contain Not expressions, but here they should have\n    been rewritten. This can be done using ``rewrite_not(...)``.\n\n    Keep in mind that this is only used for page skipping, and still needs to filter\n    on a row level.\n\n    Args:\n        expressions: Expression in Disjunctive Normal Form.\n\n    Returns:\n        Formatter filter compatible with Dask and PyArrow.\n    \"\"\"\n    # In the form of expr1 \u2228 expr2 \u2228 ... \u2228 exprN\n    visitor = ExpressionToPlainFormat(cast_int_to_datetime)\n    return [visit(expression, visitor) for expression in expressions]\n</code></pre>"},{"location":"reference/pyiceberg/expressions/visitors/#pyiceberg.expressions.visitors.visit","title":"<code>visit(obj, visitor)</code>","text":"<p>Apply a boolean expression visitor to any point within an expression.</p> <p>The function traverses the expression in post-order fashion.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>BooleanExpression</code> <p>An instance of a BooleanExpression.</p> required <code>visitor</code> <code>BooleanExpressionVisitor[T]</code> <p>An instance of an implementation of the generic BooleanExpressionVisitor base class.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If attempting to visit an unsupported expression.</p> Source code in <code>pyiceberg/expressions/visitors.py</code> <pre><code>@singledispatch\ndef visit(obj: BooleanExpression, visitor: BooleanExpressionVisitor[T]) -&gt; T:\n    \"\"\"Apply a boolean expression visitor to any point within an expression.\n\n    The function traverses the expression in post-order fashion.\n\n    Args:\n        obj (BooleanExpression): An instance of a BooleanExpression.\n        visitor (BooleanExpressionVisitor[T]): An instance of an implementation of the generic BooleanExpressionVisitor base class.\n\n    Raises:\n        NotImplementedError: If attempting to visit an unsupported expression.\n    \"\"\"\n    raise NotImplementedError(f\"Cannot visit unsupported expression: {obj}\")\n</code></pre>"},{"location":"reference/pyiceberg/io/","title":"io","text":"<p>Base FileIO classes for implementing reading and writing table files.</p> <p>The FileIO abstraction includes a subset of full filesystem implementations. Specifically, Iceberg needs to read or write a file at a given location (as a seekable stream), as well as check if a file exists. An implementation of the FileIO abstract base class is responsible for returning an InputFile instance, an OutputFile instance, and deleting a file given its location.</p>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.FileIO","title":"<code>FileIO</code>","text":"<p>             Bases: <code>ABC</code></p> <p>A base class for FileIO implementations.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>class FileIO(ABC):\n    \"\"\"A base class for FileIO implementations.\"\"\"\n\n    properties: Properties\n\n    def __init__(self, properties: Properties = EMPTY_DICT):\n        self.properties = properties\n\n    @abstractmethod\n    def new_input(self, location: str) -&gt; InputFile:\n        \"\"\"Get an InputFile instance to read bytes from the file at the given location.\n\n        Args:\n            location (str): A URI or a path to a local file.\n        \"\"\"\n\n    @abstractmethod\n    def new_output(self, location: str) -&gt; OutputFile:\n        \"\"\"Get an OutputFile instance to write bytes to the file at the given location.\n\n        Args:\n            location (str): A URI or a path to a local file.\n        \"\"\"\n\n    @abstractmethod\n    def delete(self, location: Union[str, InputFile, OutputFile]) -&gt; None:\n        \"\"\"Delete the file at the given path.\n\n        Args:\n            location (Union[str, InputFile, OutputFile]): A URI or a path to a local file--if an InputFile instance or\n                an OutputFile instance is provided, the location attribute for that instance is used as the URI to delete.\n\n        Raises:\n            PermissionError: If the file at location cannot be accessed due to a permission error.\n            FileNotFoundError: When the file at the provided location does not exist.\n        \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.FileIO.delete","title":"<code>delete(location)</code>  <code>abstractmethod</code>","text":"<p>Delete the file at the given path.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>Union[str, InputFile, OutputFile]</code> <p>A URI or a path to a local file--if an InputFile instance or an OutputFile instance is provided, the location attribute for that instance is used as the URI to delete.</p> required <p>Raises:</p> Type Description <code>PermissionError</code> <p>If the file at location cannot be accessed due to a permission error.</p> <code>FileNotFoundError</code> <p>When the file at the provided location does not exist.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@abstractmethod\ndef delete(self, location: Union[str, InputFile, OutputFile]) -&gt; None:\n    \"\"\"Delete the file at the given path.\n\n    Args:\n        location (Union[str, InputFile, OutputFile]): A URI or a path to a local file--if an InputFile instance or\n            an OutputFile instance is provided, the location attribute for that instance is used as the URI to delete.\n\n    Raises:\n        PermissionError: If the file at location cannot be accessed due to a permission error.\n        FileNotFoundError: When the file at the provided location does not exist.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.FileIO.new_input","title":"<code>new_input(location)</code>  <code>abstractmethod</code>","text":"<p>Get an InputFile instance to read bytes from the file at the given location.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>A URI or a path to a local file.</p> required Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@abstractmethod\ndef new_input(self, location: str) -&gt; InputFile:\n    \"\"\"Get an InputFile instance to read bytes from the file at the given location.\n\n    Args:\n        location (str): A URI or a path to a local file.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.FileIO.new_output","title":"<code>new_output(location)</code>  <code>abstractmethod</code>","text":"<p>Get an OutputFile instance to write bytes to the file at the given location.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>A URI or a path to a local file.</p> required Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@abstractmethod\ndef new_output(self, location: str) -&gt; OutputFile:\n    \"\"\"Get an OutputFile instance to write bytes to the file at the given location.\n\n    Args:\n        location (str): A URI or a path to a local file.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.InputFile","title":"<code>InputFile</code>","text":"<p>             Bases: <code>ABC</code></p> <p>A base class for InputFile implementations.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>A URI or a path to a local file.</p> required <p>Attributes:</p> Name Type Description <code>location</code> <code>str</code> <p>The URI or path to a local file for an InputFile instance.</p> <code>exists</code> <code>bool</code> <p>Whether the file exists or not.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>class InputFile(ABC):\n    \"\"\"A base class for InputFile implementations.\n\n    Args:\n        location (str): A URI or a path to a local file.\n\n    Attributes:\n        location (str): The URI or path to a local file for an InputFile instance.\n        exists (bool): Whether the file exists or not.\n    \"\"\"\n\n    def __init__(self, location: str):\n        self._location = location\n\n    @abstractmethod\n    def __len__(self) -&gt; int:\n        \"\"\"Return the total length of the file, in bytes.\"\"\"\n\n    @property\n    def location(self) -&gt; str:\n        \"\"\"The fully-qualified location of the input file.\"\"\"\n        return self._location\n\n    @abstractmethod\n    def exists(self) -&gt; bool:\n        \"\"\"Check whether the location exists.\n\n        Raises:\n            PermissionError: If the file at self.location cannot be accessed due to a permission error.\n        \"\"\"\n\n    @abstractmethod\n    def open(self, seekable: bool = True) -&gt; InputStream:\n        \"\"\"Return an object that matches the InputStream protocol.\n\n        Args:\n            seekable: If the stream should support seek, or if it is consumed sequential.\n\n        Returns:\n            InputStream: An object that matches the InputStream protocol.\n\n        Raises:\n            PermissionError: If the file at self.location cannot be accessed due to a permission error.\n            FileNotFoundError: If the file at self.location does not exist.\n        \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.InputFile.location","title":"<code>location: str</code>  <code>property</code>","text":"<p>The fully-qualified location of the input file.</p>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.InputFile.__len__","title":"<code>__len__()</code>  <code>abstractmethod</code>","text":"<p>Return the total length of the file, in bytes.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@abstractmethod\ndef __len__(self) -&gt; int:\n    \"\"\"Return the total length of the file, in bytes.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.InputFile.exists","title":"<code>exists()</code>  <code>abstractmethod</code>","text":"<p>Check whether the location exists.</p> <p>Raises:</p> Type Description <code>PermissionError</code> <p>If the file at self.location cannot be accessed due to a permission error.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@abstractmethod\ndef exists(self) -&gt; bool:\n    \"\"\"Check whether the location exists.\n\n    Raises:\n        PermissionError: If the file at self.location cannot be accessed due to a permission error.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.InputFile.open","title":"<code>open(seekable=True)</code>  <code>abstractmethod</code>","text":"<p>Return an object that matches the InputStream protocol.</p> <p>Parameters:</p> Name Type Description Default <code>seekable</code> <code>bool</code> <p>If the stream should support seek, or if it is consumed sequential.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>InputStream</code> <code>InputStream</code> <p>An object that matches the InputStream protocol.</p> <p>Raises:</p> Type Description <code>PermissionError</code> <p>If the file at self.location cannot be accessed due to a permission error.</p> <code>FileNotFoundError</code> <p>If the file at self.location does not exist.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@abstractmethod\ndef open(self, seekable: bool = True) -&gt; InputStream:\n    \"\"\"Return an object that matches the InputStream protocol.\n\n    Args:\n        seekable: If the stream should support seek, or if it is consumed sequential.\n\n    Returns:\n        InputStream: An object that matches the InputStream protocol.\n\n    Raises:\n        PermissionError: If the file at self.location cannot be accessed due to a permission error.\n        FileNotFoundError: If the file at self.location does not exist.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.InputStream","title":"<code>InputStream</code>","text":"<p>             Bases: <code>Protocol</code></p> <p>A protocol for the file-like object returned by InputFile.open(...).</p> <p>This outlines the minimally required methods for a seekable input stream returned from an InputFile implementation's <code>open(...)</code> method. These methods are a subset of IOBase/RawIOBase.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@runtime_checkable\nclass InputStream(Protocol):\n    \"\"\"A protocol for the file-like object returned by InputFile.open(...).\n\n    This outlines the minimally required methods for a seekable input stream returned from an InputFile\n    implementation's `open(...)` method. These methods are a subset of IOBase/RawIOBase.\n    \"\"\"\n\n    @abstractmethod\n    def read(self, size: int = 0) -&gt; bytes: ...\n\n    @abstractmethod\n    def seek(self, offset: int, whence: int = SEEK_SET) -&gt; int: ...\n\n    @abstractmethod\n    def tell(self) -&gt; int: ...\n\n    @abstractmethod\n    def close(self) -&gt; None: ...\n\n    def __enter__(self) -&gt; InputStream:\n        \"\"\"Provide setup when opening an InputStream using a 'with' statement.\"\"\"\n\n    @abstractmethod\n    def __exit__(\n        self, exctype: Optional[Type[BaseException]], excinst: Optional[BaseException], exctb: Optional[TracebackType]\n    ) -&gt; None:\n        \"\"\"Perform cleanup when exiting the scope of a 'with' statement.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.InputStream.__enter__","title":"<code>__enter__()</code>","text":"<p>Provide setup when opening an InputStream using a 'with' statement.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>def __enter__(self) -&gt; InputStream:\n    \"\"\"Provide setup when opening an InputStream using a 'with' statement.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.InputStream.__exit__","title":"<code>__exit__(exctype, excinst, exctb)</code>  <code>abstractmethod</code>","text":"<p>Perform cleanup when exiting the scope of a 'with' statement.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@abstractmethod\ndef __exit__(\n    self, exctype: Optional[Type[BaseException]], excinst: Optional[BaseException], exctb: Optional[TracebackType]\n) -&gt; None:\n    \"\"\"Perform cleanup when exiting the scope of a 'with' statement.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.OutputFile","title":"<code>OutputFile</code>","text":"<p>             Bases: <code>ABC</code></p> <p>A base class for OutputFile implementations.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>A URI or a path to a local file.</p> required <p>Attributes:</p> Name Type Description <code>location</code> <code>str</code> <p>The URI or path to a local file for an OutputFile instance.</p> <code>exists</code> <code>bool</code> <p>Whether the file exists or not.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>class OutputFile(ABC):\n    \"\"\"A base class for OutputFile implementations.\n\n    Args:\n        location (str): A URI or a path to a local file.\n\n    Attributes:\n        location (str): The URI or path to a local file for an OutputFile instance.\n        exists (bool): Whether the file exists or not.\n    \"\"\"\n\n    def __init__(self, location: str):\n        self._location = location\n\n    @abstractmethod\n    def __len__(self) -&gt; int:\n        \"\"\"Return the total length of the file, in bytes.\"\"\"\n\n    @property\n    def location(self) -&gt; str:\n        \"\"\"The fully-qualified location of the output file.\"\"\"\n        return self._location\n\n    @abstractmethod\n    def exists(self) -&gt; bool:\n        \"\"\"Check whether the location exists.\n\n        Raises:\n            PermissionError: If the file at self.location cannot be accessed due to a permission error.\n        \"\"\"\n\n    @abstractmethod\n    def to_input_file(self) -&gt; InputFile:\n        \"\"\"Return an InputFile for the location of this output file.\"\"\"\n\n    @abstractmethod\n    def create(self, overwrite: bool = False) -&gt; OutputStream:\n        \"\"\"Return an object that matches the OutputStream protocol.\n\n        Args:\n            overwrite (bool): If the file already exists at `self.location`\n                and `overwrite` is False a FileExistsError should be raised.\n\n        Returns:\n            OutputStream: An object that matches the OutputStream protocol.\n\n        Raises:\n            PermissionError: If the file at self.location cannot be accessed due to a permission error.\n            FileExistsError: If the file at self.location already exists and `overwrite=False`.\n        \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.OutputFile.location","title":"<code>location: str</code>  <code>property</code>","text":"<p>The fully-qualified location of the output file.</p>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.OutputFile.__len__","title":"<code>__len__()</code>  <code>abstractmethod</code>","text":"<p>Return the total length of the file, in bytes.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@abstractmethod\ndef __len__(self) -&gt; int:\n    \"\"\"Return the total length of the file, in bytes.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.OutputFile.create","title":"<code>create(overwrite=False)</code>  <code>abstractmethod</code>","text":"<p>Return an object that matches the OutputStream protocol.</p> <p>Parameters:</p> Name Type Description Default <code>overwrite</code> <code>bool</code> <p>If the file already exists at <code>self.location</code> and <code>overwrite</code> is False a FileExistsError should be raised.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>OutputStream</code> <code>OutputStream</code> <p>An object that matches the OutputStream protocol.</p> <p>Raises:</p> Type Description <code>PermissionError</code> <p>If the file at self.location cannot be accessed due to a permission error.</p> <code>FileExistsError</code> <p>If the file at self.location already exists and <code>overwrite=False</code>.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@abstractmethod\ndef create(self, overwrite: bool = False) -&gt; OutputStream:\n    \"\"\"Return an object that matches the OutputStream protocol.\n\n    Args:\n        overwrite (bool): If the file already exists at `self.location`\n            and `overwrite` is False a FileExistsError should be raised.\n\n    Returns:\n        OutputStream: An object that matches the OutputStream protocol.\n\n    Raises:\n        PermissionError: If the file at self.location cannot be accessed due to a permission error.\n        FileExistsError: If the file at self.location already exists and `overwrite=False`.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.OutputFile.exists","title":"<code>exists()</code>  <code>abstractmethod</code>","text":"<p>Check whether the location exists.</p> <p>Raises:</p> Type Description <code>PermissionError</code> <p>If the file at self.location cannot be accessed due to a permission error.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@abstractmethod\ndef exists(self) -&gt; bool:\n    \"\"\"Check whether the location exists.\n\n    Raises:\n        PermissionError: If the file at self.location cannot be accessed due to a permission error.\n    \"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.OutputFile.to_input_file","title":"<code>to_input_file()</code>  <code>abstractmethod</code>","text":"<p>Return an InputFile for the location of this output file.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@abstractmethod\ndef to_input_file(self) -&gt; InputFile:\n    \"\"\"Return an InputFile for the location of this output file.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.OutputStream","title":"<code>OutputStream</code>","text":"<p>             Bases: <code>Protocol</code></p> <p>A protocol for the file-like object returned by OutputFile.create(...).</p> <p>This outlines the minimally required methods for a writable output stream returned from an OutputFile implementation's <code>create(...)</code> method. These methods are a subset of IOBase/RawIOBase.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@runtime_checkable\nclass OutputStream(Protocol):  # pragma: no cover\n    \"\"\"A protocol for the file-like object returned by OutputFile.create(...).\n\n    This outlines the minimally required methods for a writable output stream returned from an OutputFile\n    implementation's `create(...)` method. These methods are a subset of IOBase/RawIOBase.\n    \"\"\"\n\n    @abstractmethod\n    def write(self, b: bytes) -&gt; int: ...\n\n    @abstractmethod\n    def close(self) -&gt; None: ...\n\n    @abstractmethod\n    def __enter__(self) -&gt; OutputStream:\n        \"\"\"Provide setup when opening an OutputStream using a 'with' statement.\"\"\"\n\n    @abstractmethod\n    def __exit__(\n        self, exctype: Optional[Type[BaseException]], excinst: Optional[BaseException], exctb: Optional[TracebackType]\n    ) -&gt; None:\n        \"\"\"Perform cleanup when exiting the scope of a 'with' statement.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.OutputStream.__enter__","title":"<code>__enter__()</code>  <code>abstractmethod</code>","text":"<p>Provide setup when opening an OutputStream using a 'with' statement.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@abstractmethod\ndef __enter__(self) -&gt; OutputStream:\n    \"\"\"Provide setup when opening an OutputStream using a 'with' statement.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/#pyiceberg.io.OutputStream.__exit__","title":"<code>__exit__(exctype, excinst, exctb)</code>  <code>abstractmethod</code>","text":"<p>Perform cleanup when exiting the scope of a 'with' statement.</p> Source code in <code>pyiceberg/io/__init__.py</code> <pre><code>@abstractmethod\ndef __exit__(\n    self, exctype: Optional[Type[BaseException]], excinst: Optional[BaseException], exctb: Optional[TracebackType]\n) -&gt; None:\n    \"\"\"Perform cleanup when exiting the scope of a 'with' statement.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/fsspec/","title":"fsspec","text":"<p>FileIO implementation for reading and writing table files that uses fsspec compatible filesystems.</p>"},{"location":"reference/pyiceberg/io/fsspec/#pyiceberg.io.fsspec.FsspecFileIO","title":"<code>FsspecFileIO</code>","text":"<p>             Bases: <code>FileIO</code></p> <p>A FileIO implementation that uses fsspec.</p> Source code in <code>pyiceberg/io/fsspec.py</code> <pre><code>class FsspecFileIO(FileIO):\n    \"\"\"A FileIO implementation that uses fsspec.\"\"\"\n\n    def __init__(self, properties: Properties):\n        self._scheme_to_fs = {}\n        self._scheme_to_fs.update(SCHEME_TO_FS)\n        self.get_fs: Callable[[str], AbstractFileSystem] = lru_cache(self._get_fs)\n        super().__init__(properties=properties)\n\n    def new_input(self, location: str) -&gt; FsspecInputFile:\n        \"\"\"Get an FsspecInputFile instance to read bytes from the file at the given location.\n\n        Args:\n            location (str): A URI or a path to a local file.\n\n        Returns:\n            FsspecInputFile: An FsspecInputFile instance for the given location.\n        \"\"\"\n        uri = urlparse(location)\n        fs = self.get_fs(uri.scheme)\n        return FsspecInputFile(location=location, fs=fs)\n\n    def new_output(self, location: str) -&gt; FsspecOutputFile:\n        \"\"\"Get an FsspecOutputFile instance to write bytes to the file at the given location.\n\n        Args:\n            location (str): A URI or a path to a local file.\n\n        Returns:\n            FsspecOutputFile: An FsspecOutputFile instance for the given location.\n        \"\"\"\n        uri = urlparse(location)\n        fs = self.get_fs(uri.scheme)\n        return FsspecOutputFile(location=location, fs=fs)\n\n    def delete(self, location: Union[str, InputFile, OutputFile]) -&gt; None:\n        \"\"\"Delete the file at the given location.\n\n        Args:\n            location (Union[str, InputFile, OutputFile]): The URI to the file--if an InputFile instance or an\n                OutputFile instance is provided, the location attribute for that instance is used as the location\n                to delete.\n        \"\"\"\n        if isinstance(location, (InputFile, OutputFile)):\n            str_location = location.location  # Use InputFile or OutputFile location\n        else:\n            str_location = location\n\n        uri = urlparse(str_location)\n        fs = self.get_fs(uri.scheme)\n        fs.rm(str_location)\n\n    def _get_fs(self, scheme: str) -&gt; AbstractFileSystem:\n        \"\"\"Get a filesystem for a specific scheme.\"\"\"\n        if scheme not in self._scheme_to_fs:\n            raise ValueError(f\"No registered filesystem for scheme: {scheme}\")\n        return self._scheme_to_fs[scheme](self.properties)\n</code></pre>"},{"location":"reference/pyiceberg/io/fsspec/#pyiceberg.io.fsspec.FsspecFileIO.delete","title":"<code>delete(location)</code>","text":"<p>Delete the file at the given location.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>Union[str, InputFile, OutputFile]</code> <p>The URI to the file--if an InputFile instance or an OutputFile instance is provided, the location attribute for that instance is used as the location to delete.</p> required Source code in <code>pyiceberg/io/fsspec.py</code> <pre><code>def delete(self, location: Union[str, InputFile, OutputFile]) -&gt; None:\n    \"\"\"Delete the file at the given location.\n\n    Args:\n        location (Union[str, InputFile, OutputFile]): The URI to the file--if an InputFile instance or an\n            OutputFile instance is provided, the location attribute for that instance is used as the location\n            to delete.\n    \"\"\"\n    if isinstance(location, (InputFile, OutputFile)):\n        str_location = location.location  # Use InputFile or OutputFile location\n    else:\n        str_location = location\n\n    uri = urlparse(str_location)\n    fs = self.get_fs(uri.scheme)\n    fs.rm(str_location)\n</code></pre>"},{"location":"reference/pyiceberg/io/fsspec/#pyiceberg.io.fsspec.FsspecFileIO.new_input","title":"<code>new_input(location)</code>","text":"<p>Get an FsspecInputFile instance to read bytes from the file at the given location.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>A URI or a path to a local file.</p> required <p>Returns:</p> Name Type Description <code>FsspecInputFile</code> <code>FsspecInputFile</code> <p>An FsspecInputFile instance for the given location.</p> Source code in <code>pyiceberg/io/fsspec.py</code> <pre><code>def new_input(self, location: str) -&gt; FsspecInputFile:\n    \"\"\"Get an FsspecInputFile instance to read bytes from the file at the given location.\n\n    Args:\n        location (str): A URI or a path to a local file.\n\n    Returns:\n        FsspecInputFile: An FsspecInputFile instance for the given location.\n    \"\"\"\n    uri = urlparse(location)\n    fs = self.get_fs(uri.scheme)\n    return FsspecInputFile(location=location, fs=fs)\n</code></pre>"},{"location":"reference/pyiceberg/io/fsspec/#pyiceberg.io.fsspec.FsspecFileIO.new_output","title":"<code>new_output(location)</code>","text":"<p>Get an FsspecOutputFile instance to write bytes to the file at the given location.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>A URI or a path to a local file.</p> required <p>Returns:</p> Name Type Description <code>FsspecOutputFile</code> <code>FsspecOutputFile</code> <p>An FsspecOutputFile instance for the given location.</p> Source code in <code>pyiceberg/io/fsspec.py</code> <pre><code>def new_output(self, location: str) -&gt; FsspecOutputFile:\n    \"\"\"Get an FsspecOutputFile instance to write bytes to the file at the given location.\n\n    Args:\n        location (str): A URI or a path to a local file.\n\n    Returns:\n        FsspecOutputFile: An FsspecOutputFile instance for the given location.\n    \"\"\"\n    uri = urlparse(location)\n    fs = self.get_fs(uri.scheme)\n    return FsspecOutputFile(location=location, fs=fs)\n</code></pre>"},{"location":"reference/pyiceberg/io/fsspec/#pyiceberg.io.fsspec.FsspecInputFile","title":"<code>FsspecInputFile</code>","text":"<p>             Bases: <code>InputFile</code></p> <p>An input file implementation for the FsspecFileIO.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>A URI to a file location.</p> required <code>fs</code> <code>AbstractFileSystem</code> <p>An fsspec filesystem instance.</p> required Source code in <code>pyiceberg/io/fsspec.py</code> <pre><code>class FsspecInputFile(InputFile):\n    \"\"\"An input file implementation for the FsspecFileIO.\n\n    Args:\n        location (str): A URI to a file location.\n        fs (AbstractFileSystem): An fsspec filesystem instance.\n    \"\"\"\n\n    def __init__(self, location: str, fs: AbstractFileSystem):\n        self._fs = fs\n        super().__init__(location=location)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the total length of the file, in bytes.\"\"\"\n        object_info = self._fs.info(self.location)\n        if size := object_info.get(\"Size\"):\n            return size\n        elif size := object_info.get(\"size\"):\n            return size\n        raise RuntimeError(f\"Cannot retrieve object info: {self.location}\")\n\n    def exists(self) -&gt; bool:\n        \"\"\"Check whether the location exists.\"\"\"\n        return self._fs.lexists(self.location)\n\n    def open(self, seekable: bool = True) -&gt; InputStream:\n        \"\"\"Create an input stream for reading the contents of the file.\n\n        Args:\n            seekable: If the stream should support seek, or if it is consumed sequential.\n\n        Returns:\n            OpenFile: An fsspec compliant file-like object.\n\n        Raises:\n            FileNotFoundError: If the file does not exist.\n        \"\"\"\n        try:\n            return self._fs.open(self.location, \"rb\")\n        except FileNotFoundError as e:\n            # To have a consistent error handling experience, make sure exception contains missing file location.\n            raise e if e.filename else FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), self.location) from e\n</code></pre>"},{"location":"reference/pyiceberg/io/fsspec/#pyiceberg.io.fsspec.FsspecInputFile.__len__","title":"<code>__len__()</code>","text":"<p>Return the total length of the file, in bytes.</p> Source code in <code>pyiceberg/io/fsspec.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the total length of the file, in bytes.\"\"\"\n    object_info = self._fs.info(self.location)\n    if size := object_info.get(\"Size\"):\n        return size\n    elif size := object_info.get(\"size\"):\n        return size\n    raise RuntimeError(f\"Cannot retrieve object info: {self.location}\")\n</code></pre>"},{"location":"reference/pyiceberg/io/fsspec/#pyiceberg.io.fsspec.FsspecInputFile.exists","title":"<code>exists()</code>","text":"<p>Check whether the location exists.</p> Source code in <code>pyiceberg/io/fsspec.py</code> <pre><code>def exists(self) -&gt; bool:\n    \"\"\"Check whether the location exists.\"\"\"\n    return self._fs.lexists(self.location)\n</code></pre>"},{"location":"reference/pyiceberg/io/fsspec/#pyiceberg.io.fsspec.FsspecInputFile.open","title":"<code>open(seekable=True)</code>","text":"<p>Create an input stream for reading the contents of the file.</p> <p>Parameters:</p> Name Type Description Default <code>seekable</code> <code>bool</code> <p>If the stream should support seek, or if it is consumed sequential.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>OpenFile</code> <code>InputStream</code> <p>An fsspec compliant file-like object.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file does not exist.</p> Source code in <code>pyiceberg/io/fsspec.py</code> <pre><code>def open(self, seekable: bool = True) -&gt; InputStream:\n    \"\"\"Create an input stream for reading the contents of the file.\n\n    Args:\n        seekable: If the stream should support seek, or if it is consumed sequential.\n\n    Returns:\n        OpenFile: An fsspec compliant file-like object.\n\n    Raises:\n        FileNotFoundError: If the file does not exist.\n    \"\"\"\n    try:\n        return self._fs.open(self.location, \"rb\")\n    except FileNotFoundError as e:\n        # To have a consistent error handling experience, make sure exception contains missing file location.\n        raise e if e.filename else FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), self.location) from e\n</code></pre>"},{"location":"reference/pyiceberg/io/fsspec/#pyiceberg.io.fsspec.FsspecOutputFile","title":"<code>FsspecOutputFile</code>","text":"<p>             Bases: <code>OutputFile</code></p> <p>An output file implementation for the FsspecFileIO.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>A URI to a file location.</p> required <code>fs</code> <code>AbstractFileSystem</code> <p>An fsspec filesystem instance.</p> required Source code in <code>pyiceberg/io/fsspec.py</code> <pre><code>class FsspecOutputFile(OutputFile):\n    \"\"\"An output file implementation for the FsspecFileIO.\n\n    Args:\n        location (str): A URI to a file location.\n        fs (AbstractFileSystem): An fsspec filesystem instance.\n    \"\"\"\n\n    def __init__(self, location: str, fs: AbstractFileSystem):\n        self._fs = fs\n        super().__init__(location=location)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the total length of the file, in bytes.\"\"\"\n        object_info = self._fs.info(self.location)\n        if size := object_info.get(\"Size\"):\n            return size\n        elif size := object_info.get(\"size\"):\n            return size\n        raise RuntimeError(f\"Cannot retrieve object info: {self.location}\")\n\n    def exists(self) -&gt; bool:\n        \"\"\"Check whether the location exists.\"\"\"\n        return self._fs.lexists(self.location)\n\n    def create(self, overwrite: bool = False) -&gt; OutputStream:\n        \"\"\"Create an output stream for reading the contents of the file.\n\n        Args:\n            overwrite (bool): Whether to overwrite the file if it already exists.\n\n        Returns:\n            OpenFile: An fsspec compliant file-like object.\n\n        Raises:\n            FileExistsError: If the file already exists at the location and overwrite is set to False.\n\n        Note:\n            If overwrite is set to False, a check is first performed to verify that the file does not exist.\n            This is not thread-safe and a possibility does exist that the file can be created by a concurrent\n            process after the existence check yet before the output stream is created. In such a case, the default\n            behavior will truncate the contents of the existing file when opening the output stream.\n        \"\"\"\n        if not overwrite and self.exists():\n            raise FileExistsError(f\"Cannot create file, file already exists: {self.location}\")\n        return self._fs.open(self.location, \"wb\")\n\n    def to_input_file(self) -&gt; FsspecInputFile:\n        \"\"\"Return a new FsspecInputFile for the location at `self.location`.\"\"\"\n        return FsspecInputFile(location=self.location, fs=self._fs)\n</code></pre>"},{"location":"reference/pyiceberg/io/fsspec/#pyiceberg.io.fsspec.FsspecOutputFile.__len__","title":"<code>__len__()</code>","text":"<p>Return the total length of the file, in bytes.</p> Source code in <code>pyiceberg/io/fsspec.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the total length of the file, in bytes.\"\"\"\n    object_info = self._fs.info(self.location)\n    if size := object_info.get(\"Size\"):\n        return size\n    elif size := object_info.get(\"size\"):\n        return size\n    raise RuntimeError(f\"Cannot retrieve object info: {self.location}\")\n</code></pre>"},{"location":"reference/pyiceberg/io/fsspec/#pyiceberg.io.fsspec.FsspecOutputFile.create","title":"<code>create(overwrite=False)</code>","text":"<p>Create an output stream for reading the contents of the file.</p> <p>Parameters:</p> Name Type Description Default <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the file if it already exists.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>OpenFile</code> <code>OutputStream</code> <p>An fsspec compliant file-like object.</p> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If the file already exists at the location and overwrite is set to False.</p> Note <p>If overwrite is set to False, a check is first performed to verify that the file does not exist. This is not thread-safe and a possibility does exist that the file can be created by a concurrent process after the existence check yet before the output stream is created. In such a case, the default behavior will truncate the contents of the existing file when opening the output stream.</p> Source code in <code>pyiceberg/io/fsspec.py</code> <pre><code>def create(self, overwrite: bool = False) -&gt; OutputStream:\n    \"\"\"Create an output stream for reading the contents of the file.\n\n    Args:\n        overwrite (bool): Whether to overwrite the file if it already exists.\n\n    Returns:\n        OpenFile: An fsspec compliant file-like object.\n\n    Raises:\n        FileExistsError: If the file already exists at the location and overwrite is set to False.\n\n    Note:\n        If overwrite is set to False, a check is first performed to verify that the file does not exist.\n        This is not thread-safe and a possibility does exist that the file can be created by a concurrent\n        process after the existence check yet before the output stream is created. In such a case, the default\n        behavior will truncate the contents of the existing file when opening the output stream.\n    \"\"\"\n    if not overwrite and self.exists():\n        raise FileExistsError(f\"Cannot create file, file already exists: {self.location}\")\n    return self._fs.open(self.location, \"wb\")\n</code></pre>"},{"location":"reference/pyiceberg/io/fsspec/#pyiceberg.io.fsspec.FsspecOutputFile.exists","title":"<code>exists()</code>","text":"<p>Check whether the location exists.</p> Source code in <code>pyiceberg/io/fsspec.py</code> <pre><code>def exists(self) -&gt; bool:\n    \"\"\"Check whether the location exists.\"\"\"\n    return self._fs.lexists(self.location)\n</code></pre>"},{"location":"reference/pyiceberg/io/fsspec/#pyiceberg.io.fsspec.FsspecOutputFile.to_input_file","title":"<code>to_input_file()</code>","text":"<p>Return a new FsspecInputFile for the location at <code>self.location</code>.</p> Source code in <code>pyiceberg/io/fsspec.py</code> <pre><code>def to_input_file(self) -&gt; FsspecInputFile:\n    \"\"\"Return a new FsspecInputFile for the location at `self.location`.\"\"\"\n    return FsspecInputFile(location=self.location, fs=self._fs)\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/","title":"pyarrow","text":"<p>FileIO implementation for reading and writing table files that uses pyarrow.fs.</p> <p>This file contains a FileIO implementation that relies on the filesystem interface provided by PyArrow. It relies on PyArrow's <code>from_uri</code> method that infers the correct filesystem type to use. Theoretically, this allows the supported storage types to grow naturally with the pyarrow library.</p>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowFile","title":"<code>PyArrowFile</code>","text":"<p>             Bases: <code>InputFile</code>, <code>OutputFile</code></p> <p>A combined InputFile and OutputFile implementation that uses a pyarrow filesystem to generate pyarrow.lib.NativeFile instances.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>A URI or a path to a local file.</p> required <p>Attributes:</p> Name Type Description <code>location(str)</code> <p>The URI or path to a local file for a PyArrowFile instance.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pyiceberg.io.pyarrow import PyArrowFile\n&gt;&gt;&gt; # input_file = PyArrowFile(\"s3://foo/bar.txt\")\n&gt;&gt;&gt; # Read the contents of the PyArrowFile instance\n&gt;&gt;&gt; # Make sure that you have permissions to read/write\n&gt;&gt;&gt; # file_content = input_file.open().read()\n</code></pre> <pre><code>&gt;&gt;&gt; # output_file = PyArrowFile(\"s3://baz/qux.txt\")\n&gt;&gt;&gt; # Write bytes to a file\n&gt;&gt;&gt; # Make sure that you have permissions to read/write\n&gt;&gt;&gt; # output_file.create().write(b'foobytes')\n</code></pre> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>class PyArrowFile(InputFile, OutputFile):\n    \"\"\"A combined InputFile and OutputFile implementation that uses a pyarrow filesystem to generate pyarrow.lib.NativeFile instances.\n\n    Args:\n        location (str): A URI or a path to a local file.\n\n    Attributes:\n        location(str): The URI or path to a local file for a PyArrowFile instance.\n\n    Examples:\n        &gt;&gt;&gt; from pyiceberg.io.pyarrow import PyArrowFile\n        &gt;&gt;&gt; # input_file = PyArrowFile(\"s3://foo/bar.txt\")\n        &gt;&gt;&gt; # Read the contents of the PyArrowFile instance\n        &gt;&gt;&gt; # Make sure that you have permissions to read/write\n        &gt;&gt;&gt; # file_content = input_file.open().read()\n\n        &gt;&gt;&gt; # output_file = PyArrowFile(\"s3://baz/qux.txt\")\n        &gt;&gt;&gt; # Write bytes to a file\n        &gt;&gt;&gt; # Make sure that you have permissions to read/write\n        &gt;&gt;&gt; # output_file.create().write(b'foobytes')\n    \"\"\"\n\n    _fs: FileSystem\n    _path: str\n    _buffer_size: int\n\n    def __init__(self, location: str, path: str, fs: FileSystem, buffer_size: int = ONE_MEGABYTE):\n        self._filesystem = fs\n        self._path = path\n        self._buffer_size = buffer_size\n        super().__init__(location=location)\n\n    def _file_info(self) -&gt; FileInfo:\n        \"\"\"Retrieve a pyarrow.fs.FileInfo object for the location.\n\n        Raises:\n            PermissionError: If the file at self.location cannot be accessed due to a permission error such as\n                an AWS error code 15.\n        \"\"\"\n        try:\n            file_info = self._filesystem.get_file_info(self._path)\n        except OSError as e:\n            if e.errno == 13 or \"AWS Error [code 15]\" in str(e):\n                raise PermissionError(f\"Cannot get file info, access denied: {self.location}\") from e\n            raise  # pragma: no cover - If some other kind of OSError, raise the raw error\n\n        if file_info.type == FileType.NotFound:\n            raise FileNotFoundError(f\"Cannot get file info, file not found: {self.location}\")\n        return file_info\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the total length of the file, in bytes.\"\"\"\n        file_info = self._file_info()\n        return file_info.size\n\n    def exists(self) -&gt; bool:\n        \"\"\"Check whether the location exists.\"\"\"\n        try:\n            self._file_info()  # raises FileNotFoundError if it does not exist\n            return True\n        except FileNotFoundError:\n            return False\n\n    def open(self, seekable: bool = True) -&gt; InputStream:\n        \"\"\"Open the location using a PyArrow FileSystem inferred from the location.\n\n        Args:\n            seekable: If the stream should support seek, or if it is consumed sequential.\n\n        Returns:\n            pyarrow.lib.NativeFile: A NativeFile instance for the file located at `self.location`.\n\n        Raises:\n            FileNotFoundError: If the file at self.location does not exist.\n            PermissionError: If the file at self.location cannot be accessed due to a permission error such as\n                an AWS error code 15.\n        \"\"\"\n        try:\n            if seekable:\n                input_file = self._filesystem.open_input_file(self._path)\n            else:\n                input_file = self._filesystem.open_input_stream(self._path, buffer_size=self._buffer_size)\n        except FileNotFoundError:\n            raise\n        except PermissionError:\n            raise\n        except OSError as e:\n            if e.errno == 2 or \"Path does not exist\" in str(e):\n                raise FileNotFoundError(f\"Cannot open file, does not exist: {self.location}\") from e\n            elif e.errno == 13 or \"AWS Error [code 15]\" in str(e):\n                raise PermissionError(f\"Cannot open file, access denied: {self.location}\") from e\n            raise  # pragma: no cover - If some other kind of OSError, raise the raw error\n        return input_file\n\n    def create(self, overwrite: bool = False) -&gt; OutputStream:\n        \"\"\"Create a writable pyarrow.lib.NativeFile for this PyArrowFile's location.\n\n        Args:\n            overwrite (bool): Whether to overwrite the file if it already exists.\n\n        Returns:\n            pyarrow.lib.NativeFile: A NativeFile instance for the file located at self.location.\n\n        Raises:\n            FileExistsError: If the file already exists at `self.location` and `overwrite` is False.\n\n        Note:\n            This retrieves a pyarrow NativeFile by opening an output stream. If overwrite is set to False,\n            a check is first performed to verify that the file does not exist. This is not thread-safe and\n            a possibility does exist that the file can be created by a concurrent process after the existence\n            check yet before the output stream is created. In such a case, the default pyarrow behavior will\n            truncate the contents of the existing file when opening the output stream.\n        \"\"\"\n        try:\n            if not overwrite and self.exists() is True:\n                raise FileExistsError(f\"Cannot create file, already exists: {self.location}\")\n            output_file = self._filesystem.open_output_stream(self._path, buffer_size=self._buffer_size)\n        except PermissionError:\n            raise\n        except OSError as e:\n            if e.errno == 13 or \"AWS Error [code 15]\" in str(e):\n                raise PermissionError(f\"Cannot create file, access denied: {self.location}\") from e\n            raise  # pragma: no cover - If some other kind of OSError, raise the raw error\n        return output_file\n\n    def to_input_file(self) -&gt; PyArrowFile:\n        \"\"\"Return a new PyArrowFile for the location of an existing PyArrowFile instance.\n\n        This method is included to abide by the OutputFile abstract base class. Since this implementation uses a single\n        PyArrowFile class (as opposed to separate InputFile and OutputFile implementations), this method effectively returns\n        a copy of the same instance.\n        \"\"\"\n        return self\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowFile.__len__","title":"<code>__len__()</code>","text":"<p>Return the total length of the file, in bytes.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the total length of the file, in bytes.\"\"\"\n    file_info = self._file_info()\n    return file_info.size\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowFile.create","title":"<code>create(overwrite=False)</code>","text":"<p>Create a writable pyarrow.lib.NativeFile for this PyArrowFile's location.</p> <p>Parameters:</p> Name Type Description Default <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the file if it already exists.</p> <code>False</code> <p>Returns:</p> Type Description <code>OutputStream</code> <p>pyarrow.lib.NativeFile: A NativeFile instance for the file located at self.location.</p> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If the file already exists at <code>self.location</code> and <code>overwrite</code> is False.</p> Note <p>This retrieves a pyarrow NativeFile by opening an output stream. If overwrite is set to False, a check is first performed to verify that the file does not exist. This is not thread-safe and a possibility does exist that the file can be created by a concurrent process after the existence check yet before the output stream is created. In such a case, the default pyarrow behavior will truncate the contents of the existing file when opening the output stream.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def create(self, overwrite: bool = False) -&gt; OutputStream:\n    \"\"\"Create a writable pyarrow.lib.NativeFile for this PyArrowFile's location.\n\n    Args:\n        overwrite (bool): Whether to overwrite the file if it already exists.\n\n    Returns:\n        pyarrow.lib.NativeFile: A NativeFile instance for the file located at self.location.\n\n    Raises:\n        FileExistsError: If the file already exists at `self.location` and `overwrite` is False.\n\n    Note:\n        This retrieves a pyarrow NativeFile by opening an output stream. If overwrite is set to False,\n        a check is first performed to verify that the file does not exist. This is not thread-safe and\n        a possibility does exist that the file can be created by a concurrent process after the existence\n        check yet before the output stream is created. In such a case, the default pyarrow behavior will\n        truncate the contents of the existing file when opening the output stream.\n    \"\"\"\n    try:\n        if not overwrite and self.exists() is True:\n            raise FileExistsError(f\"Cannot create file, already exists: {self.location}\")\n        output_file = self._filesystem.open_output_stream(self._path, buffer_size=self._buffer_size)\n    except PermissionError:\n        raise\n    except OSError as e:\n        if e.errno == 13 or \"AWS Error [code 15]\" in str(e):\n            raise PermissionError(f\"Cannot create file, access denied: {self.location}\") from e\n        raise  # pragma: no cover - If some other kind of OSError, raise the raw error\n    return output_file\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowFile.exists","title":"<code>exists()</code>","text":"<p>Check whether the location exists.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def exists(self) -&gt; bool:\n    \"\"\"Check whether the location exists.\"\"\"\n    try:\n        self._file_info()  # raises FileNotFoundError if it does not exist\n        return True\n    except FileNotFoundError:\n        return False\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowFile.open","title":"<code>open(seekable=True)</code>","text":"<p>Open the location using a PyArrow FileSystem inferred from the location.</p> <p>Parameters:</p> Name Type Description Default <code>seekable</code> <code>bool</code> <p>If the stream should support seek, or if it is consumed sequential.</p> <code>True</code> <p>Returns:</p> Type Description <code>InputStream</code> <p>pyarrow.lib.NativeFile: A NativeFile instance for the file located at <code>self.location</code>.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file at self.location does not exist.</p> <code>PermissionError</code> <p>If the file at self.location cannot be accessed due to a permission error such as an AWS error code 15.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def open(self, seekable: bool = True) -&gt; InputStream:\n    \"\"\"Open the location using a PyArrow FileSystem inferred from the location.\n\n    Args:\n        seekable: If the stream should support seek, or if it is consumed sequential.\n\n    Returns:\n        pyarrow.lib.NativeFile: A NativeFile instance for the file located at `self.location`.\n\n    Raises:\n        FileNotFoundError: If the file at self.location does not exist.\n        PermissionError: If the file at self.location cannot be accessed due to a permission error such as\n            an AWS error code 15.\n    \"\"\"\n    try:\n        if seekable:\n            input_file = self._filesystem.open_input_file(self._path)\n        else:\n            input_file = self._filesystem.open_input_stream(self._path, buffer_size=self._buffer_size)\n    except FileNotFoundError:\n        raise\n    except PermissionError:\n        raise\n    except OSError as e:\n        if e.errno == 2 or \"Path does not exist\" in str(e):\n            raise FileNotFoundError(f\"Cannot open file, does not exist: {self.location}\") from e\n        elif e.errno == 13 or \"AWS Error [code 15]\" in str(e):\n            raise PermissionError(f\"Cannot open file, access denied: {self.location}\") from e\n        raise  # pragma: no cover - If some other kind of OSError, raise the raw error\n    return input_file\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowFile.to_input_file","title":"<code>to_input_file()</code>","text":"<p>Return a new PyArrowFile for the location of an existing PyArrowFile instance.</p> <p>This method is included to abide by the OutputFile abstract base class. Since this implementation uses a single PyArrowFile class (as opposed to separate InputFile and OutputFile implementations), this method effectively returns a copy of the same instance.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def to_input_file(self) -&gt; PyArrowFile:\n    \"\"\"Return a new PyArrowFile for the location of an existing PyArrowFile instance.\n\n    This method is included to abide by the OutputFile abstract base class. Since this implementation uses a single\n    PyArrowFile class (as opposed to separate InputFile and OutputFile implementations), this method effectively returns\n    a copy of the same instance.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowFileIO","title":"<code>PyArrowFileIO</code>","text":"<p>             Bases: <code>FileIO</code></p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>class PyArrowFileIO(FileIO):\n    fs_by_scheme: Callable[[str, Optional[str]], FileSystem]\n\n    def __init__(self, properties: Properties = EMPTY_DICT):\n        self.fs_by_scheme: Callable[[str, Optional[str]], FileSystem] = lru_cache(self._initialize_fs)\n        super().__init__(properties=properties)\n\n    @staticmethod\n    def parse_location(location: str) -&gt; Tuple[str, str, str]:\n        \"\"\"Return the path without the scheme.\"\"\"\n        uri = urlparse(location)\n        if not uri.scheme:\n            return \"file\", uri.netloc, os.path.abspath(location)\n        elif uri.scheme == \"hdfs\":\n            return uri.scheme, uri.netloc, location\n        else:\n            return uri.scheme, uri.netloc, f\"{uri.netloc}{uri.path}\"\n\n    def _initialize_fs(self, scheme: str, netloc: Optional[str] = None) -&gt; FileSystem:\n        if scheme in {\"s3\", \"s3a\", \"s3n\"}:\n            from pyarrow.fs import S3FileSystem\n\n            client_kwargs: Dict[str, Any] = {\n                \"endpoint_override\": self.properties.get(S3_ENDPOINT),\n                \"access_key\": self.properties.get(S3_ACCESS_KEY_ID),\n                \"secret_key\": self.properties.get(S3_SECRET_ACCESS_KEY),\n                \"session_token\": self.properties.get(S3_SESSION_TOKEN),\n                \"region\": self.properties.get(S3_REGION),\n            }\n\n            if proxy_uri := self.properties.get(S3_PROXY_URI):\n                client_kwargs[\"proxy_options\"] = proxy_uri\n\n            if connect_timeout := self.properties.get(S3_CONNECT_TIMEOUT):\n                client_kwargs[\"connect_timeout\"] = float(connect_timeout)\n\n            return S3FileSystem(**client_kwargs)\n        elif scheme == \"hdfs\":\n            from pyarrow.fs import HadoopFileSystem\n\n            hdfs_kwargs: Dict[str, Any] = {}\n            if netloc:\n                return HadoopFileSystem.from_uri(f\"hdfs://{netloc}\")\n            if host := self.properties.get(HDFS_HOST):\n                hdfs_kwargs[\"host\"] = host\n            if port := self.properties.get(HDFS_PORT):\n                # port should be an integer type\n                hdfs_kwargs[\"port\"] = int(port)\n            if user := self.properties.get(HDFS_USER):\n                hdfs_kwargs[\"user\"] = user\n            if kerb_ticket := self.properties.get(HDFS_KERB_TICKET):\n                hdfs_kwargs[\"kerb_ticket\"] = kerb_ticket\n\n            return HadoopFileSystem(**hdfs_kwargs)\n        elif scheme in {\"gs\", \"gcs\"}:\n            from pyarrow.fs import GcsFileSystem\n\n            gcs_kwargs: Dict[str, Any] = {}\n            if access_token := self.properties.get(GCS_TOKEN):\n                gcs_kwargs[\"access_token\"] = access_token\n            if expiration := self.properties.get(GCS_TOKEN_EXPIRES_AT_MS):\n                gcs_kwargs[\"credential_token_expiration\"] = millis_to_datetime(int(expiration))\n            if bucket_location := self.properties.get(GCS_DEFAULT_LOCATION):\n                gcs_kwargs[\"default_bucket_location\"] = bucket_location\n            if endpoint := self.properties.get(GCS_ENDPOINT):\n                url_parts = urlparse(endpoint)\n                gcs_kwargs[\"scheme\"] = url_parts.scheme\n                gcs_kwargs[\"endpoint_override\"] = url_parts.netloc\n\n            return GcsFileSystem(**gcs_kwargs)\n        elif scheme == \"file\":\n            return PyArrowLocalFileSystem()\n        else:\n            raise ValueError(f\"Unrecognized filesystem type in URI: {scheme}\")\n\n    def new_input(self, location: str) -&gt; PyArrowFile:\n        \"\"\"Get a PyArrowFile instance to read bytes from the file at the given location.\n\n        Args:\n            location (str): A URI or a path to a local file.\n\n        Returns:\n            PyArrowFile: A PyArrowFile instance for the given location.\n        \"\"\"\n        scheme, netloc, path = self.parse_location(location)\n        return PyArrowFile(\n            fs=self.fs_by_scheme(scheme, netloc),\n            location=location,\n            path=path,\n            buffer_size=int(self.properties.get(BUFFER_SIZE, ONE_MEGABYTE)),\n        )\n\n    def new_output(self, location: str) -&gt; PyArrowFile:\n        \"\"\"Get a PyArrowFile instance to write bytes to the file at the given location.\n\n        Args:\n            location (str): A URI or a path to a local file.\n\n        Returns:\n            PyArrowFile: A PyArrowFile instance for the given location.\n        \"\"\"\n        scheme, netloc, path = self.parse_location(location)\n        return PyArrowFile(\n            fs=self.fs_by_scheme(scheme, netloc),\n            location=location,\n            path=path,\n            buffer_size=int(self.properties.get(BUFFER_SIZE, ONE_MEGABYTE)),\n        )\n\n    def delete(self, location: Union[str, InputFile, OutputFile]) -&gt; None:\n        \"\"\"Delete the file at the given location.\n\n        Args:\n            location (Union[str, InputFile, OutputFile]): The URI to the file--if an InputFile instance or an OutputFile instance is provided,\n                the location attribute for that instance is used as the location to delete.\n\n        Raises:\n            FileNotFoundError: When the file at the provided location does not exist.\n            PermissionError: If the file at the provided location cannot be accessed due to a permission error such as\n                an AWS error code 15.\n        \"\"\"\n        str_location = location.location if isinstance(location, (InputFile, OutputFile)) else location\n        scheme, netloc, path = self.parse_location(str_location)\n        fs = self.fs_by_scheme(scheme, netloc)\n\n        try:\n            fs.delete_file(path)\n        except FileNotFoundError:\n            raise\n        except PermissionError:\n            raise\n        except OSError as e:\n            if e.errno == 2 or \"Path does not exist\" in str(e):\n                raise FileNotFoundError(f\"Cannot delete file, does not exist: {location}\") from e\n            elif e.errno == 13 or \"AWS Error [code 15]\" in str(e):\n                raise PermissionError(f\"Cannot delete file, access denied: {location}\") from e\n            raise  # pragma: no cover - If some other kind of OSError, raise the raw error\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowFileIO.delete","title":"<code>delete(location)</code>","text":"<p>Delete the file at the given location.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>Union[str, InputFile, OutputFile]</code> <p>The URI to the file--if an InputFile instance or an OutputFile instance is provided, the location attribute for that instance is used as the location to delete.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>When the file at the provided location does not exist.</p> <code>PermissionError</code> <p>If the file at the provided location cannot be accessed due to a permission error such as an AWS error code 15.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def delete(self, location: Union[str, InputFile, OutputFile]) -&gt; None:\n    \"\"\"Delete the file at the given location.\n\n    Args:\n        location (Union[str, InputFile, OutputFile]): The URI to the file--if an InputFile instance or an OutputFile instance is provided,\n            the location attribute for that instance is used as the location to delete.\n\n    Raises:\n        FileNotFoundError: When the file at the provided location does not exist.\n        PermissionError: If the file at the provided location cannot be accessed due to a permission error such as\n            an AWS error code 15.\n    \"\"\"\n    str_location = location.location if isinstance(location, (InputFile, OutputFile)) else location\n    scheme, netloc, path = self.parse_location(str_location)\n    fs = self.fs_by_scheme(scheme, netloc)\n\n    try:\n        fs.delete_file(path)\n    except FileNotFoundError:\n        raise\n    except PermissionError:\n        raise\n    except OSError as e:\n        if e.errno == 2 or \"Path does not exist\" in str(e):\n            raise FileNotFoundError(f\"Cannot delete file, does not exist: {location}\") from e\n        elif e.errno == 13 or \"AWS Error [code 15]\" in str(e):\n            raise PermissionError(f\"Cannot delete file, access denied: {location}\") from e\n        raise  # pragma: no cover - If some other kind of OSError, raise the raw error\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowFileIO.new_input","title":"<code>new_input(location)</code>","text":"<p>Get a PyArrowFile instance to read bytes from the file at the given location.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>A URI or a path to a local file.</p> required <p>Returns:</p> Name Type Description <code>PyArrowFile</code> <code>PyArrowFile</code> <p>A PyArrowFile instance for the given location.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def new_input(self, location: str) -&gt; PyArrowFile:\n    \"\"\"Get a PyArrowFile instance to read bytes from the file at the given location.\n\n    Args:\n        location (str): A URI or a path to a local file.\n\n    Returns:\n        PyArrowFile: A PyArrowFile instance for the given location.\n    \"\"\"\n    scheme, netloc, path = self.parse_location(location)\n    return PyArrowFile(\n        fs=self.fs_by_scheme(scheme, netloc),\n        location=location,\n        path=path,\n        buffer_size=int(self.properties.get(BUFFER_SIZE, ONE_MEGABYTE)),\n    )\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowFileIO.new_output","title":"<code>new_output(location)</code>","text":"<p>Get a PyArrowFile instance to write bytes to the file at the given location.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>A URI or a path to a local file.</p> required <p>Returns:</p> Name Type Description <code>PyArrowFile</code> <code>PyArrowFile</code> <p>A PyArrowFile instance for the given location.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def new_output(self, location: str) -&gt; PyArrowFile:\n    \"\"\"Get a PyArrowFile instance to write bytes to the file at the given location.\n\n    Args:\n        location (str): A URI or a path to a local file.\n\n    Returns:\n        PyArrowFile: A PyArrowFile instance for the given location.\n    \"\"\"\n    scheme, netloc, path = self.parse_location(location)\n    return PyArrowFile(\n        fs=self.fs_by_scheme(scheme, netloc),\n        location=location,\n        path=path,\n        buffer_size=int(self.properties.get(BUFFER_SIZE, ONE_MEGABYTE)),\n    )\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowFileIO.parse_location","title":"<code>parse_location(location)</code>  <code>staticmethod</code>","text":"<p>Return the path without the scheme.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>@staticmethod\ndef parse_location(location: str) -&gt; Tuple[str, str, str]:\n    \"\"\"Return the path without the scheme.\"\"\"\n    uri = urlparse(location)\n    if not uri.scheme:\n        return \"file\", uri.netloc, os.path.abspath(location)\n    elif uri.scheme == \"hdfs\":\n        return uri.scheme, uri.netloc, location\n    else:\n        return uri.scheme, uri.netloc, f\"{uri.netloc}{uri.path}\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor","title":"<code>PyArrowSchemaVisitor</code>","text":"<p>             Bases: <code>Generic[T]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>class PyArrowSchemaVisitor(Generic[T], ABC):\n    def before_field(self, field: pa.Field) -&gt; None:\n        \"\"\"Override this method to perform an action immediately before visiting a field.\"\"\"\n\n    def after_field(self, field: pa.Field) -&gt; None:\n        \"\"\"Override this method to perform an action immediately after visiting a field.\"\"\"\n\n    def before_list_element(self, element: pa.Field) -&gt; None:\n        \"\"\"Override this method to perform an action immediately before visiting an element within a ListType.\"\"\"\n\n    def after_list_element(self, element: pa.Field) -&gt; None:\n        \"\"\"Override this method to perform an action immediately after visiting an element within a ListType.\"\"\"\n\n    def before_map_key(self, key: pa.Field) -&gt; None:\n        \"\"\"Override this method to perform an action immediately before visiting a key within a MapType.\"\"\"\n\n    def after_map_key(self, key: pa.Field) -&gt; None:\n        \"\"\"Override this method to perform an action immediately after visiting a key within a MapType.\"\"\"\n\n    def before_map_value(self, value: pa.Field) -&gt; None:\n        \"\"\"Override this method to perform an action immediately before visiting a value within a MapType.\"\"\"\n\n    def after_map_value(self, value: pa.Field) -&gt; None:\n        \"\"\"Override this method to perform an action immediately after visiting a value within a MapType.\"\"\"\n\n    @abstractmethod\n    def schema(self, schema: pa.Schema, struct_result: T) -&gt; T:\n        \"\"\"Visit a schema.\"\"\"\n\n    @abstractmethod\n    def struct(self, struct: pa.StructType, field_results: List[T]) -&gt; T:\n        \"\"\"Visit a struct.\"\"\"\n\n    @abstractmethod\n    def field(self, field: pa.Field, field_result: T) -&gt; T:\n        \"\"\"Visit a field.\"\"\"\n\n    @abstractmethod\n    def list(self, list_type: pa.ListType, element_result: T) -&gt; T:\n        \"\"\"Visit a list.\"\"\"\n\n    @abstractmethod\n    def map(self, map_type: pa.MapType, key_result: T, value_result: T) -&gt; T:\n        \"\"\"Visit a map.\"\"\"\n\n    @abstractmethod\n    def primitive(self, primitive: pa.DataType) -&gt; T:\n        \"\"\"Visit a primitive type.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.after_field","title":"<code>after_field(field)</code>","text":"<p>Override this method to perform an action immediately after visiting a field.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def after_field(self, field: pa.Field) -&gt; None:\n    \"\"\"Override this method to perform an action immediately after visiting a field.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.after_list_element","title":"<code>after_list_element(element)</code>","text":"<p>Override this method to perform an action immediately after visiting an element within a ListType.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def after_list_element(self, element: pa.Field) -&gt; None:\n    \"\"\"Override this method to perform an action immediately after visiting an element within a ListType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.after_map_key","title":"<code>after_map_key(key)</code>","text":"<p>Override this method to perform an action immediately after visiting a key within a MapType.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def after_map_key(self, key: pa.Field) -&gt; None:\n    \"\"\"Override this method to perform an action immediately after visiting a key within a MapType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.after_map_value","title":"<code>after_map_value(value)</code>","text":"<p>Override this method to perform an action immediately after visiting a value within a MapType.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def after_map_value(self, value: pa.Field) -&gt; None:\n    \"\"\"Override this method to perform an action immediately after visiting a value within a MapType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.before_field","title":"<code>before_field(field)</code>","text":"<p>Override this method to perform an action immediately before visiting a field.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def before_field(self, field: pa.Field) -&gt; None:\n    \"\"\"Override this method to perform an action immediately before visiting a field.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.before_list_element","title":"<code>before_list_element(element)</code>","text":"<p>Override this method to perform an action immediately before visiting an element within a ListType.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def before_list_element(self, element: pa.Field) -&gt; None:\n    \"\"\"Override this method to perform an action immediately before visiting an element within a ListType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.before_map_key","title":"<code>before_map_key(key)</code>","text":"<p>Override this method to perform an action immediately before visiting a key within a MapType.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def before_map_key(self, key: pa.Field) -&gt; None:\n    \"\"\"Override this method to perform an action immediately before visiting a key within a MapType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.before_map_value","title":"<code>before_map_value(value)</code>","text":"<p>Override this method to perform an action immediately before visiting a value within a MapType.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def before_map_value(self, value: pa.Field) -&gt; None:\n    \"\"\"Override this method to perform an action immediately before visiting a value within a MapType.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.field","title":"<code>field(field, field_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a field.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>@abstractmethod\ndef field(self, field: pa.Field, field_result: T) -&gt; T:\n    \"\"\"Visit a field.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.list","title":"<code>list(list_type, element_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a list.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>@abstractmethod\ndef list(self, list_type: pa.ListType, element_result: T) -&gt; T:\n    \"\"\"Visit a list.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.map","title":"<code>map(map_type, key_result, value_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a map.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>@abstractmethod\ndef map(self, map_type: pa.MapType, key_result: T, value_result: T) -&gt; T:\n    \"\"\"Visit a map.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.primitive","title":"<code>primitive(primitive)</code>  <code>abstractmethod</code>","text":"<p>Visit a primitive type.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>@abstractmethod\ndef primitive(self, primitive: pa.DataType) -&gt; T:\n    \"\"\"Visit a primitive type.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.schema","title":"<code>schema(schema, struct_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a schema.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>@abstractmethod\ndef schema(self, schema: pa.Schema, struct_result: T) -&gt; T:\n    \"\"\"Visit a schema.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.PyArrowSchemaVisitor.struct","title":"<code>struct(struct, field_results)</code>  <code>abstractmethod</code>","text":"<p>Visit a struct.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>@abstractmethod\ndef struct(self, struct: pa.StructType, field_results: List[T]) -&gt; T:\n    \"\"\"Visit a struct.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.compute_statistics_plan","title":"<code>compute_statistics_plan(schema, table_properties)</code>","text":"<p>Compute the statistics plan for all columns.</p> <p>The resulting list is assumed to have the same length and same order as the columns in the pyarrow table. This allows the list to map from the column index to the Iceberg column ID. For each element, the desired metrics collection that was provided by the user in the configuration is computed and then adjusted according to the data type of the column. For nested columns the minimum and maximum values are not computed. And truncation is only applied to text of binary strings.</p> <p>Parameters:</p> Name Type Description Default <code>table_properties</code> <code>from pyiceberg.table.metadata.TableMetadata</code> <p>The Iceberg table metadata properties. They are required to compute the mapping of column position to iceberg schema type id. It's also used to set the mode for column metrics collection</p> required Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def compute_statistics_plan(\n    schema: Schema,\n    table_properties: Dict[str, str],\n) -&gt; Dict[int, StatisticsCollector]:\n    \"\"\"\n    Compute the statistics plan for all columns.\n\n    The resulting list is assumed to have the same length and same order as the columns in the pyarrow table.\n    This allows the list to map from the column index to the Iceberg column ID.\n    For each element, the desired metrics collection that was provided by the user in the configuration\n    is computed and then adjusted according to the data type of the column. For nested columns the minimum\n    and maximum values are not computed. And truncation is only applied to text of binary strings.\n\n    Args:\n        table_properties (from pyiceberg.table.metadata.TableMetadata): The Iceberg table metadata properties.\n            They are required to compute the mapping of column position to iceberg schema type id. It's also\n            used to set the mode for column metrics collection\n    \"\"\"\n    stats_cols = pre_order_visit(schema, PyArrowStatisticsCollector(schema, table_properties))\n    result: Dict[int, StatisticsCollector] = {}\n    for stats_col in stats_cols:\n        result[stats_col.field_id] = stats_col\n    return result\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.fill_parquet_file_metadata","title":"<code>fill_parquet_file_metadata(data_file, parquet_metadata, stats_columns, parquet_column_mapping)</code>","text":"<p>Compute and fill the following fields of the DataFile object.</p> <ul> <li>file_format</li> <li>column_sizes</li> <li>value_counts</li> <li>null_value_counts</li> <li>nan_value_counts</li> <li>lower_bounds</li> <li>upper_bounds</li> <li>split_offsets</li> </ul> <p>Parameters:</p> Name Type Description Default <code>data_file</code> <code>DataFile</code> <p>A DataFile object representing the Parquet file for which metadata is to be filled.</p> required <code>parquet_metadata</code> <code>FileMetaData</code> <p>A pyarrow metadata object.</p> required <code>stats_columns</code> <code>Dict[int, StatisticsCollector]</code> <p>The statistics gathering plan. It is required to set the mode for column metrics collection</p> required Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def fill_parquet_file_metadata(\n    data_file: DataFile,\n    parquet_metadata: pq.FileMetaData,\n    stats_columns: Dict[int, StatisticsCollector],\n    parquet_column_mapping: Dict[str, int],\n) -&gt; None:\n    \"\"\"\n    Compute and fill the following fields of the DataFile object.\n\n    - file_format\n    - column_sizes\n    - value_counts\n    - null_value_counts\n    - nan_value_counts\n    - lower_bounds\n    - upper_bounds\n    - split_offsets\n\n    Args:\n        data_file (DataFile): A DataFile object representing the Parquet file for which metadata is to be filled.\n        parquet_metadata (pyarrow.parquet.FileMetaData): A pyarrow metadata object.\n        stats_columns (Dict[int, StatisticsCollector]): The statistics gathering plan. It is required to\n            set the mode for column metrics collection\n    \"\"\"\n    if parquet_metadata.num_columns != len(stats_columns):\n        raise ValueError(\n            f\"Number of columns in statistics configuration ({len(stats_columns)}) is different from the number of columns in pyarrow table ({parquet_metadata.num_columns})\"\n        )\n\n    if parquet_metadata.num_columns != len(parquet_column_mapping):\n        raise ValueError(\n            f\"Number of columns in column mapping ({len(parquet_column_mapping)}) is different from the number of columns in pyarrow table ({parquet_metadata.num_columns})\"\n        )\n\n    column_sizes: Dict[int, int] = {}\n    value_counts: Dict[int, int] = {}\n    split_offsets: List[int] = []\n\n    null_value_counts: Dict[int, int] = {}\n    nan_value_counts: Dict[int, int] = {}\n\n    col_aggs = {}\n\n    for r in range(parquet_metadata.num_row_groups):\n        # References:\n        # https://github.com/apache/iceberg/blob/fc381a81a1fdb8f51a0637ca27cd30673bd7aad3/parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java#L232\n        # https://github.com/apache/parquet-mr/blob/ac29db4611f86a07cc6877b416aa4b183e09b353/parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java#L184\n\n        row_group = parquet_metadata.row_group(r)\n\n        data_offset = row_group.column(0).data_page_offset\n        dictionary_offset = row_group.column(0).dictionary_page_offset\n\n        if row_group.column(0).has_dictionary_page and dictionary_offset &lt; data_offset:\n            split_offsets.append(dictionary_offset)\n        else:\n            split_offsets.append(data_offset)\n\n        invalidate_col: Set[int] = set()\n\n        for pos in range(parquet_metadata.num_columns):\n            column = row_group.column(pos)\n            field_id = parquet_column_mapping[column.path_in_schema]\n\n            stats_col = stats_columns[field_id]\n\n            column_sizes.setdefault(field_id, 0)\n            column_sizes[field_id] += column.total_compressed_size\n\n            if stats_col.mode == MetricsMode(MetricModeTypes.NONE):\n                continue\n\n            value_counts[field_id] = value_counts.get(field_id, 0) + column.num_values\n\n            if column.is_stats_set:\n                try:\n                    statistics = column.statistics\n\n                    if statistics.has_null_count:\n                        null_value_counts[field_id] = null_value_counts.get(field_id, 0) + statistics.null_count\n\n                    if stats_col.mode == MetricsMode(MetricModeTypes.COUNTS):\n                        continue\n\n                    if field_id not in col_aggs:\n                        col_aggs[field_id] = StatsAggregator(\n                            stats_col.iceberg_type, statistics.physical_type, stats_col.mode.length\n                        )\n\n                    col_aggs[field_id].update_min(statistics.min)\n                    col_aggs[field_id].update_max(statistics.max)\n\n                except pyarrow.lib.ArrowNotImplementedError as e:\n                    invalidate_col.add(field_id)\n                    logger.warning(e)\n            else:\n                invalidate_col.add(field_id)\n                logger.warning(\"PyArrow statistics missing for column %d when writing file\", pos)\n\n    split_offsets.sort()\n\n    lower_bounds = {}\n    upper_bounds = {}\n\n    for k, agg in col_aggs.items():\n        _min = agg.min_as_bytes()\n        if _min is not None:\n            lower_bounds[k] = _min\n        _max = agg.max_as_bytes()\n        if _max is not None:\n            upper_bounds[k] = _max\n\n    for field_id in invalidate_col:\n        del lower_bounds[field_id]\n        del upper_bounds[field_id]\n        del null_value_counts[field_id]\n\n    data_file.record_count = parquet_metadata.num_rows\n    data_file.column_sizes = column_sizes\n    data_file.value_counts = value_counts\n    data_file.null_value_counts = null_value_counts\n    data_file.nan_value_counts = nan_value_counts\n    data_file.lower_bounds = lower_bounds\n    data_file.upper_bounds = upper_bounds\n    data_file.split_offsets = split_offsets\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.parquet_path_to_id_mapping","title":"<code>parquet_path_to_id_mapping(schema)</code>","text":"<p>Compute the mapping of parquet column path to Iceberg ID.</p> <p>For each column, the parquet file metadata has a path_in_schema attribute that follows a specific naming scheme for nested columnds. This function computes a mapping of the full paths to the corresponding Iceberg IDs.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>Schema</code> <p>The current table schema.</p> required Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def parquet_path_to_id_mapping(\n    schema: Schema,\n) -&gt; Dict[str, int]:\n    \"\"\"\n    Compute the mapping of parquet column path to Iceberg ID.\n\n    For each column, the parquet file metadata has a path_in_schema attribute that follows\n    a specific naming scheme for nested columnds. This function computes a mapping of\n    the full paths to the corresponding Iceberg IDs.\n\n    Args:\n        schema (pyiceberg.schema.Schema): The current table schema.\n    \"\"\"\n    result: Dict[str, int] = {}\n    for pair in pre_order_visit(schema, ID2ParquetPathVisitor()):\n        result[pair.parquet_path] = pair.field_id\n    return result\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.project_table","title":"<code>project_table(tasks, table, row_filter, projected_schema, case_sensitive=True, limit=None)</code>","text":"<p>Resolve the right columns based on the identifier.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>Iterable[FileScanTask]</code> <p>A URI or a path to a local file.</p> required <code>table</code> <code>Table</code> <p>The table that's being queried.</p> required <code>row_filter</code> <code>BooleanExpression</code> <p>The expression for filtering rows.</p> required <code>projected_schema</code> <code>Schema</code> <p>The output schema.</p> required <code>case_sensitive</code> <code>bool</code> <p>Case sensitivity when looking up column names.</p> <code>True</code> <code>limit</code> <code>Optional[int]</code> <p>Limit the number of records.</p> <code>None</code> <p>Raises:</p> Type Description <code>ResolveError</code> <p>When an incompatible query is done.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>def project_table(\n    tasks: Iterable[FileScanTask],\n    table: Table,\n    row_filter: BooleanExpression,\n    projected_schema: Schema,\n    case_sensitive: bool = True,\n    limit: Optional[int] = None,\n) -&gt; pa.Table:\n    \"\"\"Resolve the right columns based on the identifier.\n\n    Args:\n        tasks (Iterable[FileScanTask]): A URI or a path to a local file.\n        table (Table): The table that's being queried.\n        row_filter (BooleanExpression): The expression for filtering rows.\n        projected_schema (Schema): The output schema.\n        case_sensitive (bool): Case sensitivity when looking up column names.\n        limit (Optional[int]): Limit the number of records.\n\n    Raises:\n        ResolveError: When an incompatible query is done.\n    \"\"\"\n    scheme, netloc, _ = PyArrowFileIO.parse_location(table.location())\n    if isinstance(table.io, PyArrowFileIO):\n        fs = table.io.fs_by_scheme(scheme, netloc)\n    else:\n        try:\n            from pyiceberg.io.fsspec import FsspecFileIO\n\n            if isinstance(table.io, FsspecFileIO):\n                from pyarrow.fs import PyFileSystem\n\n                fs = PyFileSystem(FSSpecHandler(table.io.get_fs(scheme)))\n            else:\n                raise ValueError(f\"Expected PyArrowFileIO or FsspecFileIO, got: {table.io}\")\n        except ModuleNotFoundError as e:\n            # When FsSpec is not installed\n            raise ValueError(f\"Expected PyArrowFileIO or FsspecFileIO, got: {table.io}\") from e\n\n    bound_row_filter = bind(table.schema(), row_filter, case_sensitive=case_sensitive)\n\n    projected_field_ids = {\n        id for id in projected_schema.field_ids if not isinstance(projected_schema.find_type(id), (MapType, ListType))\n    }.union(extract_field_ids(bound_row_filter))\n\n    row_counts: List[int] = []\n    deletes_per_file = _read_all_delete_files(fs, tasks)\n    executor = ExecutorFactory.get_or_create()\n    futures = [\n        executor.submit(\n            _task_to_table,\n            fs,\n            task,\n            bound_row_filter,\n            projected_schema,\n            projected_field_ids,\n            deletes_per_file.get(task.file.file_path),\n            case_sensitive,\n            row_counts,\n            limit,\n            table.name_mapping(),\n        )\n        for task in tasks\n    ]\n\n    # for consistent ordering, we need to maintain future order\n    futures_index = {f: i for i, f in enumerate(futures)}\n    completed_futures: SortedList[Future[pa.Table]] = SortedList(iterable=[], key=lambda f: futures_index[f])\n    for future in concurrent.futures.as_completed(futures):\n        completed_futures.add(future)\n\n        # stop early if limit is satisfied\n        if limit is not None and sum(row_counts) &gt;= limit:\n            break\n\n    # by now, we've either completed all tasks or satisfied the limit\n    if limit is not None:\n        _ = [f.cancel() for f in futures if not f.done()]\n\n    tables = [f.result() for f in completed_futures if f.result()]\n\n    if len(tables) &lt; 1:\n        return pa.Table.from_batches([], schema=schema_to_pyarrow(projected_schema))\n\n    result = pa.concat_tables(tables)\n\n    if limit is not None:\n        return result.slice(0, limit)\n\n    return result\n</code></pre>"},{"location":"reference/pyiceberg/io/pyarrow/#pyiceberg.io.pyarrow.visit_pyarrow","title":"<code>visit_pyarrow(obj, visitor)</code>","text":"<p>Apply a pyarrow schema visitor to any point within a schema.</p> <p>The function traverses the schema in post-order fashion.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Union[DataType, Schema]</code> <p>An instance of a Schema or an IcebergType.</p> required <code>visitor</code> <code>PyArrowSchemaVisitor[T]</code> <p>An instance of an implementation of the generic PyarrowSchemaVisitor base class.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If attempting to visit an unrecognized object type.</p> Source code in <code>pyiceberg/io/pyarrow.py</code> <pre><code>@singledispatch\ndef visit_pyarrow(obj: Union[pa.DataType, pa.Schema], visitor: PyArrowSchemaVisitor[T]) -&gt; T:\n    \"\"\"Apply a pyarrow schema visitor to any point within a schema.\n\n    The function traverses the schema in post-order fashion.\n\n    Args:\n        obj (Union[pa.DataType, pa.Schema]): An instance of a Schema or an IcebergType.\n        visitor (PyArrowSchemaVisitor[T]): An instance of an implementation of the generic PyarrowSchemaVisitor base class.\n\n    Raises:\n        NotImplementedError: If attempting to visit an unrecognized object type.\n    \"\"\"\n    raise NotImplementedError(f\"Cannot visit non-type: {obj}\")\n</code></pre>"},{"location":"reference/pyiceberg/table/","title":"table","text":""},{"location":"reference/pyiceberg/table/#pyiceberg.table.AssertCreate","title":"<code>AssertCreate</code>","text":"<p>             Bases: <code>TableRequirement</code></p> <p>The table must not already exist; used for create transactions.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class AssertCreate(TableRequirement):\n    \"\"\"The table must not already exist; used for create transactions.\"\"\"\n\n    type: Literal[\"assert-create\"] = Field(default=\"assert-create\")\n\n    def validate(self, base_metadata: Optional[TableMetadata]) -&gt; None:\n        if base_metadata is not None:\n            raise CommitFailedException(\"Table already exists\")\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.AssertCurrentSchemaId","title":"<code>AssertCurrentSchemaId</code>","text":"<p>             Bases: <code>TableRequirement</code></p> <p>The table's current schema id must match the requirement's <code>current-schema-id</code>.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class AssertCurrentSchemaId(TableRequirement):\n    \"\"\"The table's current schema id must match the requirement's `current-schema-id`.\"\"\"\n\n    type: Literal[\"assert-current-schema-id\"] = Field(default=\"assert-current-schema-id\")\n    current_schema_id: int = Field(..., alias=\"current-schema-id\")\n\n    def validate(self, base_metadata: Optional[TableMetadata]) -&gt; None:\n        if base_metadata is None:\n            raise CommitFailedException(\"Requirement failed: current table metadata is missing\")\n        elif self.current_schema_id != base_metadata.current_schema_id:\n            raise CommitFailedException(\n                f\"Requirement failed: current schema id has changed: expected {self.current_schema_id}, found {base_metadata.current_schema_id}\"\n            )\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.AssertDefaultSortOrderId","title":"<code>AssertDefaultSortOrderId</code>","text":"<p>             Bases: <code>TableRequirement</code></p> <p>The table's default sort order id must match the requirement's <code>default-sort-order-id</code>.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class AssertDefaultSortOrderId(TableRequirement):\n    \"\"\"The table's default sort order id must match the requirement's `default-sort-order-id`.\"\"\"\n\n    type: Literal[\"assert-default-sort-order-id\"] = Field(default=\"assert-default-sort-order-id\")\n    default_sort_order_id: int = Field(..., alias=\"default-sort-order-id\")\n\n    def validate(self, base_metadata: Optional[TableMetadata]) -&gt; None:\n        if base_metadata is None:\n            raise CommitFailedException(\"Requirement failed: current table metadata is missing\")\n        elif self.default_sort_order_id != base_metadata.default_sort_order_id:\n            raise CommitFailedException(\n                f\"Requirement failed: default sort order id has changed: expected {self.default_sort_order_id}, found {base_metadata.default_sort_order_id}\"\n            )\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.AssertDefaultSpecId","title":"<code>AssertDefaultSpecId</code>","text":"<p>             Bases: <code>TableRequirement</code></p> <p>The table's default spec id must match the requirement's <code>default-spec-id</code>.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class AssertDefaultSpecId(TableRequirement):\n    \"\"\"The table's default spec id must match the requirement's `default-spec-id`.\"\"\"\n\n    type: Literal[\"assert-default-spec-id\"] = Field(default=\"assert-default-spec-id\")\n    default_spec_id: int = Field(..., alias=\"default-spec-id\")\n\n    def validate(self, base_metadata: Optional[TableMetadata]) -&gt; None:\n        if base_metadata is None:\n            raise CommitFailedException(\"Requirement failed: current table metadata is missing\")\n        elif self.default_spec_id != base_metadata.default_spec_id:\n            raise CommitFailedException(\n                f\"Requirement failed: default spec id has changed: expected {self.default_spec_id}, found {base_metadata.default_spec_id}\"\n            )\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.AssertLastAssignedFieldId","title":"<code>AssertLastAssignedFieldId</code>","text":"<p>             Bases: <code>TableRequirement</code></p> <p>The table's last assigned column id must match the requirement's <code>last-assigned-field-id</code>.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class AssertLastAssignedFieldId(TableRequirement):\n    \"\"\"The table's last assigned column id must match the requirement's `last-assigned-field-id`.\"\"\"\n\n    type: Literal[\"assert-last-assigned-field-id\"] = Field(default=\"assert-last-assigned-field-id\")\n    last_assigned_field_id: int = Field(..., alias=\"last-assigned-field-id\")\n\n    def validate(self, base_metadata: Optional[TableMetadata]) -&gt; None:\n        if base_metadata is None:\n            raise CommitFailedException(\"Requirement failed: current table metadata is missing\")\n        elif base_metadata.last_column_id != self.last_assigned_field_id:\n            raise CommitFailedException(\n                f\"Requirement failed: last assigned field id has changed: expected {self.last_assigned_field_id}, found {base_metadata.last_column_id}\"\n            )\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.AssertLastAssignedPartitionId","title":"<code>AssertLastAssignedPartitionId</code>","text":"<p>             Bases: <code>TableRequirement</code></p> <p>The table's last assigned partition id must match the requirement's <code>last-assigned-partition-id</code>.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class AssertLastAssignedPartitionId(TableRequirement):\n    \"\"\"The table's last assigned partition id must match the requirement's `last-assigned-partition-id`.\"\"\"\n\n    type: Literal[\"assert-last-assigned-partition-id\"] = Field(default=\"assert-last-assigned-partition-id\")\n    last_assigned_partition_id: int = Field(..., alias=\"last-assigned-partition-id\")\n\n    def validate(self, base_metadata: Optional[TableMetadata]) -&gt; None:\n        if base_metadata is None:\n            raise CommitFailedException(\"Requirement failed: current table metadata is missing\")\n        elif base_metadata.last_partition_id != self.last_assigned_partition_id:\n            raise CommitFailedException(\n                f\"Requirement failed: last assigned partition id has changed: expected {self.last_assigned_partition_id}, found {base_metadata.last_partition_id}\"\n            )\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.AssertRefSnapshotId","title":"<code>AssertRefSnapshotId</code>","text":"<p>             Bases: <code>TableRequirement</code></p> <p>The table branch or tag identified by the requirement's <code>ref</code> must reference the requirement's <code>snapshot-id</code>.</p> <p>if <code>snapshot-id</code> is <code>null</code> or missing, the ref must not already exist.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class AssertRefSnapshotId(TableRequirement):\n    \"\"\"The table branch or tag identified by the requirement's `ref` must reference the requirement's `snapshot-id`.\n\n    if `snapshot-id` is `null` or missing, the ref must not already exist.\n    \"\"\"\n\n    type: Literal[\"assert-ref-snapshot-id\"] = Field(default=\"assert-ref-snapshot-id\")\n    ref: str = Field(...)\n    snapshot_id: Optional[int] = Field(default=None, alias=\"snapshot-id\")\n\n    def validate(self, base_metadata: Optional[TableMetadata]) -&gt; None:\n        if base_metadata is None:\n            raise CommitFailedException(\"Requirement failed: current table metadata is missing\")\n        elif snapshot_ref := base_metadata.refs.get(self.ref):\n            ref_type = snapshot_ref.snapshot_ref_type\n            if self.snapshot_id is None:\n                raise CommitFailedException(f\"Requirement failed: {ref_type} {self.ref} was created concurrently\")\n            elif self.snapshot_id != snapshot_ref.snapshot_id:\n                raise CommitFailedException(\n                    f\"Requirement failed: {ref_type} {self.ref} has changed: expected id {self.snapshot_id}, found {snapshot_ref.snapshot_id}\"\n                )\n        elif self.snapshot_id is not None:\n            raise CommitFailedException(f\"Requirement failed: branch or tag {self.ref} is missing, expected {self.snapshot_id}\")\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.AssertTableUUID","title":"<code>AssertTableUUID</code>","text":"<p>             Bases: <code>TableRequirement</code></p> <p>The table UUID must match the requirement's <code>uuid</code>.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class AssertTableUUID(TableRequirement):\n    \"\"\"The table UUID must match the requirement's `uuid`.\"\"\"\n\n    type: Literal[\"assert-table-uuid\"] = Field(default=\"assert-table-uuid\")\n    uuid: uuid.UUID\n\n    def validate(self, base_metadata: Optional[TableMetadata]) -&gt; None:\n        if base_metadata is None:\n            raise CommitFailedException(\"Requirement failed: current table metadata is missing\")\n        elif self.uuid != base_metadata.table_uuid:\n            raise CommitFailedException(f\"Table UUID does not match: {self.uuid} != {base_metadata.table_uuid}\")\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.DataScan","title":"<code>DataScan</code>","text":"<p>             Bases: <code>TableScan</code></p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class DataScan(TableScan):\n    def __init__(\n        self,\n        table: Table,\n        row_filter: Union[str, BooleanExpression] = ALWAYS_TRUE,\n        selected_fields: Tuple[str, ...] = (\"*\",),\n        case_sensitive: bool = True,\n        snapshot_id: Optional[int] = None,\n        options: Properties = EMPTY_DICT,\n        limit: Optional[int] = None,\n    ):\n        super().__init__(table, row_filter, selected_fields, case_sensitive, snapshot_id, options, limit)\n\n    def _build_partition_projection(self, spec_id: int) -&gt; BooleanExpression:\n        project = inclusive_projection(self.table.schema(), self.table.specs()[spec_id])\n        return project(self.row_filter)\n\n    @cached_property\n    def partition_filters(self) -&gt; KeyDefaultDict[int, BooleanExpression]:\n        return KeyDefaultDict(self._build_partition_projection)\n\n    def _build_manifest_evaluator(self, spec_id: int) -&gt; Callable[[ManifestFile], bool]:\n        spec = self.table.specs()[spec_id]\n        return visitors.manifest_evaluator(spec, self.table.schema(), self.partition_filters[spec_id], self.case_sensitive)\n\n    def _build_partition_evaluator(self, spec_id: int) -&gt; Callable[[DataFile], bool]:\n        spec = self.table.specs()[spec_id]\n        partition_type = spec.partition_type(self.table.schema())\n        partition_schema = Schema(*partition_type.fields)\n        partition_expr = self.partition_filters[spec_id]\n\n        # The lambda created here is run in multiple threads.\n        # So we avoid creating _EvaluatorExpression methods bound to a single\n        # shared instance across multiple threads.\n        return lambda data_file: visitors.expression_evaluator(partition_schema, partition_expr, self.case_sensitive)(\n            data_file.partition\n        )\n\n    def _check_sequence_number(self, min_data_sequence_number: int, manifest: ManifestFile) -&gt; bool:\n        \"\"\"Ensure that no manifests are loaded that contain deletes that are older than the data.\n\n        Args:\n            min_data_sequence_number (int): The minimal sequence number.\n            manifest (ManifestFile): A ManifestFile that can be either data or deletes.\n\n        Returns:\n            Boolean indicating if it is either a data file, or a relevant delete file.\n        \"\"\"\n        return manifest.content == ManifestContent.DATA or (\n            # Not interested in deletes that are older than the data\n            manifest.content == ManifestContent.DELETES\n            and (manifest.sequence_number or INITIAL_SEQUENCE_NUMBER) &gt;= min_data_sequence_number\n        )\n\n    def plan_files(self) -&gt; Iterable[FileScanTask]:\n        \"\"\"Plans the relevant files by filtering on the PartitionSpecs.\n\n        Returns:\n            List of FileScanTasks that contain both data and delete files.\n        \"\"\"\n        snapshot = self.snapshot()\n        if not snapshot:\n            return iter([])\n\n        io = self.table.io\n\n        # step 1: filter manifests using partition summaries\n        # the filter depends on the partition spec used to write the manifest file, so create a cache of filters for each spec id\n\n        manifest_evaluators: Dict[int, Callable[[ManifestFile], bool]] = KeyDefaultDict(self._build_manifest_evaluator)\n\n        manifests = [\n            manifest_file\n            for manifest_file in snapshot.manifests(io)\n            if manifest_evaluators[manifest_file.partition_spec_id](manifest_file)\n        ]\n\n        # step 2: filter the data files in each manifest\n        # this filter depends on the partition spec used to write the manifest file\n\n        partition_evaluators: Dict[int, Callable[[DataFile], bool]] = KeyDefaultDict(self._build_partition_evaluator)\n        metrics_evaluator = _InclusiveMetricsEvaluator(\n            self.table.schema(), self.row_filter, self.case_sensitive, self.options.get(\"include_empty_files\") == \"true\"\n        ).eval\n\n        min_data_sequence_number = _min_data_file_sequence_number(manifests)\n\n        data_entries: List[ManifestEntry] = []\n        positional_delete_entries = SortedList(key=lambda entry: entry.data_sequence_number or INITIAL_SEQUENCE_NUMBER)\n\n        executor = ExecutorFactory.get_or_create()\n        for manifest_entry in chain(\n            *executor.map(\n                lambda args: _open_manifest(*args),\n                [\n                    (\n                        io,\n                        manifest,\n                        partition_evaluators[manifest.partition_spec_id],\n                        metrics_evaluator,\n                    )\n                    for manifest in manifests\n                    if self._check_sequence_number(min_data_sequence_number, manifest)\n                ],\n            )\n        ):\n            data_file = manifest_entry.data_file\n            if data_file.content == DataFileContent.DATA:\n                data_entries.append(manifest_entry)\n            elif data_file.content == DataFileContent.POSITION_DELETES:\n                positional_delete_entries.add(manifest_entry)\n            elif data_file.content == DataFileContent.EQUALITY_DELETES:\n                raise ValueError(\"PyIceberg does not yet support equality deletes: https://github.com/apache/iceberg/issues/6568\")\n            else:\n                raise ValueError(f\"Unknown DataFileContent ({data_file.content}): {manifest_entry}\")\n\n        return [\n            FileScanTask(\n                data_entry.data_file,\n                delete_files=_match_deletes_to_data_file(\n                    data_entry,\n                    positional_delete_entries,\n                ),\n            )\n            for data_entry in data_entries\n        ]\n\n    def to_arrow(self) -&gt; pa.Table:\n        from pyiceberg.io.pyarrow import project_table\n\n        return project_table(\n            self.plan_files(),\n            self.table,\n            self.row_filter,\n            self.projection(),\n            case_sensitive=self.case_sensitive,\n            limit=self.limit,\n        )\n\n    def to_pandas(self, **kwargs: Any) -&gt; pd.DataFrame:\n        return self.to_arrow().to_pandas(**kwargs)\n\n    def to_duckdb(self, table_name: str, connection: Optional[DuckDBPyConnection] = None) -&gt; DuckDBPyConnection:\n        import duckdb\n\n        con = connection or duckdb.connect(database=\":memory:\")\n        con.register(table_name, self.to_arrow())\n\n        return con\n\n    def to_ray(self) -&gt; ray.data.dataset.Dataset:\n        import ray\n\n        return ray.data.from_arrow(self.to_arrow())\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.DataScan.plan_files","title":"<code>plan_files()</code>","text":"<p>Plans the relevant files by filtering on the PartitionSpecs.</p> <p>Returns:</p> Type Description <code>Iterable[FileScanTask]</code> <p>List of FileScanTasks that contain both data and delete files.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def plan_files(self) -&gt; Iterable[FileScanTask]:\n    \"\"\"Plans the relevant files by filtering on the PartitionSpecs.\n\n    Returns:\n        List of FileScanTasks that contain both data and delete files.\n    \"\"\"\n    snapshot = self.snapshot()\n    if not snapshot:\n        return iter([])\n\n    io = self.table.io\n\n    # step 1: filter manifests using partition summaries\n    # the filter depends on the partition spec used to write the manifest file, so create a cache of filters for each spec id\n\n    manifest_evaluators: Dict[int, Callable[[ManifestFile], bool]] = KeyDefaultDict(self._build_manifest_evaluator)\n\n    manifests = [\n        manifest_file\n        for manifest_file in snapshot.manifests(io)\n        if manifest_evaluators[manifest_file.partition_spec_id](manifest_file)\n    ]\n\n    # step 2: filter the data files in each manifest\n    # this filter depends on the partition spec used to write the manifest file\n\n    partition_evaluators: Dict[int, Callable[[DataFile], bool]] = KeyDefaultDict(self._build_partition_evaluator)\n    metrics_evaluator = _InclusiveMetricsEvaluator(\n        self.table.schema(), self.row_filter, self.case_sensitive, self.options.get(\"include_empty_files\") == \"true\"\n    ).eval\n\n    min_data_sequence_number = _min_data_file_sequence_number(manifests)\n\n    data_entries: List[ManifestEntry] = []\n    positional_delete_entries = SortedList(key=lambda entry: entry.data_sequence_number or INITIAL_SEQUENCE_NUMBER)\n\n    executor = ExecutorFactory.get_or_create()\n    for manifest_entry in chain(\n        *executor.map(\n            lambda args: _open_manifest(*args),\n            [\n                (\n                    io,\n                    manifest,\n                    partition_evaluators[manifest.partition_spec_id],\n                    metrics_evaluator,\n                )\n                for manifest in manifests\n                if self._check_sequence_number(min_data_sequence_number, manifest)\n            ],\n        )\n    ):\n        data_file = manifest_entry.data_file\n        if data_file.content == DataFileContent.DATA:\n            data_entries.append(manifest_entry)\n        elif data_file.content == DataFileContent.POSITION_DELETES:\n            positional_delete_entries.add(manifest_entry)\n        elif data_file.content == DataFileContent.EQUALITY_DELETES:\n            raise ValueError(\"PyIceberg does not yet support equality deletes: https://github.com/apache/iceberg/issues/6568\")\n        else:\n            raise ValueError(f\"Unknown DataFileContent ({data_file.content}): {manifest_entry}\")\n\n    return [\n        FileScanTask(\n            data_entry.data_file,\n            delete_files=_match_deletes_to_data_file(\n                data_entry,\n                positional_delete_entries,\n            ),\n        )\n        for data_entry in data_entries\n    ]\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Namespace","title":"<code>Namespace</code>","text":"<p>             Bases: <code>IcebergRootModel[List[str]]</code></p> <p>Reference to one or more levels of a namespace.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class Namespace(IcebergRootModel[List[str]]):\n    \"\"\"Reference to one or more levels of a namespace.\"\"\"\n\n    root: List[str] = Field(\n        ...,\n        description='Reference to one or more levels of a namespace',\n    )\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.StaticTable","title":"<code>StaticTable</code>","text":"<p>             Bases: <code>Table</code></p> <p>Load a table directly from a metadata file (i.e., without using a catalog).</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class StaticTable(Table):\n    \"\"\"Load a table directly from a metadata file (i.e., without using a catalog).\"\"\"\n\n    def refresh(self) -&gt; Table:\n        \"\"\"Refresh the current table metadata.\"\"\"\n        raise NotImplementedError(\"To be implemented\")\n\n    @classmethod\n    def from_metadata(cls, metadata_location: str, properties: Properties = EMPTY_DICT) -&gt; StaticTable:\n        io = load_file_io(properties=properties, location=metadata_location)\n        file = io.new_input(metadata_location)\n\n        from pyiceberg.serializers import FromInputFile\n\n        metadata = FromInputFile.table_metadata(file)\n\n        from pyiceberg.catalog.noop import NoopCatalog\n\n        return cls(\n            identifier=(\"static-table\", metadata_location),\n            metadata_location=metadata_location,\n            metadata=metadata,\n            io=load_file_io({**properties, **metadata.properties}),\n            catalog=NoopCatalog(\"static-table\"),\n        )\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.StaticTable.refresh","title":"<code>refresh()</code>","text":"<p>Refresh the current table metadata.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def refresh(self) -&gt; Table:\n    \"\"\"Refresh the current table metadata.\"\"\"\n    raise NotImplementedError(\"To be implemented\")\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table","title":"<code>Table</code>","text":"Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class Table:\n    identifier: Identifier = Field()\n    metadata: TableMetadata\n    metadata_location: str = Field()\n    io: FileIO\n    catalog: Catalog\n\n    def __init__(\n        self, identifier: Identifier, metadata: TableMetadata, metadata_location: str, io: FileIO, catalog: Catalog\n    ) -&gt; None:\n        self.identifier = identifier\n        self.metadata = metadata\n        self.metadata_location = metadata_location\n        self.io = io\n        self.catalog = catalog\n\n    def transaction(self) -&gt; Transaction:\n        return Transaction(self)\n\n    def refresh(self) -&gt; Table:\n        \"\"\"Refresh the current table metadata.\"\"\"\n        fresh = self.catalog.load_table(self.identifier[1:])\n        self.metadata = fresh.metadata\n        self.io = fresh.io\n        self.metadata_location = fresh.metadata_location\n        return self\n\n    def name(self) -&gt; Identifier:\n        \"\"\"Return the identifier of this table.\"\"\"\n        return self.identifier\n\n    def scan(\n        self,\n        row_filter: Union[str, BooleanExpression] = ALWAYS_TRUE,\n        selected_fields: Tuple[str, ...] = (\"*\",),\n        case_sensitive: bool = True,\n        snapshot_id: Optional[int] = None,\n        options: Properties = EMPTY_DICT,\n        limit: Optional[int] = None,\n    ) -&gt; DataScan:\n        return DataScan(\n            table=self,\n            row_filter=row_filter,\n            selected_fields=selected_fields,\n            case_sensitive=case_sensitive,\n            snapshot_id=snapshot_id,\n            options=options,\n            limit=limit,\n        )\n\n    @property\n    def format_version(self) -&gt; Literal[1, 2]:\n        return self.metadata.format_version\n\n    def schema(self) -&gt; Schema:\n        \"\"\"Return the schema for this table.\"\"\"\n        return next(schema for schema in self.metadata.schemas if schema.schema_id == self.metadata.current_schema_id)\n\n    def schemas(self) -&gt; Dict[int, Schema]:\n        \"\"\"Return a dict of the schema of this table.\"\"\"\n        return {schema.schema_id: schema for schema in self.metadata.schemas}\n\n    def spec(self) -&gt; PartitionSpec:\n        \"\"\"Return the partition spec of this table.\"\"\"\n        return next(spec for spec in self.metadata.partition_specs if spec.spec_id == self.metadata.default_spec_id)\n\n    def specs(self) -&gt; Dict[int, PartitionSpec]:\n        \"\"\"Return a dict the partition specs this table.\"\"\"\n        return {spec.spec_id: spec for spec in self.metadata.partition_specs}\n\n    def sort_order(self) -&gt; SortOrder:\n        \"\"\"Return the sort order of this table.\"\"\"\n        return next(\n            sort_order for sort_order in self.metadata.sort_orders if sort_order.order_id == self.metadata.default_sort_order_id\n        )\n\n    def sort_orders(self) -&gt; Dict[int, SortOrder]:\n        \"\"\"Return a dict of the sort orders of this table.\"\"\"\n        return {sort_order.order_id: sort_order for sort_order in self.metadata.sort_orders}\n\n    @property\n    def properties(self) -&gt; Dict[str, str]:\n        \"\"\"Properties of the table.\"\"\"\n        return self.metadata.properties\n\n    def location(self) -&gt; str:\n        \"\"\"Return the table's base location.\"\"\"\n        return self.metadata.location\n\n    @property\n    def last_sequence_number(self) -&gt; int:\n        return self.metadata.last_sequence_number\n\n    def next_sequence_number(self) -&gt; int:\n        return self.last_sequence_number + 1 if self.metadata.format_version &gt; 1 else INITIAL_SEQUENCE_NUMBER\n\n    def new_snapshot_id(self) -&gt; int:\n        \"\"\"Generate a new snapshot-id that's not in use.\"\"\"\n        snapshot_id = _generate_snapshot_id()\n        while self.snapshot_by_id(snapshot_id) is not None:\n            snapshot_id = _generate_snapshot_id()\n\n        return snapshot_id\n\n    def current_snapshot(self) -&gt; Optional[Snapshot]:\n        \"\"\"Get the current snapshot for this table, or None if there is no current snapshot.\"\"\"\n        if self.metadata.current_snapshot_id is not None:\n            return self.snapshot_by_id(self.metadata.current_snapshot_id)\n        return None\n\n    def snapshot_by_id(self, snapshot_id: int) -&gt; Optional[Snapshot]:\n        \"\"\"Get the snapshot of this table with the given id, or None if there is no matching snapshot.\"\"\"\n        return self.metadata.snapshot_by_id(snapshot_id)\n\n    def snapshot_by_name(self, name: str) -&gt; Optional[Snapshot]:\n        \"\"\"Return the snapshot referenced by the given name or null if no such reference exists.\"\"\"\n        if ref := self.metadata.refs.get(name):\n            return self.snapshot_by_id(ref.snapshot_id)\n        return None\n\n    def history(self) -&gt; List[SnapshotLogEntry]:\n        \"\"\"Get the snapshot history of this table.\"\"\"\n        return self.metadata.snapshot_log\n\n    def update_schema(self, allow_incompatible_changes: bool = False, case_sensitive: bool = True) -&gt; UpdateSchema:\n        return UpdateSchema(self, allow_incompatible_changes=allow_incompatible_changes, case_sensitive=case_sensitive)\n\n    def name_mapping(self) -&gt; NameMapping:\n        \"\"\"Return the table's field-id NameMapping.\"\"\"\n        if name_mapping_json := self.properties.get(TableProperties.DEFAULT_NAME_MAPPING):\n            return parse_mapping_from_json(name_mapping_json)\n        else:\n            return create_mapping_from_schema(self.schema())\n\n    def append(self, df: pa.Table) -&gt; None:\n        \"\"\"\n        Append data to the table.\n\n        Args:\n            df: The Arrow dataframe that will be appended to overwrite the table\n        \"\"\"\n        try:\n            import pyarrow as pa\n        except ModuleNotFoundError as e:\n            raise ModuleNotFoundError(\"For writes PyArrow needs to be installed\") from e\n\n        if not isinstance(df, pa.Table):\n            raise ValueError(f\"Expected PyArrow table, got: {df}\")\n\n        if len(self.spec().fields) &gt; 0:\n            raise ValueError(\"Cannot write to partitioned tables\")\n\n        merge = _MergingSnapshotProducer(operation=Operation.APPEND, table=self)\n\n        # skip writing data files if the dataframe is empty\n        if df.shape[0] &gt; 0:\n            data_files = _dataframe_to_data_files(self, df=df)\n            for data_file in data_files:\n                merge.append_data_file(data_file)\n\n        merge.commit()\n\n    def overwrite(self, df: pa.Table, overwrite_filter: BooleanExpression = ALWAYS_TRUE) -&gt; None:\n        \"\"\"\n        Overwrite all the data in the table.\n\n        Args:\n            df: The Arrow dataframe that will be used to overwrite the table\n            overwrite_filter: ALWAYS_TRUE when you overwrite all the data,\n                              or a boolean expression in case of a partial overwrite\n        \"\"\"\n        try:\n            import pyarrow as pa\n        except ModuleNotFoundError as e:\n            raise ModuleNotFoundError(\"For writes PyArrow needs to be installed\") from e\n\n        if not isinstance(df, pa.Table):\n            raise ValueError(f\"Expected PyArrow table, got: {df}\")\n\n        if overwrite_filter != AlwaysTrue():\n            raise NotImplementedError(\"Cannot overwrite a subset of a table\")\n\n        if len(self.spec().fields) &gt; 0:\n            raise ValueError(\"Cannot write to partitioned tables\")\n\n        merge = _MergingSnapshotProducer(\n            operation=Operation.OVERWRITE if self.current_snapshot() is not None else Operation.APPEND,\n            table=self,\n        )\n\n        # skip writing data files if the dataframe is empty\n        if df.shape[0] &gt; 0:\n            data_files = _dataframe_to_data_files(self, df=df)\n            for data_file in data_files:\n                merge.append_data_file(data_file)\n\n        merge.commit()\n\n    def refs(self) -&gt; Dict[str, SnapshotRef]:\n        \"\"\"Return the snapshot references in the table.\"\"\"\n        return self.metadata.refs\n\n    def _do_commit(self, updates: Tuple[TableUpdate, ...], requirements: Tuple[TableRequirement, ...]) -&gt; None:\n        response = self.catalog._commit_table(  # pylint: disable=W0212\n            CommitTableRequest(\n                identifier=TableIdentifier(namespace=self.identifier[:-1], name=self.identifier[-1]),\n                updates=updates,\n                requirements=requirements,\n            )\n        )  # pylint: disable=W0212\n        self.metadata = response.metadata\n        self.metadata_location = response.metadata_location\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Return the equality of two instances of the Table class.\"\"\"\n        return (\n            self.identifier == other.identifier\n            and self.metadata == other.metadata\n            and self.metadata_location == other.metadata_location\n            if isinstance(other, Table)\n            else False\n        )\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the Table class.\"\"\"\n        table_name = self.catalog.table_name_from(self.identifier)\n        schema_str = \",\\n  \".join(str(column) for column in self.schema().columns if self.schema())\n        partition_str = f\"partition by: [{', '.join(field.name for field in self.spec().fields if self.spec())}]\"\n        sort_order_str = f\"sort order: [{', '.join(str(field) for field in self.sort_order().fields if self.sort_order())}]\"\n        snapshot_str = f\"snapshot: {str(self.current_snapshot()) if self.current_snapshot() else 'null'}\"\n        result_str = f\"{table_name}(\\n  {schema_str}\\n),\\n{partition_str},\\n{sort_order_str},\\n{snapshot_str}\"\n        return result_str\n\n    def to_daft(self) -&gt; daft.DataFrame:\n        \"\"\"Read a Daft DataFrame lazily from this Iceberg table.\n\n        Returns:\n            daft.DataFrame: Unmaterialized Daft Dataframe created from the Iceberg table\n        \"\"\"\n        import daft\n\n        return daft.read_iceberg(self)\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.properties","title":"<code>properties: Dict[str, str]</code>  <code>property</code>","text":"<p>Properties of the table.</p>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Return the equality of two instances of the Table class.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Return the equality of two instances of the Table class.\"\"\"\n    return (\n        self.identifier == other.identifier\n        and self.metadata == other.metadata\n        and self.metadata_location == other.metadata_location\n        if isinstance(other, Table)\n        else False\n    )\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the Table class.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the Table class.\"\"\"\n    table_name = self.catalog.table_name_from(self.identifier)\n    schema_str = \",\\n  \".join(str(column) for column in self.schema().columns if self.schema())\n    partition_str = f\"partition by: [{', '.join(field.name for field in self.spec().fields if self.spec())}]\"\n    sort_order_str = f\"sort order: [{', '.join(str(field) for field in self.sort_order().fields if self.sort_order())}]\"\n    snapshot_str = f\"snapshot: {str(self.current_snapshot()) if self.current_snapshot() else 'null'}\"\n    result_str = f\"{table_name}(\\n  {schema_str}\\n),\\n{partition_str},\\n{sort_order_str},\\n{snapshot_str}\"\n    return result_str\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.append","title":"<code>append(df)</code>","text":"<p>Append data to the table.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>Table</code> <p>The Arrow dataframe that will be appended to overwrite the table</p> required Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def append(self, df: pa.Table) -&gt; None:\n    \"\"\"\n    Append data to the table.\n\n    Args:\n        df: The Arrow dataframe that will be appended to overwrite the table\n    \"\"\"\n    try:\n        import pyarrow as pa\n    except ModuleNotFoundError as e:\n        raise ModuleNotFoundError(\"For writes PyArrow needs to be installed\") from e\n\n    if not isinstance(df, pa.Table):\n        raise ValueError(f\"Expected PyArrow table, got: {df}\")\n\n    if len(self.spec().fields) &gt; 0:\n        raise ValueError(\"Cannot write to partitioned tables\")\n\n    merge = _MergingSnapshotProducer(operation=Operation.APPEND, table=self)\n\n    # skip writing data files if the dataframe is empty\n    if df.shape[0] &gt; 0:\n        data_files = _dataframe_to_data_files(self, df=df)\n        for data_file in data_files:\n            merge.append_data_file(data_file)\n\n    merge.commit()\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.current_snapshot","title":"<code>current_snapshot()</code>","text":"<p>Get the current snapshot for this table, or None if there is no current snapshot.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def current_snapshot(self) -&gt; Optional[Snapshot]:\n    \"\"\"Get the current snapshot for this table, or None if there is no current snapshot.\"\"\"\n    if self.metadata.current_snapshot_id is not None:\n        return self.snapshot_by_id(self.metadata.current_snapshot_id)\n    return None\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.history","title":"<code>history()</code>","text":"<p>Get the snapshot history of this table.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def history(self) -&gt; List[SnapshotLogEntry]:\n    \"\"\"Get the snapshot history of this table.\"\"\"\n    return self.metadata.snapshot_log\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.location","title":"<code>location()</code>","text":"<p>Return the table's base location.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def location(self) -&gt; str:\n    \"\"\"Return the table's base location.\"\"\"\n    return self.metadata.location\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.name","title":"<code>name()</code>","text":"<p>Return the identifier of this table.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def name(self) -&gt; Identifier:\n    \"\"\"Return the identifier of this table.\"\"\"\n    return self.identifier\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.name_mapping","title":"<code>name_mapping()</code>","text":"<p>Return the table's field-id NameMapping.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def name_mapping(self) -&gt; NameMapping:\n    \"\"\"Return the table's field-id NameMapping.\"\"\"\n    if name_mapping_json := self.properties.get(TableProperties.DEFAULT_NAME_MAPPING):\n        return parse_mapping_from_json(name_mapping_json)\n    else:\n        return create_mapping_from_schema(self.schema())\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.new_snapshot_id","title":"<code>new_snapshot_id()</code>","text":"<p>Generate a new snapshot-id that's not in use.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def new_snapshot_id(self) -&gt; int:\n    \"\"\"Generate a new snapshot-id that's not in use.\"\"\"\n    snapshot_id = _generate_snapshot_id()\n    while self.snapshot_by_id(snapshot_id) is not None:\n        snapshot_id = _generate_snapshot_id()\n\n    return snapshot_id\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.overwrite","title":"<code>overwrite(df, overwrite_filter=ALWAYS_TRUE)</code>","text":"<p>Overwrite all the data in the table.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>Table</code> <p>The Arrow dataframe that will be used to overwrite the table</p> required <code>overwrite_filter</code> <code>BooleanExpression</code> <p>ALWAYS_TRUE when you overwrite all the data,               or a boolean expression in case of a partial overwrite</p> <code>ALWAYS_TRUE</code> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def overwrite(self, df: pa.Table, overwrite_filter: BooleanExpression = ALWAYS_TRUE) -&gt; None:\n    \"\"\"\n    Overwrite all the data in the table.\n\n    Args:\n        df: The Arrow dataframe that will be used to overwrite the table\n        overwrite_filter: ALWAYS_TRUE when you overwrite all the data,\n                          or a boolean expression in case of a partial overwrite\n    \"\"\"\n    try:\n        import pyarrow as pa\n    except ModuleNotFoundError as e:\n        raise ModuleNotFoundError(\"For writes PyArrow needs to be installed\") from e\n\n    if not isinstance(df, pa.Table):\n        raise ValueError(f\"Expected PyArrow table, got: {df}\")\n\n    if overwrite_filter != AlwaysTrue():\n        raise NotImplementedError(\"Cannot overwrite a subset of a table\")\n\n    if len(self.spec().fields) &gt; 0:\n        raise ValueError(\"Cannot write to partitioned tables\")\n\n    merge = _MergingSnapshotProducer(\n        operation=Operation.OVERWRITE if self.current_snapshot() is not None else Operation.APPEND,\n        table=self,\n    )\n\n    # skip writing data files if the dataframe is empty\n    if df.shape[0] &gt; 0:\n        data_files = _dataframe_to_data_files(self, df=df)\n        for data_file in data_files:\n            merge.append_data_file(data_file)\n\n    merge.commit()\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.refresh","title":"<code>refresh()</code>","text":"<p>Refresh the current table metadata.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def refresh(self) -&gt; Table:\n    \"\"\"Refresh the current table metadata.\"\"\"\n    fresh = self.catalog.load_table(self.identifier[1:])\n    self.metadata = fresh.metadata\n    self.io = fresh.io\n    self.metadata_location = fresh.metadata_location\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.refs","title":"<code>refs()</code>","text":"<p>Return the snapshot references in the table.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def refs(self) -&gt; Dict[str, SnapshotRef]:\n    \"\"\"Return the snapshot references in the table.\"\"\"\n    return self.metadata.refs\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.schema","title":"<code>schema()</code>","text":"<p>Return the schema for this table.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def schema(self) -&gt; Schema:\n    \"\"\"Return the schema for this table.\"\"\"\n    return next(schema for schema in self.metadata.schemas if schema.schema_id == self.metadata.current_schema_id)\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.schemas","title":"<code>schemas()</code>","text":"<p>Return a dict of the schema of this table.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def schemas(self) -&gt; Dict[int, Schema]:\n    \"\"\"Return a dict of the schema of this table.\"\"\"\n    return {schema.schema_id: schema for schema in self.metadata.schemas}\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.snapshot_by_id","title":"<code>snapshot_by_id(snapshot_id)</code>","text":"<p>Get the snapshot of this table with the given id, or None if there is no matching snapshot.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def snapshot_by_id(self, snapshot_id: int) -&gt; Optional[Snapshot]:\n    \"\"\"Get the snapshot of this table with the given id, or None if there is no matching snapshot.\"\"\"\n    return self.metadata.snapshot_by_id(snapshot_id)\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.snapshot_by_name","title":"<code>snapshot_by_name(name)</code>","text":"<p>Return the snapshot referenced by the given name or null if no such reference exists.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def snapshot_by_name(self, name: str) -&gt; Optional[Snapshot]:\n    \"\"\"Return the snapshot referenced by the given name or null if no such reference exists.\"\"\"\n    if ref := self.metadata.refs.get(name):\n        return self.snapshot_by_id(ref.snapshot_id)\n    return None\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.sort_order","title":"<code>sort_order()</code>","text":"<p>Return the sort order of this table.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def sort_order(self) -&gt; SortOrder:\n    \"\"\"Return the sort order of this table.\"\"\"\n    return next(\n        sort_order for sort_order in self.metadata.sort_orders if sort_order.order_id == self.metadata.default_sort_order_id\n    )\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.sort_orders","title":"<code>sort_orders()</code>","text":"<p>Return a dict of the sort orders of this table.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def sort_orders(self) -&gt; Dict[int, SortOrder]:\n    \"\"\"Return a dict of the sort orders of this table.\"\"\"\n    return {sort_order.order_id: sort_order for sort_order in self.metadata.sort_orders}\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.spec","title":"<code>spec()</code>","text":"<p>Return the partition spec of this table.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def spec(self) -&gt; PartitionSpec:\n    \"\"\"Return the partition spec of this table.\"\"\"\n    return next(spec for spec in self.metadata.partition_specs if spec.spec_id == self.metadata.default_spec_id)\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.specs","title":"<code>specs()</code>","text":"<p>Return a dict the partition specs this table.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def specs(self) -&gt; Dict[int, PartitionSpec]:\n    \"\"\"Return a dict the partition specs this table.\"\"\"\n    return {spec.spec_id: spec for spec in self.metadata.partition_specs}\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Table.to_daft","title":"<code>to_daft()</code>","text":"<p>Read a Daft DataFrame lazily from this Iceberg table.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>daft.DataFrame: Unmaterialized Daft Dataframe created from the Iceberg table</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def to_daft(self) -&gt; daft.DataFrame:\n    \"\"\"Read a Daft DataFrame lazily from this Iceberg table.\n\n    Returns:\n        daft.DataFrame: Unmaterialized Daft Dataframe created from the Iceberg table\n    \"\"\"\n    import daft\n\n    return daft.read_iceberg(self)\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.TableIdentifier","title":"<code>TableIdentifier</code>","text":"<p>             Bases: <code>IcebergBaseModel</code></p> <p>Fully Qualified identifier to a table.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class TableIdentifier(IcebergBaseModel):\n    \"\"\"Fully Qualified identifier to a table.\"\"\"\n\n    namespace: Namespace\n    name: str\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.TableRequirement","title":"<code>TableRequirement</code>","text":"<p>             Bases: <code>IcebergBaseModel</code></p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class TableRequirement(IcebergBaseModel):\n    type: str\n\n    @abstractmethod\n    def validate(self, base_metadata: Optional[TableMetadata]) -&gt; None:\n        \"\"\"Validate the requirement against the base metadata.\n\n        Args:\n            base_metadata: The base metadata to be validated against.\n\n        Raises:\n            CommitFailedException: When the requirement is not met.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.TableRequirement.validate","title":"<code>validate(base_metadata)</code>  <code>abstractmethod</code>","text":"<p>Validate the requirement against the base metadata.</p> <p>Parameters:</p> Name Type Description Default <code>base_metadata</code> <code>Optional[TableMetadata]</code> <p>The base metadata to be validated against.</p> required <p>Raises:</p> Type Description <code>CommitFailedException</code> <p>When the requirement is not met.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>@abstractmethod\ndef validate(self, base_metadata: Optional[TableMetadata]) -&gt; None:\n    \"\"\"Validate the requirement against the base metadata.\n\n    Args:\n        base_metadata: The base metadata to be validated against.\n\n    Raises:\n        CommitFailedException: When the requirement is not met.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.TableScan","title":"<code>TableScan</code>","text":"<p>             Bases: <code>ABC</code></p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class TableScan(ABC):\n    table: Table\n    row_filter: BooleanExpression\n    selected_fields: Tuple[str, ...]\n    case_sensitive: bool\n    snapshot_id: Optional[int]\n    options: Properties\n    limit: Optional[int]\n\n    def __init__(\n        self,\n        table: Table,\n        row_filter: Union[str, BooleanExpression] = ALWAYS_TRUE,\n        selected_fields: Tuple[str, ...] = (\"*\",),\n        case_sensitive: bool = True,\n        snapshot_id: Optional[int] = None,\n        options: Properties = EMPTY_DICT,\n        limit: Optional[int] = None,\n    ):\n        self.table = table\n        self.row_filter = _parse_row_filter(row_filter)\n        self.selected_fields = selected_fields\n        self.case_sensitive = case_sensitive\n        self.snapshot_id = snapshot_id\n        self.options = options\n        self.limit = limit\n\n    def snapshot(self) -&gt; Optional[Snapshot]:\n        if self.snapshot_id:\n            return self.table.snapshot_by_id(self.snapshot_id)\n        return self.table.current_snapshot()\n\n    def projection(self) -&gt; Schema:\n        current_schema = self.table.schema()\n        if self.snapshot_id is not None:\n            snapshot = self.table.snapshot_by_id(self.snapshot_id)\n            if snapshot is not None:\n                if snapshot.schema_id is not None:\n                    snapshot_schema = self.table.schemas().get(snapshot.schema_id)\n                    if snapshot_schema is not None:\n                        current_schema = snapshot_schema\n                    else:\n                        warnings.warn(f\"Metadata does not contain schema with id: {snapshot.schema_id}\")\n            else:\n                raise ValueError(f\"Snapshot not found: {self.snapshot_id}\")\n\n        if \"*\" in self.selected_fields:\n            return current_schema\n\n        return current_schema.select(*self.selected_fields, case_sensitive=self.case_sensitive)\n\n    @abstractmethod\n    def plan_files(self) -&gt; Iterable[ScanTask]: ...\n\n    @abstractmethod\n    def to_arrow(self) -&gt; pa.Table: ...\n\n    @abstractmethod\n    def to_pandas(self, **kwargs: Any) -&gt; pd.DataFrame: ...\n\n    def update(self: S, **overrides: Any) -&gt; S:\n        \"\"\"Create a copy of this table scan with updated fields.\"\"\"\n        return type(self)(**{**self.__dict__, **overrides})\n\n    def use_ref(self: S, name: str) -&gt; S:\n        if self.snapshot_id:\n            raise ValueError(f\"Cannot override ref, already set snapshot id={self.snapshot_id}\")\n        if snapshot := self.table.snapshot_by_name(name):\n            return self.update(snapshot_id=snapshot.snapshot_id)\n\n        raise ValueError(f\"Cannot scan unknown ref={name}\")\n\n    def select(self: S, *field_names: str) -&gt; S:\n        if \"*\" in self.selected_fields:\n            return self.update(selected_fields=field_names)\n        return self.update(selected_fields=tuple(set(self.selected_fields).intersection(set(field_names))))\n\n    def filter(self: S, expr: Union[str, BooleanExpression]) -&gt; S:\n        return self.update(row_filter=And(self.row_filter, _parse_row_filter(expr)))\n\n    def with_case_sensitive(self: S, case_sensitive: bool = True) -&gt; S:\n        return self.update(case_sensitive=case_sensitive)\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.TableScan.update","title":"<code>update(**overrides)</code>","text":"<p>Create a copy of this table scan with updated fields.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def update(self: S, **overrides: Any) -&gt; S:\n    \"\"\"Create a copy of this table scan with updated fields.\"\"\"\n    return type(self)(**{**self.__dict__, **overrides})\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Transaction","title":"<code>Transaction</code>","text":"Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class Transaction:\n    _table: Table\n    _updates: Tuple[TableUpdate, ...]\n    _requirements: Tuple[TableRequirement, ...]\n\n    def __init__(\n        self,\n        table: Table,\n        actions: Optional[Tuple[TableUpdate, ...]] = None,\n        requirements: Optional[Tuple[TableRequirement, ...]] = None,\n    ):\n        self._table = table\n        self._updates = actions or ()\n        self._requirements = requirements or ()\n\n    def __enter__(self) -&gt; Transaction:\n        \"\"\"Start a transaction to update the table.\"\"\"\n        return self\n\n    def __exit__(self, _: Any, value: Any, traceback: Any) -&gt; None:\n        \"\"\"Close and commit the transaction.\"\"\"\n        fresh_table = self.commit_transaction()\n        # Update the new data in place\n        self._table.metadata = fresh_table.metadata\n        self._table.metadata_location = fresh_table.metadata_location\n\n    def _append_updates(self, *new_updates: TableUpdate) -&gt; Transaction:\n        \"\"\"Append updates to the set of staged updates.\n\n        Args:\n            *new_updates: Any new updates.\n\n        Raises:\n            ValueError: When the type of update is not unique.\n\n        Returns:\n            Transaction object with the new updates appended.\n        \"\"\"\n        for new_update in new_updates:\n            # explicitly get type of new_update as new_update is an instantiated class\n            type_new_update = type(new_update)\n            if any(isinstance(update, type_new_update) for update in self._updates):\n                raise ValueError(f\"Updates in a single commit need to be unique, duplicate: {type_new_update}\")\n        self._updates = self._updates + new_updates\n        return self\n\n    def _append_requirements(self, *new_requirements: TableRequirement) -&gt; Transaction:\n        \"\"\"Append requirements to the set of staged requirements.\n\n        Args:\n            *new_requirements: Any new requirements.\n\n        Raises:\n            ValueError: When the type of requirement is not unique.\n\n        Returns:\n            Transaction object with the new requirements appended.\n        \"\"\"\n        for new_requirement in new_requirements:\n            # explicitly get type of new_update as requirement is an instantiated class\n            type_new_requirement = type(new_requirement)\n            if any(isinstance(requirement, type_new_requirement) for requirement in self._requirements):\n                raise ValueError(f\"Requirements in a single commit need to be unique, duplicate: {type_new_requirement}\")\n        self._requirements = self._requirements + new_requirements\n        return self\n\n    def upgrade_table_version(self, format_version: Literal[1, 2]) -&gt; Transaction:\n        \"\"\"Set the table to a certain version.\n\n        Args:\n            format_version: The newly set version.\n\n        Returns:\n            The alter table builder.\n        \"\"\"\n        if format_version not in {1, 2}:\n            raise ValueError(f\"Unsupported table format version: {format_version}\")\n\n        if format_version &lt; self._table.metadata.format_version:\n            raise ValueError(f\"Cannot downgrade v{self._table.metadata.format_version} table to v{format_version}\")\n        if format_version &gt; self._table.metadata.format_version:\n            return self._append_updates(UpgradeFormatVersionUpdate(format_version=format_version))\n        else:\n            return self\n\n    def set_properties(self, **updates: str) -&gt; Transaction:\n        \"\"\"Set properties.\n\n        When a property is already set, it will be overwritten.\n\n        Args:\n            updates: The properties set on the table.\n\n        Returns:\n            The alter table builder.\n        \"\"\"\n        return self._append_updates(SetPropertiesUpdate(updates=updates))\n\n    def add_snapshot(self, snapshot: Snapshot) -&gt; Transaction:\n        \"\"\"Add a new snapshot to the table.\n\n        Returns:\n            The transaction with the add-snapshot staged.\n        \"\"\"\n        self._append_updates(AddSnapshotUpdate(snapshot=snapshot))\n        self._append_requirements(AssertTableUUID(uuid=self._table.metadata.table_uuid))\n\n        return self\n\n    def set_ref_snapshot(\n        self,\n        snapshot_id: int,\n        parent_snapshot_id: Optional[int],\n        ref_name: str,\n        type: str,\n        max_age_ref_ms: Optional[int] = None,\n        max_snapshot_age_ms: Optional[int] = None,\n        min_snapshots_to_keep: Optional[int] = None,\n    ) -&gt; Transaction:\n        \"\"\"Update a ref to a snapshot.\n\n        Returns:\n            The transaction with the set-snapshot-ref staged\n        \"\"\"\n        self._append_updates(\n            SetSnapshotRefUpdate(\n                snapshot_id=snapshot_id,\n                parent_snapshot_id=parent_snapshot_id,\n                ref_name=ref_name,\n                type=type,\n                max_age_ref_ms=max_age_ref_ms,\n                max_snapshot_age_ms=max_snapshot_age_ms,\n                min_snapshots_to_keep=min_snapshots_to_keep,\n            )\n        )\n\n        self._append_requirements(AssertRefSnapshotId(snapshot_id=parent_snapshot_id, ref=\"main\"))\n        return self\n\n    def update_schema(self) -&gt; UpdateSchema:\n        \"\"\"Create a new UpdateSchema to alter the columns of this table.\n\n        Returns:\n            A new UpdateSchema.\n        \"\"\"\n        return UpdateSchema(self._table, self)\n\n    def remove_properties(self, *removals: str) -&gt; Transaction:\n        \"\"\"Remove properties.\n\n        Args:\n            removals: Properties to be removed.\n\n        Returns:\n            The alter table builder.\n        \"\"\"\n        return self._append_updates(RemovePropertiesUpdate(removals=removals))\n\n    def update_location(self, location: str) -&gt; Transaction:\n        \"\"\"Set the new table location.\n\n        Args:\n            location: The new location of the table.\n\n        Returns:\n            The alter table builder.\n        \"\"\"\n        raise NotImplementedError(\"Not yet implemented\")\n\n    def commit_transaction(self) -&gt; Table:\n        \"\"\"Commit the changes to the catalog.\n\n        Returns:\n            The table with the updates applied.\n        \"\"\"\n        # Strip the catalog name\n        if len(self._updates) &gt; 0:\n            self._table._do_commit(  # pylint: disable=W0212\n                updates=self._updates,\n                requirements=self._requirements,\n            )\n            return self._table\n        else:\n            return self._table\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Transaction.__enter__","title":"<code>__enter__()</code>","text":"<p>Start a transaction to update the table.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def __enter__(self) -&gt; Transaction:\n    \"\"\"Start a transaction to update the table.\"\"\"\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Transaction.__exit__","title":"<code>__exit__(_, value, traceback)</code>","text":"<p>Close and commit the transaction.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def __exit__(self, _: Any, value: Any, traceback: Any) -&gt; None:\n    \"\"\"Close and commit the transaction.\"\"\"\n    fresh_table = self.commit_transaction()\n    # Update the new data in place\n    self._table.metadata = fresh_table.metadata\n    self._table.metadata_location = fresh_table.metadata_location\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Transaction.add_snapshot","title":"<code>add_snapshot(snapshot)</code>","text":"<p>Add a new snapshot to the table.</p> <p>Returns:</p> Type Description <code>Transaction</code> <p>The transaction with the add-snapshot staged.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def add_snapshot(self, snapshot: Snapshot) -&gt; Transaction:\n    \"\"\"Add a new snapshot to the table.\n\n    Returns:\n        The transaction with the add-snapshot staged.\n    \"\"\"\n    self._append_updates(AddSnapshotUpdate(snapshot=snapshot))\n    self._append_requirements(AssertTableUUID(uuid=self._table.metadata.table_uuid))\n\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Transaction.commit_transaction","title":"<code>commit_transaction()</code>","text":"<p>Commit the changes to the catalog.</p> <p>Returns:</p> Type Description <code>Table</code> <p>The table with the updates applied.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def commit_transaction(self) -&gt; Table:\n    \"\"\"Commit the changes to the catalog.\n\n    Returns:\n        The table with the updates applied.\n    \"\"\"\n    # Strip the catalog name\n    if len(self._updates) &gt; 0:\n        self._table._do_commit(  # pylint: disable=W0212\n            updates=self._updates,\n            requirements=self._requirements,\n        )\n        return self._table\n    else:\n        return self._table\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Transaction.remove_properties","title":"<code>remove_properties(*removals)</code>","text":"<p>Remove properties.</p> <p>Parameters:</p> Name Type Description Default <code>removals</code> <code>str</code> <p>Properties to be removed.</p> <code>()</code> <p>Returns:</p> Type Description <code>Transaction</code> <p>The alter table builder.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def remove_properties(self, *removals: str) -&gt; Transaction:\n    \"\"\"Remove properties.\n\n    Args:\n        removals: Properties to be removed.\n\n    Returns:\n        The alter table builder.\n    \"\"\"\n    return self._append_updates(RemovePropertiesUpdate(removals=removals))\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Transaction.set_properties","title":"<code>set_properties(**updates)</code>","text":"<p>Set properties.</p> <p>When a property is already set, it will be overwritten.</p> <p>Parameters:</p> Name Type Description Default <code>updates</code> <code>str</code> <p>The properties set on the table.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Transaction</code> <p>The alter table builder.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def set_properties(self, **updates: str) -&gt; Transaction:\n    \"\"\"Set properties.\n\n    When a property is already set, it will be overwritten.\n\n    Args:\n        updates: The properties set on the table.\n\n    Returns:\n        The alter table builder.\n    \"\"\"\n    return self._append_updates(SetPropertiesUpdate(updates=updates))\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Transaction.set_ref_snapshot","title":"<code>set_ref_snapshot(snapshot_id, parent_snapshot_id, ref_name, type, max_age_ref_ms=None, max_snapshot_age_ms=None, min_snapshots_to_keep=None)</code>","text":"<p>Update a ref to a snapshot.</p> <p>Returns:</p> Type Description <code>Transaction</code> <p>The transaction with the set-snapshot-ref staged</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def set_ref_snapshot(\n    self,\n    snapshot_id: int,\n    parent_snapshot_id: Optional[int],\n    ref_name: str,\n    type: str,\n    max_age_ref_ms: Optional[int] = None,\n    max_snapshot_age_ms: Optional[int] = None,\n    min_snapshots_to_keep: Optional[int] = None,\n) -&gt; Transaction:\n    \"\"\"Update a ref to a snapshot.\n\n    Returns:\n        The transaction with the set-snapshot-ref staged\n    \"\"\"\n    self._append_updates(\n        SetSnapshotRefUpdate(\n            snapshot_id=snapshot_id,\n            parent_snapshot_id=parent_snapshot_id,\n            ref_name=ref_name,\n            type=type,\n            max_age_ref_ms=max_age_ref_ms,\n            max_snapshot_age_ms=max_snapshot_age_ms,\n            min_snapshots_to_keep=min_snapshots_to_keep,\n        )\n    )\n\n    self._append_requirements(AssertRefSnapshotId(snapshot_id=parent_snapshot_id, ref=\"main\"))\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Transaction.update_location","title":"<code>update_location(location)</code>","text":"<p>Set the new table location.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>The new location of the table.</p> required <p>Returns:</p> Type Description <code>Transaction</code> <p>The alter table builder.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def update_location(self, location: str) -&gt; Transaction:\n    \"\"\"Set the new table location.\n\n    Args:\n        location: The new location of the table.\n\n    Returns:\n        The alter table builder.\n    \"\"\"\n    raise NotImplementedError(\"Not yet implemented\")\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Transaction.update_schema","title":"<code>update_schema()</code>","text":"<p>Create a new UpdateSchema to alter the columns of this table.</p> <p>Returns:</p> Type Description <code>UpdateSchema</code> <p>A new UpdateSchema.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def update_schema(self) -&gt; UpdateSchema:\n    \"\"\"Create a new UpdateSchema to alter the columns of this table.\n\n    Returns:\n        A new UpdateSchema.\n    \"\"\"\n    return UpdateSchema(self._table, self)\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.Transaction.upgrade_table_version","title":"<code>upgrade_table_version(format_version)</code>","text":"<p>Set the table to a certain version.</p> <p>Parameters:</p> Name Type Description Default <code>format_version</code> <code>Literal[1, 2]</code> <p>The newly set version.</p> required <p>Returns:</p> Type Description <code>Transaction</code> <p>The alter table builder.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def upgrade_table_version(self, format_version: Literal[1, 2]) -&gt; Transaction:\n    \"\"\"Set the table to a certain version.\n\n    Args:\n        format_version: The newly set version.\n\n    Returns:\n        The alter table builder.\n    \"\"\"\n    if format_version not in {1, 2}:\n        raise ValueError(f\"Unsupported table format version: {format_version}\")\n\n    if format_version &lt; self._table.metadata.format_version:\n        raise ValueError(f\"Cannot downgrade v{self._table.metadata.format_version} table to v{format_version}\")\n    if format_version &gt; self._table.metadata.format_version:\n        return self._append_updates(UpgradeFormatVersionUpdate(format_version=format_version))\n    else:\n        return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.UpdateSchema","title":"<code>UpdateSchema</code>","text":"Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>class UpdateSchema:\n    _table: Optional[Table]\n    _schema: Schema\n    _last_column_id: itertools.count[int]\n    _identifier_field_names: Set[str]\n\n    _adds: Dict[int, List[NestedField]] = {}\n    _updates: Dict[int, NestedField] = {}\n    _deletes: Set[int] = set()\n    _moves: Dict[int, List[Move]] = {}\n\n    _added_name_to_id: Dict[str, int] = {}\n    # Part of https://github.com/apache/iceberg/pull/8393\n    _id_to_parent: Dict[int, str] = {}\n    _allow_incompatible_changes: bool\n    _case_sensitive: bool\n    _transaction: Optional[Transaction]\n\n    def __init__(\n        self,\n        table: Optional[Table],\n        transaction: Optional[Transaction] = None,\n        allow_incompatible_changes: bool = False,\n        case_sensitive: bool = True,\n        schema: Optional[Schema] = None,\n    ) -&gt; None:\n        self._table = table\n\n        if isinstance(schema, Schema):\n            self._schema = schema\n            self._last_column_id = itertools.count(1 + schema.highest_field_id)\n        elif table is not None:\n            self._schema = table.schema()\n            self._last_column_id = itertools.count(1 + table.metadata.last_column_id)\n        else:\n            raise ValueError(\"Either provide a table or a schema\")\n\n        self._identifier_field_names = self._schema.identifier_field_names()\n\n        self._adds = {}\n        self._updates = {}\n        self._deletes = set()\n        self._moves = {}\n\n        self._added_name_to_id = {}\n\n        def get_column_name(field_id: int) -&gt; str:\n            column_name = self._schema.find_column_name(column_id=field_id)\n            if column_name is None:\n                raise ValueError(f\"Could not find field-id: {field_id}\")\n            return column_name\n\n        self._id_to_parent = {\n            field_id: get_column_name(parent_field_id) for field_id, parent_field_id in self._schema._lazy_id_to_parent.items()\n        }\n\n        self._allow_incompatible_changes = allow_incompatible_changes\n        self._case_sensitive = case_sensitive\n        self._transaction = transaction\n\n    def __exit__(self, _: Any, value: Any, traceback: Any) -&gt; None:\n        \"\"\"Close and commit the change.\"\"\"\n        return self.commit()\n\n    def __enter__(self) -&gt; UpdateSchema:\n        \"\"\"Update the table.\"\"\"\n        return self\n\n    def case_sensitive(self, case_sensitive: bool) -&gt; UpdateSchema:\n        \"\"\"Determine if the case of schema needs to be considered when comparing column names.\n\n        Args:\n            case_sensitive: When false case is not considered in column name comparisons.\n\n        Returns:\n            This for method chaining\n        \"\"\"\n        self._case_sensitive = case_sensitive\n        return self\n\n    def union_by_name(self, new_schema: Union[Schema, \"pa.Schema\"]) -&gt; UpdateSchema:\n        from pyiceberg.catalog import Catalog\n\n        visit_with_partner(\n            Catalog._convert_schema_if_needed(new_schema),\n            -1,\n            UnionByNameVisitor(update_schema=self, existing_schema=self._schema, case_sensitive=self._case_sensitive),  # type: ignore\n            PartnerIdByNameAccessor(partner_schema=self._schema, case_sensitive=self._case_sensitive),\n        )\n        return self\n\n    def add_column(\n        self, path: Union[str, Tuple[str, ...]], field_type: IcebergType, doc: Optional[str] = None, required: bool = False\n    ) -&gt; UpdateSchema:\n        \"\"\"Add a new column to a nested struct or Add a new top-level column.\n\n        Because \".\" may be interpreted as a column path separator or may be used in field names, it\n        is not allowed to add nested column by passing in a string. To add to nested structures or\n        to add fields with names that contain \".\" use a tuple instead to indicate the path.\n\n        If type is a nested type, its field IDs are reassigned when added to the existing schema.\n\n        Args:\n            path: Name for the new column.\n            field_type: Type for the new column.\n            doc: Documentation string for the new column.\n            required: Whether the new column is required.\n\n        Returns:\n            This for method chaining.\n        \"\"\"\n        if isinstance(path, str):\n            if \".\" in path:\n                raise ValueError(f\"Cannot add column with ambiguous name: {path}, provide a tuple instead\")\n            path = (path,)\n\n        if required and not self._allow_incompatible_changes:\n            # Table format version 1 and 2 cannot add required column because there is no initial value\n            raise ValueError(f'Incompatible change: cannot add required column: {\".\".join(path)}')\n\n        name = path[-1]\n        parent = path[:-1]\n\n        full_name = \".\".join(path)\n        parent_full_path = \".\".join(parent)\n        parent_id: int = TABLE_ROOT_ID\n\n        if len(parent) &gt; 0:\n            parent_field = self._schema.find_field(parent_full_path, self._case_sensitive)\n            parent_type = parent_field.field_type\n            if isinstance(parent_type, MapType):\n                parent_field = parent_type.value_field\n            elif isinstance(parent_type, ListType):\n                parent_field = parent_type.element_field\n\n            if not parent_field.field_type.is_struct:\n                raise ValueError(f\"Cannot add column '{name}' to non-struct type: {parent_full_path}\")\n\n            parent_id = parent_field.field_id\n\n        existing_field = None\n        try:\n            existing_field = self._schema.find_field(full_name, self._case_sensitive)\n        except ValueError:\n            pass\n\n        if existing_field is not None and existing_field.field_id not in self._deletes:\n            raise ValueError(f\"Cannot add column, name already exists: {full_name}\")\n\n        # assign new IDs in order\n        new_id = self.assign_new_column_id()\n\n        # update tracking for moves\n        self._added_name_to_id[full_name] = new_id\n        self._id_to_parent[new_id] = parent_full_path\n\n        new_type = assign_fresh_schema_ids(field_type, self.assign_new_column_id)\n        field = NestedField(field_id=new_id, name=name, field_type=new_type, required=required, doc=doc)\n\n        if parent_id in self._adds:\n            self._adds[parent_id].append(field)\n        else:\n            self._adds[parent_id] = [field]\n\n        return self\n\n    def delete_column(self, path: Union[str, Tuple[str, ...]]) -&gt; UpdateSchema:\n        \"\"\"Delete a column from a table.\n\n        Args:\n            path: The path to the column.\n\n        Returns:\n            The UpdateSchema with the delete operation staged.\n        \"\"\"\n        name = (path,) if isinstance(path, str) else path\n        full_name = \".\".join(name)\n\n        field = self._schema.find_field(full_name, case_sensitive=self._case_sensitive)\n\n        if field.field_id in self._adds:\n            raise ValueError(f\"Cannot delete a column that has additions: {full_name}\")\n        if field.field_id in self._updates:\n            raise ValueError(f\"Cannot delete a column that has updates: {full_name}\")\n\n        self._deletes.add(field.field_id)\n\n        return self\n\n    def rename_column(self, path_from: Union[str, Tuple[str, ...]], new_name: str) -&gt; UpdateSchema:\n        \"\"\"Update the name of a column.\n\n        Args:\n            path_from: The path to the column to be renamed.\n            new_name: The new path of the column.\n\n        Returns:\n            The UpdateSchema with the rename operation staged.\n        \"\"\"\n        path_from = \".\".join(path_from) if isinstance(path_from, tuple) else path_from\n        field_from = self._schema.find_field(path_from, self._case_sensitive)\n\n        if field_from.field_id in self._deletes:\n            raise ValueError(f\"Cannot rename a column that will be deleted: {path_from}\")\n\n        if updated := self._updates.get(field_from.field_id):\n            self._updates[field_from.field_id] = NestedField(\n                field_id=updated.field_id,\n                name=new_name,\n                field_type=updated.field_type,\n                doc=updated.doc,\n                required=updated.required,\n            )\n        else:\n            self._updates[field_from.field_id] = NestedField(\n                field_id=field_from.field_id,\n                name=new_name,\n                field_type=field_from.field_type,\n                doc=field_from.doc,\n                required=field_from.required,\n            )\n\n        # Lookup the field because of casing\n        from_field_correct_casing = self._schema.find_column_name(field_from.field_id)\n        if from_field_correct_casing in self._identifier_field_names:\n            self._identifier_field_names.remove(from_field_correct_casing)\n            new_identifier_path = f\"{from_field_correct_casing[:-len(field_from.name)]}{new_name}\"\n            self._identifier_field_names.add(new_identifier_path)\n\n        return self\n\n    def make_column_optional(self, path: Union[str, Tuple[str, ...]]) -&gt; UpdateSchema:\n        \"\"\"Make a column optional.\n\n        Args:\n            path: The path to the field.\n\n        Returns:\n            The UpdateSchema with the requirement change staged.\n        \"\"\"\n        self._set_column_requirement(path, required=False)\n        return self\n\n    def set_identifier_fields(self, *fields: str) -&gt; None:\n        self._identifier_field_names = set(fields)\n\n    def _set_column_requirement(self, path: Union[str, Tuple[str, ...]], required: bool) -&gt; None:\n        path = (path,) if isinstance(path, str) else path\n        name = \".\".join(path)\n\n        field = self._schema.find_field(name, self._case_sensitive)\n\n        if (field.required and required) or (field.optional and not required):\n            # if the change is a noop, allow it even if allowIncompatibleChanges is false\n            return\n\n        if not self._allow_incompatible_changes and required:\n            raise ValueError(f\"Cannot change column nullability: {name}: optional -&gt; required\")\n\n        if field.field_id in self._deletes:\n            raise ValueError(f\"Cannot update a column that will be deleted: {name}\")\n\n        if updated := self._updates.get(field.field_id):\n            self._updates[field.field_id] = NestedField(\n                field_id=updated.field_id,\n                name=updated.name,\n                field_type=updated.field_type,\n                doc=updated.doc,\n                required=required,\n            )\n        else:\n            self._updates[field.field_id] = NestedField(\n                field_id=field.field_id,\n                name=field.name,\n                field_type=field.field_type,\n                doc=field.doc,\n                required=required,\n            )\n\n    def update_column(\n        self,\n        path: Union[str, Tuple[str, ...]],\n        field_type: Optional[IcebergType] = None,\n        required: Optional[bool] = None,\n        doc: Optional[str] = None,\n    ) -&gt; UpdateSchema:\n        \"\"\"Update the type of column.\n\n        Args:\n            path: The path to the field.\n            field_type: The new type\n            required: If the field should be required\n            doc: Documentation describing the column\n\n        Returns:\n            The UpdateSchema with the type update staged.\n        \"\"\"\n        path = (path,) if isinstance(path, str) else path\n        full_name = \".\".join(path)\n\n        if field_type is None and required is None and doc is None:\n            return self\n\n        field = self._schema.find_field(full_name, self._case_sensitive)\n\n        if field.field_id in self._deletes:\n            raise ValueError(f\"Cannot update a column that will be deleted: {full_name}\")\n\n        if field_type is not None:\n            if not field.field_type.is_primitive:\n                raise ValidationError(f\"Cannot change column type: {field.field_type} is not a primitive\")\n\n            if not self._allow_incompatible_changes and field.field_type != field_type:\n                try:\n                    promote(field.field_type, field_type)\n                except ResolveError as e:\n                    raise ValidationError(f\"Cannot change column type: {full_name}: {field.field_type} -&gt; {field_type}\") from e\n\n        if updated := self._updates.get(field.field_id):\n            self._updates[field.field_id] = NestedField(\n                field_id=updated.field_id,\n                name=updated.name,\n                field_type=field_type or updated.field_type,\n                doc=doc or updated.doc,\n                required=updated.required,\n            )\n        else:\n            self._updates[field.field_id] = NestedField(\n                field_id=field.field_id,\n                name=field.name,\n                field_type=field_type or field.field_type,\n                doc=doc or field.doc,\n                required=field.required,\n            )\n\n        if required is not None:\n            self._set_column_requirement(path, required=required)\n\n        return self\n\n    def _find_for_move(self, name: str) -&gt; Optional[int]:\n        try:\n            return self._schema.find_field(name, self._case_sensitive).field_id\n        except ValueError:\n            pass\n\n        return self._added_name_to_id.get(name)\n\n    def _move(self, move: Move) -&gt; None:\n        if parent_name := self._id_to_parent.get(move.field_id):\n            parent_field = self._schema.find_field(parent_name, case_sensitive=self._case_sensitive)\n            if not parent_field.field_type.is_struct:\n                raise ValueError(f\"Cannot move fields in non-struct type: {parent_field.field_type}\")\n\n            if move.op == MoveOperation.After or move.op == MoveOperation.Before:\n                if move.other_field_id is None:\n                    raise ValueError(\"Expected other field when performing before/after move\")\n\n                if self._id_to_parent.get(move.field_id) != self._id_to_parent.get(move.other_field_id):\n                    raise ValueError(f\"Cannot move field {move.full_name} to a different struct\")\n\n            self._moves[parent_field.field_id] = self._moves.get(parent_field.field_id, []) + [move]\n        else:\n            # In the top level field\n            if move.op == MoveOperation.After or move.op == MoveOperation.Before:\n                if move.other_field_id is None:\n                    raise ValueError(\"Expected other field when performing before/after move\")\n\n                if other_struct := self._id_to_parent.get(move.other_field_id):\n                    raise ValueError(f\"Cannot move field {move.full_name} to a different struct: {other_struct}\")\n\n            self._moves[TABLE_ROOT_ID] = self._moves.get(TABLE_ROOT_ID, []) + [move]\n\n    def move_first(self, path: Union[str, Tuple[str, ...]]) -&gt; UpdateSchema:\n        \"\"\"Move the field to the first position of the parent struct.\n\n        Args:\n            path: The path to the field.\n\n        Returns:\n            The UpdateSchema with the move operation staged.\n        \"\"\"\n        full_name = \".\".join(path) if isinstance(path, tuple) else path\n\n        field_id = self._find_for_move(full_name)\n\n        if field_id is None:\n            raise ValueError(f\"Cannot move missing column: {full_name}\")\n\n        self._move(Move(field_id=field_id, full_name=full_name, op=MoveOperation.First))\n\n        return self\n\n    def move_before(self, path: Union[str, Tuple[str, ...]], before_path: Union[str, Tuple[str, ...]]) -&gt; UpdateSchema:\n        \"\"\"Move the field to before another field.\n\n        Args:\n            path: The path to the field.\n\n        Returns:\n            The UpdateSchema with the move operation staged.\n        \"\"\"\n        full_name = \".\".join(path) if isinstance(path, tuple) else path\n        field_id = self._find_for_move(full_name)\n\n        if field_id is None:\n            raise ValueError(f\"Cannot move missing column: {full_name}\")\n\n        before_full_name = (\n            \".\".join(\n                before_path,\n            )\n            if isinstance(before_path, tuple)\n            else before_path\n        )\n        before_field_id = self._find_for_move(before_full_name)\n\n        if before_field_id is None:\n            raise ValueError(f\"Cannot move {full_name} before missing column: {before_full_name}\")\n\n        if field_id == before_field_id:\n            raise ValueError(f\"Cannot move {full_name} before itself\")\n\n        self._move(Move(field_id=field_id, full_name=full_name, other_field_id=before_field_id, op=MoveOperation.Before))\n\n        return self\n\n    def move_after(self, path: Union[str, Tuple[str, ...]], after_name: Union[str, Tuple[str, ...]]) -&gt; UpdateSchema:\n        \"\"\"Move the field to after another field.\n\n        Args:\n            path: The path to the field.\n\n        Returns:\n            The UpdateSchema with the move operation staged.\n        \"\"\"\n        full_name = \".\".join(path) if isinstance(path, tuple) else path\n\n        field_id = self._find_for_move(full_name)\n\n        if field_id is None:\n            raise ValueError(f\"Cannot move missing column: {full_name}\")\n\n        after_path = \".\".join(after_name) if isinstance(after_name, tuple) else after_name\n        after_field_id = self._find_for_move(after_path)\n\n        if after_field_id is None:\n            raise ValueError(f\"Cannot move {full_name} after missing column: {after_path}\")\n\n        if field_id == after_field_id:\n            raise ValueError(f\"Cannot move {full_name} after itself\")\n\n        self._move(Move(field_id=field_id, full_name=full_name, other_field_id=after_field_id, op=MoveOperation.After))\n\n        return self\n\n    def commit(self) -&gt; None:\n        \"\"\"Apply the pending changes and commit.\"\"\"\n        if self._table is None:\n            raise ValueError(\"Requires a table to commit to\")\n\n        new_schema = self._apply()\n\n        existing_schema_id = next((schema.schema_id for schema in self._table.metadata.schemas if schema == new_schema), None)\n\n        # Check if it is different current schema ID\n        if existing_schema_id != self._table.schema().schema_id:\n            requirements = (AssertCurrentSchemaId(current_schema_id=self._schema.schema_id),)\n            if existing_schema_id is None:\n                last_column_id = max(self._table.metadata.last_column_id, new_schema.highest_field_id)\n                updates = (\n                    AddSchemaUpdate(schema=new_schema, last_column_id=last_column_id),\n                    SetCurrentSchemaUpdate(schema_id=-1),\n                )\n            else:\n                updates = (SetCurrentSchemaUpdate(schema_id=existing_schema_id),)  # type: ignore\n\n            if self._transaction is not None:\n                self._transaction._append_updates(*updates)  # pylint: disable=W0212\n                self._transaction._append_requirements(*requirements)  # pylint: disable=W0212\n            else:\n                self._table._do_commit(updates=updates, requirements=requirements)  # pylint: disable=W0212\n\n    def _apply(self) -&gt; Schema:\n        \"\"\"Apply the pending changes to the original schema and returns the result.\n\n        Returns:\n            the result Schema when all pending updates are applied\n        \"\"\"\n        struct = visit(self._schema, _ApplyChanges(self._adds, self._updates, self._deletes, self._moves))\n        if struct is None:\n            # Should never happen\n            raise ValueError(\"Could not apply changes\")\n\n        # Check the field-ids\n        new_schema = Schema(*struct.fields)\n        field_ids = set()\n        for name in self._identifier_field_names:\n            try:\n                field = new_schema.find_field(name, case_sensitive=self._case_sensitive)\n            except ValueError as e:\n                raise ValueError(\n                    f\"Cannot find identifier field {name}. In case of deletion, update the identifier fields first.\"\n                ) from e\n\n            field_ids.add(field.field_id)\n\n        next_schema_id = 1 + (max(self._table.schemas().keys()) if self._table is not None else self._schema.schema_id)\n        return Schema(*struct.fields, schema_id=next_schema_id, identifier_field_ids=field_ids)\n\n    def assign_new_column_id(self) -&gt; int:\n        return next(self._last_column_id)\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.UpdateSchema.__enter__","title":"<code>__enter__()</code>","text":"<p>Update the table.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def __enter__(self) -&gt; UpdateSchema:\n    \"\"\"Update the table.\"\"\"\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.UpdateSchema.__exit__","title":"<code>__exit__(_, value, traceback)</code>","text":"<p>Close and commit the change.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def __exit__(self, _: Any, value: Any, traceback: Any) -&gt; None:\n    \"\"\"Close and commit the change.\"\"\"\n    return self.commit()\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.UpdateSchema.add_column","title":"<code>add_column(path, field_type, doc=None, required=False)</code>","text":"<p>Add a new column to a nested struct or Add a new top-level column.</p> <p>Because \".\" may be interpreted as a column path separator or may be used in field names, it is not allowed to add nested column by passing in a string. To add to nested structures or to add fields with names that contain \".\" use a tuple instead to indicate the path.</p> <p>If type is a nested type, its field IDs are reassigned when added to the existing schema.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Tuple[str, ...]]</code> <p>Name for the new column.</p> required <code>field_type</code> <code>IcebergType</code> <p>Type for the new column.</p> required <code>doc</code> <code>Optional[str]</code> <p>Documentation string for the new column.</p> <code>None</code> <code>required</code> <code>bool</code> <p>Whether the new column is required.</p> <code>False</code> <p>Returns:</p> Type Description <code>UpdateSchema</code> <p>This for method chaining.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def add_column(\n    self, path: Union[str, Tuple[str, ...]], field_type: IcebergType, doc: Optional[str] = None, required: bool = False\n) -&gt; UpdateSchema:\n    \"\"\"Add a new column to a nested struct or Add a new top-level column.\n\n    Because \".\" may be interpreted as a column path separator or may be used in field names, it\n    is not allowed to add nested column by passing in a string. To add to nested structures or\n    to add fields with names that contain \".\" use a tuple instead to indicate the path.\n\n    If type is a nested type, its field IDs are reassigned when added to the existing schema.\n\n    Args:\n        path: Name for the new column.\n        field_type: Type for the new column.\n        doc: Documentation string for the new column.\n        required: Whether the new column is required.\n\n    Returns:\n        This for method chaining.\n    \"\"\"\n    if isinstance(path, str):\n        if \".\" in path:\n            raise ValueError(f\"Cannot add column with ambiguous name: {path}, provide a tuple instead\")\n        path = (path,)\n\n    if required and not self._allow_incompatible_changes:\n        # Table format version 1 and 2 cannot add required column because there is no initial value\n        raise ValueError(f'Incompatible change: cannot add required column: {\".\".join(path)}')\n\n    name = path[-1]\n    parent = path[:-1]\n\n    full_name = \".\".join(path)\n    parent_full_path = \".\".join(parent)\n    parent_id: int = TABLE_ROOT_ID\n\n    if len(parent) &gt; 0:\n        parent_field = self._schema.find_field(parent_full_path, self._case_sensitive)\n        parent_type = parent_field.field_type\n        if isinstance(parent_type, MapType):\n            parent_field = parent_type.value_field\n        elif isinstance(parent_type, ListType):\n            parent_field = parent_type.element_field\n\n        if not parent_field.field_type.is_struct:\n            raise ValueError(f\"Cannot add column '{name}' to non-struct type: {parent_full_path}\")\n\n        parent_id = parent_field.field_id\n\n    existing_field = None\n    try:\n        existing_field = self._schema.find_field(full_name, self._case_sensitive)\n    except ValueError:\n        pass\n\n    if existing_field is not None and existing_field.field_id not in self._deletes:\n        raise ValueError(f\"Cannot add column, name already exists: {full_name}\")\n\n    # assign new IDs in order\n    new_id = self.assign_new_column_id()\n\n    # update tracking for moves\n    self._added_name_to_id[full_name] = new_id\n    self._id_to_parent[new_id] = parent_full_path\n\n    new_type = assign_fresh_schema_ids(field_type, self.assign_new_column_id)\n    field = NestedField(field_id=new_id, name=name, field_type=new_type, required=required, doc=doc)\n\n    if parent_id in self._adds:\n        self._adds[parent_id].append(field)\n    else:\n        self._adds[parent_id] = [field]\n\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.UpdateSchema.case_sensitive","title":"<code>case_sensitive(case_sensitive)</code>","text":"<p>Determine if the case of schema needs to be considered when comparing column names.</p> <p>Parameters:</p> Name Type Description Default <code>case_sensitive</code> <code>bool</code> <p>When false case is not considered in column name comparisons.</p> required <p>Returns:</p> Type Description <code>UpdateSchema</code> <p>This for method chaining</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def case_sensitive(self, case_sensitive: bool) -&gt; UpdateSchema:\n    \"\"\"Determine if the case of schema needs to be considered when comparing column names.\n\n    Args:\n        case_sensitive: When false case is not considered in column name comparisons.\n\n    Returns:\n        This for method chaining\n    \"\"\"\n    self._case_sensitive = case_sensitive\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.UpdateSchema.commit","title":"<code>commit()</code>","text":"<p>Apply the pending changes and commit.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def commit(self) -&gt; None:\n    \"\"\"Apply the pending changes and commit.\"\"\"\n    if self._table is None:\n        raise ValueError(\"Requires a table to commit to\")\n\n    new_schema = self._apply()\n\n    existing_schema_id = next((schema.schema_id for schema in self._table.metadata.schemas if schema == new_schema), None)\n\n    # Check if it is different current schema ID\n    if existing_schema_id != self._table.schema().schema_id:\n        requirements = (AssertCurrentSchemaId(current_schema_id=self._schema.schema_id),)\n        if existing_schema_id is None:\n            last_column_id = max(self._table.metadata.last_column_id, new_schema.highest_field_id)\n            updates = (\n                AddSchemaUpdate(schema=new_schema, last_column_id=last_column_id),\n                SetCurrentSchemaUpdate(schema_id=-1),\n            )\n        else:\n            updates = (SetCurrentSchemaUpdate(schema_id=existing_schema_id),)  # type: ignore\n\n        if self._transaction is not None:\n            self._transaction._append_updates(*updates)  # pylint: disable=W0212\n            self._transaction._append_requirements(*requirements)  # pylint: disable=W0212\n        else:\n            self._table._do_commit(updates=updates, requirements=requirements)  # pylint: disable=W0212\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.UpdateSchema.delete_column","title":"<code>delete_column(path)</code>","text":"<p>Delete a column from a table.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Tuple[str, ...]]</code> <p>The path to the column.</p> required <p>Returns:</p> Type Description <code>UpdateSchema</code> <p>The UpdateSchema with the delete operation staged.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def delete_column(self, path: Union[str, Tuple[str, ...]]) -&gt; UpdateSchema:\n    \"\"\"Delete a column from a table.\n\n    Args:\n        path: The path to the column.\n\n    Returns:\n        The UpdateSchema with the delete operation staged.\n    \"\"\"\n    name = (path,) if isinstance(path, str) else path\n    full_name = \".\".join(name)\n\n    field = self._schema.find_field(full_name, case_sensitive=self._case_sensitive)\n\n    if field.field_id in self._adds:\n        raise ValueError(f\"Cannot delete a column that has additions: {full_name}\")\n    if field.field_id in self._updates:\n        raise ValueError(f\"Cannot delete a column that has updates: {full_name}\")\n\n    self._deletes.add(field.field_id)\n\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.UpdateSchema.make_column_optional","title":"<code>make_column_optional(path)</code>","text":"<p>Make a column optional.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Tuple[str, ...]]</code> <p>The path to the field.</p> required <p>Returns:</p> Type Description <code>UpdateSchema</code> <p>The UpdateSchema with the requirement change staged.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def make_column_optional(self, path: Union[str, Tuple[str, ...]]) -&gt; UpdateSchema:\n    \"\"\"Make a column optional.\n\n    Args:\n        path: The path to the field.\n\n    Returns:\n        The UpdateSchema with the requirement change staged.\n    \"\"\"\n    self._set_column_requirement(path, required=False)\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.UpdateSchema.move_after","title":"<code>move_after(path, after_name)</code>","text":"<p>Move the field to after another field.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Tuple[str, ...]]</code> <p>The path to the field.</p> required <p>Returns:</p> Type Description <code>UpdateSchema</code> <p>The UpdateSchema with the move operation staged.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def move_after(self, path: Union[str, Tuple[str, ...]], after_name: Union[str, Tuple[str, ...]]) -&gt; UpdateSchema:\n    \"\"\"Move the field to after another field.\n\n    Args:\n        path: The path to the field.\n\n    Returns:\n        The UpdateSchema with the move operation staged.\n    \"\"\"\n    full_name = \".\".join(path) if isinstance(path, tuple) else path\n\n    field_id = self._find_for_move(full_name)\n\n    if field_id is None:\n        raise ValueError(f\"Cannot move missing column: {full_name}\")\n\n    after_path = \".\".join(after_name) if isinstance(after_name, tuple) else after_name\n    after_field_id = self._find_for_move(after_path)\n\n    if after_field_id is None:\n        raise ValueError(f\"Cannot move {full_name} after missing column: {after_path}\")\n\n    if field_id == after_field_id:\n        raise ValueError(f\"Cannot move {full_name} after itself\")\n\n    self._move(Move(field_id=field_id, full_name=full_name, other_field_id=after_field_id, op=MoveOperation.After))\n\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.UpdateSchema.move_before","title":"<code>move_before(path, before_path)</code>","text":"<p>Move the field to before another field.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Tuple[str, ...]]</code> <p>The path to the field.</p> required <p>Returns:</p> Type Description <code>UpdateSchema</code> <p>The UpdateSchema with the move operation staged.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def move_before(self, path: Union[str, Tuple[str, ...]], before_path: Union[str, Tuple[str, ...]]) -&gt; UpdateSchema:\n    \"\"\"Move the field to before another field.\n\n    Args:\n        path: The path to the field.\n\n    Returns:\n        The UpdateSchema with the move operation staged.\n    \"\"\"\n    full_name = \".\".join(path) if isinstance(path, tuple) else path\n    field_id = self._find_for_move(full_name)\n\n    if field_id is None:\n        raise ValueError(f\"Cannot move missing column: {full_name}\")\n\n    before_full_name = (\n        \".\".join(\n            before_path,\n        )\n        if isinstance(before_path, tuple)\n        else before_path\n    )\n    before_field_id = self._find_for_move(before_full_name)\n\n    if before_field_id is None:\n        raise ValueError(f\"Cannot move {full_name} before missing column: {before_full_name}\")\n\n    if field_id == before_field_id:\n        raise ValueError(f\"Cannot move {full_name} before itself\")\n\n    self._move(Move(field_id=field_id, full_name=full_name, other_field_id=before_field_id, op=MoveOperation.Before))\n\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.UpdateSchema.move_first","title":"<code>move_first(path)</code>","text":"<p>Move the field to the first position of the parent struct.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Tuple[str, ...]]</code> <p>The path to the field.</p> required <p>Returns:</p> Type Description <code>UpdateSchema</code> <p>The UpdateSchema with the move operation staged.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def move_first(self, path: Union[str, Tuple[str, ...]]) -&gt; UpdateSchema:\n    \"\"\"Move the field to the first position of the parent struct.\n\n    Args:\n        path: The path to the field.\n\n    Returns:\n        The UpdateSchema with the move operation staged.\n    \"\"\"\n    full_name = \".\".join(path) if isinstance(path, tuple) else path\n\n    field_id = self._find_for_move(full_name)\n\n    if field_id is None:\n        raise ValueError(f\"Cannot move missing column: {full_name}\")\n\n    self._move(Move(field_id=field_id, full_name=full_name, op=MoveOperation.First))\n\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.UpdateSchema.rename_column","title":"<code>rename_column(path_from, new_name)</code>","text":"<p>Update the name of a column.</p> <p>Parameters:</p> Name Type Description Default <code>path_from</code> <code>Union[str, Tuple[str, ...]]</code> <p>The path to the column to be renamed.</p> required <code>new_name</code> <code>str</code> <p>The new path of the column.</p> required <p>Returns:</p> Type Description <code>UpdateSchema</code> <p>The UpdateSchema with the rename operation staged.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def rename_column(self, path_from: Union[str, Tuple[str, ...]], new_name: str) -&gt; UpdateSchema:\n    \"\"\"Update the name of a column.\n\n    Args:\n        path_from: The path to the column to be renamed.\n        new_name: The new path of the column.\n\n    Returns:\n        The UpdateSchema with the rename operation staged.\n    \"\"\"\n    path_from = \".\".join(path_from) if isinstance(path_from, tuple) else path_from\n    field_from = self._schema.find_field(path_from, self._case_sensitive)\n\n    if field_from.field_id in self._deletes:\n        raise ValueError(f\"Cannot rename a column that will be deleted: {path_from}\")\n\n    if updated := self._updates.get(field_from.field_id):\n        self._updates[field_from.field_id] = NestedField(\n            field_id=updated.field_id,\n            name=new_name,\n            field_type=updated.field_type,\n            doc=updated.doc,\n            required=updated.required,\n        )\n    else:\n        self._updates[field_from.field_id] = NestedField(\n            field_id=field_from.field_id,\n            name=new_name,\n            field_type=field_from.field_type,\n            doc=field_from.doc,\n            required=field_from.required,\n        )\n\n    # Lookup the field because of casing\n    from_field_correct_casing = self._schema.find_column_name(field_from.field_id)\n    if from_field_correct_casing in self._identifier_field_names:\n        self._identifier_field_names.remove(from_field_correct_casing)\n        new_identifier_path = f\"{from_field_correct_casing[:-len(field_from.name)]}{new_name}\"\n        self._identifier_field_names.add(new_identifier_path)\n\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.UpdateSchema.update_column","title":"<code>update_column(path, field_type=None, required=None, doc=None)</code>","text":"<p>Update the type of column.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Tuple[str, ...]]</code> <p>The path to the field.</p> required <code>field_type</code> <code>Optional[IcebergType]</code> <p>The new type</p> <code>None</code> <code>required</code> <code>Optional[bool]</code> <p>If the field should be required</p> <code>None</code> <code>doc</code> <code>Optional[str]</code> <p>Documentation describing the column</p> <code>None</code> <p>Returns:</p> Type Description <code>UpdateSchema</code> <p>The UpdateSchema with the type update staged.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def update_column(\n    self,\n    path: Union[str, Tuple[str, ...]],\n    field_type: Optional[IcebergType] = None,\n    required: Optional[bool] = None,\n    doc: Optional[str] = None,\n) -&gt; UpdateSchema:\n    \"\"\"Update the type of column.\n\n    Args:\n        path: The path to the field.\n        field_type: The new type\n        required: If the field should be required\n        doc: Documentation describing the column\n\n    Returns:\n        The UpdateSchema with the type update staged.\n    \"\"\"\n    path = (path,) if isinstance(path, str) else path\n    full_name = \".\".join(path)\n\n    if field_type is None and required is None and doc is None:\n        return self\n\n    field = self._schema.find_field(full_name, self._case_sensitive)\n\n    if field.field_id in self._deletes:\n        raise ValueError(f\"Cannot update a column that will be deleted: {full_name}\")\n\n    if field_type is not None:\n        if not field.field_type.is_primitive:\n            raise ValidationError(f\"Cannot change column type: {field.field_type} is not a primitive\")\n\n        if not self._allow_incompatible_changes and field.field_type != field_type:\n            try:\n                promote(field.field_type, field_type)\n            except ResolveError as e:\n                raise ValidationError(f\"Cannot change column type: {full_name}: {field.field_type} -&gt; {field_type}\") from e\n\n    if updated := self._updates.get(field.field_id):\n        self._updates[field.field_id] = NestedField(\n            field_id=updated.field_id,\n            name=updated.name,\n            field_type=field_type or updated.field_type,\n            doc=doc or updated.doc,\n            required=updated.required,\n        )\n    else:\n        self._updates[field.field_id] = NestedField(\n            field_id=field.field_id,\n            name=field.name,\n            field_type=field_type or field.field_type,\n            doc=doc or field.doc,\n            required=field.required,\n        )\n\n    if required is not None:\n        self._set_column_requirement(path, required=required)\n\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/table/#pyiceberg.table.update_table_metadata","title":"<code>update_table_metadata(base_metadata, updates)</code>","text":"<p>Update the table metadata with the given updates in one transaction.</p> <p>Parameters:</p> Name Type Description Default <code>base_metadata</code> <code>TableMetadata</code> <p>The base metadata to be updated.</p> required <code>updates</code> <code>Tuple[TableUpdate, ...]</code> <p>The updates in one transaction.</p> required <p>Returns:</p> Type Description <code>TableMetadata</code> <p>The metadata with the updates applied.</p> Source code in <code>pyiceberg/table/__init__.py</code> <pre><code>def update_table_metadata(base_metadata: TableMetadata, updates: Tuple[TableUpdate, ...]) -&gt; TableMetadata:\n    \"\"\"Update the table metadata with the given updates in one transaction.\n\n    Args:\n        base_metadata: The base metadata to be updated.\n        updates: The updates in one transaction.\n\n    Returns:\n        The metadata with the updates applied.\n    \"\"\"\n    context = _TableMetadataUpdateContext()\n    new_metadata = base_metadata\n\n    for update in updates:\n        new_metadata = _apply_table_update(update, new_metadata, context)\n\n    return new_metadata.model_copy(deep=True)\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/","title":"metadata","text":""},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields","title":"<code>TableMetadataCommonFields</code>","text":"<p>             Bases: <code>IcebergBaseModel</code></p> <p>Metadata for an Iceberg table as specified in the Apache Iceberg spec.</p> <p>https://iceberg.apache.org/spec/#iceberg-table-spec</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>class TableMetadataCommonFields(IcebergBaseModel):\n    \"\"\"Metadata for an Iceberg table as specified in the Apache Iceberg spec.\n\n    https://iceberg.apache.org/spec/#iceberg-table-spec\n    \"\"\"\n\n    location: str = Field()\n    \"\"\"The table\u2019s base location. This is used by writers to determine where\n    to store data files, manifest files, and table metadata files.\"\"\"\n\n    table_uuid: uuid.UUID = Field(alias=\"table-uuid\", default_factory=uuid.uuid4)\n    \"\"\"A UUID that identifies the table, generated when the table is created.\n    Implementations must throw an exception if a table\u2019s UUID does not match\n    the expected UUID after refreshing metadata.\"\"\"\n\n    last_updated_ms: int = Field(\n        alias=\"last-updated-ms\", default_factory=lambda: datetime_to_millis(datetime.datetime.now().astimezone())\n    )\n    \"\"\"Timestamp in milliseconds from the unix epoch when the table\n    was last updated. Each table metadata file should update this\n    field just before writing.\"\"\"\n\n    last_column_id: int = Field(alias=\"last-column-id\")\n    \"\"\"An integer; the highest assigned column ID for the table.\n    This is used to ensure fields are always assigned an unused ID\n    when evolving schemas.\"\"\"\n\n    schemas: List[Schema] = Field(default_factory=list)\n    \"\"\"A list of schemas, stored as objects with schema-id.\"\"\"\n\n    current_schema_id: int = Field(alias=\"current-schema-id\", default=DEFAULT_SCHEMA_ID)\n    \"\"\"ID of the table\u2019s current schema.\"\"\"\n\n    partition_specs: List[PartitionSpec] = Field(alias=\"partition-specs\", default_factory=list)\n    \"\"\"A list of partition specs, stored as full partition spec objects.\"\"\"\n\n    default_spec_id: int = Field(alias=\"default-spec-id\", default=INITIAL_SPEC_ID)\n    \"\"\"ID of the \u201ccurrent\u201d spec that writers should use by default.\"\"\"\n\n    last_partition_id: Optional[int] = Field(alias=\"last-partition-id\", default=None)\n    \"\"\"An integer; the highest assigned partition field ID across all\n    partition specs for the table. This is used to ensure partition fields\n    are always assigned an unused ID when evolving specs.\"\"\"\n\n    properties: Dict[str, str] = Field(default_factory=dict)\n    \"\"\"A string to string map of table properties. This is used to\n    control settings that affect reading and writing and is not intended\n    to be used for arbitrary metadata. For example, commit.retry.num-retries\n    is used to control the number of commit retries.\"\"\"\n\n    current_snapshot_id: Optional[int] = Field(alias=\"current-snapshot-id\", default=None)\n    \"\"\"ID of the current table snapshot.\"\"\"\n\n    snapshots: List[Snapshot] = Field(default_factory=list)\n    \"\"\"A list of valid snapshots. Valid snapshots are snapshots for which\n    all data files exist in the file system. A data file must not be\n    deleted from the file system until the last snapshot in which it was\n    listed is garbage collected.\"\"\"\n\n    snapshot_log: List[SnapshotLogEntry] = Field(alias=\"snapshot-log\", default_factory=list)\n    \"\"\"A list (optional) of timestamp and snapshot ID pairs that encodes\n    changes to the current snapshot for the table. Each time the\n    current-snapshot-id is changed, a new entry should be added with the\n    last-updated-ms and the new current-snapshot-id. When snapshots are\n    expired from the list of valid snapshots, all entries before a snapshot\n    that has expired should be removed.\"\"\"\n\n    metadata_log: List[MetadataLogEntry] = Field(alias=\"metadata-log\", default_factory=list)\n    \"\"\"A list (optional) of timestamp and metadata file location pairs that\n    encodes changes to the previous metadata files for the table. Each time\n    a new metadata file is created, a new entry of the previous metadata\n    file location should be added to the list. Tables can be configured to\n    remove oldest metadata log entries and keep a fixed-size log of the most\n    recent entries after a commit.\"\"\"\n\n    sort_orders: List[SortOrder] = Field(alias=\"sort-orders\", default_factory=list)\n    \"\"\"A list of sort orders, stored as full sort order objects.\"\"\"\n\n    default_sort_order_id: int = Field(alias=\"default-sort-order-id\", default=UNSORTED_SORT_ORDER_ID)\n    \"\"\"Default sort order id of the table. Note that this could be used by\n    writers, but is not used when reading because reads use the specs stored\n     in manifest files.\"\"\"\n\n    refs: Dict[str, SnapshotRef] = Field(default_factory=dict)\n    \"\"\"A map of snapshot references.\n    The map keys are the unique snapshot reference names in the table,\n    and the map values are snapshot reference objects.\n    There is always a main branch reference pointing to the\n    current-snapshot-id even if the refs map is null.\"\"\"\n\n    def snapshot_by_id(self, snapshot_id: int) -&gt; Optional[Snapshot]:\n        \"\"\"Get the snapshot by snapshot_id.\"\"\"\n        return next((snapshot for snapshot in self.snapshots if snapshot.snapshot_id == snapshot_id), None)\n\n    def schema_by_id(self, schema_id: int) -&gt; Optional[Schema]:\n        \"\"\"Get the schema by schema_id.\"\"\"\n        return next((schema for schema in self.schemas if schema.schema_id == schema_id), None)\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.current_schema_id","title":"<code>current_schema_id: int = Field(alias='current-schema-id', default=DEFAULT_SCHEMA_ID)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ID of the table\u2019s current schema.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.current_snapshot_id","title":"<code>current_snapshot_id: Optional[int] = Field(alias='current-snapshot-id', default=None)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ID of the current table snapshot.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.default_sort_order_id","title":"<code>default_sort_order_id: int = Field(alias='default-sort-order-id', default=UNSORTED_SORT_ORDER_ID)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Default sort order id of the table. Note that this could be used by writers, but is not used when reading because reads use the specs stored  in manifest files.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.default_spec_id","title":"<code>default_spec_id: int = Field(alias='default-spec-id', default=INITIAL_SPEC_ID)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ID of the \u201ccurrent\u201d spec that writers should use by default.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.last_column_id","title":"<code>last_column_id: int = Field(alias='last-column-id')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>An integer; the highest assigned column ID for the table. This is used to ensure fields are always assigned an unused ID when evolving schemas.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.last_partition_id","title":"<code>last_partition_id: Optional[int] = Field(alias='last-partition-id', default=None)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>An integer; the highest assigned partition field ID across all partition specs for the table. This is used to ensure partition fields are always assigned an unused ID when evolving specs.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.last_updated_ms","title":"<code>last_updated_ms: int = Field(alias='last-updated-ms', default_factory=lambda : datetime_to_millis(datetime.datetime.now().astimezone()))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Timestamp in milliseconds from the unix epoch when the table was last updated. Each table metadata file should update this field just before writing.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.location","title":"<code>location: str = Field()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The table\u2019s base location. This is used by writers to determine where to store data files, manifest files, and table metadata files.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.metadata_log","title":"<code>metadata_log: List[MetadataLogEntry] = Field(alias='metadata-log', default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A list (optional) of timestamp and metadata file location pairs that encodes changes to the previous metadata files for the table. Each time a new metadata file is created, a new entry of the previous metadata file location should be added to the list. Tables can be configured to remove oldest metadata log entries and keep a fixed-size log of the most recent entries after a commit.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.partition_specs","title":"<code>partition_specs: List[PartitionSpec] = Field(alias='partition-specs', default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A list of partition specs, stored as full partition spec objects.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.properties","title":"<code>properties: Dict[str, str] = Field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A string to string map of table properties. This is used to control settings that affect reading and writing and is not intended to be used for arbitrary metadata. For example, commit.retry.num-retries is used to control the number of commit retries.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.refs","title":"<code>refs: Dict[str, SnapshotRef] = Field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A map of snapshot references. The map keys are the unique snapshot reference names in the table, and the map values are snapshot reference objects. There is always a main branch reference pointing to the current-snapshot-id even if the refs map is null.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.schemas","title":"<code>schemas: List[Schema] = Field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A list of schemas, stored as objects with schema-id.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.snapshot_log","title":"<code>snapshot_log: List[SnapshotLogEntry] = Field(alias='snapshot-log', default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A list (optional) of timestamp and snapshot ID pairs that encodes changes to the current snapshot for the table. Each time the current-snapshot-id is changed, a new entry should be added with the last-updated-ms and the new current-snapshot-id. When snapshots are expired from the list of valid snapshots, all entries before a snapshot that has expired should be removed.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.snapshots","title":"<code>snapshots: List[Snapshot] = Field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A list of valid snapshots. Valid snapshots are snapshots for which all data files exist in the file system. A data file must not be deleted from the file system until the last snapshot in which it was listed is garbage collected.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.sort_orders","title":"<code>sort_orders: List[SortOrder] = Field(alias='sort-orders', default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A list of sort orders, stored as full sort order objects.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.table_uuid","title":"<code>table_uuid: uuid.UUID = Field(alias='table-uuid', default_factory=uuid.uuid4)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A UUID that identifies the table, generated when the table is created. Implementations must throw an exception if a table\u2019s UUID does not match the expected UUID after refreshing metadata.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.schema_by_id","title":"<code>schema_by_id(schema_id)</code>","text":"<p>Get the schema by schema_id.</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>def schema_by_id(self, schema_id: int) -&gt; Optional[Schema]:\n    \"\"\"Get the schema by schema_id.\"\"\"\n    return next((schema for schema in self.schemas if schema.schema_id == schema_id), None)\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataCommonFields.snapshot_by_id","title":"<code>snapshot_by_id(snapshot_id)</code>","text":"<p>Get the snapshot by snapshot_id.</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>def snapshot_by_id(self, snapshot_id: int) -&gt; Optional[Snapshot]:\n    \"\"\"Get the snapshot by snapshot_id.\"\"\"\n    return next((snapshot for snapshot in self.snapshots if snapshot.snapshot_id == snapshot_id), None)\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataUtil","title":"<code>TableMetadataUtil</code>","text":"<p>Helper class for parsing TableMetadata.</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>class TableMetadataUtil:\n    \"\"\"Helper class for parsing TableMetadata.\"\"\"\n\n    @staticmethod\n    def parse_raw(data: str) -&gt; TableMetadata:\n        try:\n            return TableMetadataWrapper.model_validate_json(data).root\n        except PydanticValidationError as e:\n            raise ValidationError(e) from e\n\n    @staticmethod\n    def parse_obj(data: Dict[str, Any]) -&gt; TableMetadata:\n        if \"format-version\" not in data:\n            raise ValidationError(f\"Missing format-version in TableMetadata: {data}\")\n        format_version = data[\"format-version\"]\n\n        if format_version == 1:\n            return TableMetadataV1(**data)\n        elif format_version == 2:\n            return TableMetadataV2(**data)\n        else:\n            raise ValidationError(f\"Unknown format version: {format_version}\")\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataV1","title":"<code>TableMetadataV1</code>","text":"<p>             Bases: <code>TableMetadataCommonFields</code>, <code>IcebergBaseModel</code></p> <p>Represents version 1 of the Table Metadata.</p> <p>More information about the specification: https://iceberg.apache.org/spec/#version-1-analytic-data-tables</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>class TableMetadataV1(TableMetadataCommonFields, IcebergBaseModel):\n    \"\"\"Represents version 1 of the Table Metadata.\n\n    More information about the specification:\n    https://iceberg.apache.org/spec/#version-1-analytic-data-tables\n    \"\"\"\n\n    # When we read a V1 format-version, we'll make sure to populate the fields\n    # for V2 as well. This makes it easier downstream because we can just\n    # assume that everything is a TableMetadataV2.\n    # When writing, we should stick to the same version that it was,\n    # because bumping the version should be an explicit operation that is up\n    # to the owner of the table.\n\n    @model_validator(mode=\"before\")\n    def cleanup_snapshot_id(cls, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        return cleanup_snapshot_id(data)\n\n    @model_validator(mode=\"after\")\n    def construct_refs(cls, data: TableMetadataV1) -&gt; TableMetadataV1:\n        return construct_refs(data)\n\n    @model_validator(mode=\"before\")\n    def set_v2_compatible_defaults(cls, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Set default values to be compatible with the format v2.\n\n        Args:\n            data: The raw arguments when initializing a V1 TableMetadata.\n\n        Returns:\n            The TableMetadata with the defaults applied.\n        \"\"\"\n        # When the schema doesn't have an ID\n        schema = data.get(\"schema\")\n        if isinstance(schema, dict):\n            if \"schema_id\" not in schema and \"schema-id\" not in schema:\n                schema[\"schema_id\"] = DEFAULT_SCHEMA_ID\n\n        return data\n\n    @model_validator(mode=\"before\")\n    def construct_schemas(cls, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Convert the schema into schemas.\n\n        For V1 schemas is optional, and if they aren't set, we'll set them\n        in this validator. This was we can always use the schemas when reading\n        table metadata, and we don't have to worry if it is a v1 or v2 format.\n\n        Args:\n            data: The raw data after validation, meaning that the aliases are applied.\n\n        Returns:\n            The TableMetadata with the schemas set, if not provided.\n        \"\"\"\n        if not data.get(\"schemas\"):\n            schema = data[\"schema\"]\n            data[\"schemas\"] = [schema]\n        return data\n\n    @model_validator(mode=\"before\")\n    def construct_partition_specs(cls, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Convert the partition_spec into partition_specs.\n\n        For V1 partition_specs is optional, and if they aren't set, we'll set them\n        in this validator. This was we can always use the partition_specs when reading\n        table metadata, and we don't have to worry if it is a v1 or v2 format.\n\n        Args:\n            data: The raw data after validation, meaning that the aliases are applied.\n\n        Returns:\n            The TableMetadata with the partition_specs set, if not provided.\n        \"\"\"\n        if not data.get(PARTITION_SPECS):\n            if data.get(PARTITION_SPEC) is not None:\n                # Promote the spec from partition-spec to partition-specs\n                fields = data[PARTITION_SPEC]\n                data[PARTITION_SPECS] = [{SPEC_ID: INITIAL_SPEC_ID, FIELDS: fields}]\n                data[DEFAULT_SPEC_ID] = INITIAL_SPEC_ID\n            else:\n                data[PARTITION_SPECS] = [{\"field-id\": 0, \"fields\": ()}]\n\n        data[LAST_PARTITION_ID] = max(\n            [field.get(FIELD_ID) for spec in data[PARTITION_SPECS] for field in spec[FIELDS]], default=PARTITION_FIELD_ID_START\n        )\n\n        return data\n\n    @model_validator(mode=\"before\")\n    def set_sort_orders(cls, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Set the sort_orders if not provided.\n\n        For V1 sort_orders is optional, and if they aren't set, we'll set them\n        in this validator.\n\n        Args:\n            data: The raw data after validation, meaning that the aliases are applied.\n\n        Returns:\n            The TableMetadata with the sort_orders set, if not provided.\n        \"\"\"\n        if not data.get(SORT_ORDERS):\n            data[SORT_ORDERS] = [UNSORTED_SORT_ORDER]\n        return data\n\n    def to_v2(self) -&gt; TableMetadataV2:\n        metadata = copy(self.model_dump())\n        metadata[\"format-version\"] = 2\n        return TableMetadataV2.model_validate(metadata)\n\n    format_version: Literal[1] = Field(alias=\"format-version\", default=1)\n    \"\"\"An integer version number for the format. Currently, this can be 1 or 2\n    based on the spec. Implementations must throw an exception if a table\u2019s\n    version is higher than the supported version.\"\"\"\n\n    schema_: Schema = Field(alias=\"schema\")\n    \"\"\"The table\u2019s current schema. (Deprecated: use schemas and\n    current-schema-id instead).\"\"\"\n\n    partition_spec: List[Dict[str, Any]] = Field(alias=\"partition-spec\")\n    \"\"\"The table\u2019s current partition spec, stored as only fields.\n    Note that this is used by writers to partition data, but is\n    not used when reading because reads use the specs stored in\n    manifest files. (Deprecated: use partition-specs and default-spec-id\n    instead).\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataV1.format_version","title":"<code>format_version: Literal[1] = Field(alias='format-version', default=1)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>An integer version number for the format. Currently, this can be 1 or 2 based on the spec. Implementations must throw an exception if a table\u2019s version is higher than the supported version.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataV1.partition_spec","title":"<code>partition_spec: List[Dict[str, Any]] = Field(alias='partition-spec')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The table\u2019s current partition spec, stored as only fields. Note that this is used by writers to partition data, but is not used when reading because reads use the specs stored in manifest files. (Deprecated: use partition-specs and default-spec-id instead).</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataV1.schema_","title":"<code>schema_: Schema = Field(alias='schema')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The table\u2019s current schema. (Deprecated: use schemas and current-schema-id instead).</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataV1.construct_partition_specs","title":"<code>construct_partition_specs(data)</code>","text":"<p>Convert the partition_spec into partition_specs.</p> <p>For V1 partition_specs is optional, and if they aren't set, we'll set them in this validator. This was we can always use the partition_specs when reading table metadata, and we don't have to worry if it is a v1 or v2 format.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>The raw data after validation, meaning that the aliases are applied.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The TableMetadata with the partition_specs set, if not provided.</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>@model_validator(mode=\"before\")\ndef construct_partition_specs(cls, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"Convert the partition_spec into partition_specs.\n\n    For V1 partition_specs is optional, and if they aren't set, we'll set them\n    in this validator. This was we can always use the partition_specs when reading\n    table metadata, and we don't have to worry if it is a v1 or v2 format.\n\n    Args:\n        data: The raw data after validation, meaning that the aliases are applied.\n\n    Returns:\n        The TableMetadata with the partition_specs set, if not provided.\n    \"\"\"\n    if not data.get(PARTITION_SPECS):\n        if data.get(PARTITION_SPEC) is not None:\n            # Promote the spec from partition-spec to partition-specs\n            fields = data[PARTITION_SPEC]\n            data[PARTITION_SPECS] = [{SPEC_ID: INITIAL_SPEC_ID, FIELDS: fields}]\n            data[DEFAULT_SPEC_ID] = INITIAL_SPEC_ID\n        else:\n            data[PARTITION_SPECS] = [{\"field-id\": 0, \"fields\": ()}]\n\n    data[LAST_PARTITION_ID] = max(\n        [field.get(FIELD_ID) for spec in data[PARTITION_SPECS] for field in spec[FIELDS]], default=PARTITION_FIELD_ID_START\n    )\n\n    return data\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataV1.construct_schemas","title":"<code>construct_schemas(data)</code>","text":"<p>Convert the schema into schemas.</p> <p>For V1 schemas is optional, and if they aren't set, we'll set them in this validator. This was we can always use the schemas when reading table metadata, and we don't have to worry if it is a v1 or v2 format.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>The raw data after validation, meaning that the aliases are applied.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The TableMetadata with the schemas set, if not provided.</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>@model_validator(mode=\"before\")\ndef construct_schemas(cls, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"Convert the schema into schemas.\n\n    For V1 schemas is optional, and if they aren't set, we'll set them\n    in this validator. This was we can always use the schemas when reading\n    table metadata, and we don't have to worry if it is a v1 or v2 format.\n\n    Args:\n        data: The raw data after validation, meaning that the aliases are applied.\n\n    Returns:\n        The TableMetadata with the schemas set, if not provided.\n    \"\"\"\n    if not data.get(\"schemas\"):\n        schema = data[\"schema\"]\n        data[\"schemas\"] = [schema]\n    return data\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataV1.set_sort_orders","title":"<code>set_sort_orders(data)</code>","text":"<p>Set the sort_orders if not provided.</p> <p>For V1 sort_orders is optional, and if they aren't set, we'll set them in this validator.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>The raw data after validation, meaning that the aliases are applied.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The TableMetadata with the sort_orders set, if not provided.</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>@model_validator(mode=\"before\")\ndef set_sort_orders(cls, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"Set the sort_orders if not provided.\n\n    For V1 sort_orders is optional, and if they aren't set, we'll set them\n    in this validator.\n\n    Args:\n        data: The raw data after validation, meaning that the aliases are applied.\n\n    Returns:\n        The TableMetadata with the sort_orders set, if not provided.\n    \"\"\"\n    if not data.get(SORT_ORDERS):\n        data[SORT_ORDERS] = [UNSORTED_SORT_ORDER]\n    return data\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataV1.set_v2_compatible_defaults","title":"<code>set_v2_compatible_defaults(data)</code>","text":"<p>Set default values to be compatible with the format v2.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>The raw arguments when initializing a V1 TableMetadata.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The TableMetadata with the defaults applied.</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>@model_validator(mode=\"before\")\ndef set_v2_compatible_defaults(cls, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"Set default values to be compatible with the format v2.\n\n    Args:\n        data: The raw arguments when initializing a V1 TableMetadata.\n\n    Returns:\n        The TableMetadata with the defaults applied.\n    \"\"\"\n    # When the schema doesn't have an ID\n    schema = data.get(\"schema\")\n    if isinstance(schema, dict):\n        if \"schema_id\" not in schema and \"schema-id\" not in schema:\n            schema[\"schema_id\"] = DEFAULT_SCHEMA_ID\n\n    return data\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataV2","title":"<code>TableMetadataV2</code>","text":"<p>             Bases: <code>TableMetadataCommonFields</code>, <code>IcebergBaseModel</code></p> <p>Represents version 2 of the Table Metadata.</p> <p>This extends Version 1 with row-level deletes, and adds some additional information to the schema, such as all the historical schemas, partition-specs, sort-orders.</p> <p>For more information: https://iceberg.apache.org/spec/#version-2-row-level-deletes</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>class TableMetadataV2(TableMetadataCommonFields, IcebergBaseModel):\n    \"\"\"Represents version 2 of the Table Metadata.\n\n    This extends Version 1 with row-level deletes, and adds some additional\n    information to the schema, such as all the historical schemas, partition-specs,\n    sort-orders.\n\n    For more information:\n    https://iceberg.apache.org/spec/#version-2-row-level-deletes\n    \"\"\"\n\n    @model_validator(mode=\"before\")\n    def cleanup_snapshot_id(cls, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        return cleanup_snapshot_id(data)\n\n    @model_validator(mode=\"after\")\n    def check_schemas(cls, table_metadata: TableMetadata) -&gt; TableMetadata:\n        return check_schemas(table_metadata)\n\n    @model_validator(mode=\"after\")\n    def check_partition_specs(cls, table_metadata: TableMetadata) -&gt; TableMetadata:\n        return check_partition_specs(table_metadata)\n\n    @model_validator(mode=\"after\")\n    def check_sort_orders(cls, table_metadata: TableMetadata) -&gt; TableMetadata:\n        return check_sort_orders(table_metadata)\n\n    @model_validator(mode=\"after\")\n    def construct_refs(cls, table_metadata: TableMetadata) -&gt; TableMetadata:\n        return construct_refs(table_metadata)\n\n    format_version: Literal[2] = Field(alias=\"format-version\", default=2)\n    \"\"\"An integer version number for the format. Currently, this can be 1 or 2\n    based on the spec. Implementations must throw an exception if a table\u2019s\n    version is higher than the supported version.\"\"\"\n\n    last_sequence_number: int = Field(alias=\"last-sequence-number\", default=INITIAL_SEQUENCE_NUMBER)\n    \"\"\"The table\u2019s highest assigned sequence number, a monotonically\n    increasing long that tracks the order of snapshots in a table.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataV2.format_version","title":"<code>format_version: Literal[2] = Field(alias='format-version', default=2)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>An integer version number for the format. Currently, this can be 1 or 2 based on the spec. Implementations must throw an exception if a table\u2019s version is higher than the supported version.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.TableMetadataV2.last_sequence_number","title":"<code>last_sequence_number: int = Field(alias='last-sequence-number', default=INITIAL_SEQUENCE_NUMBER)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The table\u2019s highest assigned sequence number, a monotonically increasing long that tracks the order of snapshots in a table.</p>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.check_partition_specs","title":"<code>check_partition_specs(table_metadata)</code>","text":"<p>Check if the default-spec-id is present in partition-specs.</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>def check_partition_specs(table_metadata: TableMetadata) -&gt; TableMetadata:\n    \"\"\"Check if the default-spec-id is present in partition-specs.\"\"\"\n    default_spec_id = table_metadata.default_spec_id\n\n    partition_specs: List[PartitionSpec] = table_metadata.partition_specs\n    for spec in partition_specs:\n        if spec.spec_id == default_spec_id:\n            return table_metadata\n\n    raise ValidationError(f\"default-spec-id {default_spec_id} can't be found\")\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.check_schemas","title":"<code>check_schemas(table_metadata)</code>","text":"<p>Check if the current-schema-id is actually present in schemas.</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>def check_schemas(table_metadata: TableMetadata) -&gt; TableMetadata:\n    \"\"\"Check if the current-schema-id is actually present in schemas.\"\"\"\n    current_schema_id = table_metadata.current_schema_id\n\n    for schema in table_metadata.schemas:\n        if schema.schema_id == current_schema_id:\n            return table_metadata\n\n    raise ValidationError(f\"current-schema-id {current_schema_id} can't be found in the schemas\")\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.check_sort_orders","title":"<code>check_sort_orders(table_metadata)</code>","text":"<p>Check if the default_sort_order_id is present in sort-orders.</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>def check_sort_orders(table_metadata: TableMetadata) -&gt; TableMetadata:\n    \"\"\"Check if the default_sort_order_id is present in sort-orders.\"\"\"\n    default_sort_order_id: int = table_metadata.default_sort_order_id\n\n    if default_sort_order_id != UNSORTED_SORT_ORDER_ID:\n        sort_orders: List[SortOrder] = table_metadata.sort_orders\n        for sort_order in sort_orders:\n            if sort_order.order_id == default_sort_order_id:\n                return table_metadata\n\n        raise ValidationError(f\"default-sort-order-id {default_sort_order_id} can't be found in {sort_orders}\")\n    return table_metadata\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.cleanup_snapshot_id","title":"<code>cleanup_snapshot_id(data)</code>","text":"<p>Run before validation.</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>def cleanup_snapshot_id(data: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"Run before validation.\"\"\"\n    if CURRENT_SNAPSHOT_ID in data and data[CURRENT_SNAPSHOT_ID] == -1:\n        # We treat -1 and None the same, by cleaning this up\n        # in a pre-validator, we can simplify the logic later on\n        data[CURRENT_SNAPSHOT_ID] = None\n    return data\n</code></pre>"},{"location":"reference/pyiceberg/table/metadata/#pyiceberg.table.metadata.construct_refs","title":"<code>construct_refs(table_metadata)</code>","text":"<p>Set the main branch if missing.</p> Source code in <code>pyiceberg/table/metadata.py</code> <pre><code>def construct_refs(table_metadata: TableMetadata) -&gt; TableMetadata:\n    \"\"\"Set the main branch if missing.\"\"\"\n    if table_metadata.current_snapshot_id is not None:\n        if MAIN_BRANCH not in table_metadata.refs:\n            table_metadata.refs[MAIN_BRANCH] = SnapshotRef(\n                snapshot_id=table_metadata.current_snapshot_id, snapshot_ref_type=SnapshotRefType.BRANCH\n            )\n    return table_metadata\n</code></pre>"},{"location":"reference/pyiceberg/table/name_mapping/","title":"name_mapping","text":"<p>Contains everything around the name mapping.</p> <p>More information can be found on here: https://iceberg.apache.org/spec/#name-mapping-serialization</p>"},{"location":"reference/pyiceberg/table/name_mapping/#pyiceberg.table.name_mapping.MappedField","title":"<code>MappedField</code>","text":"<p>             Bases: <code>IcebergBaseModel</code></p> Source code in <code>pyiceberg/table/name_mapping.py</code> <pre><code>class MappedField(IcebergBaseModel):\n    field_id: int = Field(alias=\"field-id\")\n    names: List[str] = conlist(str, min_length=1)\n    fields: List[MappedField] = Field(default_factory=list)\n\n    @field_validator('fields', mode='before')\n    @classmethod\n    def convert_null_to_empty_List(cls, v: Any) -&gt; Any:\n        return v or []\n\n    @model_serializer\n    def ser_model(self) -&gt; Dict[str, Any]:\n        \"\"\"Set custom serializer to leave out the field when it is empty.\"\"\"\n        fields = {'fields': self.fields} if len(self.fields) &gt; 0 else {}\n        return {\n            'field-id': self.field_id,\n            'names': self.names,\n            **fields,\n        }\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of fields.\"\"\"\n        return len(self.fields)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Convert the mapped-field into a nicely formatted string.\"\"\"\n        # Otherwise the UTs fail because the order of the set can change\n        fields_str = \", \".join([str(e) for e in self.fields]) or \"\"\n        fields_str = \" \" + fields_str if fields_str else \"\"\n        return \"([\" + \", \".join(self.names) + \"] -&gt; \" + (str(self.field_id) or \"?\") + fields_str + \")\"\n</code></pre>"},{"location":"reference/pyiceberg/table/name_mapping/#pyiceberg.table.name_mapping.MappedField.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of fields.</p> Source code in <code>pyiceberg/table/name_mapping.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of fields.\"\"\"\n    return len(self.fields)\n</code></pre>"},{"location":"reference/pyiceberg/table/name_mapping/#pyiceberg.table.name_mapping.MappedField.__str__","title":"<code>__str__()</code>","text":"<p>Convert the mapped-field into a nicely formatted string.</p> Source code in <code>pyiceberg/table/name_mapping.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Convert the mapped-field into a nicely formatted string.\"\"\"\n    # Otherwise the UTs fail because the order of the set can change\n    fields_str = \", \".join([str(e) for e in self.fields]) or \"\"\n    fields_str = \" \" + fields_str if fields_str else \"\"\n    return \"([\" + \", \".join(self.names) + \"] -&gt; \" + (str(self.field_id) or \"?\") + fields_str + \")\"\n</code></pre>"},{"location":"reference/pyiceberg/table/name_mapping/#pyiceberg.table.name_mapping.MappedField.ser_model","title":"<code>ser_model()</code>","text":"<p>Set custom serializer to leave out the field when it is empty.</p> Source code in <code>pyiceberg/table/name_mapping.py</code> <pre><code>@model_serializer\ndef ser_model(self) -&gt; Dict[str, Any]:\n    \"\"\"Set custom serializer to leave out the field when it is empty.\"\"\"\n    fields = {'fields': self.fields} if len(self.fields) &gt; 0 else {}\n    return {\n        'field-id': self.field_id,\n        'names': self.names,\n        **fields,\n    }\n</code></pre>"},{"location":"reference/pyiceberg/table/name_mapping/#pyiceberg.table.name_mapping.NameMapping","title":"<code>NameMapping</code>","text":"<p>             Bases: <code>IcebergRootModel[List[MappedField]]</code></p> Source code in <code>pyiceberg/table/name_mapping.py</code> <pre><code>class NameMapping(IcebergRootModel[List[MappedField]]):\n    root: List[MappedField]\n\n    @cached_property\n    def _field_by_name(self) -&gt; Dict[str, MappedField]:\n        return visit_name_mapping(self, _IndexByName())\n\n    def find(self, *names: str) -&gt; MappedField:\n        name = '.'.join(names)\n        try:\n            return self._field_by_name[name]\n        except KeyError as e:\n            raise ValueError(f\"Could not find field with name: {name}\") from e\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of mappings.\"\"\"\n        return len(self.root)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Convert the name-mapping into a nicely formatted string.\"\"\"\n        if len(self.root) == 0:\n            return \"[]\"\n        else:\n            return \"[\\n  \" + \"\\n  \".join([str(e) for e in self.root]) + \"\\n]\"\n</code></pre>"},{"location":"reference/pyiceberg/table/name_mapping/#pyiceberg.table.name_mapping.NameMapping.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of mappings.</p> Source code in <code>pyiceberg/table/name_mapping.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of mappings.\"\"\"\n    return len(self.root)\n</code></pre>"},{"location":"reference/pyiceberg/table/name_mapping/#pyiceberg.table.name_mapping.NameMapping.__str__","title":"<code>__str__()</code>","text":"<p>Convert the name-mapping into a nicely formatted string.</p> Source code in <code>pyiceberg/table/name_mapping.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Convert the name-mapping into a nicely formatted string.\"\"\"\n    if len(self.root) == 0:\n        return \"[]\"\n    else:\n        return \"[\\n  \" + \"\\n  \".join([str(e) for e in self.root]) + \"\\n]\"\n</code></pre>"},{"location":"reference/pyiceberg/table/name_mapping/#pyiceberg.table.name_mapping.NameMappingVisitor","title":"<code>NameMappingVisitor</code>","text":"<p>             Bases: <code>Generic[T]</code>, <code>ABC</code></p> Source code in <code>pyiceberg/table/name_mapping.py</code> <pre><code>class NameMappingVisitor(Generic[T], ABC):\n    @abstractmethod\n    def mapping(self, nm: NameMapping, field_results: T) -&gt; T:\n        \"\"\"Visit a NameMapping.\"\"\"\n\n    @abstractmethod\n    def fields(self, struct: List[MappedField], field_results: List[T]) -&gt; T:\n        \"\"\"Visit a List[MappedField].\"\"\"\n\n    @abstractmethod\n    def field(self, field: MappedField, field_result: T) -&gt; T:\n        \"\"\"Visit a MappedField.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/table/name_mapping/#pyiceberg.table.name_mapping.NameMappingVisitor.field","title":"<code>field(field, field_result)</code>  <code>abstractmethod</code>","text":"<p>Visit a MappedField.</p> Source code in <code>pyiceberg/table/name_mapping.py</code> <pre><code>@abstractmethod\ndef field(self, field: MappedField, field_result: T) -&gt; T:\n    \"\"\"Visit a MappedField.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/table/name_mapping/#pyiceberg.table.name_mapping.NameMappingVisitor.fields","title":"<code>fields(struct, field_results)</code>  <code>abstractmethod</code>","text":"<p>Visit a List[MappedField].</p> Source code in <code>pyiceberg/table/name_mapping.py</code> <pre><code>@abstractmethod\ndef fields(self, struct: List[MappedField], field_results: List[T]) -&gt; T:\n    \"\"\"Visit a List[MappedField].\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/table/name_mapping/#pyiceberg.table.name_mapping.NameMappingVisitor.mapping","title":"<code>mapping(nm, field_results)</code>  <code>abstractmethod</code>","text":"<p>Visit a NameMapping.</p> Source code in <code>pyiceberg/table/name_mapping.py</code> <pre><code>@abstractmethod\ndef mapping(self, nm: NameMapping, field_results: T) -&gt; T:\n    \"\"\"Visit a NameMapping.\"\"\"\n</code></pre>"},{"location":"reference/pyiceberg/table/name_mapping/#pyiceberg.table.name_mapping.visit_name_mapping","title":"<code>visit_name_mapping(obj, visitor)</code>","text":"<p>Traverse the name mapping in post-order traversal.</p> Source code in <code>pyiceberg/table/name_mapping.py</code> <pre><code>@singledispatch\ndef visit_name_mapping(obj: Union[NameMapping, List[MappedField], MappedField], visitor: NameMappingVisitor[T]) -&gt; T:\n    \"\"\"Traverse the name mapping in post-order traversal.\"\"\"\n    raise NotImplementedError(f\"Cannot visit non-type: {obj}\")\n</code></pre>"},{"location":"reference/pyiceberg/table/refs/","title":"refs","text":""},{"location":"reference/pyiceberg/table/refs/#pyiceberg.table.refs.SnapshotRefType","title":"<code>SnapshotRefType</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>pyiceberg/table/refs.py</code> <pre><code>class SnapshotRefType(str, Enum):\n    BRANCH = \"branch\"\n    TAG = \"tag\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the SnapshotRefType class.\"\"\"\n        return f\"SnapshotRefType.{self.name}\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the SnapshotRefType class.\"\"\"\n        return self.value\n</code></pre>"},{"location":"reference/pyiceberg/table/refs/#pyiceberg.table.refs.SnapshotRefType.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the SnapshotRefType class.</p> Source code in <code>pyiceberg/table/refs.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the SnapshotRefType class.\"\"\"\n    return f\"SnapshotRefType.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/table/refs/#pyiceberg.table.refs.SnapshotRefType.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the SnapshotRefType class.</p> Source code in <code>pyiceberg/table/refs.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the SnapshotRefType class.\"\"\"\n    return self.value\n</code></pre>"},{"location":"reference/pyiceberg/table/snapshots/","title":"snapshots","text":""},{"location":"reference/pyiceberg/table/snapshots/#pyiceberg.table.snapshots.Operation","title":"<code>Operation</code>","text":"<p>             Bases: <code>Enum</code></p> <p>Describes the operation.</p> Possible operation values are <ul> <li>append: Only data files were added and no files were removed.</li> <li>replace: Data and delete files were added and removed without changing table data; i.e., compaction, changing the data file format, or relocating data files.</li> <li>overwrite: Data and delete files were added and removed in a logical overwrite operation.</li> <li>delete: Data files were removed and their contents logically deleted and/or delete files were added to delete rows.</li> </ul> Source code in <code>pyiceberg/table/snapshots.py</code> <pre><code>class Operation(Enum):\n    \"\"\"Describes the operation.\n\n    Possible operation values are:\n        - append: Only data files were added and no files were removed.\n        - replace: Data and delete files were added and removed without changing table data; i.e., compaction, changing the data file format, or relocating data files.\n        - overwrite: Data and delete files were added and removed in a logical overwrite operation.\n        - delete: Data files were removed and their contents logically deleted and/or delete files were added to delete rows.\n    \"\"\"\n\n    APPEND = \"append\"\n    REPLACE = \"replace\"\n    OVERWRITE = \"overwrite\"\n    DELETE = \"delete\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the Operation class.\"\"\"\n        return f\"Operation.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/table/snapshots/#pyiceberg.table.snapshots.Operation.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the Operation class.</p> Source code in <code>pyiceberg/table/snapshots.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the Operation class.\"\"\"\n    return f\"Operation.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/table/snapshots/#pyiceberg.table.snapshots.Snapshot","title":"<code>Snapshot</code>","text":"<p>             Bases: <code>IcebergBaseModel</code></p> Source code in <code>pyiceberg/table/snapshots.py</code> <pre><code>class Snapshot(IcebergBaseModel):\n    snapshot_id: int = Field(alias=\"snapshot-id\")\n    parent_snapshot_id: Optional[int] = Field(alias=\"parent-snapshot-id\", default=None)\n    sequence_number: Optional[int] = Field(alias=\"sequence-number\", default=None)\n    timestamp_ms: int = Field(alias=\"timestamp-ms\", default_factory=lambda: int(time.time() * 1000))\n    manifest_list: Optional[str] = Field(\n        alias=\"manifest-list\", description=\"Location of the snapshot's manifest list file\", default=None\n    )\n    summary: Optional[Summary] = Field(default=None)\n    schema_id: Optional[int] = Field(alias=\"schema-id\", default=None)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the Snapshot class.\"\"\"\n        operation = f\"{self.summary.operation}: \" if self.summary else \"\"\n        parent_id = f\", parent_id={self.parent_snapshot_id}\" if self.parent_snapshot_id else \"\"\n        schema_id = f\", schema_id={self.schema_id}\" if self.schema_id is not None else \"\"\n        result_str = f\"{operation}id={self.snapshot_id}{parent_id}{schema_id}\"\n        return result_str\n\n    def manifests(self, io: FileIO) -&gt; List[ManifestFile]:\n        if self.manifest_list is not None:\n            file = io.new_input(self.manifest_list)\n            return list(read_manifest_list(file))\n        return []\n</code></pre>"},{"location":"reference/pyiceberg/table/snapshots/#pyiceberg.table.snapshots.Snapshot.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the Snapshot class.</p> Source code in <code>pyiceberg/table/snapshots.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the Snapshot class.\"\"\"\n    operation = f\"{self.summary.operation}: \" if self.summary else \"\"\n    parent_id = f\", parent_id={self.parent_snapshot_id}\" if self.parent_snapshot_id else \"\"\n    schema_id = f\", schema_id={self.schema_id}\" if self.schema_id is not None else \"\"\n    result_str = f\"{operation}id={self.snapshot_id}{parent_id}{schema_id}\"\n    return result_str\n</code></pre>"},{"location":"reference/pyiceberg/table/snapshots/#pyiceberg.table.snapshots.Summary","title":"<code>Summary</code>","text":"<p>             Bases: <code>IcebergBaseModel</code>, <code>Mapping[str, str]</code></p> <p>A class that stores the summary information for a Snapshot.</p> <p>The snapshot summary\u2019s operation field is used by some operations, like snapshot expiration, to skip processing certain snapshots.</p> Source code in <code>pyiceberg/table/snapshots.py</code> <pre><code>class Summary(IcebergBaseModel, Mapping[str, str]):\n    \"\"\"A class that stores the summary information for a Snapshot.\n\n    The snapshot summary\u2019s operation field is used by some operations,\n    like snapshot expiration, to skip processing certain snapshots.\n    \"\"\"\n\n    operation: Operation = Field()\n    _additional_properties: Dict[str, str] = PrivateAttr()\n\n    def __init__(self, operation: Operation, **data: Any) -&gt; None:\n        super().__init__(operation=operation, **data)\n        self._additional_properties = data\n\n    def __getitem__(self, __key: str) -&gt; Optional[Any]:  # type: ignore\n        \"\"\"Return a key as it is a map.\"\"\"\n        if __key.lower() == 'operation':\n            return self.operation\n        else:\n            return self._additional_properties.get(__key)\n\n    def __setitem__(self, key: str, value: Any) -&gt; None:\n        \"\"\"Set a key as it is a map.\"\"\"\n        if key.lower() == 'operation':\n            self.operation = value\n        else:\n            self._additional_properties[key] = value\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of keys in the summary.\"\"\"\n        # Operation is required\n        return 1 + len(self._additional_properties)\n\n    @model_serializer\n    def ser_model(self) -&gt; Dict[str, str]:\n        return {\n            \"operation\": str(self.operation.value),\n            **self._additional_properties,\n        }\n\n    @property\n    def additional_properties(self) -&gt; Dict[str, str]:\n        return self._additional_properties\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the Summary class.\"\"\"\n        repr_properties = f\", **{repr(self._additional_properties)}\" if self._additional_properties else \"\"\n        return f\"Summary({repr(self.operation)}{repr_properties})\"\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Compare if the summary is equal to another summary.\"\"\"\n        return (\n            self.operation == other.operation and self.additional_properties == other.additional_properties\n            if isinstance(other, Summary)\n            else False\n        )\n</code></pre>"},{"location":"reference/pyiceberg/table/snapshots/#pyiceberg.table.snapshots.Summary.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Compare if the summary is equal to another summary.</p> Source code in <code>pyiceberg/table/snapshots.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Compare if the summary is equal to another summary.\"\"\"\n    return (\n        self.operation == other.operation and self.additional_properties == other.additional_properties\n        if isinstance(other, Summary)\n        else False\n    )\n</code></pre>"},{"location":"reference/pyiceberg/table/snapshots/#pyiceberg.table.snapshots.Summary.__getitem__","title":"<code>__getitem__(__key)</code>","text":"<p>Return a key as it is a map.</p> Source code in <code>pyiceberg/table/snapshots.py</code> <pre><code>def __getitem__(self, __key: str) -&gt; Optional[Any]:  # type: ignore\n    \"\"\"Return a key as it is a map.\"\"\"\n    if __key.lower() == 'operation':\n        return self.operation\n    else:\n        return self._additional_properties.get(__key)\n</code></pre>"},{"location":"reference/pyiceberg/table/snapshots/#pyiceberg.table.snapshots.Summary.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of keys in the summary.</p> Source code in <code>pyiceberg/table/snapshots.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of keys in the summary.\"\"\"\n    # Operation is required\n    return 1 + len(self._additional_properties)\n</code></pre>"},{"location":"reference/pyiceberg/table/snapshots/#pyiceberg.table.snapshots.Summary.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the Summary class.</p> Source code in <code>pyiceberg/table/snapshots.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the Summary class.\"\"\"\n    repr_properties = f\", **{repr(self._additional_properties)}\" if self._additional_properties else \"\"\n    return f\"Summary({repr(self.operation)}{repr_properties})\"\n</code></pre>"},{"location":"reference/pyiceberg/table/snapshots/#pyiceberg.table.snapshots.Summary.__setitem__","title":"<code>__setitem__(key, value)</code>","text":"<p>Set a key as it is a map.</p> Source code in <code>pyiceberg/table/snapshots.py</code> <pre><code>def __setitem__(self, key: str, value: Any) -&gt; None:\n    \"\"\"Set a key as it is a map.\"\"\"\n    if key.lower() == 'operation':\n        self.operation = value\n    else:\n        self._additional_properties[key] = value\n</code></pre>"},{"location":"reference/pyiceberg/table/sorting/","title":"sorting","text":""},{"location":"reference/pyiceberg/table/sorting/#pyiceberg.table.sorting.NullOrder","title":"<code>NullOrder</code>","text":"<p>             Bases: <code>Enum</code></p> Source code in <code>pyiceberg/table/sorting.py</code> <pre><code>class NullOrder(Enum):\n    NULLS_FIRST = \"nulls-first\"\n    NULLS_LAST = \"nulls-last\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the NullOrder class.\"\"\"\n        return self.name.replace(\"_\", \" \")\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the NullOrder class.\"\"\"\n        return f\"NullOrder.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/table/sorting/#pyiceberg.table.sorting.NullOrder.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the NullOrder class.</p> Source code in <code>pyiceberg/table/sorting.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the NullOrder class.\"\"\"\n    return f\"NullOrder.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/table/sorting/#pyiceberg.table.sorting.NullOrder.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the NullOrder class.</p> Source code in <code>pyiceberg/table/sorting.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the NullOrder class.\"\"\"\n    return self.name.replace(\"_\", \" \")\n</code></pre>"},{"location":"reference/pyiceberg/table/sorting/#pyiceberg.table.sorting.SortDirection","title":"<code>SortDirection</code>","text":"<p>             Bases: <code>Enum</code></p> Source code in <code>pyiceberg/table/sorting.py</code> <pre><code>class SortDirection(Enum):\n    ASC = \"asc\"\n    DESC = \"desc\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the SortDirection class.\"\"\"\n        return self.name\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the SortDirection class.\"\"\"\n        return f\"SortDirection.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/table/sorting/#pyiceberg.table.sorting.SortDirection.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the SortDirection class.</p> Source code in <code>pyiceberg/table/sorting.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the SortDirection class.\"\"\"\n    return f\"SortDirection.{self.name}\"\n</code></pre>"},{"location":"reference/pyiceberg/table/sorting/#pyiceberg.table.sorting.SortDirection.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the SortDirection class.</p> Source code in <code>pyiceberg/table/sorting.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the SortDirection class.\"\"\"\n    return self.name\n</code></pre>"},{"location":"reference/pyiceberg/table/sorting/#pyiceberg.table.sorting.SortField","title":"<code>SortField</code>","text":"<p>             Bases: <code>IcebergBaseModel</code></p> <p>Sort order field.</p> <p>Parameters:</p> Name Type Description Default <code>source_id</code> <code>int</code> <p>Source column id from the table\u2019s schema.</p> <code>None</code> <code>transform</code> <code>str</code> <p>Transform that is used to produce values to be sorted on from the source column.                This is the same transform as described in partition transforms.</p> <code>None</code> <code>direction</code> <code>SortDirection</code> <p>Sort direction, that can only be either asc or desc.</p> <code>None</code> <code>null_order</code> <code>NullOrder</code> <p>Null order that describes the order of null values when sorted. Can only be either nulls-first or nulls-last.</p> <code>None</code> Source code in <code>pyiceberg/table/sorting.py</code> <pre><code>class SortField(IcebergBaseModel):\n    \"\"\"Sort order field.\n\n    Args:\n      source_id (int): Source column id from the table\u2019s schema.\n      transform (str): Transform that is used to produce values to be sorted on from the source column.\n                       This is the same transform as described in partition transforms.\n      direction (SortDirection): Sort direction, that can only be either asc or desc.\n      null_order (NullOrder): Null order that describes the order of null values when sorted. Can only be either nulls-first or nulls-last.\n    \"\"\"\n\n    def __init__(\n        self,\n        source_id: Optional[int] = None,\n        transform: Optional[Union[Transform[Any, Any], Callable[[IcebergType], Transform[Any, Any]]]] = None,\n        direction: Optional[SortDirection] = None,\n        null_order: Optional[NullOrder] = None,\n        **data: Any,\n    ):\n        if source_id is not None:\n            data[\"source-id\"] = source_id\n        if transform is not None:\n            data[\"transform\"] = transform\n        if direction is not None:\n            data[\"direction\"] = direction\n        if null_order is not None:\n            data[\"null-order\"] = null_order\n        super().__init__(**data)\n\n    @model_validator(mode=\"before\")\n    def set_null_order(cls, values: Dict[str, Any]) -&gt; Dict[str, Any]:\n        values[\"direction\"] = values[\"direction\"] if values.get(\"direction\") else SortDirection.ASC\n        if not values.get(\"null-order\"):\n            values[\"null-order\"] = NullOrder.NULLS_FIRST if values[\"direction\"] == SortDirection.ASC else NullOrder.NULLS_LAST\n        return values\n\n    source_id: int = Field(alias=\"source-id\")\n    transform: Annotated[  # type: ignore\n        Transform,\n        BeforeValidator(parse_transform),\n        PlainSerializer(lambda c: str(c), return_type=str),  # pylint: disable=W0108\n        WithJsonSchema({\"type\": \"string\"}, mode=\"serialization\"),\n    ] = Field()\n    direction: SortDirection = Field()\n    null_order: NullOrder = Field(alias=\"null-order\")\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the SortField class.\"\"\"\n        if isinstance(self.transform, IdentityTransform):\n            # In the case of an identity transform, we can omit the transform\n            return f\"{self.source_id} {self.direction} {self.null_order}\"\n        else:\n            return f\"{self.transform}({self.source_id}) {self.direction} {self.null_order}\"\n</code></pre>"},{"location":"reference/pyiceberg/table/sorting/#pyiceberg.table.sorting.SortField.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the SortField class.</p> Source code in <code>pyiceberg/table/sorting.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the SortField class.\"\"\"\n    if isinstance(self.transform, IdentityTransform):\n        # In the case of an identity transform, we can omit the transform\n        return f\"{self.source_id} {self.direction} {self.null_order}\"\n    else:\n        return f\"{self.transform}({self.source_id}) {self.direction} {self.null_order}\"\n</code></pre>"},{"location":"reference/pyiceberg/table/sorting/#pyiceberg.table.sorting.SortOrder","title":"<code>SortOrder</code>","text":"<p>             Bases: <code>IcebergBaseModel</code></p> <p>Describes how the data is sorted within the table.</p> <p>Users can sort their data within partitions by columns to gain performance.</p> <p>The order of the sort fields within the list defines the order in which the sort is applied to the data.</p> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>List[SortField]</code> <p>The fields how the table is sorted.</p> <code>()</code> <p>Other Parameters:</p> Name Type Description <code>order_id</code> <code>int</code> <p>An unique id of the sort-order of a table.</p> Source code in <code>pyiceberg/table/sorting.py</code> <pre><code>class SortOrder(IcebergBaseModel):\n    \"\"\"Describes how the data is sorted within the table.\n\n    Users can sort their data within partitions by columns to gain performance.\n\n    The order of the sort fields within the list defines the order in which the sort is applied to the data.\n\n    Args:\n      fields (List[SortField]): The fields how the table is sorted.\n\n    Keyword Args:\n      order_id (int): An unique id of the sort-order of a table.\n    \"\"\"\n\n    order_id: int = Field(alias=\"order-id\", default=INITIAL_SORT_ORDER_ID)\n    fields: List[SortField] = Field(default_factory=list)\n\n    def __init__(self, *fields: SortField, **data: Any):\n        if fields:\n            data[\"fields\"] = fields\n        super().__init__(**data)\n\n    @property\n    def is_unsorted(self) -&gt; bool:\n        return len(self.fields) == 0\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the string representation of the SortOrder class.\"\"\"\n        result_str = \"[\"\n        if self.fields:\n            result_str += \"\\n  \" + \"\\n  \".join([str(field) for field in self.fields]) + \"\\n\"\n        result_str += \"]\"\n        return result_str\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of the SortOrder class.\"\"\"\n        fields = f\"{', '.join(repr(column) for column in self.fields)}, \" if self.fields else \"\"\n        return f\"SortOrder({fields}order_id={self.order_id})\"\n</code></pre>"},{"location":"reference/pyiceberg/table/sorting/#pyiceberg.table.sorting.SortOrder.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of the SortOrder class.</p> Source code in <code>pyiceberg/table/sorting.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of the SortOrder class.\"\"\"\n    fields = f\"{', '.join(repr(column) for column in self.fields)}, \" if self.fields else \"\"\n    return f\"SortOrder({fields}order_id={self.order_id})\"\n</code></pre>"},{"location":"reference/pyiceberg/table/sorting/#pyiceberg.table.sorting.SortOrder.__str__","title":"<code>__str__()</code>","text":"<p>Return the string representation of the SortOrder class.</p> Source code in <code>pyiceberg/table/sorting.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the string representation of the SortOrder class.\"\"\"\n    result_str = \"[\"\n    if self.fields:\n        result_str += \"\\n  \" + \"\\n  \".join([str(field) for field in self.fields]) + \"\\n\"\n    result_str += \"]\"\n    return result_str\n</code></pre>"},{"location":"reference/pyiceberg/utils/","title":"utils","text":""},{"location":"reference/pyiceberg/utils/bin_packing/","title":"bin_packing","text":""},{"location":"reference/pyiceberg/utils/bin_packing/#pyiceberg.utils.bin_packing.PackingIterator","title":"<code>PackingIterator</code>","text":"<p>             Bases: <code>Generic[T]</code></p> Source code in <code>pyiceberg/utils/bin_packing.py</code> <pre><code>class PackingIterator(Generic[T]):\n    bins: List[Bin[T]]\n\n    def __init__(\n        self,\n        items: Iterable[T],\n        target_weight: int,\n        lookback: int,\n        weight_func: Callable[[T], int],\n        largest_bin_first: bool = False,\n    ) -&gt; None:\n        self.items = iter(items)\n        self.target_weight = target_weight\n        self.lookback = lookback\n        self.weight_func = weight_func\n        self.largest_bin_first = largest_bin_first\n        self.bins = []\n\n    def __iter__(self) -&gt; PackingIterator[T]:\n        \"\"\"Return an iterator for the PackingIterator class.\"\"\"\n        return self\n\n    def __next__(self) -&gt; List[T]:\n        \"\"\"Return the next item when iterating over the PackingIterator class.\"\"\"\n        while True:\n            try:\n                item = next(self.items)\n                weight = self.weight_func(item)\n                bin_ = self.find_bin(weight)\n                if bin_ is not None:\n                    bin_.add(item, weight)\n                else:\n                    bin_ = Bin(self.target_weight)\n                    bin_.add(item, weight)\n                    self.bins.append(bin_)\n\n                    if len(self.bins) &gt; self.lookback:\n                        return self.remove_bin().items\n            except StopIteration:\n                break\n\n        if len(self.bins) == 0:\n            raise StopIteration()\n\n        return self.remove_bin().items\n\n    def find_bin(self, weight: int) -&gt; Optional[Bin[T]]:\n        for bin_ in self.bins:\n            if bin_.can_add(weight):\n                return bin_\n        return None\n\n    def remove_bin(self) -&gt; Bin[T]:\n        if self.largest_bin_first:\n            bin_ = max(self.bins, key=lambda b: b.weight())\n            self.bins.remove(bin_)\n            return bin_\n        else:\n            return self.bins.pop(0)\n</code></pre>"},{"location":"reference/pyiceberg/utils/bin_packing/#pyiceberg.utils.bin_packing.PackingIterator.__iter__","title":"<code>__iter__()</code>","text":"<p>Return an iterator for the PackingIterator class.</p> Source code in <code>pyiceberg/utils/bin_packing.py</code> <pre><code>def __iter__(self) -&gt; PackingIterator[T]:\n    \"\"\"Return an iterator for the PackingIterator class.\"\"\"\n    return self\n</code></pre>"},{"location":"reference/pyiceberg/utils/bin_packing/#pyiceberg.utils.bin_packing.PackingIterator.__next__","title":"<code>__next__()</code>","text":"<p>Return the next item when iterating over the PackingIterator class.</p> Source code in <code>pyiceberg/utils/bin_packing.py</code> <pre><code>def __next__(self) -&gt; List[T]:\n    \"\"\"Return the next item when iterating over the PackingIterator class.\"\"\"\n    while True:\n        try:\n            item = next(self.items)\n            weight = self.weight_func(item)\n            bin_ = self.find_bin(weight)\n            if bin_ is not None:\n                bin_.add(item, weight)\n            else:\n                bin_ = Bin(self.target_weight)\n                bin_.add(item, weight)\n                self.bins.append(bin_)\n\n                if len(self.bins) &gt; self.lookback:\n                    return self.remove_bin().items\n        except StopIteration:\n            break\n\n    if len(self.bins) == 0:\n        raise StopIteration()\n\n    return self.remove_bin().items\n</code></pre>"},{"location":"reference/pyiceberg/utils/concurrent/","title":"concurrent","text":"<p>Concurrency concepts that support efficient multi-threading.</p>"},{"location":"reference/pyiceberg/utils/concurrent/#pyiceberg.utils.concurrent.ExecutorFactory","title":"<code>ExecutorFactory</code>","text":"Source code in <code>pyiceberg/utils/concurrent.py</code> <pre><code>class ExecutorFactory:\n    _instance: Optional[Executor] = None\n\n    @staticmethod\n    def get_or_create() -&gt; Executor:\n        \"\"\"Return the same executor in each call.\"\"\"\n        if ExecutorFactory._instance is None:\n            max_workers = ExecutorFactory.max_workers()\n            ExecutorFactory._instance = ThreadPoolExecutor(max_workers=max_workers)\n\n        return ExecutorFactory._instance\n\n    @staticmethod\n    def max_workers() -&gt; Optional[int]:\n        \"\"\"Return the max number of workers configured.\"\"\"\n        config = Config()\n        val = config.config.get(\"max-workers\")\n\n        if val is None:\n            return None\n\n        try:\n            return int(val)  # type: ignore\n        except ValueError as err:\n            raise ValueError(f\"Max workers should be an integer or left unset. Current value: {val}\") from err\n</code></pre>"},{"location":"reference/pyiceberg/utils/concurrent/#pyiceberg.utils.concurrent.ExecutorFactory.get_or_create","title":"<code>get_or_create()</code>  <code>staticmethod</code>","text":"<p>Return the same executor in each call.</p> Source code in <code>pyiceberg/utils/concurrent.py</code> <pre><code>@staticmethod\ndef get_or_create() -&gt; Executor:\n    \"\"\"Return the same executor in each call.\"\"\"\n    if ExecutorFactory._instance is None:\n        max_workers = ExecutorFactory.max_workers()\n        ExecutorFactory._instance = ThreadPoolExecutor(max_workers=max_workers)\n\n    return ExecutorFactory._instance\n</code></pre>"},{"location":"reference/pyiceberg/utils/concurrent/#pyiceberg.utils.concurrent.ExecutorFactory.max_workers","title":"<code>max_workers()</code>  <code>staticmethod</code>","text":"<p>Return the max number of workers configured.</p> Source code in <code>pyiceberg/utils/concurrent.py</code> <pre><code>@staticmethod\ndef max_workers() -&gt; Optional[int]:\n    \"\"\"Return the max number of workers configured.\"\"\"\n    config = Config()\n    val = config.config.get(\"max-workers\")\n\n    if val is None:\n        return None\n\n    try:\n        return int(val)  # type: ignore\n    except ValueError as err:\n        raise ValueError(f\"Max workers should be an integer or left unset. Current value: {val}\") from err\n</code></pre>"},{"location":"reference/pyiceberg/utils/config/","title":"config","text":""},{"location":"reference/pyiceberg/utils/config/#pyiceberg.utils.config.Config","title":"<code>Config</code>","text":"Source code in <code>pyiceberg/utils/config.py</code> <pre><code>class Config:\n    config: RecursiveDict\n\n    def __init__(self) -&gt; None:\n        config = self._from_configuration_files() or {}\n        config = merge_config(config, self._from_environment_variables(config))\n        self.config = FrozenDict(**config)\n\n    @staticmethod\n    def _from_configuration_files() -&gt; Optional[RecursiveDict]:\n        \"\"\"Load the first configuration file that its finds.\n\n        Will first look in the PYICEBERG_HOME env variable,\n        and then in the home directory.\n        \"\"\"\n\n        def _load_yaml(directory: Optional[str]) -&gt; Optional[RecursiveDict]:\n            if directory:\n                path = os.path.join(directory, PYICEBERG_YML)\n                if os.path.isfile(path):\n                    with open(path, encoding=UTF8) as f:\n                        yml_str = f.read()\n                    file_config = strictyaml.load(yml_str).data\n                    file_config_lowercase = _lowercase_dictionary_keys(file_config)\n                    return file_config_lowercase\n            return None\n\n        # Give priority to the PYICEBERG_HOME directory\n        if pyiceberg_home_config := _load_yaml(os.environ.get(PYICEBERG_HOME)):\n            return pyiceberg_home_config\n        # Look into the home directory\n        if pyiceberg_home_config := _load_yaml(os.path.expanduser(\"~\")):\n            return pyiceberg_home_config\n        # Didn't find a config\n        return None\n\n    @staticmethod\n    def _from_environment_variables(config: RecursiveDict) -&gt; RecursiveDict:\n        \"\"\"Read the environment variables, to check if there are any prepended by PYICEBERG_.\n\n        Args:\n            config: Existing configuration that's being amended with configuration from environment variables.\n\n        Returns:\n            Amended configuration.\n        \"\"\"\n\n        def set_property(_config: RecursiveDict, path: List[str], config_value: str) -&gt; None:\n            while len(path) &gt; 0:\n                element = path.pop(0)\n                if len(path) == 0:\n                    # We're at the end\n                    _config[element] = config_value\n                else:\n                    # We have to go deeper\n                    if element not in _config:\n                        _config[element] = {}\n                    if isinstance(_config[element], dict):\n                        _config = _config[element]  # type: ignore\n                    else:\n                        raise ValueError(\n                            f\"Incompatible configurations, merging dict with a value: {'.'.join(path)}, value: {config_value}\"\n                        )\n\n        for env_var, config_value in os.environ.items():\n            # Make it lowercase to make it case-insensitive\n            env_var_lower = env_var.lower()\n            if env_var_lower.startswith(PYICEBERG.lower()):\n                key = env_var_lower[len(PYICEBERG) :]\n                parts = key.split(\"__\", maxsplit=2)\n                parts_normalized = [part.replace('__', '.').replace(\"_\", \"-\") for part in parts]\n                set_property(config, parts_normalized, config_value)\n\n        return config\n\n    def get_default_catalog_name(self) -&gt; str:\n        \"\"\"Return the default catalog name.\n\n        Returns: The name of the default catalog in `default-catalog`.\n                 Returns `default` when the key cannot be found in the config file.\n        \"\"\"\n        if default_catalog_name := self.config.get(DEFAULT_CATALOG):\n            if not isinstance(default_catalog_name, str):\n                raise ValueError(f\"Default catalog name should be a str: {default_catalog_name}\")\n            return default_catalog_name\n        return DEFAULT\n\n    def get_catalog_config(self, catalog_name: str) -&gt; Optional[RecursiveDict]:\n        if CATALOG in self.config:\n            catalog_name_lower = catalog_name.lower()\n            catalogs = self.config[CATALOG]\n            if not isinstance(catalogs, dict):\n                raise ValueError(f\"Catalog configurations needs to be an object: {catalog_name}\")\n            if catalog_name_lower in catalogs:\n                catalog_conf = catalogs[catalog_name_lower]\n                assert isinstance(catalog_conf, dict), f\"Configuration path catalogs.{catalog_name_lower} needs to be an object\"\n                return catalog_conf\n        return None\n</code></pre>"},{"location":"reference/pyiceberg/utils/config/#pyiceberg.utils.config.Config.get_default_catalog_name","title":"<code>get_default_catalog_name()</code>","text":"<p>Return the default catalog name.</p> <p>The name of the default catalog in `default-catalog`.</p> Type Description <code>str</code> <p>Returns <code>default</code> when the key cannot be found in the config file.</p> Source code in <code>pyiceberg/utils/config.py</code> <pre><code>def get_default_catalog_name(self) -&gt; str:\n    \"\"\"Return the default catalog name.\n\n    Returns: The name of the default catalog in `default-catalog`.\n             Returns `default` when the key cannot be found in the config file.\n    \"\"\"\n    if default_catalog_name := self.config.get(DEFAULT_CATALOG):\n        if not isinstance(default_catalog_name, str):\n            raise ValueError(f\"Default catalog name should be a str: {default_catalog_name}\")\n        return default_catalog_name\n    return DEFAULT\n</code></pre>"},{"location":"reference/pyiceberg/utils/config/#pyiceberg.utils.config.merge_config","title":"<code>merge_config(lhs, rhs)</code>","text":"<p>Merge right-hand side into the left-hand side.</p> Source code in <code>pyiceberg/utils/config.py</code> <pre><code>def merge_config(lhs: RecursiveDict, rhs: RecursiveDict) -&gt; RecursiveDict:\n    \"\"\"Merge right-hand side into the left-hand side.\"\"\"\n    new_config = lhs.copy()\n    for rhs_key, rhs_value in rhs.items():\n        if rhs_key in new_config:\n            lhs_value = new_config[rhs_key]\n            if isinstance(lhs_value, dict) and isinstance(rhs_value, dict):\n                # If they are both dicts, then we have to go deeper\n                new_config[rhs_key] = merge_config(lhs_value, rhs_value)\n            else:\n                # Take the non-null value, with precedence on rhs\n                new_config[rhs_key] = rhs_value or lhs_value\n        else:\n            # New key\n            new_config[rhs_key] = rhs_value\n\n    return new_config\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/","title":"datetime","text":"<p>Helper methods for working with date/time representations.</p>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.date_str_to_days","title":"<code>date_str_to_days(date_str)</code>","text":"<p>Convert an ISO-8601 formatted date to days from 1970-01-01.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def date_str_to_days(date_str: str) -&gt; int:\n    \"\"\"Convert an ISO-8601 formatted date to days from 1970-01-01.\"\"\"\n    return (date.fromisoformat(date_str) - EPOCH_DATE).days\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.date_to_days","title":"<code>date_to_days(date_val)</code>","text":"<p>Convert a Python date object to days from 1970-01-01.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def date_to_days(date_val: date) -&gt; int:\n    \"\"\"Convert a Python date object to days from 1970-01-01.\"\"\"\n    return (date_val - EPOCH_DATE).days\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.datetime_to_micros","title":"<code>datetime_to_micros(dt)</code>","text":"<p>Convert a datetime to microseconds from 1970-01-01T00:00:00.000000.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def datetime_to_micros(dt: datetime) -&gt; int:\n    \"\"\"Convert a datetime to microseconds from 1970-01-01T00:00:00.000000.\"\"\"\n    if dt.tzinfo:\n        delta = dt - EPOCH_TIMESTAMPTZ\n    else:\n        delta = dt - EPOCH_TIMESTAMP\n    return (delta.days * 86400 + delta.seconds) * 1_000_000 + delta.microseconds\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.datetime_to_millis","title":"<code>datetime_to_millis(dt)</code>","text":"<p>Convert a datetime to milliseconds from 1970-01-01T00:00:00.000000.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def datetime_to_millis(dt: datetime) -&gt; int:\n    \"\"\"Convert a datetime to milliseconds from 1970-01-01T00:00:00.000000.\"\"\"\n    if dt.tzinfo:\n        delta = dt - EPOCH_TIMESTAMPTZ\n    else:\n        delta = dt - EPOCH_TIMESTAMP\n    return (delta.days * 86400 + delta.seconds) * 1_000 + delta.microseconds // 1_000\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.days_to_date","title":"<code>days_to_date(days)</code>","text":"<p>Create a date from the number of days from 1970-01-01.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def days_to_date(days: int) -&gt; date:\n    \"\"\"Create a date from the number of days from 1970-01-01.\"\"\"\n    return EPOCH_DATE + timedelta(days)\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.micros_to_days","title":"<code>micros_to_days(timestamp)</code>","text":"<p>Convert a timestamp in microseconds to a date in days.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def micros_to_days(timestamp: int) -&gt; int:\n    \"\"\"Convert a timestamp in microseconds to a date in days.\"\"\"\n    return timedelta(microseconds=timestamp).days\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.micros_to_hours","title":"<code>micros_to_hours(micros)</code>","text":"<p>Convert a timestamp in microseconds to hours from 1970-01-01T00:00.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def micros_to_hours(micros: int) -&gt; int:\n    \"\"\"Convert a timestamp in microseconds to hours from 1970-01-01T00:00.\"\"\"\n    return micros // 3_600_000_000\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.micros_to_time","title":"<code>micros_to_time(micros)</code>","text":"<p>Convert a timestamp in microseconds to a time.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def micros_to_time(micros: int) -&gt; time:\n    \"\"\"Convert a timestamp in microseconds to a time.\"\"\"\n    micros, microseconds = divmod(micros, 1000000)\n    micros, seconds = divmod(micros, 60)\n    micros, minutes = divmod(micros, 60)\n    hours = micros\n    return time(hour=hours, minute=minutes, second=seconds, microsecond=microseconds)\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.micros_to_timestamp","title":"<code>micros_to_timestamp(micros)</code>","text":"<p>Convert microseconds from epoch to a timestamp.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def micros_to_timestamp(micros: int) -&gt; datetime:\n    \"\"\"Convert microseconds from epoch to a timestamp.\"\"\"\n    dt = timedelta(microseconds=micros)\n    return EPOCH_TIMESTAMP + dt\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.micros_to_timestamptz","title":"<code>micros_to_timestamptz(micros)</code>","text":"<p>Convert microseconds from epoch to an utc timestamp.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def micros_to_timestamptz(micros: int) -&gt; datetime:\n    \"\"\"Convert microseconds from epoch to an utc timestamp.\"\"\"\n    dt = timedelta(microseconds=micros)\n    return EPOCH_TIMESTAMPTZ + dt\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.millis_to_datetime","title":"<code>millis_to_datetime(millis)</code>","text":"<p>Convert milliseconds from epoch to a timestamp.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def millis_to_datetime(millis: int) -&gt; datetime:\n    \"\"\"Convert milliseconds from epoch to a timestamp.\"\"\"\n    dt = timedelta(milliseconds=millis)\n    return EPOCH_TIMESTAMP + dt\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.time_str_to_micros","title":"<code>time_str_to_micros(time_str)</code>","text":"<p>Convert an ISO-8601 formatted time to microseconds from midnight.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def time_str_to_micros(time_str: str) -&gt; int:\n    \"\"\"Convert an ISO-8601 formatted time to microseconds from midnight.\"\"\"\n    return time_to_micros(time.fromisoformat(time_str))\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.time_to_micros","title":"<code>time_to_micros(t)</code>","text":"<p>Convert a datetime.time object to microseconds from midnight.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def time_to_micros(t: time) -&gt; int:\n    \"\"\"Convert a datetime.time object to microseconds from midnight.\"\"\"\n    return (((t.hour * 60 + t.minute) * 60) + t.second) * 1_000_000 + t.microsecond\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.timestamp_to_micros","title":"<code>timestamp_to_micros(timestamp_str)</code>","text":"<p>Convert an ISO-9601 formatted timestamp without zone to microseconds from 1970-01-01T00:00:00.000000.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def timestamp_to_micros(timestamp_str: str) -&gt; int:\n    \"\"\"Convert an ISO-9601 formatted timestamp without zone to microseconds from 1970-01-01T00:00:00.000000.\"\"\"\n    if ISO_TIMESTAMP.fullmatch(timestamp_str):\n        return datetime_to_micros(datetime.fromisoformat(timestamp_str))\n    if ISO_TIMESTAMPTZ.fullmatch(timestamp_str):\n        # When we can match a timestamp without a zone, we can give a more specific error\n        raise ValueError(f\"Zone offset provided, but not expected: {timestamp_str}\")\n    raise ValueError(f\"Invalid timestamp without zone: {timestamp_str} (must be ISO-8601)\")\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.timestamptz_to_micros","title":"<code>timestamptz_to_micros(timestamptz_str)</code>","text":"<p>Convert an ISO-8601 formatted timestamp with zone to microseconds from 1970-01-01T00:00:00.000000+00:00.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def timestamptz_to_micros(timestamptz_str: str) -&gt; int:\n    \"\"\"Convert an ISO-8601 formatted timestamp with zone to microseconds from 1970-01-01T00:00:00.000000+00:00.\"\"\"\n    if ISO_TIMESTAMPTZ.fullmatch(timestamptz_str):\n        return datetime_to_micros(datetime.fromisoformat(timestamptz_str))\n    if ISO_TIMESTAMP.fullmatch(timestamptz_str):\n        # When we can match a timestamp without a zone, we can give a more specific error\n        raise ValueError(f\"Missing zone offset: {timestamptz_str} (must be ISO-8601)\")\n    raise ValueError(f\"Invalid timestamp with zone: {timestamptz_str} (must be ISO-8601)\")\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.to_human_day","title":"<code>to_human_day(day_ordinal)</code>","text":"<p>Convert a DateType value to human string.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def to_human_day(day_ordinal: int) -&gt; str:\n    \"\"\"Convert a DateType value to human string.\"\"\"\n    return (EPOCH_DATE + timedelta(days=day_ordinal)).isoformat()\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.to_human_hour","title":"<code>to_human_hour(hour_ordinal)</code>","text":"<p>Convert a DateType value to human string.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def to_human_hour(hour_ordinal: int) -&gt; str:\n    \"\"\"Convert a DateType value to human string.\"\"\"\n    return (EPOCH_TIMESTAMP + timedelta(hours=hour_ordinal)).isoformat(\"-\", \"hours\")\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.to_human_month","title":"<code>to_human_month(month_ordinal)</code>","text":"<p>Convert a DateType value to human string.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def to_human_month(month_ordinal: int) -&gt; str:\n    \"\"\"Convert a DateType value to human string.\"\"\"\n    return f\"{EPOCH_TIMESTAMP.year + month_ordinal // 12:0=4d}-{1 + month_ordinal % 12:0=2d}\"\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.to_human_time","title":"<code>to_human_time(micros_from_midnight)</code>","text":"<p>Convert a TimeType value to human string.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def to_human_time(micros_from_midnight: int) -&gt; str:\n    \"\"\"Convert a TimeType value to human string.\"\"\"\n    return micros_to_time(micros_from_midnight).isoformat()\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.to_human_timestamp","title":"<code>to_human_timestamp(timestamp_micros)</code>","text":"<p>Convert a TimestampType value to human string.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def to_human_timestamp(timestamp_micros: int) -&gt; str:\n    \"\"\"Convert a TimestampType value to human string.\"\"\"\n    return (EPOCH_TIMESTAMP + timedelta(microseconds=timestamp_micros)).isoformat()\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.to_human_timestamptz","title":"<code>to_human_timestamptz(timestamp_micros)</code>","text":"<p>Convert a TimestamptzType value to human string.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def to_human_timestamptz(timestamp_micros: int) -&gt; str:\n    \"\"\"Convert a TimestamptzType value to human string.\"\"\"\n    return (EPOCH_TIMESTAMPTZ + timedelta(microseconds=timestamp_micros)).isoformat()\n</code></pre>"},{"location":"reference/pyiceberg/utils/datetime/#pyiceberg.utils.datetime.to_human_year","title":"<code>to_human_year(year_ordinal)</code>","text":"<p>Convert a DateType value to human string.</p> Source code in <code>pyiceberg/utils/datetime.py</code> <pre><code>def to_human_year(year_ordinal: int) -&gt; str:\n    \"\"\"Convert a DateType value to human string.\"\"\"\n    return f\"{EPOCH_TIMESTAMP.year + year_ordinal:0=4d}\"\n</code></pre>"},{"location":"reference/pyiceberg/utils/decimal/","title":"decimal","text":"<p>Helper methods for working with Python Decimals.</p>"},{"location":"reference/pyiceberg/utils/decimal/#pyiceberg.utils.decimal.bytes_required","title":"<code>bytes_required(value)</code>","text":"<p>Return the minimum number of bytes needed to serialize a decimal or unscaled value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int | Decimal</code> <p>a Decimal value or unscaled int value.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>the minimum number of bytes needed to serialize the value.</p> Source code in <code>pyiceberg/utils/decimal.py</code> <pre><code>def bytes_required(value: Union[int, Decimal]) -&gt; int:\n    \"\"\"Return the minimum number of bytes needed to serialize a decimal or unscaled value.\n\n    Args:\n        value (int | Decimal): a Decimal value or unscaled int value.\n\n    Returns:\n        int: the minimum number of bytes needed to serialize the value.\n    \"\"\"\n    if isinstance(value, int):\n        return (value.bit_length() + 7) // 8\n    elif isinstance(value, Decimal):\n        return (decimal_to_unscaled(value).bit_length() + 7) // 8\n\n    raise ValueError(f\"Unsupported value: {value}\")\n</code></pre>"},{"location":"reference/pyiceberg/utils/decimal/#pyiceberg.utils.decimal.bytes_to_decimal","title":"<code>bytes_to_decimal(value, scale)</code>","text":"<p>Return a decimal from the bytes.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bytes</code> <p>tbe bytes to be converted into a decimal.</p> required <code>scale</code> <code>int</code> <p>the scale of the decimal.</p> required <p>Returns:</p> Name Type Description <code>Decimal</code> <code>Decimal</code> <p>the scaled decimal.</p> Source code in <code>pyiceberg/utils/decimal.py</code> <pre><code>def bytes_to_decimal(value: bytes, scale: int) -&gt; Decimal:\n    \"\"\"Return a decimal from the bytes.\n\n    Args:\n        value (bytes): tbe bytes to be converted into a decimal.\n        scale (int): the scale of the decimal.\n\n    Returns:\n        Decimal: the scaled decimal.\n    \"\"\"\n    unscaled_datum = int.from_bytes(value, byteorder=\"big\", signed=True)\n    return unscaled_to_decimal(unscaled_datum, scale)\n</code></pre>"},{"location":"reference/pyiceberg/utils/decimal/#pyiceberg.utils.decimal.decimal_required_bytes","title":"<code>decimal_required_bytes(precision)</code>","text":"<p>Compute the number of bytes required to store a precision.</p> <p>Parameters:</p> Name Type Description Default <code>precision</code> <code>int</code> <p>The number of digits to store.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The number of bytes required to store a decimal with a certain precision.</p> Source code in <code>pyiceberg/utils/decimal.py</code> <pre><code>def decimal_required_bytes(precision: int) -&gt; int:\n    \"\"\"Compute the number of bytes required to store a precision.\n\n    Args:\n        precision: The number of digits to store.\n\n    Returns:\n        The number of bytes required to store a decimal with a certain precision.\n    \"\"\"\n    if precision &lt;= 0 or precision &gt;= 40:\n        raise ValueError(f\"Unsupported precision, outside of (0, 40]: {precision}\")\n\n    return REQUIRED_LENGTH[precision]\n</code></pre>"},{"location":"reference/pyiceberg/utils/decimal/#pyiceberg.utils.decimal.decimal_to_bytes","title":"<code>decimal_to_bytes(value, byte_length=None)</code>","text":"<p>Return a byte representation of a decimal.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Decimal</code> <p>a decimal value.</p> required <code>byte_length</code> <code>int</code> <p>The number of bytes.</p> <code>None</code> <p>Returns:     bytes: the unscaled value of the Decimal as bytes.</p> Source code in <code>pyiceberg/utils/decimal.py</code> <pre><code>def decimal_to_bytes(value: Decimal, byte_length: Optional[int] = None) -&gt; bytes:\n    \"\"\"Return a byte representation of a decimal.\n\n    Args:\n        value (Decimal): a decimal value.\n        byte_length (int): The number of bytes.\n    Returns:\n        bytes: the unscaled value of the Decimal as bytes.\n    \"\"\"\n    unscaled_value = decimal_to_unscaled(value)\n    if byte_length is None:\n        byte_length = bytes_required(unscaled_value)\n    return unscaled_value.to_bytes(byte_length, byteorder=\"big\", signed=True)\n</code></pre>"},{"location":"reference/pyiceberg/utils/decimal/#pyiceberg.utils.decimal.decimal_to_unscaled","title":"<code>decimal_to_unscaled(value)</code>","text":"<p>Get an unscaled value given a Decimal value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Decimal</code> <p>A Decimal instance.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The unscaled value.</p> Source code in <code>pyiceberg/utils/decimal.py</code> <pre><code>def decimal_to_unscaled(value: Decimal) -&gt; int:\n    \"\"\"Get an unscaled value given a Decimal value.\n\n    Args:\n        value (Decimal): A Decimal instance.\n\n    Returns:\n        int: The unscaled value.\n    \"\"\"\n    sign, digits, _ = value.as_tuple()\n    return int(Decimal((sign, digits, 0)).to_integral_value())\n</code></pre>"},{"location":"reference/pyiceberg/utils/decimal/#pyiceberg.utils.decimal.truncate_decimal","title":"<code>truncate_decimal(value, width)</code>","text":"<p>Get a truncated Decimal value given a decimal value and a width.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Decimal</code> <p>a decimal value.</p> required <code>width</code> <code>int</code> <p>A width for the returned Decimal instance.</p> required <p>Returns:     Decimal: A truncated Decimal instance.</p> Source code in <code>pyiceberg/utils/decimal.py</code> <pre><code>def truncate_decimal(value: Decimal, width: int) -&gt; Decimal:\n    \"\"\"Get a truncated Decimal value given a decimal value and a width.\n\n    Args:\n        value (Decimal): a decimal value.\n        width (int): A width for the returned Decimal instance.\n    Returns:\n        Decimal: A truncated Decimal instance.\n    \"\"\"\n    unscaled_value = decimal_to_unscaled(value)\n    applied_value = unscaled_value - (((unscaled_value % width) + width) % width)\n    return unscaled_to_decimal(applied_value, abs(int(value.as_tuple().exponent)))\n</code></pre>"},{"location":"reference/pyiceberg/utils/decimal/#pyiceberg.utils.decimal.unscaled_to_decimal","title":"<code>unscaled_to_decimal(unscaled, scale)</code>","text":"<p>Get a scaled Decimal value given an unscaled value and a scale.</p> <p>Parameters:</p> Name Type Description Default <code>unscaled</code> <code>int</code> <p>An unscaled value.</p> required <code>scale</code> <code>int</code> <p>A scale to set for the returned Decimal instance.</p> required <p>Returns:</p> Name Type Description <code>Decimal</code> <code>Decimal</code> <p>A scaled Decimal instance.</p> Source code in <code>pyiceberg/utils/decimal.py</code> <pre><code>def unscaled_to_decimal(unscaled: int, scale: int) -&gt; Decimal:\n    \"\"\"Get a scaled Decimal value given an unscaled value and a scale.\n\n    Args:\n        unscaled (int): An unscaled value.\n        scale (int): A scale to set for the returned Decimal instance.\n\n    Returns:\n        Decimal: A scaled Decimal instance.\n    \"\"\"\n    sign, digits, _ = Decimal(unscaled).as_tuple()\n    return Decimal((sign, digits, -scale))\n</code></pre>"},{"location":"reference/pyiceberg/utils/deprecated/","title":"deprecated","text":""},{"location":"reference/pyiceberg/utils/deprecated/#pyiceberg.utils.deprecated.deprecated","title":"<code>deprecated(deprecated_in, removed_in, help_message=None)</code>","text":"<p>Mark functions as deprecated.</p> <p>Adding this will result in a warning being emitted when the function is used.</p> Source code in <code>pyiceberg/utils/deprecated.py</code> <pre><code>def deprecated(deprecated_in: str, removed_in: str, help_message: Optional[str] = None) -&gt; Callable:  # type: ignore\n    \"\"\"Mark functions as deprecated.\n\n    Adding this will result in a warning being emitted when the function is used.\n    \"\"\"\n    if help_message is not None:\n        help_message = f\" {help_message}.\"\n\n    def decorator(func: Callable):  # type: ignore\n        @functools.wraps(func)\n        def new_func(*args: Any, **kwargs: Any) -&gt; Any:\n            warnings.simplefilter(\"always\", DeprecationWarning)  # turn off filter\n\n            warnings.warn(\n                f\"Call to {func.__name__}, deprecated in {deprecated_in}, will be removed in {removed_in}.{help_message}\",\n                category=DeprecationWarning,\n                stacklevel=2,\n            )\n            warnings.simplefilter(\"default\", DeprecationWarning)  # reset filter\n            return func(*args, **kwargs)\n\n        return new_func\n\n    return decorator\n</code></pre>"},{"location":"reference/pyiceberg/utils/lazydict/","title":"lazydict","text":""},{"location":"reference/pyiceberg/utils/lazydict/#pyiceberg.utils.lazydict.LazyDict","title":"<code>LazyDict</code>","text":"<p>             Bases: <code>Mapping[K, V]</code></p> <p>Lazily build a dictionary from an array of items.</p> Source code in <code>pyiceberg/utils/lazydict.py</code> <pre><code>class LazyDict(Mapping[K, V]):\n    \"\"\"Lazily build a dictionary from an array of items.\"\"\"\n\n    __slots__ = (\"_contents\", \"_dict\")\n\n    # Since Python's type system is not powerful enough to express the type of the\n    # contents of the dictionary, we use specify the type as a sequence of either K or V\n    # values.\n    #\n    # Rather than spending the runtime cost of checking the type of each item, we presume\n    # that the developer has correctly used the class and that the contents are valid.\n    def __init__(self, contents: Sequence[Sequence[Union[K, V]]]):\n        self._contents = contents\n        self._dict: Optional[Dict[K, V]] = None\n\n    def _build_dict(self) -&gt; Dict[K, V]:\n        self._dict = {}\n        for item in self._contents:\n            self._dict.update(dict(zip(cast(Sequence[K], item[::2]), cast(Sequence[V], item[1::2]))))\n\n        return self._dict\n\n    def __getitem__(self, key: K, /) -&gt; V:\n        \"\"\"Return the value for the given key.\"\"\"\n        source = self._dict or self._build_dict()\n        return source[key]\n\n    def __iter__(self) -&gt; Iterator[K]:\n        \"\"\"Return an iterator over the keys of the dictionary.\"\"\"\n        source = self._dict or self._build_dict()\n        return iter(source)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of items in the dictionary.\"\"\"\n        source = self._dict or self._build_dict()\n        return len(source)\n</code></pre>"},{"location":"reference/pyiceberg/utils/lazydict/#pyiceberg.utils.lazydict.LazyDict.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Return the value for the given key.</p> Source code in <code>pyiceberg/utils/lazydict.py</code> <pre><code>def __getitem__(self, key: K, /) -&gt; V:\n    \"\"\"Return the value for the given key.\"\"\"\n    source = self._dict or self._build_dict()\n    return source[key]\n</code></pre>"},{"location":"reference/pyiceberg/utils/lazydict/#pyiceberg.utils.lazydict.LazyDict.__iter__","title":"<code>__iter__()</code>","text":"<p>Return an iterator over the keys of the dictionary.</p> Source code in <code>pyiceberg/utils/lazydict.py</code> <pre><code>def __iter__(self) -&gt; Iterator[K]:\n    \"\"\"Return an iterator over the keys of the dictionary.\"\"\"\n    source = self._dict or self._build_dict()\n    return iter(source)\n</code></pre>"},{"location":"reference/pyiceberg/utils/lazydict/#pyiceberg.utils.lazydict.LazyDict.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of items in the dictionary.</p> Source code in <code>pyiceberg/utils/lazydict.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of items in the dictionary.\"\"\"\n    source = self._dict or self._build_dict()\n    return len(source)\n</code></pre>"},{"location":"reference/pyiceberg/utils/parsing/","title":"parsing","text":""},{"location":"reference/pyiceberg/utils/parsing/#pyiceberg.utils.parsing.ParseNumberFromBrackets","title":"<code>ParseNumberFromBrackets</code>","text":"<p>Extracts the size from a string in the form of prefix[22].</p> Source code in <code>pyiceberg/utils/parsing.py</code> <pre><code>class ParseNumberFromBrackets:\n    \"\"\"Extracts the size from a string in the form of prefix[22].\"\"\"\n\n    regex: Pattern  # type: ignore\n    prefix: str\n\n    def __init__(self, prefix: str):\n        self.prefix = prefix\n        self.regex = re.compile(rf\"{prefix}\\[(\\d+)\\]\")\n\n    def match(self, str_repr: str) -&gt; int:\n        matches = self.regex.search(str_repr)\n        if matches:\n            return int(matches.group(1))\n        raise ValidationError(f\"Could not match {str_repr}, expected format {self.prefix}[22]\")\n</code></pre>"},{"location":"reference/pyiceberg/utils/schema_conversion/","title":"schema_conversion","text":"<p>Utility class for converting between Avro and Iceberg schemas.</p>"},{"location":"reference/pyiceberg/utils/schema_conversion/#pyiceberg.utils.schema_conversion.AvroSchemaConversion","title":"<code>AvroSchemaConversion</code>","text":"Source code in <code>pyiceberg/utils/schema_conversion.py</code> <pre><code>class AvroSchemaConversion:\n    def avro_to_iceberg(self, avro_schema: Dict[str, Any]) -&gt; Schema:\n        \"\"\"Convert an Apache Avro into an Apache Iceberg schema equivalent.\n\n        This expects to have field id's to be encoded in the Avro schema:\n\n            {\n                \"type\": \"record\",\n                \"name\": \"manifest_file\",\n                \"fields\": [\n                    {\"name\": \"manifest_path\", \"type\": \"string\", \"doc\": \"Location URI with FS scheme\", \"field-id\": 500},\n                    {\"name\": \"manifest_length\", \"type\": \"long\", \"doc\": \"Total file size in bytes\", \"field-id\": 501}\n                ]\n            }\n\n        Example:\n            This converts an Avro schema into an Iceberg schema:\n\n            &gt;&gt;&gt; avro_schema = AvroSchemaConversion().avro_to_iceberg({\n            ...     \"type\": \"record\",\n            ...     \"name\": \"manifest_file\",\n            ...     \"fields\": [\n            ...         {\"name\": \"manifest_path\", \"type\": \"string\", \"doc\": \"Location URI with FS scheme\", \"field-id\": 500},\n            ...         {\"name\": \"manifest_length\", \"type\": \"long\", \"doc\": \"Total file size in bytes\", \"field-id\": 501}\n            ...     ]\n            ... })\n            &gt;&gt;&gt; iceberg_schema = Schema(\n            ...     NestedField(\n            ...         field_id=500, name=\"manifest_path\", field_type=StringType(), required=False, doc=\"Location URI with FS scheme\"\n            ...     ),\n            ...     NestedField(\n            ...         field_id=501, name=\"manifest_length\", field_type=LongType(), required=False, doc=\"Total file size in bytes\"\n            ...     ),\n            ...     schema_id=1\n            ... )\n            &gt;&gt;&gt; avro_schema == iceberg_schema\n            True\n\n        Args:\n            avro_schema (Dict[str, Any]): The JSON decoded Avro schema.\n\n        Returns:\n            Equivalent Iceberg schema.\n        \"\"\"\n        return Schema(*[self._convert_field(field) for field in avro_schema[\"fields\"]], schema_id=1)\n\n    def iceberg_to_avro(self, schema: Schema, schema_name: Optional[str] = None) -&gt; AvroType:\n        \"\"\"Convert an Iceberg schema into an Avro dictionary that can be serialized to JSON.\"\"\"\n        return visit(schema, ConvertSchemaToAvro(schema_name))\n\n    def _resolve_union(\n        self, type_union: Union[Dict[str, str], List[Union[str, Dict[str, str]]], str]\n    ) -&gt; Tuple[Union[str, Dict[str, Any]], bool]:\n        \"\"\"\n        Convert Unions into their type and resolves if the field is required.\n\n        Examples:\n            &gt;&gt;&gt; AvroSchemaConversion()._resolve_union('str')\n            ('str', True)\n            &gt;&gt;&gt; AvroSchemaConversion()._resolve_union(['null', 'str'])\n            ('str', False)\n            &gt;&gt;&gt; AvroSchemaConversion()._resolve_union([{'type': 'str'}])\n            ({'type': 'str'}, True)\n            &gt;&gt;&gt; AvroSchemaConversion()._resolve_union(['null', {'type': 'str'}])\n            ({'type': 'str'}, False)\n\n        Args:\n            type_union: The field, can be a string 'str', list ['null', 'str'], or dict {\"type\": 'str'}.\n\n        Returns:\n            A tuple containing the type and if required.\n\n        Raises:\n            TypeError: In the case non-optional union types are encountered.\n        \"\"\"\n        avro_types: Union[Dict[str, str], List[Union[Dict[str, str], str]]]\n        if isinstance(type_union, str):\n            # It is a primitive and required\n            return type_union, True\n        elif isinstance(type_union, dict):\n            # It is a context and required\n            return type_union, True\n        else:\n            avro_types = type_union\n\n        if len(avro_types) &gt; 2:\n            raise TypeError(f\"Non-optional types aren't part of the Iceberg specification: {avro_types}\")\n\n        # For the Iceberg spec it is required to set the default value to null\n        # From https://iceberg.apache.org/spec/#avro\n        # Optional fields must always set the Avro field default value to null.\n        #\n        # This means that null has to come first:\n        # https://avro.apache.org/docs/current/spec.html\n        # type of the default value must match the first element of the union.\n        if \"null\" != avro_types[0]:\n            raise TypeError(\"Only null-unions are supported\")\n\n        # Filter the null value and return the type\n        return list(filter(lambda t: t != \"null\", avro_types))[0], False\n\n    def _convert_schema(self, avro_type: Union[str, Dict[str, Any]]) -&gt; IcebergType:\n        \"\"\"\n        Resolve the Avro type.\n\n        Args:\n            avro_type: The Avro type, can be simple or complex.\n\n        Returns:\n            The equivalent IcebergType.\n\n        Raises:\n            ValueError: When there are unknown types\n        \"\"\"\n        if isinstance(avro_type, str) and avro_type in PRIMITIVE_FIELD_TYPE_MAPPING:\n            return PRIMITIVE_FIELD_TYPE_MAPPING[avro_type]\n        elif isinstance(avro_type, dict):\n            if \"logicalType\" in avro_type:\n                return self._convert_logical_type(avro_type)\n            else:\n                # Resolve potential nested types\n                while \"type\" in avro_type and isinstance(avro_type[\"type\"], dict):\n                    avro_type = avro_type[\"type\"]\n                type_identifier = avro_type[\"type\"]\n                if type_identifier == \"record\":\n                    return self._convert_record_type(avro_type)\n                elif type_identifier == \"array\":\n                    return self._convert_array_type(avro_type)\n                elif type_identifier == \"map\":\n                    return self._convert_map_type(avro_type)\n                elif type_identifier == \"fixed\":\n                    return self._convert_fixed_type(avro_type)\n                elif isinstance(type_identifier, str) and type_identifier in PRIMITIVE_FIELD_TYPE_MAPPING:\n                    return PRIMITIVE_FIELD_TYPE_MAPPING[type_identifier]\n                else:\n                    raise TypeError(f\"Unknown type: {avro_type}\")\n        else:\n            raise TypeError(f\"Unknown type: {avro_type}\")\n\n    def _convert_field(self, field: Dict[str, Any]) -&gt; NestedField:\n        \"\"\"Convert an Avro field into an Iceberg equivalent field.\n\n        Args:\n            field: The Avro field.\n\n        Returns:\n            The Iceberg equivalent field.\n        \"\"\"\n        if \"field-id\" not in field:\n            raise ValueError(f\"Cannot convert field, missing field-id: {field}\")\n\n        plain_type, required = self._resolve_union(field[\"type\"])\n\n        return NestedField(\n            field_id=field[\"field-id\"],\n            name=field[\"name\"],\n            field_type=self._convert_schema(plain_type),\n            required=required,\n            doc=field.get(\"doc\"),\n        )\n\n    def _convert_record_type(self, record_type: Dict[str, Any]) -&gt; StructType:\n        \"\"\"\n        Convert the fields from a record into an Iceberg struct.\n\n        Examples:\n            &gt;&gt;&gt; from pyiceberg.utils.schema_conversion import AvroSchemaConversion\n            &gt;&gt;&gt; record_type = {\n            ...     \"type\": \"record\",\n            ...     \"name\": \"r508\",\n            ...     \"fields\": [{\n            ...         \"name\": \"contains_null\",\n            ...         \"type\": \"boolean\",\n            ...         \"doc\": \"True if any file has a null partition value\",\n            ...         \"field-id\": 509,\n            ...      }, {\n            ...          \"name\": \"contains_nan\",\n            ...          \"type\": [\"null\", \"boolean\"],\n            ...          \"doc\": \"True if any file has a nan partition value\",\n            ...          \"default\": None,\n            ...          \"field-id\": 518,\n            ...      }],\n            ... }\n            &gt;&gt;&gt; actual = AvroSchemaConversion()._convert_record_type(record_type)\n            &gt;&gt;&gt; expected = StructType(\n            ...     fields=(\n            ...         NestedField(\n            ...             field_id=509,\n            ...             name=\"contains_null\",\n            ...             field_type=BooleanType(),\n            ...             required=False,\n            ...             doc=\"True if any file has a null partition value\",\n            ...         ),\n            ...         NestedField(\n            ...             field_id=518,\n            ...             name=\"contains_nan\",\n            ...             field_type=BooleanType(),\n            ...             required=True,\n            ...             doc=\"True if any file has a nan partition value\",\n            ...         ),\n            ...     )\n            ... )\n            &gt;&gt;&gt; expected == actual\n            True\n\n        Args:\n            record_type: The record type itself.\n\n        Returns: A StructType.\n        \"\"\"\n        if record_type[\"type\"] != \"record\":\n            raise ValueError(f\"Expected record type, got: {record_type}\")\n\n        return StructType(*[self._convert_field(field) for field in record_type[\"fields\"]])\n\n    def _convert_array_type(self, array_type: Dict[str, Any]) -&gt; ListType:\n        if \"element-id\" not in array_type:\n            raise ValueError(f\"Cannot convert array-type, missing element-id: {array_type}\")\n\n        plain_type, element_required = self._resolve_union(array_type[\"items\"])\n\n        return ListType(\n            element_id=array_type[\"element-id\"],\n            element_type=self._convert_schema(plain_type),\n            element_required=element_required,\n        )\n\n    def _convert_map_type(self, map_type: Dict[str, Any]) -&gt; MapType:\n        \"\"\"Convert an avro map type into an Iceberg MapType.\n\n        Args:\n            map_type: The dict that describes the Avro map type.\n\n        Examples:\n            &gt;&gt;&gt; from pyiceberg.utils.schema_conversion import AvroSchemaConversion\n            &gt;&gt;&gt; avro_field = {\n            ...     \"type\": \"map\",\n            ...     \"values\": [\"null\", \"long\"],\n            ...     \"key-id\": 101,\n            ...     \"value-id\": 102,\n            ... }\n            &gt;&gt;&gt; actual = AvroSchemaConversion()._convert_map_type(avro_field)\n            &gt;&gt;&gt; expected = MapType(\n            ...     key_id=101,\n            ...     key_type=StringType(),\n            ...     value_id=102,\n            ...     value_type=LongType(),\n            ...     value_required=True\n            ... )\n            &gt;&gt;&gt; actual == expected\n            True\n\n        Returns: A MapType.\n        \"\"\"\n        value_type, value_required = self._resolve_union(map_type[\"values\"])\n        return MapType(\n            key_id=map_type[\"key-id\"],\n            # Avro only supports string keys\n            key_type=StringType(),\n            value_id=map_type[\"value-id\"],\n            value_type=self._convert_schema(value_type),\n            value_required=value_required,\n        )\n\n    def _convert_logical_type(self, avro_logical_type: Dict[str, Any]) -&gt; IcebergType:\n        \"\"\"Convert a schema with a logical type annotation into an IcebergType.\n\n        For the decimal and map we need to fetch more keys from the dict, and for\n        the simple ones we can just look it up in the mapping.\n\n        Examples:\n            &gt;&gt;&gt; from pyiceberg.utils.schema_conversion import AvroSchemaConversion\n            &gt;&gt;&gt; avro_logical_type = {\n            ...     \"type\": \"int\",\n            ...     \"logicalType\": \"date\"\n            ... }\n            &gt;&gt;&gt; actual = AvroSchemaConversion()._convert_logical_type(avro_logical_type)\n            &gt;&gt;&gt; actual == DateType()\n            True\n\n        Args:\n            avro_logical_type: The logical type.\n\n        Returns:\n            The converted logical type.\n\n        Raises:\n            ValueError: When the logical type is unknown.\n        \"\"\"\n        logical_type = avro_logical_type[\"logicalType\"]\n        physical_type = avro_logical_type[\"type\"]\n        if logical_type == \"decimal\":\n            return self._convert_logical_decimal_type(avro_logical_type)\n        elif logical_type == \"map\":\n            return self._convert_logical_map_type(avro_logical_type)\n        elif logical_type == \"timestamp-micros\":\n            if avro_logical_type.get(\"adjust-to-utc\", False) is True:\n                return TimestamptzType()\n            else:\n                return TimestampType()\n        elif (logical_type, physical_type) in LOGICAL_FIELD_TYPE_MAPPING:\n            return LOGICAL_FIELD_TYPE_MAPPING[(logical_type, physical_type)]\n        else:\n            raise ValueError(f\"Unknown logical/physical type combination: {avro_logical_type}\")\n\n    def _convert_logical_decimal_type(self, avro_type: Dict[str, Any]) -&gt; DecimalType:\n        \"\"\"Convert an avro type to an Iceberg DecimalType.\n\n        Args:\n            avro_type: The Avro type.\n\n        Examples:\n            &gt;&gt;&gt; from pyiceberg.utils.schema_conversion import AvroSchemaConversion\n            &gt;&gt;&gt; avro_decimal_type = {\n            ...     \"type\": \"bytes\",\n            ...     \"logicalType\": \"decimal\",\n            ...     \"precision\": 19,\n            ...     \"scale\": 25\n            ... }\n            &gt;&gt;&gt; actual = AvroSchemaConversion()._convert_logical_decimal_type(avro_decimal_type)\n            &gt;&gt;&gt; expected = DecimalType(\n            ...     precision=19,\n            ...     scale=25\n            ... )\n            &gt;&gt;&gt; actual == expected\n            True\n\n        Returns:\n            A Iceberg DecimalType.\n        \"\"\"\n        return DecimalType(precision=avro_type[\"precision\"], scale=avro_type[\"scale\"])\n\n    def _convert_logical_map_type(self, avro_type: Dict[str, Any]) -&gt; MapType:\n        \"\"\"Convert an avro map type to an Iceberg MapType.\n\n        In the case where a map hasn't a key as a type you can use a logical map to still encode this in Avro.\n\n        Args:\n            avro_type: The Avro Type.\n\n        Examples:\n            &gt;&gt;&gt; from pyiceberg.utils.schema_conversion import AvroSchemaConversion\n            &gt;&gt;&gt; avro_type = {\n            ...     \"type\": \"array\",\n            ...     \"logicalType\": \"map\",\n            ...     \"items\": {\n            ...         \"type\": \"record\",\n            ...         \"name\": \"k101_v102\",\n            ...         \"fields\": [\n            ...             {\"name\": \"key\", \"type\": \"int\", \"field-id\": 101},\n            ...             {\"name\": \"value\", \"type\": \"string\", \"field-id\": 102},\n            ...         ],\n            ...     },\n            ... }\n            &gt;&gt;&gt; actual = AvroSchemaConversion()._convert_logical_map_type(avro_type)\n            &gt;&gt;&gt; expected = MapType(\n            ...         key_id=101,\n            ...         key_type=IntegerType(),\n            ...         value_id=102,\n            ...         value_type=StringType(),\n            ...         value_required=False\n            ... )\n            &gt;&gt;&gt; actual == expected\n            True\n\n        .. _Apache Iceberg specification:\n            https://iceberg.apache.org/spec/#appendix-a-format-specific-requirements\n\n        Returns:\n            The logical map.\n        \"\"\"\n        fields = avro_type[\"items\"][\"fields\"]\n        if len(fields) != 2:\n            raise ValueError(f'Invalid key-value pair schema: {avro_type[\"items\"]}')\n        key = self._convert_field(list(filter(lambda f: f[\"name\"] == \"key\", fields))[0])\n        value = self._convert_field(list(filter(lambda f: f[\"name\"] == \"value\", fields))[0])\n        return MapType(\n            key_id=key.field_id,\n            key_type=key.field_type,\n            value_id=value.field_id,\n            value_type=value.field_type,\n            value_required=value.required,\n        )\n\n    def _convert_fixed_type(self, avro_type: Dict[str, Any]) -&gt; FixedType:\n        \"\"\"\n        Convert Avro Type to the equivalent Iceberg fixed type.\n\n        - https://avro.apache.org/docs/current/spec.html#Fixed\n\n        Args:\n            avro_type: The Avro type.\n\n        Examples:\n            &gt;&gt;&gt; from pyiceberg.utils.schema_conversion import AvroSchemaConversion\n            &gt;&gt;&gt; avro_fixed_type = {\n            ...     \"name\": \"md5\",\n            ...     \"type\": \"fixed\",\n            ...     \"size\": 16\n            ... }\n            &gt;&gt;&gt; FixedType(length=16) == AvroSchemaConversion()._convert_fixed_type(avro_fixed_type)\n            True\n\n        Returns:\n            An Iceberg equivalent fixed type.\n        \"\"\"\n        return FixedType(length=avro_type[\"size\"])\n</code></pre>"},{"location":"reference/pyiceberg/utils/schema_conversion/#pyiceberg.utils.schema_conversion.AvroSchemaConversion.avro_to_iceberg","title":"<code>avro_to_iceberg(avro_schema)</code>","text":"<p>Convert an Apache Avro into an Apache Iceberg schema equivalent.</p> <p>This expects to have field id's to be encoded in the Avro schema:</p> <pre><code>{\n    \"type\": \"record\",\n    \"name\": \"manifest_file\",\n    \"fields\": [\n        {\"name\": \"manifest_path\", \"type\": \"string\", \"doc\": \"Location URI with FS scheme\", \"field-id\": 500},\n        {\"name\": \"manifest_length\", \"type\": \"long\", \"doc\": \"Total file size in bytes\", \"field-id\": 501}\n    ]\n}\n</code></pre> Example <p>This converts an Avro schema into an Iceberg schema:</p> <p>avro_schema = AvroSchemaConversion().avro_to_iceberg({ ...     \"type\": \"record\", ...     \"name\": \"manifest_file\", ...     \"fields\": [ ...         {\"name\": \"manifest_path\", \"type\": \"string\", \"doc\": \"Location URI with FS scheme\", \"field-id\": 500}, ...         {\"name\": \"manifest_length\", \"type\": \"long\", \"doc\": \"Total file size in bytes\", \"field-id\": 501} ...     ] ... }) iceberg_schema = Schema( ...     NestedField( ...         field_id=500, name=\"manifest_path\", field_type=StringType(), required=False, doc=\"Location URI with FS scheme\" ...     ), ...     NestedField( ...         field_id=501, name=\"manifest_length\", field_type=LongType(), required=False, doc=\"Total file size in bytes\" ...     ), ...     schema_id=1 ... ) avro_schema == iceberg_schema True</p> <p>Parameters:</p> Name Type Description Default <code>avro_schema</code> <code>Dict[str, Any]</code> <p>The JSON decoded Avro schema.</p> required <p>Returns:</p> Type Description <code>Schema</code> <p>Equivalent Iceberg schema.</p> Source code in <code>pyiceberg/utils/schema_conversion.py</code> <pre><code>def avro_to_iceberg(self, avro_schema: Dict[str, Any]) -&gt; Schema:\n    \"\"\"Convert an Apache Avro into an Apache Iceberg schema equivalent.\n\n    This expects to have field id's to be encoded in the Avro schema:\n\n        {\n            \"type\": \"record\",\n            \"name\": \"manifest_file\",\n            \"fields\": [\n                {\"name\": \"manifest_path\", \"type\": \"string\", \"doc\": \"Location URI with FS scheme\", \"field-id\": 500},\n                {\"name\": \"manifest_length\", \"type\": \"long\", \"doc\": \"Total file size in bytes\", \"field-id\": 501}\n            ]\n        }\n\n    Example:\n        This converts an Avro schema into an Iceberg schema:\n\n        &gt;&gt;&gt; avro_schema = AvroSchemaConversion().avro_to_iceberg({\n        ...     \"type\": \"record\",\n        ...     \"name\": \"manifest_file\",\n        ...     \"fields\": [\n        ...         {\"name\": \"manifest_path\", \"type\": \"string\", \"doc\": \"Location URI with FS scheme\", \"field-id\": 500},\n        ...         {\"name\": \"manifest_length\", \"type\": \"long\", \"doc\": \"Total file size in bytes\", \"field-id\": 501}\n        ...     ]\n        ... })\n        &gt;&gt;&gt; iceberg_schema = Schema(\n        ...     NestedField(\n        ...         field_id=500, name=\"manifest_path\", field_type=StringType(), required=False, doc=\"Location URI with FS scheme\"\n        ...     ),\n        ...     NestedField(\n        ...         field_id=501, name=\"manifest_length\", field_type=LongType(), required=False, doc=\"Total file size in bytes\"\n        ...     ),\n        ...     schema_id=1\n        ... )\n        &gt;&gt;&gt; avro_schema == iceberg_schema\n        True\n\n    Args:\n        avro_schema (Dict[str, Any]): The JSON decoded Avro schema.\n\n    Returns:\n        Equivalent Iceberg schema.\n    \"\"\"\n    return Schema(*[self._convert_field(field) for field in avro_schema[\"fields\"]], schema_id=1)\n</code></pre>"},{"location":"reference/pyiceberg/utils/schema_conversion/#pyiceberg.utils.schema_conversion.AvroSchemaConversion.iceberg_to_avro","title":"<code>iceberg_to_avro(schema, schema_name=None)</code>","text":"<p>Convert an Iceberg schema into an Avro dictionary that can be serialized to JSON.</p> Source code in <code>pyiceberg/utils/schema_conversion.py</code> <pre><code>def iceberg_to_avro(self, schema: Schema, schema_name: Optional[str] = None) -&gt; AvroType:\n    \"\"\"Convert an Iceberg schema into an Avro dictionary that can be serialized to JSON.\"\"\"\n    return visit(schema, ConvertSchemaToAvro(schema_name))\n</code></pre>"},{"location":"reference/pyiceberg/utils/schema_conversion/#pyiceberg.utils.schema_conversion.ConvertSchemaToAvro","title":"<code>ConvertSchemaToAvro</code>","text":"<p>             Bases: <code>SchemaVisitorPerPrimitiveType[AvroType]</code></p> <p>Convert an Iceberg schema to an Avro schema.</p> Source code in <code>pyiceberg/utils/schema_conversion.py</code> <pre><code>class ConvertSchemaToAvro(SchemaVisitorPerPrimitiveType[AvroType]):\n    \"\"\"Convert an Iceberg schema to an Avro schema.\"\"\"\n\n    schema_name: Optional[str]\n    last_list_field_id: int\n    last_map_key_field_id: int\n    last_map_value_field_id: int\n\n    def __init__(self, schema_name: Optional[str]) -&gt; None:\n        \"\"\"Convert an Iceberg schema to an Avro schema.\n\n        Args:\n            schema_name: The name of the root record.\n        \"\"\"\n        self.schema_name = schema_name\n\n    def schema(self, schema: Schema, struct_result: AvroType) -&gt; AvroType:\n        if isinstance(struct_result, dict) and self.schema_name is not None:\n            struct_result[\"name\"] = self.schema_name\n        return struct_result\n\n    def before_list_element(self, element: NestedField) -&gt; None:\n        self.last_list_field_id = element.field_id\n\n    def before_map_key(self, key: NestedField) -&gt; None:\n        self.last_map_key_field_id = key.field_id\n\n    def before_map_value(self, value: NestedField) -&gt; None:\n        self.last_map_value_field_id = value.field_id\n\n    def struct(self, struct: StructType, field_results: List[AvroType]) -&gt; AvroType:\n        return {\"type\": \"record\", \"fields\": field_results}\n\n    def field(self, field: NestedField, field_result: AvroType) -&gt; AvroType:\n        # Sets the schema name\n        if isinstance(field_result, dict) and field_result.get(\"type\") == \"record\":\n            field_result[\"name\"] = f\"r{field.field_id}\"\n\n        result = {\n            \"name\": field.name,\n            \"field-id\": field.field_id,\n            \"type\": field_result if field.required else [\"null\", field_result],\n        }\n\n        if field.optional:\n            result[\"default\"] = None\n\n        if field.doc is not None:\n            result[\"doc\"] = field.doc\n\n        return result\n\n    def list(self, list_type: ListType, element_result: AvroType) -&gt; AvroType:\n        # Sets the schema name in case of a record\n        if isinstance(element_result, dict) and element_result.get(\"type\") == \"record\":\n            element_result[\"name\"] = f\"r{self.last_list_field_id}\"\n        return {\"type\": \"array\", \"element-id\": self.last_list_field_id, \"items\": element_result}\n\n    def map(self, map_type: MapType, key_result: AvroType, value_result: AvroType) -&gt; AvroType:\n        if isinstance(key_result, StringType):\n            # Avro Maps does not support other keys than a String,\n            return {\n                \"type\": \"map\",\n                \"values\": value_result,\n                \"key-id\": self.last_map_key_field_id,\n                \"value-id\": self.last_map_value_field_id,\n            }\n        else:\n            # Creates a logical map that's a list of schema's\n            # binary compatible\n            return {\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"record\",\n                    \"name\": f\"k{self.last_map_key_field_id}_v{self.last_map_value_field_id}\",\n                    \"fields\": [\n                        {\"name\": \"key\", \"type\": key_result, \"field-id\": self.last_map_key_field_id},\n                        {\"name\": \"value\", \"type\": value_result, \"field-id\": self.last_map_value_field_id},\n                    ],\n                },\n                \"logicalType\": \"map\",\n            }\n\n    def visit_fixed(self, fixed_type: FixedType) -&gt; AvroType:\n        return {\"type\": \"fixed\", \"size\": len(fixed_type), \"name\": f\"fixed_{len(fixed_type)}\"}\n\n    def visit_decimal(self, decimal_type: DecimalType) -&gt; AvroType:\n        return {\n            \"type\": \"fixed\",\n            \"size\": decimal_required_bytes(decimal_type.precision),\n            \"logicalType\": \"decimal\",\n            \"precision\": decimal_type.precision,\n            \"scale\": decimal_type.scale,\n            \"name\": f\"decimal_{decimal_type.precision}_{decimal_type.scale}\",\n        }\n\n    def visit_boolean(self, boolean_type: BooleanType) -&gt; AvroType:\n        return \"boolean\"\n\n    def visit_integer(self, integer_type: IntegerType) -&gt; AvroType:\n        return \"int\"\n\n    def visit_long(self, long_type: LongType) -&gt; AvroType:\n        return \"long\"\n\n    def visit_float(self, float_type: FloatType) -&gt; AvroType:\n        return \"float\"\n\n    def visit_double(self, double_type: DoubleType) -&gt; AvroType:\n        return \"double\"\n\n    def visit_date(self, date_type: DateType) -&gt; AvroType:\n        return {\"type\": \"int\", \"logicalType\": \"date\"}\n\n    def visit_time(self, time_type: TimeType) -&gt; AvroType:\n        return {\"type\": \"long\", \"logicalType\": \"time-micros\"}\n\n    def visit_timestamp(self, timestamp_type: TimestampType) -&gt; AvroType:\n        # Iceberg only supports micro's\n        return {\"type\": \"long\", \"logicalType\": \"timestamp-micros\", \"adjust-to-utc\": False}\n\n    def visit_timestamptz(self, timestamptz_type: TimestamptzType) -&gt; AvroType:\n        # Iceberg only supports micro's\n        return {\"type\": \"long\", \"logicalType\": \"timestamp-micros\", \"adjust-to-utc\": True}\n\n    def visit_string(self, string_type: StringType) -&gt; AvroType:\n        return \"string\"\n\n    def visit_uuid(self, uuid_type: UUIDType) -&gt; AvroType:\n        return {\"type\": \"fixed\", \"size\": 16, \"logicalType\": \"uuid\", \"name\": \"uuid_fixed\"}\n\n    def visit_binary(self, binary_type: BinaryType) -&gt; AvroType:\n        return \"bytes\"\n</code></pre>"},{"location":"reference/pyiceberg/utils/schema_conversion/#pyiceberg.utils.schema_conversion.ConvertSchemaToAvro.__init__","title":"<code>__init__(schema_name)</code>","text":"<p>Convert an Iceberg schema to an Avro schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>Optional[str]</code> <p>The name of the root record.</p> required Source code in <code>pyiceberg/utils/schema_conversion.py</code> <pre><code>def __init__(self, schema_name: Optional[str]) -&gt; None:\n    \"\"\"Convert an Iceberg schema to an Avro schema.\n\n    Args:\n        schema_name: The name of the root record.\n    \"\"\"\n    self.schema_name = schema_name\n</code></pre>"},{"location":"reference/pyiceberg/utils/singleton/","title":"singleton","text":"<p>This is a singleton metaclass that can be used to cache and re-use existing objects.</p> <p>In the Iceberg codebase we have a lot of objects that are stateless (for example Types such as StringType, BooleanType etc). FixedTypes have arguments (eg. Fixed[22]) that we also make part of the key when caching the newly created object.</p> <p>The Singleton uses a metaclass which essentially defines a new type. When the Type gets created, it will first evaluate the <code>__call__</code> method with all the arguments. If we already initialized a class earlier, we'll just return it.</p> <p>More information on metaclasses: https://docs.python.org/3/reference/datamodel.html#metaclasses</p>"},{"location":"reference/pyiceberg/utils/truncate/","title":"truncate","text":""}]}